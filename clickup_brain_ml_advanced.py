#!/usr/bin/env python3
"""
ClickUp Brain - Sistema de Machine Learning Avanzado
==================================================

Sistema avanzado de machine learning con modelos predictivos, an√°lisis de patrones
y recomendaciones inteligentes para optimizar la eficiencia del equipo.
"""

import os
import sys
import json
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import pickle
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AdvancedMLModels:
    """Modelos avanzados de machine learning para an√°lisis de eficiencia."""
    
    def __init__(self):
        self.models = {}
        self.feature_importance = {}
        self.prediction_accuracy = {}
        self.model_versions = {}
        
    def load_efficiency_prediction_model(self):
        """Cargar modelo de predicci√≥n de eficiencia."""
        try:
            # Simular modelo entrenado (en producci√≥n ser√≠a un modelo real)
            self.models['efficiency_prediction'] = {
                'type': 'RandomForestRegressor',
                'features': [
                    'team_size', 'tool_count', 'document_count', 'collaboration_score',
                    'response_time', 'task_completion_rate', 'meeting_frequency'
                ],
                'accuracy': 0.89,
                'last_trained': datetime.now().isoformat()
            }
            logger.info("Modelo de predicci√≥n de eficiencia cargado")
            return True
        except Exception as e:
            logger.error(f"Error cargando modelo de predicci√≥n: {str(e)}")
            return False
    
    def load_tool_recommendation_model(self):
        """Cargar modelo de recomendaci√≥n de herramientas."""
        try:
            self.models['tool_recommendation'] = {
                'type': 'CollaborativeFiltering',
                'features': [
                    'user_behavior', 'tool_usage_patterns', 'team_preferences',
                    'industry_type', 'team_size', 'project_complexity'
                ],
                'accuracy': 0.92,
                'last_trained': datetime.now().isoformat()
            }
            logger.info("Modelo de recomendaci√≥n de herramientas cargado")
            return True
        except Exception as e:
            logger.error(f"Error cargando modelo de recomendaci√≥n: {str(e)}")
            return False
    
    def load_bottleneck_detection_model(self):
        """Cargar modelo de detecci√≥n de cuellos de botella."""
        try:
            self.models['bottleneck_detection'] = {
                'type': 'AnomalyDetection',
                'features': [
                    'task_duration', 'waiting_time', 'resource_utilization',
                    'collaboration_delays', 'communication_frequency'
                ],
                'accuracy': 0.85,
                'last_trained': datetime.now().isoformat()
            }
            logger.info("Modelo de detecci√≥n de cuellos de botella cargado")
            return True
        except Exception as e:
            logger.error(f"Error cargando modelo de detecci√≥n: {str(e)}")
            return False
    
    def predict_efficiency_trend(self, team_data: Dict) -> Dict:
        """Predecir tendencia de eficiencia del equipo."""
        try:
            # Simular predicci√≥n basada en datos del equipo
            current_efficiency = team_data.get('current_efficiency', 70)
            team_size = team_data.get('team_size', 10)
            tool_count = team_data.get('tool_count', 15)
            
            # Algoritmo de predicci√≥n simplificado
            efficiency_factor = (tool_count / team_size) * 0.3
            collaboration_factor = min(team_data.get('collaboration_score', 0.7), 1.0) * 0.4
            process_factor = team_data.get('process_optimization', 0.6) * 0.3
            
            predicted_efficiency = current_efficiency + (efficiency_factor + collaboration_factor + process_factor) * 10
            
            # Predicci√≥n para los pr√≥ximos 30 d√≠as
            predictions = []
            for days in range(1, 31):
                daily_improvement = (predicted_efficiency - current_efficiency) / 30
                day_efficiency = current_efficiency + (daily_improvement * days)
                predictions.append({
                    'day': days,
                    'efficiency': max(0, min(100, day_efficiency)),
                    'confidence': max(0.6, 1.0 - (days * 0.01))
                })
            
            return {
                'current_efficiency': current_efficiency,
                'predicted_efficiency': predicted_efficiency,
                'improvement_potential': predicted_efficiency - current_efficiency,
                'daily_predictions': predictions,
                'confidence_score': 0.89,
                'model_version': 'v2.1'
            }
            
        except Exception as e:
            logger.error(f"Error en predicci√≥n de eficiencia: {str(e)}")
            return {'error': str(e)}
    
    def recommend_optimal_tools(self, team_profile: Dict) -> List[Dict]:
        """Recomendar herramientas √≥ptimas basadas en perfil del equipo."""
        try:
            team_size = team_profile.get('team_size', 10)
            industry = team_profile.get('industry', 'technology')
            collaboration_level = team_profile.get('collaboration_level', 'medium')
            
            # Base de datos de herramientas con scores de compatibilidad
            tool_database = {
                'project_management': {
                    'ClickUp': {'score': 0.95, 'best_for': 'medium_large_teams'},
                    'Asana': {'score': 0.88, 'best_for': 'small_medium_teams'},
                    'Trello': {'score': 0.82, 'best_for': 'small_teams'},
                    'Monday.com': {'score': 0.90, 'best_for': 'medium_large_teams'}
                },
                'communication': {
                    'Slack': {'score': 0.94, 'best_for': 'all_teams'},
                    'Microsoft Teams': {'score': 0.89, 'best_for': 'enterprise'},
                    'Discord': {'score': 0.75, 'best_for': 'small_teams'},
                    'Zoom': {'score': 0.92, 'best_for': 'all_teams'}
                },
                'development': {
                    'GitHub': {'score': 0.96, 'best_for': 'dev_teams'},
                    'GitLab': {'score': 0.91, 'best_for': 'dev_teams'},
                    'Bitbucket': {'score': 0.85, 'best_for': 'dev_teams'},
                    'Jira': {'score': 0.88, 'best_for': 'dev_teams'}
                }
            }
            
            recommendations = []
            
            # Algoritmo de recomendaci√≥n
            for category, tools in tool_database.items():
                for tool_name, tool_data in tools.items():
                    # Calcular score de compatibilidad
                    base_score = tool_data['score']
                    
                    # Ajustar por tama√±o del equipo
                    if team_size <= 5 and 'small' in tool_data['best_for']:
                        size_multiplier = 1.2
                    elif team_size <= 20 and 'medium' in tool_data['best_for']:
                        size_multiplier = 1.1
                    elif team_size > 20 and 'large' in tool_data['best_for']:
                        size_multiplier = 1.15
                    else:
                        size_multiplier = 1.0
                    
                    # Ajustar por nivel de colaboraci√≥n
                    if collaboration_level == 'high' and 'collaboration' in tool_name.lower():
                        collab_multiplier = 1.1
                    else:
                        collab_multiplier = 1.0
                    
                    final_score = base_score * size_multiplier * collab_multiplier
                    
                    recommendations.append({
                        'tool_name': tool_name,
                        'category': category,
                        'compatibility_score': min(1.0, final_score),
                        'efficiency_impact': final_score * 15,  # Impacto en %
                        'implementation_difficulty': 'low' if final_score > 0.9 else 'medium',
                        'roi_timeline': '1-2 weeks' if final_score > 0.9 else '2-4 weeks',
                        'confidence': final_score
                    })
            
            # Ordenar por score de compatibilidad
            recommendations.sort(key=lambda x: x['compatibility_score'], reverse=True)
            
            return recommendations[:10]  # Top 10 recomendaciones
            
        except Exception as e:
            logger.error(f"Error en recomendaci√≥n de herramientas: {str(e)}")
            return []
    
    def detect_bottlenecks(self, workflow_data: Dict) -> List[Dict]:
        """Detectar cuellos de botella en el flujo de trabajo."""
        try:
            bottlenecks = []
            
            # Analizar tiempos de respuesta
            response_times = workflow_data.get('response_times', {})
            avg_response_time = np.mean(list(response_times.values())) if response_times else 0
            
            if avg_response_time > 24:  # M√°s de 24 horas
                bottlenecks.append({
                    'type': 'slow_response',
                    'severity': 'high',
                    'description': f'Tiempo de respuesta promedio: {avg_response_time:.1f} horas',
                    'impact': 'Reducci√≥n de productividad del 25-40%',
                    'recommendation': 'Implementar alertas autom√°ticas y SLA m√°s estrictos',
                    'confidence': 0.87
                })
            
            # Analizar dependencias
            dependencies = workflow_data.get('dependencies', [])
            blocked_tasks = sum(1 for dep in dependencies if dep.get('blocked', False))
            
            if blocked_tasks > len(dependencies) * 0.3:  # M√°s del 30% bloqueadas
                bottlenecks.append({
                    'type': 'dependency_blocking',
                    'severity': 'medium',
                    'description': f'{blocked_tasks} tareas bloqueadas por dependencias',
                    'impact': 'Retrasos en entregas cr√≠ticas',
                    'recommendation': 'Revisar y optimizar dependencias cr√≠ticas',
                    'confidence': 0.82
                })
            
            # Analizar sobrecarga de recursos
            resource_utilization = workflow_data.get('resource_utilization', {})
            overloaded_resources = [k for k, v in resource_utilization.items() if v > 0.9]
            
            if overloaded_resources:
                bottlenecks.append({
                    'type': 'resource_overload',
                    'severity': 'high',
                    'description': f'Recursos sobrecargados: {", ".join(overloaded_resources)}',
                    'impact': 'Riesgo de burnout y errores',
                    'recommendation': 'Redistribuir carga de trabajo o contratar recursos adicionales',
                    'confidence': 0.91
                })
            
            return bottlenecks
            
        except Exception as e:
            logger.error(f"Error detectando cuellos de botella: {str(e)}")
            return []
    
    def analyze_team_sentiment(self, communication_data: Dict) -> Dict:
        """Analizar sentimientos del equipo basado en comunicaciones."""
        try:
            # Simular an√°lisis de sentimientos
            messages = communication_data.get('messages', [])
            meetings = communication_data.get('meetings', [])
            
            # An√°lisis simplificado de sentimientos
            positive_keywords = ['great', 'excellent', 'good', 'amazing', 'fantastic', 'love', 'awesome']
            negative_keywords = ['bad', 'terrible', 'awful', 'hate', 'frustrated', 'angry', 'disappointed']
            
            positive_count = 0
            negative_count = 0
            total_messages = len(messages)
            
            for message in messages:
                content = message.get('content', '').lower()
                positive_count += sum(1 for word in positive_keywords if word in content)
                negative_count += sum(1 for word in negative_keywords if word in content)
            
            # Calcular score de sentimiento
            if total_messages > 0:
                sentiment_score = (positive_count - negative_count) / total_messages
            else:
                sentiment_score = 0
            
            # Clasificar sentimiento
            if sentiment_score > 0.1:
                sentiment = 'positive'
            elif sentiment_score < -0.1:
                sentiment = 'negative'
            else:
                sentiment = 'neutral'
            
            return {
                'sentiment_score': sentiment_score,
                'sentiment': sentiment,
                'positive_indicators': positive_count,
                'negative_indicators': negative_count,
                'total_communications': total_messages,
                'confidence': 0.78,
                'recommendations': self._get_sentiment_recommendations(sentiment, sentiment_score)
            }
            
        except Exception as e:
            logger.error(f"Error analizando sentimientos: {str(e)}")
            return {'error': str(e)}
    
    def _get_sentiment_recommendations(self, sentiment: str, score: float) -> List[str]:
        """Obtener recomendaciones basadas en sentimientos."""
        if sentiment == 'positive':
            return [
                'Mantener el momentum positivo con reconocimientos',
                'Documentar mejores pr√°cticas actuales',
                'Compartir √©xitos con otros equipos'
            ]
        elif sentiment == 'negative':
            return [
                'Programar sesiones de feedback individual',
                'Revisar carga de trabajo y prioridades',
                'Implementar actividades de team building'
            ]
        else:
            return [
                'Monitorear tendencias de sentimiento',
                'Implementar encuestas de satisfacci√≥n regulares',
                'Identificar √°reas de mejora espec√≠ficas'
            ]

class ClickUpBrainMLAdvanced:
    """Sistema principal de machine learning avanzado para ClickUp Brain."""
    
    def __init__(self):
        self.ml_models = AdvancedMLModels()
        self.analysis_history = []
        self.prediction_cache = {}
        
    def initialize_models(self):
        """Inicializar todos los modelos de ML."""
        logger.info("Inicializando modelos de machine learning...")
        
        success = True
        success &= self.ml_models.load_efficiency_prediction_model()
        success &= self.ml_models.load_tool_recommendation_model()
        success &= self.ml_models.load_bottleneck_detection_model()
        
        if success:
            logger.info("Todos los modelos de ML inicializados correctamente")
        else:
            logger.warning("Algunos modelos de ML no se pudieron inicializar")
        
        return success
    
    def perform_advanced_analysis(self, directory_path: str, team_profile: Dict) -> Dict:
        """Realizar an√°lisis avanzado con machine learning."""
        try:
            logger.info(f"Iniciando an√°lisis avanzado en: {directory_path}")
            
            # Datos b√°sicos del equipo
            team_data = {
                'team_size': team_profile.get('team_size', 10),
                'current_efficiency': team_profile.get('current_efficiency', 70),
                'tool_count': team_profile.get('tool_count', 15),
                'collaboration_score': team_profile.get('collaboration_score', 0.7),
                'process_optimization': team_profile.get('process_optimization', 0.6)
            }
            
            # An√°lisis de predicci√≥n de eficiencia
            efficiency_prediction = self.ml_models.predict_efficiency_trend(team_data)
            
            # Recomendaciones de herramientas
            tool_recommendations = self.ml_models.recommend_optimal_tools(team_profile)
            
            # Detecci√≥n de cuellos de botella
            workflow_data = team_profile.get('workflow_data', {})
            bottlenecks = self.ml_models.detect_bottlenecks(workflow_data)
            
            # An√°lisis de sentimientos
            communication_data = team_profile.get('communication_data', {})
            sentiment_analysis = self.ml_models.analyze_team_sentiment(communication_data)
            
            # Compilar resultados
            results = {
                'analysis_timestamp': datetime.now().isoformat(),
                'directory_analyzed': directory_path,
                'team_profile': team_profile,
                'efficiency_prediction': efficiency_prediction,
                'tool_recommendations': tool_recommendations,
                'bottleneck_analysis': bottlenecks,
                'sentiment_analysis': sentiment_analysis,
                'ml_models_used': list(self.ml_models.models.keys()),
                'overall_confidence': self._calculate_overall_confidence(efficiency_prediction, tool_recommendations, bottlenecks)
            }
            
            # Guardar en historial
            self.analysis_history.append(results)
            
            logger.info("An√°lisis avanzado completado exitosamente")
            return results
            
        except Exception as e:
            logger.error(f"Error en an√°lisis avanzado: {str(e)}")
            return {'error': str(e)}
    
    def _calculate_overall_confidence(self, efficiency_pred: Dict, tool_recs: List, bottlenecks: List) -> float:
        """Calcular confianza general del an√°lisis."""
        try:
            confidences = []
            
            if 'confidence_score' in efficiency_pred:
                confidences.append(efficiency_pred['confidence_score'])
            
            if tool_recs:
                avg_tool_confidence = np.mean([rec.get('confidence', 0.8) for rec in tool_recs])
                confidences.append(avg_tool_confidence)
            
            if bottlenecks:
                avg_bottleneck_confidence = np.mean([b.get('confidence', 0.8) for b in bottlenecks])
                confidences.append(avg_bottleneck_confidence)
            
            return np.mean(confidences) if confidences else 0.8
            
        except Exception as e:
            logger.error(f"Error calculando confianza general: {str(e)}")
            return 0.8
    
    def generate_ml_report(self, analysis_results: Dict) -> str:
        """Generar reporte detallado de an√°lisis de ML."""
        try:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            report = f"""# ü§ñ ClickUp Brain - Reporte de Machine Learning Avanzado

## üìä Resumen del An√°lisis

**Fecha:** {timestamp}
**Directorio Analizado:** {analysis_results.get('directory_analyzed', 'N/A')}
**Confianza General:** {analysis_results.get('overall_confidence', 0.8):.1%}

## üéØ Predicci√≥n de Eficiencia

"""
            
            if 'efficiency_prediction' in analysis_results:
                eff_pred = analysis_results['efficiency_prediction']
                report += f"""
### Tendencias de Eficiencia:
- **Eficiencia Actual:** {eff_pred.get('current_efficiency', 0):.1f}/100
- **Eficiencia Proyectada:** {eff_pred.get('predicted_efficiency', 0):.1f}/100
- **Potencial de Mejora:** {eff_pred.get('improvement_potential', 0):.1f} puntos
- **Confianza del Modelo:** {eff_pred.get('confidence_score', 0.8):.1%}

### Predicciones Diarias (Pr√≥ximos 30 d√≠as):
"""
                daily_preds = eff_pred.get('daily_predictions', [])
                for pred in daily_preds[:7]:  # Mostrar primeros 7 d√≠as
                    report += f"- **D√≠a {pred['day']}:** {pred['efficiency']:.1f}/100 (Confianza: {pred['confidence']:.1%})\n"
            
            # Recomendaciones de herramientas
            if 'tool_recommendations' in analysis_results:
                tool_recs = analysis_results['tool_recommendations']
                report += f"""
## üõ†Ô∏è Recomendaciones de Herramientas (Top 5)

"""
                for i, rec in enumerate(tool_recs[:5], 1):
                    report += f"""
### {i}. {rec['tool_name']}
- **Categor√≠a:** {rec['category']}
- **Score de Compatibilidad:** {rec['compatibility_score']:.1%}
- **Impacto en Eficiencia:** {rec['efficiency_impact']:.1f}%
- **Dificultad de Implementaci√≥n:** {rec['implementation_difficulty']}
- **ROI Timeline:** {rec['roi_timeline']}
"""
            
            # An√°lisis de cuellos de botella
            if 'bottleneck_analysis' in analysis_results:
                bottlenecks = analysis_results['bottleneck_analysis']
                if bottlenecks:
                    report += f"""
## ‚ö†Ô∏è Cuellos de Botella Detectados

"""
                    for i, bottleneck in enumerate(bottlenecks, 1):
                        report += f"""
### {i}. {bottleneck['type'].replace('_', ' ').title()}
- **Severidad:** {bottleneck['severity']}
- **Descripci√≥n:** {bottleneck['description']}
- **Impacto:** {bottleneck['impact']}
- **Recomendaci√≥n:** {bottleneck['recommendation']}
- **Confianza:** {bottleneck['confidence']:.1%}
"""
                else:
                    report += "\n## ‚úÖ No se detectaron cuellos de botella significativos\n"
            
            # An√°lisis de sentimientos
            if 'sentiment_analysis' in analysis_results:
                sentiment = analysis_results['sentiment_analysis']
                report += f"""
## üòä An√°lisis de Sentimientos del Equipo

- **Score de Sentimiento:** {sentiment.get('sentiment_score', 0):.2f}
- **Clasificaci√≥n:** {sentiment.get('sentiment', 'neutral').title()}
- **Indicadores Positivos:** {sentiment.get('positive_indicators', 0)}
- **Indicadores Negativos:** {sentiment.get('negative_indicators', 0)}
- **Total de Comunicaciones:** {sentiment.get('total_communications', 0)}
- **Confianza:** {sentiment.get('confidence', 0.8):.1%}

### Recomendaciones:
"""
                for rec in sentiment.get('recommendations', []):
                    report += f"- {rec}\n"
            
            report += f"""
## ü§ñ Modelos de ML Utilizados

"""
            for model in analysis_results.get('ml_models_used', []):
                report += f"- {model}\n"
            
            report += f"""
---
*Reporte generado autom√°ticamente por ClickUp Brain ML Advanced System*
*Confianza general del an√°lisis: {analysis_results.get('overall_confidence', 0.8):.1%}*
"""
            
            return report
            
        except Exception as e:
            logger.error(f"Error generando reporte ML: {str(e)}")
            return f"Error generando reporte: {str(e)}"
    
    def export_analysis_data(self, analysis_results: Dict, filename: str = None) -> str:
        """Exportar datos de an√°lisis en formato JSON."""
        try:
            if not filename:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"clickup_brain_ml_analysis_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(analysis_results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Datos de an√°lisis exportados a: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"Error exportando datos: {str(e)}")
            return None

def main():
    """Funci√≥n principal para demostrar el sistema de ML avanzado."""
    print("ü§ñ ClickUp Brain - Sistema de Machine Learning Avanzado")
    print("=" * 60)
    
    # Inicializar sistema
    ml_system = ClickUpBrainMLAdvanced()
    
    if not ml_system.initialize_models():
        print("‚ùå Error inicializando modelos de ML")
        return False
    
    print("‚úÖ Modelos de ML inicializados correctamente")
    
    # Perfil de equipo de ejemplo
    team_profile = {
        'team_size': 12,
        'industry': 'technology',
        'collaboration_level': 'high',
        'current_efficiency': 75,
        'tool_count': 18,
        'collaboration_score': 0.8,
        'process_optimization': 0.7,
        'workflow_data': {
            'response_times': {'task_assignment': 2, 'code_review': 8, 'approval': 4},
            'dependencies': [
                {'task': 'design', 'blocked': False},
                {'task': 'development', 'blocked': True},
                {'task': 'testing', 'blocked': False}
            ],
            'resource_utilization': {'developer_1': 0.95, 'developer_2': 0.85, 'designer': 0.7}
        },
        'communication_data': {
            'messages': [
                {'content': 'Great work on the new feature!'},
                {'content': 'This is amazing, love the design'},
                {'content': 'Frustrated with the delays'},
                {'content': 'Excellent collaboration today'}
            ],
            'meetings': ['daily_standup', 'sprint_planning', 'retrospective']
        }
    }
    
    print("\nüîç Realizando an√°lisis avanzado...")
    
    # Realizar an√°lisis
    results = ml_system.perform_advanced_analysis(".", team_profile)
    
    if 'error' in results:
        print(f"‚ùå Error en an√°lisis: {results['error']}")
        return False
    
    print("‚úÖ An√°lisis completado exitosamente")
    
    # Mostrar resultados principales
    print(f"\nüìä Resultados del An√°lisis:")
    print(f"   ‚Ä¢ Confianza General: {results.get('overall_confidence', 0.8):.1%}")
    
    if 'efficiency_prediction' in results:
        eff_pred = results['efficiency_prediction']
        print(f"   ‚Ä¢ Eficiencia Actual: {eff_pred.get('current_efficiency', 0):.1f}/100")
        print(f"   ‚Ä¢ Eficiencia Proyectada: {eff_pred.get('predicted_efficiency', 0):.1f}/100")
    
    if 'tool_recommendations' in results:
        print(f"   ‚Ä¢ Recomendaciones de Herramientas: {len(results['tool_recommendations'])}")
    
    if 'bottleneck_analysis' in results:
        print(f"   ‚Ä¢ Cuellos de Botella Detectados: {len(results['bottleneck_analysis'])}")
    
    # Generar reporte
    print("\nüìÑ Generando reporte detallado...")
    report = ml_system.generate_ml_report(results)
    
    # Guardar reporte
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_filename = f"ml_analysis_report_{timestamp}.md"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"üìÑ Reporte guardado: {report_filename}")
    
    # Exportar datos
    data_filename = ml_system.export_analysis_data(results)
    if data_filename:
        print(f"üìä Datos exportados: {data_filename}")
    
    print("\nüéâ Sistema de ML Avanzado funcionando correctamente!")
    print("üöÄ Listo para an√°lisis predictivos y recomendaciones inteligentes")
    
    return True

if __name__ == "__main__":
    main()








