#!/usr/bin/env bash
set -euo pipefail
# Analiza los assets y genera reporte con estad√≠sticas

ROOT_DIR="$(cd "$(dirname "$0")/.." && pwd)"
SRC_DIR="${SRC_DIR:-$ROOT_DIR/design/instagram}"
EXPORT_DIR="${EXPORT_DIR:-$ROOT_DIR/exports}"
REPORT="${REPORT:-$EXPORT_DIR/assets_report.txt}"
OUTPUT_FORMAT="${OUTPUT_FORMAT:-text}"

# Flags por CLI (opcionales):
#   --quiet / -q                 ‚Üí QUIET=true (no imprime todo en consola)
#   --summary-only / -s          ‚Üí SUMMARY_ONLY=true (imprime resumen)
#   --output-format / -o         ‚Üí OUTPUT_FORMAT=[text|all|html|csv|json]
#   --report / -r FILE           ‚Üí REPORT=FILE
#   --min-score / -m N           ‚Üí MIN_HEALTH_SCORE=N (para CI)
#   --palette-strict             ‚Üí PALETTE_STRICT=true (falla si hay colores fuera de tokens)
#   --fail-on-error              ‚Üí FAIL_ON_ERROR=true (exit 2 ante errores cr√≠ticos)
#   --fail-on-warn               ‚Üí FAIL_ON_WARN=true (exit 1 ante warnings)
#   --max-dom-nodes N            ‚Üí MAX_DOM_NODES=N
#   --max-filters N              ‚Üí MAX_FILTERS=N
#   --max-gradients N            ‚Üí MAX_GRADIENTS=N
#   --help / -h                  ‚Üí muestra ayuda

QUIET="${QUIET:-false}"
SUMMARY_ONLY="${SUMMARY_ONLY:-false}"
MIN_HEALTH_SCORE="${MIN_HEALTH_SCORE:-75}"
PALETTE_STRICT="${PALETTE_STRICT:-false}"
FAIL_ON_ERROR="${FAIL_ON_ERROR:-false}"
FAIL_ON_WARN="${FAIL_ON_WARN:-false}"
MAX_DOM_NODES="${MAX_DOM_NODES:-500}"
MAX_FILTERS="${MAX_FILTERS:-5}"
MAX_GRADIENTS="${MAX_GRADIENTS:-10}"
BASELINE_FILE="${BASELINE_FILE:-}"
PROFILE="${PROFILE:-}"
LOG_LEVEL="${LOG_LEVEL:-info}"
CONTINUE_ON_ERROR="${CONTINUE_ON_ERROR:-false}"
SHOW_PERFORMANCE="${SHOW_PERFORMANCE:-true}"
AUTO_REPAIR="${AUTO_REPAIR:-false}"
USE_CACHE="${USE_CACHE:-true}"
SHOW_PROGRESS="${SHOW_PROGRESS:-true}"
GENERATE_JUNIT="${GENERATE_JUNIT:-false}"
PARALLEL_ANALYSIS="${PARALLEL_ANALYSIS:-false}"
MAX_PARALLEL="${MAX_PARALLEL:-4}"
DETECT_DUPLICATES="${DETECT_DUPLICATES:-true}"
COMPARE_HISTORY="${COMPARE_HISTORY:-true}"
GENERATE_RECOMMENDATIONS="${GENERATE_RECOMMENDATIONS:-true}"

# Sistema de logging estructurado con niveles
log_level_num() {
  case "${1:-info}" in
    debug) echo 0 ;;
    info)  echo 1 ;;
    warn)  echo 2 ;;
    error) echo 3 ;;
    *)     echo 1 ;;
  esac
}

LOG_LEVEL_NUM=$(log_level_num "$LOG_LEVEL")

_log_debug() {
  if [ "$LOG_LEVEL_NUM" -le 0 ]; then
    echo "[DEBUG] $1" >&2
  fi
}

_log_info() {
  if [ "$LOG_LEVEL_NUM" -le 1 ]; then
    echo "[INFO] $1" >&2
  fi
}

_log_warn() {
  if [ "$LOG_LEVEL_NUM" -le 2 ]; then
    echo "[WARN] $1" >&2
  fi
}

_log_error() {
  if [ "$LOG_LEVEL_NUM" -le 3 ]; then
    echo "[ERROR] $1" >&2
  fi
}

# Funci√≥n para validar n√∫mero positivo
validate_positive_number() {
  local value="$1"
  local name="$2"
  if ! [[ "$value" =~ ^[0-9]+$ ]] || [ "$value" -le 0 ]; then
    _log_error "$name debe ser un n√∫mero positivo, se recibi√≥: '$value'"
    [ "$CONTINUE_ON_ERROR" = "false" ] && exit 2
    return 1
  fi
  return 0
}

# Funci√≥n para validar formato de salida
validate_output_format() {
  local fmt="$1"
  case "$fmt" in
    text|all|html|csv|json) return 0 ;;
    *) 
      _log_error "Formato de salida inv√°lido: '$fmt'. V√°lidos: text, all, html, csv, json"
      [ "$CONTINUE_ON_ERROR" = "false" ] && exit 2
      return 1 ;;
  esac
}

# Cargar perfil de configuraci√≥n
load_profile() {
  local profile_name="$1"
  local profile_file="$ROOT_DIR/tools/profiles/${profile_name}.json"
  
  if [ ! -f "$profile_file" ]; then
    _log_warn "Perfil '$profile_name' no encontrado en $profile_file"
    return 1
  fi
  
  if command -v jq >/dev/null 2>&1; then
    _log_info "Cargando perfil: $profile_name"
    export MIN_HEALTH_SCORE=$(jq -r '.min_health_score // 75' "$profile_file" 2>/dev/null || echo "$MIN_HEALTH_SCORE")
    export MAX_DOM_NODES=$(jq -r '.max_dom_nodes // 500' "$profile_file" 2>/dev/null || echo "$MAX_DOM_NODES")
    export MAX_FILTERS=$(jq -r '.max_filters // 5' "$profile_file" 2>/dev/null || echo "$MAX_FILTERS")
    export MAX_GRADIENTS=$(jq -r '.max_gradients // 10' "$profile_file" 2>/dev/null || echo "$MAX_GRADIENTS")
    export PALETTE_STRICT=$(jq -r '.palette_strict // false' "$profile_file" 2>/dev/null || echo "$PALETTE_STRICT")
    export FAIL_ON_ERROR=$(jq -r '.fail_on_error // false' "$profile_file" 2>/dev/null || echo "$FAIL_ON_ERROR")
    export FAIL_ON_WARN=$(jq -r '.fail_on_warn // false' "$profile_file" 2>/dev/null || echo "$FAIL_ON_WARN")
    _log_info "Perfil cargado exitosamente"
  else
    _log_warn "jq no disponible, no se puede cargar perfil JSON"
    return 1
  fi
}

# Validar paths y permisos antes de procesar
validate_paths() {
  local errors=0
  
  if [ ! -d "$SRC_DIR" ]; then
    _log_error "Directorio fuente no existe: $SRC_DIR"
    errors=$((errors + 1))
  elif [ ! -r "$SRC_DIR" ]; then
    _log_error "Sin permisos de lectura en: $SRC_DIR"
    errors=$((errors + 1))
  fi
  
  if [ ! -w "$(dirname "$REPORT")" ] 2>/dev/null; then
    _log_error "Sin permisos de escritura en: $(dirname "$REPORT")"
    errors=$((errors + 1))
  fi
  
  if [ ! -w "$EXPORT_DIR" ] 2>/dev/null; then
    _log_error "Sin permisos de escritura en: $EXPORT_DIR"
    errors=$((errors + 1))
  fi
  
  if [ "$errors" -gt 0 ]; then
    _log_error "Se encontraron $errors errores de validaci√≥n"
    [ "$CONTINUE_ON_ERROR" = "false" ] && exit 1
    return 1
  fi
  
  _log_debug "Validaci√≥n de paths exitosa"
  return 0
}

print_usage() {
  cat <<USAGE
Uso: $(basename "$0") [opciones]

Opciones:
  -q, --quiet                Ejecuta en modo silencioso (resumen en consola)
  -s, --summary-only         Muestra solo resumen (no imprime reporte completo)
  -o, --output-format FMT     Formato de salida: text|all|html|csv|json (default: text)
  -r, --report FILE          Ruta del reporte principal (default: exports/assets_report.txt)
  -m, --min-score N          Umbral m√≠nimo de Health Score para √©xito (default: 75)
      --palette-strict       Falla si hay colores fuera de la paleta (tokens.json)
      --fail-on-error        Exit 2 ante errores cr√≠ticos (seguridad/rotos/inv√°lidos)
      --fail-on-warn         Exit 1 ante advertencias
      --max-dom-nodes N      Umbral de nodos DOM para advertencia (default: 500)
      --max-filters N        Umbral de filtros por archivo (default: 5)
      --max-gradients N      Umbral de gradientes por archivo (default: 10)
      --config FILE           Archivo de configuraci√≥n JSON con umbrales (default: tools/analyze_assets.config.json)
      --diff                  Compara con reporte anterior y muestra diferencias
      --slack-webhook URL     Env√≠a alertas a Slack (webhook URL)
      --teams-webhook URL     Env√≠a alertas a Microsoft Teams (webhook URL)
      --cache-dir PATH        Directorio para cach√© incremental (default: .cache/analyze_assets)
      --no-cache              Deshabilita cach√© incremental
      --no-progress            Deshabilita barras de progreso
      --auto-repair            Auto-reparar problemas detectados (experimental)
      --junit FILE             Generar salida JUnit XML para CI (default: off)
      --parallel               Usar an√°lisis paralelo (acelera procesamiento)
      --max-parallel N         M√°ximo de procesos paralelos (default: 4)
      --no-duplicates          Saltar detecci√≥n de duplicados por contenido
      --no-history             Saltar comparaci√≥n con ejecuciones anteriores
      --no-recommendations     Saltar generaci√≥n de recomendaciones inteligentes
      --xml                    Exportar reporte en formato XML
      --yaml                   Exportar reporte en formato YAML
      --compliance             Validar compliance (WCAG, etc.)
      --business-metrics       Generar m√©tricas de negocio
      --git-analysis           An√°lisis de cambios con Git
      --detect-patterns        Detectar patrones de dise√±o
      --changelog              Generar changelog autom√°tico
      --bi-export              Exportar CSV para PowerBI/Tableau
      --validate-metadata      Validaci√≥n completa de metadatos
      --generate-docs          Generar documentaci√≥n autom√°tica
      --validate-versioning    Validar versionado sem√°ntico
      --plugins                Ejecutar plugins personalizados
      --analyze-usage          An√°lisis de uso de assets
      --detect-obsolete        Detectar assets obsoletos por fecha
      --validate-branding      Validar consistencia de branding
      --alerts                 Generar alertas autom√°ticas
      --detect-duplicates      Detectar duplicados por contenido
      --analyze-complexity     An√°lisis de complejidad visual
      --generate-thumbnails    Generar thumbnails autom√°ticos
      --accessibility-adv      An√°lisis de accesibilidad avanzado
      --validate-wcag           Validaci√≥n de compliance WCAG 2.1
      --analyze-markers         An√°lisis de uso de markers y patterns
      --detect-scaling          Detecci√≥n de problemas de scaling
      --validate-css-vars       Validaci√≥n de CSS custom properties
      --analyze-foreign         An√°lisis de uso de foreignObject
      --detect-vulnerabilities  Detecci√≥n de vulnerabilidades conocidas (XXE, XSS)
      --advanced-performance    An√°lisis avanzado de performance
      --detect-orphans          Detectar assets hu√©rfanos (sin referencias)
      --markdown                Generar reporte en formato Markdown
      --analyze-dependencies  An√°lisis de dependencias entre assets
      --generate-badges        Generar badges para CI/CD (shields.io)
      --visual-similarity      An√°lisis de similitud visual entre assets
      --ascii-chart            Generar gr√°fico ASCII de m√©tricas
      --export-executive       Exportar resumen ejecutivo (JSON/YAML)
      --validate-naming        Validaci√≥n estricta de naming conventions
      --change-impact          An√°lisis de impacto de cambios (Git)
  -h, --help                 Muestra esta ayuda

Ejemplos:
  # An√°lisis completo enterprise
  $0 --profile strict --security-scan --compliance --business-metrics --xml
  
  # CI/CD pipeline completo
  $0 --profile ci --fail-on-error --xml --dashboard --slack-webhook "https://..."
  
  # An√°lisis de calidad avanzado
  $0 --performance-adv --optimization-suggest --analyze-deps --yaml
  
  # An√°lisis r√°pido para desarrollo
  $0 --validate-naming --detect-orphans --quiet --output-format json
USAGE
}

while [[ ${1:-} =~ ^- ]]; do
  case "$1" in
    -q|--quiet) 
      QUIET=true; shift ;;
    -s|--summary-only) 
      SUMMARY_ONLY=true; shift ;;
    -o|--output-format)
      if [ -z "${2:-}" ]; then
        _log_error "--output-format requiere un valor"
        print_usage; exit 2
      fi
      validate_output_format "$2"
      OUTPUT_FORMAT="$2"; shift 2 ;;
    -r|--report)
      if [ -z "${2:-}" ]; then
        _log_error "--report requiere una ruta"
        print_usage; exit 2
      fi
      REPORT="$2"; shift 2 ;;
    -m|--min-score)
      if [ -z "${2:-}" ]; then
        _log_error "--min-score requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--min-score"
      MIN_HEALTH_SCORE="$2"; shift 2 ;;
    --palette-strict)
      PALETTE_STRICT=true; shift ;;
    --fail-on-error)
      FAIL_ON_ERROR=true; shift ;;
    --fail-on-warn)
      FAIL_ON_WARN=true; shift ;;
    --max-dom-nodes)
      if [ -z "${2:-}" ]; then
        _log_error "--max-dom-nodes requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-dom-nodes"
      MAX_DOM_NODES="$2"; shift 2 ;;
    --max-filters)
      if [ -z "${2:-}" ]; then
        _log_error "--max-filters requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-filters"
      MAX_FILTERS="$2"; shift 2 ;;
    --max-gradients)
      if [ -z "${2:-}" ]; then
        _log_error "--max-gradients requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-gradients"
      MAX_GRADIENTS="$2"; shift 2 ;;
    --baseline)
      if [ -z "${2:-}" ]; then
        _log_error "--baseline requiere una ruta de archivo"
        print_usage; exit 2
      fi
      if [ ! -f "$2" ]; then
        _log_warn "Archivo baseline no encontrado: $2"
      fi
      BASELINE_FILE="$2"; shift 2 ;;
    --export-dir)
      if [ -z "${2:-}" ]; then
        echo "‚ùå Error: --export-dir requiere una ruta" >&2
        print_usage; exit 2
      fi
      EXPORT_DIR="$2"
      # Actualizar REPORT si est√° en el directorio de exports por defecto
      if [[ "$REPORT" == "$ROOT_DIR/exports"* ]]; then
        REPORT="$EXPORT_DIR/assets_report.txt"
      fi
      shift 2 ;;
    --src)
      if [ -z "${2:-}" ]; then
        _log_error "--src requiere una ruta"
        print_usage; exit 2
      fi
      SRC_DIR="$2"; shift 2 ;;
    --profile)
      if [ -z "${2:-}" ]; then
        _log_error "--profile requiere un nombre de perfil"
        print_usage; exit 2
      fi
      PROFILE="$2"
      load_profile "$PROFILE" || _log_warn "Continuando con configuraci√≥n por defecto"
      shift 2 ;;
    --log-level)
      if [ -z "${2:-}" ]; then
        _log_error "--log-level requiere un nivel: debug|info|warn|error"
        print_usage; exit 2
      fi
      case "$2" in
        debug|info|warn|error) LOG_LEVEL="$2"; LOG_LEVEL_NUM=$(log_level_num "$LOG_LEVEL") ;;
        *) 
          _log_error "Nivel de log inv√°lido: $2. V√°lidos: debug|info|warn|error"
          print_usage; exit 2 ;;
      esac
      shift 2 ;;
    --continue-on-error)
      CONTINUE_ON_ERROR=true; shift ;;
    --show-performance)
      SHOW_PERFORMANCE=true; shift ;;
    --no-performance)
      SHOW_PERFORMANCE=false; shift ;;
    --cache-dir)
      if [ -z "${2:-}" ]; then
        _log_error "--cache-dir requiere una ruta"
        print_usage; exit 2
      fi
      CACHE_DIR="$2"
      USE_CACHE=true
      shift 2 ;;
    --no-cache)
      USE_CACHE=false; shift ;;
    --parallel)
      PARALLEL_ANALYSIS=true; shift ;;
    --max-parallel)
      if [ -z "${2:-}" ]; then
        _log_error "--max-parallel requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-parallel"
      MAX_PARALLEL="$2"; shift 2 ;;
    --no-duplicates)
      DETECT_DUPLICATES=false; shift ;;
    --no-history)
      COMPARE_HISTORY=false; shift ;;
    --no-recommendations)
      GENERATE_RECOMMENDATIONS=false; shift ;;
    --slack-webhook)
      if [ -z "${2:-}" ]; then
        _log_error "--slack-webhook requiere una URL"
        print_usage; exit 2
      fi
      SLACK_WEBHOOK="$2"; shift 2 ;;
    --teams-webhook)
      if [ -z "${2:-}" ]; then
        _log_error "--teams-webhook requiere una URL"
        print_usage; exit 2
      fi
      TEAMS_WEBHOOK="$2"; shift 2 ;;
    --notify-on-error)
      NOTIFY_ON_ERROR=true; shift ;;
    --notify-on-warn)
      NOTIFY_ON_WARN=true; shift ;;
    --detect-orphans)
      DETECT_ORPHANS=true; shift ;;
    --analyze-trends)
      ANALYZE_TRENDS=true; shift ;;
    --validate-naming)
      VALIDATE_NAMING=true; shift ;;
    --dashboard)
      GENERATE_DASHBOARD=true; shift ;;
    --markdown)
      EXPORT_MARKDOWN=true; shift ;;
    --analyze-deps)
      ANALYZE_DEPS=true; shift ;;
    --security-scan)
      SECURITY_SCAN=true; shift ;;
    --performance-adv)
      PERFORMANCE_ADV=true; shift ;;
    --optimization-suggest)
      OPTIMIZATION_SUGGEST=true; shift ;;
    --xml)
      EXPORT_XML=true; shift ;;
    --yaml)
      EXPORT_YAML=true; shift ;;
    --compliance)
      VALIDATE_COMPLIANCE=true; shift ;;
    --business-metrics)
      GENERATE_BUSINESS_METRICS=true; shift ;;
    --git-analysis)
      GIT_ANALYSIS=true; shift ;;
    --detect-patterns)
      DETECT_PATTERNS=true; shift ;;
    --changelog)
      GENERATE_CHANGELOG=true; shift ;;
    --bi-export)
      BI_EXPORT=true; shift ;;
    --validate-metadata)
      VALIDATE_METADATA=true; shift ;;
    --generate-docs)
      GENERATE_DOCS=true; shift ;;
    --validate-versioning)
      VALIDATE_VERSIONING=true; shift ;;
    --plugins)
      RUN_PLUGINS=true; shift ;;
    --analyze-usage)
      ANALYZE_USAGE=true; shift ;;
    --detect-obsolete)
      DETECT_OBSOLETE=true; shift ;;
    --validate-branding)
      VALIDATE_BRANDING=true; shift ;;
    --alerts)
      GENERATE_ALERTS=true; shift ;;
    --detect-duplicates)
      DETECT_DUPLICATES=true; shift ;;
    --analyze-complexity)
      ANALYZE_COMPLEXITY=true; shift ;;
    --generate-thumbnails)
      GENERATE_THUMBNAILS=true; shift ;;
    --accessibility-adv)
      ACCESSIBILITY_ADV=true; shift ;;
    --validate-wcag)
      VALIDATE_WCAG=true; shift ;;
    --analyze-markers)
      ANALYZE_MARKERS=true; shift ;;
    --detect-scaling)
      DETECT_SCALING=true; shift ;;
    --validate-css-vars)
      VALIDATE_CSS_VARS=true; shift ;;
    --analyze-foreign)
      ANALYZE_FOREIGN=true; shift ;;
    --detect-vulnerabilities)
      DETECT_VULNERABILITIES=true; shift ;;
    --advanced-performance)
      ADVANCED_PERFORMANCE=true; shift ;;
    --detect-orphans)
      DETECT_ORPHANS=true; shift ;;
    --markdown)
      GENERATE_MARKDOWN=true; shift ;;
    --analyze-dependencies)
      ANALYZE_DEPENDENCIES=true; shift ;;
    --generate-badges)
      GENERATE_BADGES=true; shift ;;
    --visual-similarity)
      VISUAL_SIMILARITY=true; shift ;;
    --ascii-chart)
      ASCII_CHART=true; shift ;;
    --export-executive)
      EXPORT_EXECUTIVE=true; shift ;;
    --validate-naming)
      VALIDATE_NAMING=true; shift ;;
    --change-impact)
      ANALYZE_CHANGE_IMPACT=true; shift ;;
    -h|--help)
      print_usage; exit 0 ;;
    --) shift; break ;;
    *) 
      _log_error "Opci√≥n desconocida: $1"
      print_usage; exit 2 ;;
  esac
done

# Validar paths despu√©s de procesar argumentos
validate_paths

# Asegurar que EXPORT_DIR y directorio del reporte existen
mkdir -p "$EXPORT_DIR" "$(dirname "$REPORT")"

# Tiempo de inicio
START_TIME=$(date +%s)
SECTION_TIMES=()

# Sistema de cach√© inteligente
USE_CACHE="${USE_CACHE:-true}"
CACHE_DIR="${CACHE_DIR:-$ROOT_DIR/.cache/asset_analysis}"
PARALLEL_ANALYSIS="${PARALLEL_ANALYSIS:-false}"
MAX_PARALLEL="${MAX_PARALLEL:-4}"
DETECT_DUPLICATES="${DETECT_DUPLICATES:-true}"
COMPARE_HISTORY="${COMPARE_HISTORY:-true}"
GENERATE_RECOMMENDATIONS="${GENERATE_RECOMMENDATIONS:-true}"

# Funciones de cach√©
get_file_hash() {
  local file="$1"
  if command -v md5 >/dev/null 2>&1; then
    md5 -q "$file" 2>/dev/null || echo ""
  elif command -v md5sum >/dev/null 2>&1; then
    md5sum "$file" 2>/dev/null | cut -d' ' -f1 || echo ""
  elif command -v shasum >/dev/null 2>&1; then
    shasum -a 256 "$file" 2>/dev/null | cut -d' ' -f1 || echo ""
  else
    echo ""
  fi
}

get_cache_key() {
  local file="$1"
  local hash=$(get_file_hash "$file")
  if [ -n "$hash" ]; then
    echo "${file//\//_}_$hash"
  else
    echo "${file//\//_}_$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo 0)"
  fi
}

is_cached() {
  local file="$1"
  local cache_key=$(get_cache_key "$file")
  local cache_file="$CACHE_DIR/$cache_key"
  
  if [ "$USE_CACHE" != "true" ] || [ ! -f "$cache_file" ]; then
    return 1
  fi
  
  # Verificar que el archivo no ha cambiado desde el cach√©
  local cached_time=$(stat -f%m "$cache_file" 2>/dev/null || stat -c%Y "$cache_file" 2>/dev/null || echo 0)
  local file_time=$(stat -f%m "$file" 2>/dev/null || stat -c%Y "$file" 2>/dev/null || echo 0)
  
  if [ "$file_time" -le "$cached_time" ]; then
    return 0
  fi
  
  return 1
}

save_to_cache() {
  local file="$1"
  local data="$2"
  local cache_key=$(get_cache_key "$file")
  local cache_file="$CACHE_DIR/$cache_key"
  
  if [ "$USE_CACHE" = "true" ]; then
    echo "$data" > "$cache_file" 2>/dev/null || true
  fi
}

get_from_cache() {
  local file="$1"
  local cache_key=$(get_cache_key "$file")
  local cache_file="$CACHE_DIR/$cache_key"
  
  if [ -f "$cache_file" ]; then
    cat "$cache_file" 2>/dev/null || echo ""
  else
    echo ""
  fi
}

# Inicializar cach√© si est√° habilitado
if [ "$USE_CACHE" = "true" ]; then
  mkdir -p "$CACHE_DIR"
  _log_debug "Cach√© habilitado: $CACHE_DIR"
fi

# Variables para notificaciones
SLACK_WEBHOOK="${SLACK_WEBHOOK:-}"
TEAMS_WEBHOOK="${TEAMS_WEBHOOK:-}"
NOTIFY_ON_ERROR="${NOTIFY_ON_ERROR:-false}"
NOTIFY_ON_WARN="${NOTIFY_ON_WARN:-false}"

# Funciones de notificaci√≥n
send_slack_notification() {
  local message="$1"
  local webhook="${SLACK_WEBHOOK}"
  
  if [ -z "$webhook" ]; then
    return 1
  fi
  
  local color="good"
  if echo "$message" | grep -q "‚ö†Ô∏è\|‚ùå\|ERROR"; then
    color="danger"
  elif echo "$message" | grep -q "‚ö†Ô∏è\|WARN"; then
    color="warning"
  fi
  
  local payload=$(cat <<EOF
{
  "text": "Asset Analysis Report",
  "attachments": [{
    "color": "$color",
    "text": "$message",
    "footer": "Asset Analyzer",
    "ts": $(date +%s)
  }]
}
EOF
)
  
  curl -s -X POST -H 'Content-type: application/json' \
    --data "$payload" "$webhook" >/dev/null 2>&1 || return 1
}

send_teams_notification() {
  local message="$1"
  local webhook="${TEAMS_WEBHOOK}"
  
  if [ -z "$webhook" ]; then
    return 1
  fi
  
  local theme_color="28a745"
  if echo "$message" | grep -q "‚ö†Ô∏è\|‚ùå\|ERROR"; then
    theme_color="dc3545"
  elif echo "$message" | grep -q "‚ö†Ô∏è\|WARN"; then
    theme_color="ffc107"
  fi
  
  local payload=$(cat <<EOF
{
  "@type": "MessageCard",
  "@context": "https://schema.org/extensions",
  "summary": "Asset Analysis Report",
  "themeColor": "$theme_color",
  "sections": [{
    "activityTitle": "Asset Analysis Report",
    "text": "$message",
    "markdown": true
  }]
}
EOF
)
  
  curl -s -X POST -H 'Content-type: application/json' \
    --data "$payload" "$webhook" >/dev/null 2>&1 || return 1
}

# Detecci√≥n de archivos hu√©rfanos (no referenciados)
detect_orphan_files() {
  local orphans_tmp=$(mktemp)
  local orphan_count=0
  
  _log_debug "Analizando archivos hu√©rfanos..."
  
  # Buscar SVGs que no est√°n referenciados en CSV, HTML u otros archivos
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local filename=$(basename "$svg_file")
    local relative_path="${svg_file#$ROOT_DIR/}"
    
    # Verificar referencias en CSV
    local in_csv=false
    if [ -f "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" ]; then
      if grep -q "$filename\|$relative_path" "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" 2>/dev/null; then
        in_csv=true
      fi
    fi
    
    # Verificar referencias en otros archivos
    local referenced=false
    if find "$ROOT_DIR" -name "*.svg" -o -name "*.html" -o -name "*.md" -o -name "*.js" -o -name "*.json" 2>/dev/null | \
       xargs grep -l "$filename" 2>/dev/null | grep -v "^$svg_file$" | head -1 | grep -q .; then
      referenced=true
    fi
    
    if [ "$in_csv" = false ] && [ "$referenced" = false ]; then
      echo "$svg_file" >> "$orphans_tmp"
      orphan_count=$((orphan_count + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if [ "$orphan_count" -gt 0 ]; then
    log_info "Archivos hu√©rfanos encontrados: $orphan_count"
    head -10 "$orphans_tmp" | while read -r orphan; do
      log_info "  ‚Ä¢ $orphan"
    done
    [ "$orphan_count" -gt 10 ] && log_info "  ... y $((orphan_count - 10)) m√°s"
    
    # Exportar lista completa
    ORPHANS_JSON="$EXPORT_DIR/orphan_files.json"
    if command -v jq >/dev/null 2>&1; then
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"orphan_count\": $orphan_count,"
        echo "  \"files\": ["
        FIRST=true
        while read -r f; do
          [ "$FIRST" = false ] && echo ","
          echo "    \"$f\""
          FIRST=false
        done < "$orphans_tmp"
        echo "  ]"
        echo "}"
      } > "$ORPHANS_JSON" 2>/dev/null && log_info "üìä Lista JSON: $ORPHANS_JSON"
    fi
    
    rm -f "$orphans_tmp"
    return 0
  else
    rm -f "$orphans_tmp"
    return 1
  fi
}

# An√°lisis de tendencias temporales (si hay historial)
analyze_trends() {
  if [ "$COMPARE_HISTORY" != "true" ]; then
    return 0
  fi
  
  local history_dir="$EXPORT_DIR/history"
  mkdir -p "$history_dir"
  
  # Guardar m√©tricas actuales para comparaci√≥n futura
  local metrics_file="$history_dir/metrics_$(date +%Y%m%d).json"
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"date\": \"$(date +%Y-%m-%d)\","
      echo "  \"total_svgs\": $TOTAL_SVGS,"
      echo "  \"health_score\": $HEALTH_SCORE,"
      echo "  \"empty_svgs\": ${EMPTY_SVGS:-0},"
      echo "  \"broken_svgs\": ${BROKEN_SVGS:-0},"
      echo "  \"security_issues\": ${SECURITY_ISSUES:-0},"
      echo "  \"coverage_percent\": ${COVERAGE_PERCENT:-0}"
      echo "}"
    } > "$metrics_file" 2>/dev/null || true
    
    # Analizar tendencias si hay archivos previos
    local prev_files=$(find "$history_dir" -name "metrics_*.json" -type f | sort | tail -7)
    if [ -n "$prev_files" ] && [ "$(echo "$prev_files" | wc -l | xargs)" -ge 2 ]; then
      _log_debug "Analizando tendencias de $(echo "$prev_files" | wc -l | xargs) puntos de datos"
    fi
  fi
}

# Validaci√≥n de naming conventions
validate_naming_conventions() {
  local violations=0
  local violations_tmp=$(mktemp)
  
  _log_debug "Validando convenciones de nombres..."
  
  # Patrones esperados: lowercase, underscores, n√∫meros
  local valid_pattern='^[a-z0-9_]+(-[a-z0-9_]+)*\.svg$'
  
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    local basename=$(basename "$svg_file")
    
    # Verificar patrones comunes de violaci√≥n
    local issues=()
    
    # Espacios en nombres
    if echo "$basename" | grep -q ' '; then
      issues+=("contiene espacios")
    fi
    
    # May√∫sculas
    if echo "$basename" | grep -q '[A-Z]'; then
      issues+=("contiene may√∫sculas")
    fi
    
    # Caracteres especiales no permitidos
    if echo "$basename" | grep -qE '[^a-z0-9_\-\.]'; then
      issues+=("contiene caracteres especiales")
    fi
    
    # Nombres muy largos (>100 chars)
    if [ "${#basename}" -gt 100 ]; then
      issues+=("nombre muy largo (${#basename} chars)")
    fi
    
    # Nombres muy cortos (<3 chars sin extensi√≥n)
    local name_no_ext="${basename%.svg}"
    if [ "${#name_no_ext}" -lt 3 ]; then
      issues+=("nombre muy corto")
    fi
    
    if [ ${#issues[@]} -gt 0 ]; then
      echo "$svg_file|${issues[*]}" >> "$violations_tmp"
      violations=$((violations + 1))
    fi
  done
  
  local violation_count=$(wc -l < "$violations_tmp" | xargs)
  
  if [ "$violation_count" -gt 0 ]; then
    return 0
  else
    rm -f "$violations_tmp"
    return 1
  fi
}

# Generar dashboard HTML interactivo mejorado
generate_interactive_dashboard() {
  local dashboard_file="$EXPORT_DIR/dashboard.html"
  
  cat > "$dashboard_file" <<'DASHBOARD_EOF'
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>üìä Asset Analysis Dashboard</title>
  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      padding: 20px;
      min-height: 100vh;
    }
    .container { max-width: 1400px; margin: 0 auto; }
    .header {
      background: white; padding: 30px; border-radius: 15px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.2); margin-bottom: 30px;
    }
    .stats-grid {
      display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 20px; margin-bottom: 30px;
    }
    .stat-card {
      background: white; padding: 25px; border-radius: 15px;
      box-shadow: 0 5px 15px rgba(0,0,0,0.1); transition: transform 0.3s;
    }
    .stat-card:hover { transform: translateY(-5px); }
    .stat-card h3 {
      color: #666; font-size: 0.9em; text-transform: uppercase;
      letter-spacing: 1px; margin-bottom: 10px;
    }
    .stat-card .value {
      color: #333; font-size: 2.5em; font-weight: bold;
    }
    .chart-container {
      background: white; padding: 25px; border-radius: 15px;
      box-shadow: 0 5px 15px rgba(0,0,0,0.1); margin-bottom: 30px;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>üìä Asset Analysis Dashboard</h1>
      <p>Generated: DASHBOARD_TIMESTAMP</p>
    </div>
    <div class="stats-grid">
      <div class="stat-card">
        <h3>Total Assets</h3>
        <div class="value">DASHBOARD_TOTAL_SVGS</div>
      </div>
      <div class="stat-card">
        <h3>Health Score</h3>
        <div class="value">DASHBOARD_HEALTH_SCORE</div>
      </div>
      <div class="stat-card">
        <h3>Coverage</h3>
        <div class="value">DASHBOARD_COVERAGE%</div>
      </div>
      <div class="stat-card">
        <h3>Issues</h3>
        <div class="value">DASHBOARD_ISSUES</div>
      </div>
    </div>
    <div class="chart-container">
      <canvas id="healthChart"></canvas>
    </div>
  </div>
  <script>
    const ctx = document.getElementById('healthChart').getContext('2d');
    new Chart(ctx, {
      type: 'bar',
      data: {
        labels: ['Health Score', 'Coverage', 'Performance'],
        datasets: [{
          label: 'Metrics',
          data: [DASHBOARD_HEALTH_SCORE, DASHBOARD_COVERAGE, 85],
          backgroundColor: ['#28a745', '#17a2b8', '#ffc107']
        }]
      },
      options: {
        responsive: true,
        scales: { y: { beginAtZero: true, max: 100 } }
      }
    });
  </script>
</body>
</html>
DASHBOARD_EOF
  
  # Reemplazar placeholders
  sed -i.bak \
    -e "s|DASHBOARD_TIMESTAMP|$(date '+%Y-%m-%d %H:%M:%S')|g" \
    -e "s|DASHBOARD_TOTAL_SVGS|${TOTAL_SVGS:-0}|g" \
    -e "s|DASHBOARD_HEALTH_SCORE|${HEALTH_SCORE:-0}|g" \
    -e "s|DASHBOARD_COVERAGE|${COVERAGE_PERCENT:-0}|g" \
    -e "s|DASHBOARD_ISSUES|$(( ${EMPTY_SVGS:-0} + ${BROKEN_SVGS:-0} + ${SECURITY_ISSUES:-0} ))|g" \
    "$dashboard_file" 2>/dev/null || true
  
  rm -f "${dashboard_file}.bak" 2>/dev/null || true
  
  if [ -f "$dashboard_file" ]; then
    echo "$dashboard_file"
    return 0
  fi
  return 1
}

# Exportar a Markdown
export_to_markdown() {
  local md_file="${REPORT%.txt}.md"
  
  {
    echo "# üìä Asset Analysis Report"
    echo ""
    echo "**Generated:** $(date '+%Y-%m-%d %H:%M:%S')"
    echo ""
    echo "## Summary"
    echo ""
    echo "| Metric | Value |"
    echo "|--------|-------|"
    echo "| Total SVGs | ${TOTAL_SVGS:-0} |"
    echo "| Health Score | ${HEALTH_SCORE:-0}/100 |"
    echo "| Empty SVGs | ${EMPTY_SVGS:-0} |"
    echo "| Broken SVGs | ${BROKEN_SVGS:-0} |"
    echo "| Security Issues | ${SECURITY_ISSUES:-0} |"
    echo "| Coverage | ${COVERAGE_PERCENT:-0}% |"
    echo ""
    echo "## Full Report"
    echo ""
    echo "\`\`\`"
    cat "$REPORT"
    echo "\`\`\`"
  } > "$md_file" 2>/dev/null || return 1
  
  if [ -f "$md_file" ]; then
    echo "$md_file"
    return 0
  fi
  return 1
}

# An√°lisis de dependencias entre archivos
analyze_dependencies() {
  local deps_file="$EXPORT_DIR/dependencies.json"
  local deps_count=0
  
  _log_debug "Analizando dependencias entre archivos..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"dependencies\": ["
      
      FIRST=true
      find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
        [ ! -f "$svg_file" ] && continue
        
        # Buscar referencias a otros archivos
        local references=$(grep -oE 'href=["'\'']([^"'\'']+)["'\'']|xlink:href=["'\'']([^"'\'']+)["'\'']|url\(([^)]+)\)' "$svg_file" 2>/dev/null || true)
        
        if [ -n "$references" ]; then
          if [ "$FIRST" = false ]; then
            echo ","
          fi
          
          echo "    {"
          echo "      \"file\": \"${svg_file#$ROOT_DIR/}\","
          echo "      \"references\": ["
          
          FIRST_REF=true
          echo "$references" | grep -oE 'href=["'\'']([^"'\'']+)["'\'']|xlink:href=["'\'']([^"'\'']+)["'\'']|url\(([^)]+)\)' | while read -r ref; do
            local ref_path=$(echo "$ref" | sed -E 's/.*["'\'']([^"'\'']+)["'\''].*/\1/' | sed -E 's/url\(([^)]+)\)/\1/')
            
            if [ -n "$ref_path" ]; then
              if [ "$FIRST_REF" = false ]; then
                echo ","
              fi
              echo "        \"$ref_path\""
              FIRST_REF=false
              deps_count=$((deps_count + 1))
            fi
          done
          
          echo "      ]"
          echo "    }"
          FIRST=false
        fi
      done
      
      echo "  ],"
      echo "  \"total_dependencies\": $deps_count"
      echo "}"
    } > "$deps_file" 2>/dev/null || true
    
    if [ -f "$deps_file" ]; then
      echo "$deps_file"
      return 0
    fi
  fi
  
  return 1
}

# Detecci√≥n avanzada de vulnerabilidades
detect_vulnerabilities() {
  local vuln_count=0
  local vuln_tmp=$(mktemp)
  
  _log_debug "Detectando vulnerabilidades de seguridad..."
  
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local issues=()
    
    # Script tags (XSS potencial)
    if grep -qiE '<script[^>]*>' "$svg_file" 2>/dev/null; then
      issues+=("Contiene tags <script> (riesgo XSS)")
    fi
    
    # Event handlers inline
    if grep -qiE 'on\w+\s*=' "$svg_file" 2>/dev/null; then
      issues+=("Event handlers inline (riesgo XSS)")
    fi
    
    # Links a dominios externos no confiables
    if grep -qiE 'href=["'\'']http://[^"'\'']+["'\'']' "$svg_file" 2>/dev/null; then
      issues+=("Enlaces HTTP no seguros")
    fi
    
    # Data URIs sospechosos
    if grep -qiE 'data:.*base64.*eval|data:.*javascript' "$svg_file" 2>/dev/null; then
      issues+=("Data URIs potencialmente peligrosos")
    fi
    
    # Inclusi√≥n de archivos externos sin validar
    if grep -qiE '<image[^>]*href=["'\'']http' "$svg_file" 2>/dev/null; then
      issues+=("Im√°genes desde URLs externas")
    fi
    
    if [ ${#issues[@]} -gt 0 ]; then
      echo "$svg_file|${issues[*]}" >> "$vuln_tmp"
      vuln_count=$((vuln_count + 1))
    fi
  done
  
  local total_vulns=$(wc -l < "$vuln_tmp" | xargs)
  
  if [ "$total_vulns" -gt 0 ]; then
    log_info "‚ö†Ô∏è  Vulnerabilidades detectadas: $total_vulns archivos"
    head -5 "$vuln_tmp" | while IFS='|' read -r file issues; do
      log_info "  ‚Ä¢ $(basename "$file"): $issues"
    done
    
    # Exportar a JSON
    if command -v jq >/dev/null 2>&1; then
      VULN_JSON="$EXPORT_DIR/vulnerabilities.json"
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"vulnerability_count\": $total_vulns,"
        echo "  \"vulnerabilities\": ["
        FIRST=true
        while IFS='|' read -r file issues; do
          [ "$FIRST" = false ] && echo ","
          echo "    {"
          echo "      \"file\": \"$file\","
          echo "      \"issues\": [$(echo "$issues" | sed 's/ /", "/g' | sed 's/^/"/' | sed 's/$/"/')]"
          echo "    }"
          FIRST=false
        done < "$vuln_tmp"
        echo "  ]"
        echo "}"
      } > "$VULN_JSON" 2>/dev/null && log_info "üìä Vulnerabilidades JSON: $VULN_JSON"
    fi
    
    rm -f "$vuln_tmp"
    return 0
  else
    rm -f "$vuln_tmp"
    return 1
  fi
}

# An√°lisis de performance avanzado
analyze_performance_advanced() {
  local perf_tmp=$(mktemp)
  local slow_files=0
  
  _log_debug "An√°lisis avanzado de performance..."
  
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo 0)
    local node_count=$(grep -oE '<[^/>]+>' "$svg_file" 2>/dev/null | wc -l | xargs)
    local filter_count=$(grep -c '<filter>' "$svg_file" 2>/dev/null || echo 0)
    local gradient_count=$(grep -cE '<linearGradient|<radialGradient>' "$svg_file" 2>/dev/null || echo 0)
    
    # Calcular score de performance (0-100, mayor es mejor)
    local perf_score=100
    
    # Penalizar por tama√±o
    if [ "$file_size" -gt 500000 ]; then
      perf_score=$((perf_score - 20))
    elif [ "$file_size" -gt 200000 ]; then
      perf_score=$((perf_score - 10))
    fi
    
    # Penalizar por complejidad
    if [ "$node_count" -gt "$MAX_DOM_NODES" ]; then
      perf_score=$((perf_score - 15))
    fi
    
    if [ "$filter_count" -gt "$MAX_FILTERS" ]; then
      perf_score=$((perf_score - 10))
    fi
    
    if [ "$gradient_count" -gt "$MAX_GRADIENTS" ]; then
      perf_score=$((perf_score - 5))
    fi
    
    if [ "$perf_score" -lt 70 ]; then
      echo "$svg_file|$file_size|$node_count|$perf_score" >> "$perf_tmp"
      slow_files=$((slow_files + 1))
    fi
  done
  
  local total_slow=$(wc -l < "$perf_tmp" | xargs)
  
  if [ "$total_slow" -gt 0 ]; then
    return 0
  else
    rm -f "$perf_tmp"
    return 1
  fi
}

# Generar sugerencias de optimizaci√≥n autom√°tica
generate_optimization_suggestions() {
  local suggestions_file="$EXPORT_DIR/optimization_suggestions.json"
  
  _log_debug "Generando sugerencias de optimizaci√≥n..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"suggestions\": ["
      
      FIRST=true
      
      # Sugerencia 1: Archivos grandes
      if [ "${LARGE_COUNT:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"size_optimization\","
        echo "      \"priority\": \"high\","
        echo "      \"title\": \"Optimizar archivos grandes\","
        echo "      \"description\": \"${LARGE_COUNT:-0} archivos superan 500KB. Considera usar SVGO para optimizar.\","
        echo "      \"action\": \"Ejecutar: svgo --folder . --recursive\""
        echo "    }"
        FIRST=false
      fi
      
      # Sugerencia 2: Duplicados
      if [ "${DUPLICATE_GROUPS:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"deduplication\","
        echo "      \"priority\": \"medium\","
        echo "      \"title\": \"Eliminar archivos duplicados\","
        echo "      \"description\": \"${DUPLICATE_GROUPS:-0} grupos de duplicados detectados. Puedes eliminar redundancias.\","
        echo "      \"action\": \"Revisar exports/duplicates.json\""
        echo "    }"
        FIRST=false
      fi
      
      # Sugerencia 3: Accesibilidad
      if [ "${NO_ACCESSIBILITY:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"accessibility\","
        echo "      \"priority\": \"high\","
        echo "      \"title\": \"Mejorar accesibilidad\","
        echo "      \"description\": \"${NO_ACCESSIBILITY:-0} archivos sin atributos de accesibilidad. A√±ade aria-label y <title>.\","
        echo "      \"action\": \"A√±adir aria-label y <title> a todos los SVGs\""
        echo "    }"
        FIRST=false
      fi
      
      echo "  ]"
      echo "}"
    } > "$suggestions_file" 2>/dev/null || true
    
    if [ -f "$suggestions_file" ]; then
      echo "$suggestions_file"
      return 0
    fi
  fi
  
  return 1
}

# Exportar a XML para herramientas de CI/CD
export_to_xml() {
  local xml_file="${REPORT%.txt}.xml"
  
  {
    echo "<?xml version=\"1.0\" encoding=\"UTF-8\"?>"
    echo "<asset-analysis>"
    echo "  <timestamp>$(date -u +"%Y-%m-%dT%H:%M:%SZ")</timestamp>"
    echo "  <summary>"
    echo "    <total-svgs>${TOTAL_SVGS:-0}</total-svgs>"
    echo "    <health-score>${HEALTH_SCORE:-0}</health-score>"
    echo "    <empty-svgs>${EMPTY_SVGS:-0}</empty-svgs>"
    echo "    <broken-svgs>${BROKEN_SVGS:-0}</broken-svgs>"
    echo "    <security-issues>${SECURITY_ISSUES:-0}</security-issues>"
    echo "    <coverage-percent>${COVERAGE_PERCENT:-0}</coverage-percent>"
    echo "  </summary>"
    echo "  <issues>"
    [ "${EMPTY_SVGS:-0}" -gt 0 ] && echo "    <empty-svgs count=\"${EMPTY_SVGS:-0}\" severity=\"warning\"/>"
    [ "${BROKEN_SVGS:-0}" -gt 0 ] && echo "    <broken-svgs count=\"${BROKEN_SVGS:-0}\" severity=\"error\"/>"
    [ "${SECURITY_ISSUES:-0}" -gt 0 ] && echo "    <security-issues count=\"${SECURITY_ISSUES:-0}\" severity=\"critical\"/>"
    echo "  </issues>"
    echo "</asset-analysis>"
  } > "$xml_file" 2>/dev/null || return 1
  
  if [ -f "$xml_file" ]; then
    echo "$xml_file"
    return 0
  fi
  return 1
}

# Exportar a YAML
export_to_yaml() {
  local yaml_file="${REPORT%.txt}.yaml"
  
  {
    echo "---"
    echo "generated_at: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
    echo "summary:"
    echo "  total_svgs: ${TOTAL_SVGS:-0}"
    echo "  health_score: ${HEALTH_SCORE:-0}"
    echo "  empty_svgs: ${EMPTY_SVGS:-0}"
    echo "  broken_svgs: ${BROKEN_SVGS:-0}"
    echo "  security_issues: ${SECURITY_ISSUES:-0}"
    echo "  coverage_percent: ${COVERAGE_PERCENT:-0}"
    echo "issues:"
    echo "  empty_svgs: ${EMPTY_SVGS:-0}"
    echo "  broken_svgs: ${BROKEN_SVGS:-0}"
    echo "  security_issues: ${SECURITY_ISSUES:-0}"
    echo "  missing_accessibility: ${NO_ACCESSIBILITY:-0}"
  } > "$yaml_file" 2>/dev/null || return 1
  
  if [ -f "$yaml_file" ]; then
    echo "$yaml_file"
    return 0
  fi
  return 1
}

# Validaci√≥n de compliance (WCAG, etc.)
validate_compliance() {
  local compliance_file="$EXPORT_DIR/compliance_report.json"
  local wcag_score=0
  local wcag_issues=0
  
  _log_debug "Validando compliance con est√°ndares..."
  
  # Verificar WCAG 2.1 AA b√°sico
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    # Verificar contraste (simplificado - verificar si tiene texto)
    if grep -q '<text' "$svg_file" 2>/dev/null; then
      # Verificar si tiene aria-label o title para texto
      if ! grep -qiE 'aria-label|<title>|<desc>' "$svg_file" 2>/dev/null; then
        wcag_issues=$((wcag_issues + 1))
      fi
    fi
    
    # Verificar si tiene roles ARIA apropiados
    if ! grep -qiE 'role=|aria-' "$svg_file" 2>/dev/null; then
      wcag_issues=$((wcag_issues + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | head -100)
  
  # Calcular score (100 - (issues * 2))
  wcag_score=$((100 - (wcag_issues * 2)))
  [ "$wcag_score" -lt 0 ] && wcag_score=0
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"compliance\": {"
      echo "    \"wcag_2_1_aa\": {"
      echo "      \"score\": $wcag_score,"
      echo "      \"issues\": $wcag_issues,"
      echo "      \"status\": \"$([ "$wcag_score" -ge 80 ] && echo "compliant" || echo "needs_improvement")\""
      echo "    }"
      echo "  }"
      echo "}"
    } > "$compliance_file" 2>/dev/null || true
    
    if [ -f "$compliance_file" ]; then
      echo "$compliance_file"
      return 0
    fi
  fi
  
  return 1
}

# Generar m√©tricas de negocio
generate_business_metrics() {
  local business_file="$EXPORT_DIR/business_metrics.json"
  
  _log_debug "Generando m√©tricas de negocio..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"business_metrics\": {"
      echo "    \"asset_health\": ${HEALTH_SCORE:-0},"
      echo "    \"coverage_completeness\": ${COVERAGE_PERCENT:-0},"
      echo "    \"maintenance_score\": ${MAINT_SCORE:-100},"
      echo "    \"security_score\": $((100 - (${SECURITY_ISSUES:-0} * 10))),"
      echo "    \"accessibility_score\": $([ "${NO_ACCESSIBILITY:-0}" -eq 0 ] && echo "100" || echo "$((100 - ${NO_ACCESSIBILITY:-0} * 5))"),"
      echo "    \"quality_index\": $(awk "BEGIN {printf \"%.1f\", (${HEALTH_SCORE:-0} + ${COVERAGE_PERCENT:-0} + ${MAINT_SCORE:-100}) / 3}")"
      echo "  },"
      echo "  \"recommendations\": {"
      echo "    \"priority\": \"$([ "$HEALTH_SCORE" -lt 70 ] && echo "high" || echo "medium")\","
      echo "    \"estimated_impact\": \"$([ "$HEALTH_SCORE" -lt 60 ] && echo "critical" || [ "$HEALTH_SCORE" -lt 80 ] && echo "high" || echo "low")\""
      echo "  }"
      echo "}"
    } > "$business_file" 2>/dev/null || true
    
    if [ -f "$business_file" ]; then
      echo "$business_file"
      return 0
    fi
  fi
  
  return 1
}

# An√°lisis de impacto de cambios (Git integration)
analyze_changes_impact() {
  local changes_file="$EXPORT_DIR/changes_impact.json"
  local changed_files=0
  local modified_count=0
  local added_count=0
  local deleted_count=0
  
  _log_debug "Analizando impacto de cambios con Git..."
  
  if command -v git >/dev/null 2>&1 && [ -d "$ROOT_DIR/.git" ]; then
    # Archivos modificados en el √∫ltimo commit
    local git_changed=$(git diff --name-only HEAD~1 HEAD 2>/dev/null | grep '\.svg$' || true)
    modified_count=$(echo "$git_changed" | wc -l | xargs)
    
    # Archivos agregados
    local git_added=$(git diff --name-only --diff-filter=A HEAD~1 HEAD 2>/dev/null | grep '\.svg$' || true)
    added_count=$(echo "$git_added" | wc -l | xargs)
    
    # Archivos eliminados
    local git_deleted=$(git diff --name-only --diff-filter=D HEAD~1 HEAD 2>/dev/null | grep '\.svg$' || true)
    deleted_count=$(echo "$git_deleted" | wc -l | xargs)
    
    changed_files=$((modified_count + added_count + deleted_count))
    
    if command -v jq >/dev/null 2>&1; then
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"git_info\": {"
        echo "    \"branch\": \"$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "unknown")\","
        echo "    \"commit\": \"$(git rev-parse --short HEAD 2>/dev/null || echo "unknown")\","
        echo "    \"last_commit_date\": \"$(git log -1 --format=%ci 2>/dev/null || echo "unknown")\""
        echo "  },"
        echo "  \"changes\": {"
        echo "    \"total_changed\": $changed_files,"
        echo "    \"modified\": $modified_count,"
        echo "    \"added\": $added_count,"
        echo "    \"deleted\": $deleted_count"
        echo "  },"
        echo "  \"impact\": {"
        echo "    \"level\": \"$([ "$changed_files" -gt 50 ] && echo "high" || [ "$changed_files" -gt 10 ] && echo "medium" || echo "low")\","
        echo "    \"requires_review\": $([ "$changed_files" -gt 20 ] && echo "true" || echo "false")"
        echo "  }"
        echo "}"
      } > "$changes_file" 2>/dev/null || true
      
      if [ -f "$changes_file" ]; then
        echo "$changes_file"
        return 0
      fi
    fi
  else
    _log_debug "Git no disponible o no es un repositorio Git"
  fi
  
  return 1
}

# Detectar patrones de dise√±o
detect_design_patterns() {
  local patterns_file="$EXPORT_DIR/design_patterns.json"
  local pattern_count=0
  
  _log_debug "Detectando patrones de dise√±o..."
  
  declare -A PATTERNS=(
    ["before_after"]="before.*after|antes.*despu"
    ["testimonial"]="testimonial|testimonio|review"
    ["benefits"]="benefit|beneficio|ventaja"
    ["social_proof"]="social.*proof|prueba.*social|rating|estrellas"
    ["urgency"]="urgent|urgente|limited|limitado"
    ["cta"]="call.*to.*action|click|mas.*info|compra.*ahora"
  )
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"patterns\": {"
      
      FIRST=true
      for pattern_name in "${!PATTERNS[@]}"; do
        pattern_regex="${PATTERNS[$pattern_name]}"
        count=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | xargs grep -liE "$pattern_regex" 2>/dev/null | wc -l | xargs)
        
        [ "$FIRST" = false ] && echo ","
        echo "    \"$pattern_name\": {"
        echo "      \"count\": $count,"
        echo "      \"percentage\": $(awk "BEGIN {printf \"%.1f\", ($count / ($TOTAL_SVGS + 1)) * 100}" 2>/dev/null || echo "0")"
        echo "    }"
        FIRST=false
        pattern_count=$((pattern_count + count))
      done
      
      echo "  },"
      echo "  \"total_patterns_detected\": $pattern_count"
      echo "}"
    } > "$patterns_file" 2>/dev/null || true
    
    if [ -f "$patterns_file" ]; then
      echo "$patterns_file"
      return 0
    fi
  fi
  
  return 1
}

# Generar changelog autom√°tico
generate_changelog() {
  local changelog_file="$EXPORT_DIR/CHANGELOG.md"
  
  _log_debug "Generando changelog autom√°tico..."
  
  {
    echo "# Changelog - Asset Analysis"
    echo ""
    echo "## $(date '+%Y-%m-%d')"
    echo ""
    echo "### M√©tricas"
    echo "- Total SVGs: ${TOTAL_SVGS:-0}"
    echo "- Health Score: ${HEALTH_SCORE:-0}/100"
    echo "- Coverage: ${COVERAGE_PERCENT:-0}%"
    echo ""
    echo "### Cambios detectados"
    [ "${EMPTY_SVGS:-0}" -gt 0 ] && echo "- ‚ö†Ô∏è ${EMPTY_SVGS:-0} archivos vac√≠os detectados"
    [ "${BROKEN_SVGS:-0}" -gt 0 ] && echo "- ‚ùå ${BROKEN_SVGS:-0} archivos rotos"
    [ "${SECURITY_ISSUES:-0}" -gt 0 ] && echo "- üîí ${SECURITY_ISSUES:-0} problemas de seguridad"
    [ "${DUPLICATE_GROUPS:-0}" -gt 0 ] && echo "- üîÑ ${DUPLICATE_GROUPS:-0} grupos de duplicados"
    echo ""
    echo "### Mejoras recomendadas"
    [ "${LARGE_COUNT:-0}" -gt 0 ] && echo "- üíæ Optimizar ${LARGE_COUNT:-0} archivos grandes"
    [ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && echo "- ‚ôø Mejorar accesibilidad en ${NO_ACCESSIBILITY:-0} archivos"
    echo ""
    echo "---"
    echo "*Generado autom√°ticamente por analyze_assets.sh*"
  } > "$changelog_file" 2>/dev/null || return 1
  
  if [ -f "$changelog_file" ]; then
    echo "$changelog_file"
    return 0
  fi
  return 1
}

# Exportar para PowerBI/Tableau (CSV estructurado)
export_for_bi() {
  local bi_file="$EXPORT_DIR/assets_bi_export.csv"
  
  _log_debug "Generando exportaci√≥n para herramientas de BI..."
  
  {
    echo "Date,Asset_Count,Health_Score,Coverage_Percent,Empty_Files,Broken_Files,Security_Issues,Accessibility_Score,Performance_Score,Quality_Index"
    echo "$(date +%Y-%m-%d),${TOTAL_SVGS:-0},${HEALTH_SCORE:-0},${COVERAGE_PERCENT:-0},${EMPTY_SVGS:-0},${BROKEN_SVGS:-0},${SECURITY_ISSUES:-0},$([ "${NO_ACCESSIBILITY:-0}" -eq 0 ] && echo "100" || echo "$((100 - ${NO_ACCESSIBILITY:-0} * 5))"),85,$(awk "BEGIN {printf \"%.1f\", (${HEALTH_SCORE:-0} + ${COVERAGE_PERCENT:-0} + ${MAINT_SCORE:-100}) / 3}")"
  } > "$bi_file" 2>/dev/null || return 1
  
  if [ -f "$bi_file" ]; then
    echo "$bi_file"
    return 0
  fi
  return 1
}

# Validaci√≥n completa de metadatos
validate_metadata_complete() {
  local metadata_file="$EXPORT_DIR/metadata_validation.json"
  local missing_metadata=0
  local incomplete_metadata=0
  
  _log_debug "Validando metadatos completos..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local has_title=false
    local has_desc=false
    local has_metadata=false
    local has_dublin_core=false
    
    # Verificar elementos de metadata
    grep -qiE '<title[^>]*>' "$svg_file" 2>/dev/null && has_title=true
    grep -qiE '<desc[^>]*>|<description' "$svg_file" 2>/dev/null && has_desc=true
    grep -qiE '<metadata' "$svg_file" 2>/dev/null && has_metadata=true
    grep -qiE 'dc:title|dc:creator|dublin.*core' "$svg_file" 2>/dev/null && has_dublin_core=true
    
    if [ "$has_title" = false ] && [ "$has_desc" = false ]; then
      missing_metadata=$((missing_metadata + 1))
    elif [ "$has_title" = false ] || [ "$has_desc" = false ]; then
      incomplete_metadata=$((incomplete_metadata + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | head -100)
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"validation\": {"
      echo "    \"files_without_metadata\": $missing_metadata,"
      echo "    \"files_incomplete_metadata\": $incomplete_metadata,"
      echo "    \"coverage_percent\": $(awk "BEGIN {printf \"%.1f\", ((100 - $missing_metadata - $incomplete_metadata) / 100) * 100}" 2>/dev/null || echo "0")"
      echo "  },"
      echo "  \"recommendations\": ["
      [ "$missing_metadata" -gt 0 ] && echo "    \"Agregar <title> y <desc> a $missing_metadata archivos\","
      [ "$incomplete_metadata" -gt 0 ] && echo "    \"Completar metadatos en $incomplete_metadata archivos\""
      echo "  ]"
      echo "}"
    } > "$metadata_file" 2>/dev/null || true
    
    if [ -f "$metadata_file" ]; then
      echo "$metadata_file"
      return 0
    fi
  fi
  
  return 1
}

# Generar documentaci√≥n autom√°tica completa
generate_auto_documentation() {
  local doc_file="$EXPORT_DIR/ASSETS_DOCUMENTATION.md"
  
  _log_debug "Generando documentaci√≥n autom√°tica..."
  
  {
    echo "# üìö Documentaci√≥n de Assets - Generada Autom√°ticamente"
    echo ""
    echo "**Generado:** $(date '+%Y-%m-%d %H:%M:%S')"
    echo ""
    echo "## üìä Resumen Ejecutivo"
    echo ""
    echo "| M√©trica | Valor |"
    echo "|---------|-------|"
    echo "| Total de Assets | ${TOTAL_SVGS:-0} |"
    echo "| Health Score | ${HEALTH_SCORE:-0}/100 |"
    echo "| Cobertura | ${COVERAGE_PERCENT:-0}% |"
    echo "| Estado General | $HEALTH_STATUS |"
    echo ""
    echo "## üéØ Estructura de Directorios"
    echo ""
    echo "\`\`\`"
    find "$SRC_DIR" -type d -maxdepth 2 2>/dev/null | head -20 | sed "s|$ROOT_DIR/||"
    echo "\`\`\`"
    echo ""
    echo "## üìã Formatos Soportados"
    echo ""
    echo "- **Instagram Feed:** 1080x1080"
    echo "- **Instagram Ads:** 1080x1350"
    echo "- **Instagram Stories:** 1080x1920"
    echo "- **LinkedIn:** 1200x627 (horizontal), 1080x1080 (square), 1080x1920 (vertical)"
    echo ""
    echo "## üîç Validaciones Realizadas"
    echo ""
    echo "- ‚úÖ Estructura SVG"
    echo "- ‚úÖ Integridad de archivos"
    echo "- ‚úÖ Accesibilidad (WCAG)"
    echo "- ‚úÖ Seguridad"
    echo "- ‚úÖ Performance"
    echo "- ‚úÖ Compliance"
    echo ""
    echo "## üìà M√©tricas de Calidad"
    echo ""
    echo "- **Mantenibilidad:** ${MAINT_SCORE:-100}/100"
    echo "- **Seguridad:** $((100 - (${SECURITY_ISSUES:-0} * 10)))"
    echo "- **Accesibilidad:** $([ "${NO_ACCESSIBILITY:-0}" -eq 0 ] && echo "100" || echo "$((100 - ${NO_ACCESSIBILITY:-0} * 5))")"
    echo ""
    echo "## üõ†Ô∏è Herramientas Recomendadas"
    echo ""
    echo "- SVGO para optimizaci√≥n"
    echo "- Lighthouse para performance"
    echo "- WAVE para accesibilidad"
    echo ""
    echo "---"
    echo "*Documentaci√≥n generada autom√°ticamente. Actualiza con: \`./tools/analyze_assets.sh --generate-docs\`*"
  } > "$doc_file" 2>/dev/null || return 1
  
  if [ -f "$doc_file" ]; then
    echo "$doc_file"
    return 0
  fi
  return 1
}

# Validar versionado sem√°ntico en nombres
validate_semantic_versioning() {
  local versioning_file="$EXPORT_DIR/versioning_analysis.json"
  local versioned_files=0
  local invalid_versions=0
  
  _log_debug "Validando versionado sem√°ntico..."
  
  # Patr√≥n de versionado sem√°ntico: v1.0.0, 1.0.0, v2.1.3, etc.
  local semver_pattern='v?[0-9]+\.[0-9]+(\.[0-9]+)?(-[a-zA-Z0-9]+)?'
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local basename=$(basename "$svg_file" .svg)
    
    # Buscar versiones en el nombre
    if echo "$basename" | grep -qE "$semver_pattern"; then
      versioned_files=$((versioned_files + 1))
      
      # Verificar que la versi√≥n es v√°lida (no duplicada, no inconsistente)
      local version=$(echo "$basename" | grep -oE "$semver_pattern" | head -1)
      if [ -z "$version" ]; then
        invalid_versions=$((invalid_versions + 1))
      fi
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"versioning\": {"
      echo "    \"files_with_versions\": $versioned_files,"
      echo "    \"invalid_versions\": $invalid_versions,"
      echo "    \"versioning_rate\": $(awk "BEGIN {printf \"%.1f\", ($versioned_files / ($TOTAL_SVGS + 1)) * 100}" 2>/dev/null || echo "0")"
      echo "  }"
      echo "}"
    } > "$versioning_file" 2>/dev/null || true
    
    if [ -f "$versioning_file" ]; then
      echo "$versioning_file"
      return 0
    fi
  fi
  
  return 1
}

# Sistema de plugins (ejecutar scripts externos)
run_plugins() {
  local plugins_dir="$ROOT_DIR/tools/plugins"
  local plugins_executed=0
  local plugins_failed=0
  
  _log_debug "Ejecutando plugins..."
  
  if [ ! -d "$plugins_dir" ]; then
    _log_debug "Directorio de plugins no existe: $plugins_dir"
    return 1
  fi
  
  # Exportar variables para plugins
  export ASSET_ANALYSIS_REPORT="$REPORT"
  export ASSET_ANALYSIS_TOTAL_SVGS="$TOTAL_SVGS"
  export ASSET_ANALYSIS_HEALTH_SCORE="$HEALTH_SCORE"
  export ASSET_ANALYSIS_EXPORT_DIR="$EXPORT_DIR"
  export ASSET_ANALYSIS_ROOT_DIR="$ROOT_DIR"
  export ASSET_ANALYSIS_SRC_DIR="$SRC_DIR"
  
  # Buscar scripts ejecutables en plugins/ (excluir ejemplo)
  find "$plugins_dir" -type f -perm +111 ! -name "example_*" 2>/dev/null | while read -r plugin; do
    [ ! -f "$plugin" ] && continue
    
    local plugin_name=$(basename "$plugin")
    _log_debug "Ejecutando plugin: $plugin_name"
    
    # Ejecutar plugin con timeout de 30 segundos
    if timeout 30 "$plugin" >> "$EXPORT_DIR/plugins.log" 2>&1; then
      plugins_executed=$((plugins_executed + 1))
      log_info "  ‚úÖ Plugin ejecutado: $plugin_name"
    else
      plugins_failed=$((plugins_failed + 1))
      _log_warn "Plugin fall√≥: $plugin_name"
    fi
  done
  
  if [ "$plugins_executed" -gt 0 ]; then
    log_info "Total plugins ejecutados: $plugins_executed"
    [ "$plugins_failed" -gt 0 ] && log_info "Plugins con errores: $plugins_failed"
    return 0
  fi
  
  return 1
}

# An√°lisis de uso de assets (archivos m√°s referenciados)
analyze_asset_usage() {
  local usage_file="$EXPORT_DIR/asset_usage_analysis.json"
  local usage_tmp=$(mktemp)
  
  _log_debug "Analizando uso de assets..."
  
  # Contar referencias a cada archivo SVG
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local filename=$(basename "$svg_file")
    local reference_count=0
    
    # Buscar referencias en CSV
    if [ -f "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" ]; then
      local csv_refs=$(grep -c "$filename" "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" 2>/dev/null || echo "0")
      reference_count=$((reference_count + csv_refs))
    fi
    
    # Buscar referencias en otros archivos
    local file_refs=$(find "$ROOT_DIR" -name "*.svg" -o -name "*.html" -o -name "*.md" -o -name "*.js" 2>/dev/null | \
      xargs grep -l "$filename" 2>/dev/null | wc -l | xargs)
    reference_count=$((reference_count + file_refs))
    
    if [ "$reference_count" -gt 0 ]; then
      echo "$filename|$reference_count|${svg_file#$ROOT_DIR/}" >> "$usage_tmp"
    fi
  done
  
  local total_referenced=$(wc -l < "$usage_tmp" | xargs)
  
  if [ "$total_referenced" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"usage_stats\": {"
      echo "    \"total_referenced\": $total_referenced,"
      echo "    \"unreferenced\": $((TOTAL_SVGS - total_referenced))"
      echo "  },"
      echo "  \"most_used\": ["
      
      FIRST=true
      sort -t'|' -k2 -nr "$usage_tmp" | head -10 | while IFS='|' read -r filename count path; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$filename\","
        echo "      \"references\": $count,"
        echo "      \"path\": \"$path\""
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$usage_file" 2>/dev/null || true
    
    rm -f "$usage_tmp"
    
    if [ -f "$usage_file" ]; then
      echo "$usage_file"
      return 0
    fi
  fi
  
  rm -f "$usage_tmp" 2>/dev/null || true
  return 1
}

# Detectar assets obsoletos por fecha
detect_obsolete_assets() {
  local obsolete_file="$EXPORT_DIR/obsolete_assets.json"
  local obsolete_days="${OBSOLETE_DAYS:-365}"
  local obsolete_count=0
  local obsolete_tmp=$(mktemp)
  local current_time=$(date +%s)
  
  _log_debug "Detectando assets obsoletos (m√°s de $obsolete_days d√≠as sin modificar)..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_time=$(stat -f%m "$svg_file" 2>/dev/null || stat -c%Y "$svg_file" 2>/dev/null || echo 0)
    local days_old=$(( (current_time - file_time) / 86400 ))
    
    if [ "$days_old" -gt "$obsolete_days" ]; then
      echo "${svg_file#$ROOT_DIR/}|$days_old" >> "$obsolete_tmp"
      obsolete_count=$((obsolete_count + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if [ "$obsolete_count" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"threshold_days\": $obsolete_days,"
      echo "  \"obsolete_count\": $obsolete_count,"
      echo "  \"obsolete_assets\": ["
      
      FIRST=true
      sort -t'|' -k2 -nr "$obsolete_tmp" | head -20 | while IFS='|' read -r file days; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"days_old\": $days"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$obsolete_file" 2>/dev/null || true
    
    rm -f "$obsolete_tmp"
    
    if [ -f "$obsolete_file" ]; then
      echo "$obsolete_file"
      return 0
    fi
  fi
  
  rm -f "$obsolete_tmp" 2>/dev/null || true
  return 1
}

# Validar branding consistente
validate_branding() {
  local branding_file="$EXPORT_DIR/branding_validation.json"
  local branding_issues=0
  
  _log_debug "Validando consistencia de branding..."
  
  # Buscar colores de marca en tokens.json
  if [ -f "$ROOT_DIR/tokens.json" ]; then
    local brand_colors=$(grep -oE '"[a-zA-Z0-9_]+":\s*"#[0-9a-fA-F]{3,6}"' "$ROOT_DIR/tokens.json" 2>/dev/null | \
      grep -iE 'brand|primary|secondary|accent' | wc -l | xargs)
    
    # Verificar uso consistente de colores de marca
    local inconsistent_usage=0
    
    if command -v jq >/dev/null 2>&1; then
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"branding\": {"
        echo "    \"brand_colors_defined\": $brand_colors,"
        echo "    \"consistency_score\": $([ "$OUT_OF_PALETTE" -gt 0 ] && echo "$((100 - OUT_OF_PALETTE * 2))" || echo "100"),"
        echo "    \"issues\": ${OUT_OF_PALETTE:-0}"
        echo "  }"
        echo "}"
      } > "$branding_file" 2>/dev/null || true
      
      if [ -f "$branding_file" ]; then
        echo "$branding_file"
        return 0
      fi
    fi
  fi
  
  return 1
}

# Generar alertas autom√°ticas
generate_alerts() {
  local alerts_file="$EXPORT_DIR/alerts.json"
  local alert_count=0
  
  _log_debug "Generando alertas autom√°ticas..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"alerts\": ["
      
      FIRST=true
      
      # Alerta: Health score bajo
      if [ "$HEALTH_SCORE" -lt "${MIN_HEALTH_SCORE:-75}" ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"health_score\","
        echo "      \"severity\": \"$([ "$HEALTH_SCORE" -lt 50 ] && echo "critical" || echo "warning")\","
        echo "      \"message\": \"Health score bajo: $HEALTH_SCORE/100\","
        echo "      \"value\": $HEALTH_SCORE,"
        echo "      \"threshold\": ${MIN_HEALTH_SCORE:-75}"
        echo "    }"
        FIRST=false
        alert_count=$((alert_count + 1))
      fi
      
      # Alerta: Problemas de seguridad
      if [ "${SECURITY_ISSUES:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"security\","
        echo "      \"severity\": \"critical\","
        echo "      \"message\": \"${SECURITY_ISSUES:-0} problemas de seguridad detectados\","
        echo "      \"count\": ${SECURITY_ISSUES:-0}"
        echo "    }"
        FIRST=false
        alert_count=$((alert_count + 1))
      fi
      
      # Alerta: Archivos rotos
      if [ "${BROKEN_SVGS:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"broken_files\","
        echo "      \"severity\": \"error\","
        echo "      \"message\": \"${BROKEN_SVGS:-0} archivos SVG rotos\","
        echo "      \"count\": ${BROKEN_SVGS:-0}"
        echo "    }"
        FIRST=false
        alert_count=$((alert_count + 1))
      fi
      
      echo "  ],"
      echo "  \"total_alerts\": $alert_count"
      echo "}"
    } > "$alerts_file" 2>/dev/null || true
    
    if [ -f "$alerts_file" ]; then
      echo "$alerts_file"
      return 0
    fi
  fi
  
  return 1
}

# Detectar duplicados por contenido (hash)
detect_content_duplicates() {
  local duplicates_file="$EXPORT_DIR/content_duplicates.json"
  local duplicates_tmp=$(mktemp)
  local duplicate_count=0
  
  _log_debug "Detectando duplicados por contenido..."
  
  # Crear mapa de hashes
  declare -A hash_map
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    # Calcular hash del contenido (ignorar metadatos y comentarios)
    local content_hash=$(grep -v '^<!--' "$svg_file" 2>/dev/null | \
      grep -v '^[[:space:]]*$' | \
      sha256sum 2>/dev/null | cut -d' ' -f1 || echo "")
    
    if [ -n "$content_hash" ]; then
      if [ -z "${hash_map[$content_hash]:-}" ]; then
        hash_map[$content_hash]="$svg_file"
      else
        # Duplicado encontrado
        echo "${hash_map[$content_hash]}|${svg_file#$ROOT_DIR/}|$content_hash" >> "$duplicates_tmp"
        duplicate_count=$((duplicate_count + 1))
      fi
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if [ "$duplicate_count" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"duplicate_count\": $duplicate_count,"
      echo "  \"duplicate_groups\": ["
      
      FIRST=true
      sort "$duplicates_tmp" | while IFS='|' read -r original duplicate hash; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"original\": \"$original\","
        echo "      \"duplicate\": \"$duplicate\","
        echo "      \"hash\": \"$hash\""
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$duplicates_file" 2>/dev/null || true
    
    rm -f "$duplicates_tmp"
    
    if [ -f "$duplicates_file" ]; then
      echo "$duplicates_file"
      return 0
    fi
  else
    rm -f "$duplicates_tmp" 2>/dev/null || true
  fi
  
  return 1
}

# An√°lisis de complejidad visual
analyze_visual_complexity() {
  local complexity_file="$EXPORT_DIR/visual_complexity.json"
  local complexity_tmp=$(mktemp)
  
  _log_debug "Analizando complejidad visual..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local complexity_score=0
    
    # Contar elementos complejos
    local paths=$(grep -c '<path' "$svg_file" 2>/dev/null || echo "0")
    local groups=$(grep -c '<g' "$svg_file" 2>/dev/null || echo "0")
    local gradients=$(grep -c '<linearGradient\|<radialGradient' "$svg_file" 2>/dev/null || echo "0")
    local filters=$(grep -c '<filter' "$svg_file" 2>/dev/null || echo "0")
    local transforms=$(grep -o 'transform=' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
    
    # Calcular score de complejidad (0-100)
    complexity_score=$((paths * 2 + groups + gradients * 3 + filters * 5 + transforms))
    [ "$complexity_score" -gt 100 ] && complexity_score=100
    
    # Clasificar
    local category="simple"
    [ "$complexity_score" -gt 50 ] && category="complex"
    [ "$complexity_score" -gt 75 ] && category="very_complex"
    
    echo "${svg_file#$ROOT_DIR/}|$complexity_score|$category|$paths|$groups|$gradients|$filters|$transforms" >> "$complexity_tmp"
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(wc -l < "$complexity_tmp" | xargs)
  
  if [ "$total_files" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    # Calcular estad√≠sticas
    local avg_complexity=$(awk -F'|' '{sum+=$2; count++} END {if(count>0) print int(sum/count); else print 0}' "$complexity_tmp")
    local simple_count=$(grep -c "|simple|" "$complexity_tmp" || echo "0")
    local complex_count=$(grep -c "|complex|" "$complexity_tmp" || echo "0")
    local very_complex_count=$(grep -c "|very_complex|" "$complexity_tmp" || echo "0")
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"average_complexity\": $avg_complexity,"
      echo "    \"simple\": $simple_count,"
      echo "    \"complex\": $complex_count,"
      echo "    \"very_complex\": $very_complex_count"
      echo "  },"
      echo "  \"files\": ["
      
      FIRST=true
      sort -t'|' -k2 -nr "$complexity_tmp" | head -20 | while IFS='|' read -r file score category paths groups gradients filters transforms; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"complexity_score\": $score,"
        echo "      \"category\": \"$category\","
        echo "      \"elements\": {"
        echo "        \"paths\": $paths,"
        echo "        \"groups\": $groups,"
        echo "        \"gradients\": $gradients,"
        echo "        \"filters\": $filters,"
        echo "        \"transforms\": $transforms"
        echo "      }"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$complexity_file" 2>/dev/null || true
    
    rm -f "$complexity_tmp"
    
    if [ -f "$complexity_file" ]; then
      echo "$complexity_file"
      return 0
    fi
  fi
  
  rm -f "$complexity_tmp" 2>/dev/null || true
  return 1
}

# Generar thumbnails/previews autom√°ticos
generate_thumbnails() {
  local thumbnails_dir="$EXPORT_DIR/thumbnails"
  local thumbnails_created=0
  
  _log_debug "Generando thumbnails..."
  
  mkdir -p "$thumbnails_dir" 2>/dev/null || true
  
  # Verificar si tenemos herramientas para generar thumbnails
  if command -v convert >/dev/null 2>&1 || command -v rsvg-convert >/dev/null 2>&1; then
    while IFS= read -r svg_file; do
      [ ! -f "$svg_file" ] && continue
      
      local filename=$(basename "$svg_file" .svg)
      local thumbnail_path="$thumbnails_dir/${filename}_thumb.png"
      
      # Usar ImageMagick o librsvg
      if command -v convert >/dev/null 2>&1; then
        convert -background transparent -density 72 -resize 200x200 "$svg_file" "$thumbnail_path" 2>/dev/null && \
          thumbnails_created=$((thumbnails_created + 1)) || true
      elif command -v rsvg-convert >/dev/null 2>&1; then
        rsvg-convert -w 200 -h 200 "$svg_file" > "$thumbnail_path" 2>/dev/null && \
          thumbnails_created=$((thumbnails_created + 1)) || true
      fi
    done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | head -50)
    
    if [ "$thumbnails_created" -gt 0 ]; then
      echo "$thumbnails_dir"
      return 0
    fi
  else
    _log_debug "Herramientas de thumbnail no disponibles (ImageMagick/librsvg)"
  fi
  
  return 1
}

# An√°lisis de accesibilidad avanzado
analyze_accessibility_advanced() {
  local a11y_file="$EXPORT_DIR/accessibility_advanced.json"
  local a11y_issues=0
  local total_files=0
  
  _log_debug "Analizando accesibilidad avanzada..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    total_files=$((total_files + 1))
    local file_issues=0
    local issues_detail=()
    
    # Verificar elementos de accesibilidad
    local has_title=$(grep -q '<title>' "$svg_file" 2>/dev/null && echo "true" || echo "false")
    local has_desc=$(grep -q '<desc>' "$svg_file" 2>/dev/null && echo "true" || echo "false")
    local has_aria=$(grep -q 'aria-' "$svg_file" 2>/dev/null && echo "true" || echo "false")
    local has_role=$(grep -q 'role=' "$svg_file" 2>/dev/null && echo "true" || echo "false")
    
    # Verificar contraste (buscar colores oscuros sobre claros o viceversa)
    local text_elements=$(grep -c '<text\|<tspan' "$svg_file" 2>/dev/null || echo "0")
    
    # Contar im√°genes sin alt
    local images=$(grep -c '<image' "$svg_file" 2>/dev/null || echo "0")
    local images_with_alt=$(grep '<image' "$svg_file" 2>/dev/null | grep -c 'aria-label\|alt=' || echo "0")
    
    if [ "$images" -gt 0 ] && [ "$images" != "$images_with_alt" ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_alt_text")
    fi
    
    if [ "$has_title" = "false" ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_title")
    fi
    
    if [ "$has_desc" = "false" ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_desc")
    fi
    
    if [ "$has_aria" = "false" ] && [ "$text_elements" -gt 0 ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_aria")
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      a11y_issues=$((a11y_issues + file_issues))
      
      # Guardar para reporte
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$a11y_file.tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$a11y_file.tmp" ]; then
    local files_with_issues=$(wc -l < "$a11y_file.tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $a11y_issues,"
      echo "    \"compliance_rate\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -20 "$a11y_file.tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$a11y_file" 2>/dev/null || true
    
    rm -f "$a11y_file.tmp"
    
    if [ -f "$a11y_file" ]; then
      echo "$a11y_file"
      return 0
    fi
  fi
  
  rm -f "$a11y_file.tmp" 2>/dev/null || true
  return 1
}

# An√°lisis de uso de colores y paletas
analyze_color_usage() {
  local color_file="$EXPORT_DIR/color_usage_analysis.json"
  local color_tmp=$(mktemp)
  declare -A color_count
  
  _log_debug "Analizando uso de colores..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    # Extraer colores (hex, rgb, named)
    local colors=$(grep -oE '#[0-9a-fA-F]{3,6}|rgb\([^)]+\)|rgba\([^)]+\)|fill="[^"]*"|stroke="[^"]*"' "$svg_file" 2>/dev/null | \
      grep -oE '#[0-9a-fA-F]{3,6}|rgb\([^)]+\)|rgba\([^)]+\)' | sort | uniq)
    
    while IFS= read -r color; do
      [ -z "$color" ] && continue
      color_count[$color]=$((${color_count[$color]:-0} + 1))
      echo "$color|${svg_file#$ROOT_DIR/}" >> "$color_tmp"
    done <<< "$colors"
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_colors=${#color_count[@]}
  
  if [ "$total_colors" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"unique_colors\": $total_colors"
      echo "  },"
      echo "  \"most_used_colors\": ["
      
      FIRST=true
      for color in "${!color_count[@]}"; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"color\": \"$color\","
        echo "      \"usage_count\": ${color_count[$color]}"
        echo "    }"
        FIRST=false
      done | sort -t'"' -k6 -nr | head -20
      
      echo "  ]"
      echo "}"
    } > "$color_file" 2>/dev/null || true
    
    rm -f "$color_tmp"
    
    if [ -f "$color_file" ]; then
      echo "$color_file"
      return 0
    fi
  fi
  
  rm -f "$color_tmp" 2>/dev/null || true
  return 1
}

# Validaci√≥n de estructura SVG
validate_svg_structure() {
  local structure_file="$EXPORT_DIR/svg_structure_validation.json"
  local structure_issues=0
  local structure_tmp=$(mktemp)
  
  _log_debug "Validando estructura SVG..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_issues=0
    local issues_detail=()
    
    # Verificar que tenga tag SVG
    if ! grep -q '<svg' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_svg_tag")
    fi
    
    # Verificar que tenga xmlns
    if ! grep -q 'xmlns=' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_xmlns")
    fi
    
    # Verificar que tenga viewBox o width/height
    if ! grep -q 'viewBox=\|width=\|height=' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_dimensions")
    fi
    
    # Verificar balance de tags
    local open_tags=$(grep -o '<[^/>][^>]*>' "$svg_file" 2>/dev/null | grep -v '<!' | wc -l | xargs || echo "0")
    local close_tags=$(grep -o '</[^>]*>' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
    local self_closing=$(grep -o '<[^/>]*/>' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
    
    # Calcular diferencia (aproximada)
    local expected_closes=$((open_tags - self_closing))
    if [ "$expected_closes" -gt "$close_tags" ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("unbalanced_tags")
    fi
    
    # Verificar caracteres especiales no escapados
    if grep -qE '<[^>]*&[^a-zA-Z#]' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("unescaped_entities")
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      structure_issues=$((structure_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$structure_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$structure_tmp" ]; then
    local files_with_issues=$(wc -l < "$structure_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $structure_issues,"
      echo "    \"structure_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$structure_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$structure_file" 2>/dev/null || true
    
    rm -f "$structure_tmp"
    
    if [ -f "$structure_file" ]; then
      echo "$structure_file"
      return 0
    fi
  fi
  
  rm -f "$structure_tmp" 2>/dev/null || true
  return 1
}

# An√°lisis de uso de fuentes
analyze_font_usage() {
  local font_file="$EXPORT_DIR/font_usage_analysis.json"
  local font_tmp=$(mktemp)
  declare -A font_families
  
  _log_debug "Analizando uso de fuentes..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    # Buscar font-family en estilos y atributos
    local fonts=$(grep -oE 'font-family:\s*[^;"]+|font-family="[^"]*"' "$svg_file" 2>/dev/null | \
      sed 's/font-family:\s*//;s/font-family="//;s/"//;s/;.*//' | sort | uniq)
    
    # Buscar en @font-face
    local font_faces=$(grep -oE '@font-face[^}]+font-family[^}]+' "$svg_file" 2>/dev/null | \
      grep -oE 'font-family:\s*[^;"]+' | sed 's/font-family:\s*//' | sort | uniq)
    
    local all_fonts=$(echo -e "$fonts\n$font_faces" | sort | uniq)
    
    while IFS= read -r font; do
      [ -z "$font" ] && continue
      font_families[$font]=$((${font_families[$font]:-0} + 1))
      echo "$font|${svg_file#$ROOT_DIR/}" >> "$font_tmp"
    done <<< "$all_fonts"
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_fonts=${#font_families[@]}
  
  if [ "$total_fonts" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"unique_font_families\": $total_fonts"
      echo "  },"
      echo "  \"font_usage\": ["
      
      FIRST=true
      for font in "${!font_families[@]}"; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"font_family\": \"$font\","
        echo "      \"usage_count\": ${font_families[$font]}"
        echo "    }"
        FIRST=false
      done | sort -t'"' -k6 -nr
      
      echo "  ]"
      echo "}"
    } > "$font_file" 2>/dev/null || true
    
    rm -f "$font_tmp"
    
    if [ -f "$font_file" ]; then
      echo "$font_file"
      return 0
    fi
  fi
  
  rm -f "$font_tmp" 2>/dev/null || true
  return 1
}

# Detecci√≥n de problemas de responsive
detect_responsive_issues() {
  local responsive_file="$EXPORT_DIR/responsive_issues.json"
  local responsive_issues=0
  local responsive_tmp=$(mktemp)
  
  _log_debug "Detectando problemas de responsive..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_issues=0
    local issues_detail=()
    
    # Verificar viewBox (esencial para responsive)
    if ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_viewBox")
    fi
    
    # Verificar si tiene width y height fijos sin viewBox
    if grep -q 'width="[^"]*"\|height="[^"]*"' "$svg_file" 2>/dev/null && ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      local has_fixed_dimensions=$(grep -q 'width="[0-9]*"\|height="[0-9]*"' "$svg_file" 2>/dev/null && echo "true" || echo "false")
      if [ "$has_fixed_dimensions" = "true" ]; then
        file_issues=$((file_issues + 1))
        issues_detail+=("fixed_dimensions_without_viewBox")
      fi
    fi
    
    # Verificar uso de unidades absolutas (px) en elementos cr√≠ticos
    local px_usage=$(grep -oE '[xy]="[0-9]+"|width="[0-9]+"|height="[0-9]+"' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
    if [ "$px_usage" -gt 20 ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("excessive_absolute_units")
    fi
    
    # Verificar presencia de preserveAspectRatio
    if ! grep -q 'preserveAspectRatio=' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_preserveAspectRatio")
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      responsive_issues=$((responsive_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$responsive_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$responsive_tmp" ]; then
    local files_with_issues=$(wc -l < "$responsive_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $responsive_issues,"
      echo "    \"responsive_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$responsive_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$responsive_file" 2>/dev/null || true
    
    rm -f "$responsive_tmp"
    
    if [ -f "$responsive_file" ]; then
      echo "$responsive_file"
      return 0
    fi
  fi
  
  rm -f "$responsive_tmp" 2>/dev/null || true
  return 1
}

# An√°lisis de uso de efectos y filtros
analyze_effects_usage() {
  local effects_file="$EXPORT_DIR/effects_usage_analysis.json"
  local effects_tmp=$(mktemp)
  declare -A effect_types
  
  _log_debug "Analizando uso de efectos y filtros..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    # Detectar diferentes tipos de efectos
    if grep -q '<filter' "$svg_file" 2>/dev/null; then
      effect_types[filter]=$((${effect_types[filter]:-0} + 1))
      
      # Detectar tipos espec√≠ficos de filtros
      if grep -qi 'feGaussianBlur' "$svg_file" 2>/dev/null; then
        effect_types[blur]=$((${effect_types[blur]:-0} + 1))
      fi
      if grep -qi 'feDropShadow\|feOffset' "$svg_file" 2>/dev/null; then
        effect_types[shadow]=$((${effect_types[shadow]:-0} + 1))
      fi
      if grep -qi 'feColorMatrix' "$svg_file" 2>/dev/null; then
        effect_types[color_matrix]=$((${effect_types[color_matrix]:-0} + 1))
      fi
    fi
    
    if grep -q '<clipPath' "$svg_file" 2>/dev/null; then
      effect_types[clip_path]=$((${effect_types[clip_path]:-0} + 1))
    fi
    
    if grep -q '<mask' "$svg_file" 2>/dev/null; then
      effect_types[mask]=$((${effect_types[mask]:-0} + 1))
    fi
    
    if grep -q 'transform=' "$svg_file" 2>/dev/null; then
      effect_types[transform]=$((${effect_types[transform]:-0} + 1))
    fi
    
    if grep -q 'opacity=' "$svg_file" 2>/dev/null || grep -q 'fill-opacity\|stroke-opacity' "$svg_file" 2>/dev/null; then
      effect_types[opacity]=$((${effect_types[opacity]:-0} + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_effects=${#effect_types[@]}
  
  if [ "$total_effects" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"effects_usage\": {"
      
      FIRST=true
      for effect in "${!effect_types[@]}"; do
        [ "$FIRST" = false ] && echo ","
        echo "    \"$effect\": ${effect_types[$effect]}"
        FIRST=false
      done
      
      echo "  }"
      echo "}"
    } > "$effects_file" 2>/dev/null || true
    
    if [ -f "$effects_file" ]; then
      echo "$effects_file"
      return 0
    fi
  fi
  
  rm -f "$effects_tmp" 2>/dev/null || true
  return 1
}

# Detecci√≥n de problemas de legibilidad
detect_readability_issues() {
  local readability_file="$EXPORT_DIR/readability_issues.json"
  local readability_issues=0
  local readability_tmp=$(mktemp)
  
  _log_debug "Detectando problemas de legibilidad..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_issues=0
    local issues_detail=()
    
    # Verificar tama√±o de fuente m√≠nimo
    local font_sizes=$(grep -oE 'font-size="[^"]*"|font-size:\s*[^;"]+' "$svg_file" 2>/dev/null)
    if [ -n "$font_sizes" ]; then
      local small_fonts=$(echo "$font_sizes" | grep -oE '[0-9]+' | while read size; do
        [ "$size" -lt 12 ] && echo "small"
      done | wc -l | xargs)
      
      if [ "$small_fonts" -gt 0 ]; then
        file_issues=$((file_issues + 1))
        issues_detail+=("small_font_size")
      fi
    fi
    
    # Verificar contraste (buscar texto blanco sobre fondo claro o viceversa)
    local text_elements=$(grep -c '<text' "$svg_file" 2>/dev/null || echo "0")
    if [ "$text_elements" -gt 0 ]; then
      # Verificar si hay texto sin fill expl√≠cito (puede ser problema de contraste)
      local text_without_fill=$(grep '<text' "$svg_file" 2>/dev/null | grep -v 'fill=' | wc -l | xargs || echo "0")
      if [ "$text_without_fill" -gt 0 ]; then
        file_issues=$((file_issues + 1))
        issues_detail+=("text_without_explicit_fill")
      fi
    fi
    
    # Verificar texto con efectos que reducen legibilidad
    if grep -q '<text[^>]*filter=' "$svg_file" 2>/dev/null; then
      local text_with_filters=$(grep -c '<text[^>]*filter=' "$svg_file" 2>/dev/null || echo "0")
      if [ "$text_with_filters" -gt 0 ]; then
        # Verificar si es blur excesivo
        if grep -qi 'feGaussianBlur.*stdDeviation="[5-9]\|feGaussianBlur.*stdDeviation="[0-9][0-9]' "$svg_file" 2>/dev/null; then
          file_issues=$((file_issues + 1))
          issues_detail+=("text_with_excessive_blur")
        fi
      fi
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      readability_issues=$((readability_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$readability_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$readability_tmp" ]; then
    local files_with_issues=$(wc -l < "$readability_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $readability_issues,"
      echo "    \"readability_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$readability_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$readability_file" 2>/dev/null || true
    
    rm -f "$readability_tmp"
    
    if [ -f "$readability_file" ]; then
      echo "$readability_file"
      return 0
    fi
  fi
  
  rm -f "$readability_tmp" 2>/dev/null || true
  return 1
}

# An√°lisis de metadatos Dublin Core
analyze_dublin_core() {
  local dc_file="$EXPORT_DIR/dublin_core_analysis.json"
  local dc_count=0
  local dc_tmp=$(mktemp)
  
  _log_debug "Analizando metadatos Dublin Core..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local has_dc=false
    local dc_elements=()
    
    # Buscar elementos Dublin Core
    if grep -qi 'dc:title\|dcterms:title' "$svg_file" 2>/dev/null; then
      has_dc=true
      dc_elements+=("title")
    fi
    
    if grep -qi 'dc:creator\|dcterms:creator' "$svg_file" 2>/dev/null; then
      has_dc=true
      dc_elements+=("creator")
    fi
    
    if grep -qi 'dc:subject\|dcterms:subject' "$svg_file" 2>/dev/null; then
      has_dc=true
      dc_elements+=("subject")
    fi
    
    if grep -qi 'dc:description\|dcterms:description' "$svg_file" 2>/dev/null; then
      has_dc=true
      dc_elements+=("description")
    fi
    
    if grep -qi 'dc:date\|dcterms:date' "$svg_file" 2>/dev/null; then
      has_dc=true
      dc_elements+=("date")
    fi
    
    if grep -qi 'dc:rights\|dcterms:rights' "$svg_file" 2>/dev/null; then
      has_dc=true
      dc_elements+=("rights")
    fi
    
    if [ "$has_dc" = "true" ]; then
      dc_count=$((dc_count + 1))
      echo "${svg_file#$ROOT_DIR/}|${dc_elements[*]}" >> "$dc_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if [ "$dc_count" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_dc\": $dc_count,"
      echo "    \"dc_coverage_percent\": $([ "$total_files" -gt 0 ] && echo "$((dc_count * 100 / total_files))" || echo "0")"
      echo "  },"
      echo "  \"files_with_dc\": ["
      
      FIRST=true
      head -30 "$dc_tmp" | while IFS='|' read -r file elements; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"dc_elements\": [$(echo "$elements" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$dc_file" 2>/dev/null || true
    
    rm -f "$dc_tmp"
    
    if [ -f "$dc_file" ]; then
      echo "$dc_file"
      return 0
    fi
  fi
  
  rm -f "$dc_tmp" 2>/dev/null || true
  return 1
}

# Validaci√≥n avanzada de naming conventions
validate_naming_advanced() {
  local naming_file="$EXPORT_DIR/naming_conventions_advanced.json"
  local naming_issues=0
  local naming_tmp=$(mktemp)
  
  _log_debug "Validando naming conventions avanzado..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local filename=$(basename "$svg_file" .svg)
    local file_issues=0
    local issues_detail=()
    
    # Verificar longitud del nombre
    local name_length=${#filename}
    if [ "$name_length" -gt 100 ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("name_too_long:$name_length")
    fi
    
    if [ "$name_length" -lt 3 ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("name_too_short:$name_length")
    fi
    
    # Verificar caracteres especiales problem√°ticos
    if echo "$filename" | grep -q '[^a-z0-9_-]'; then
      file_issues=$((file_issues + 1))
      issues_detail+=("special_characters")
    fi
    
    # Verificar espacios (deber√≠an ser guiones o underscores)
    if echo "$filename" | grep -q ' '; then
      file_issues=$((file_issues + 1))
      issues_detail+=("contains_spaces")
    fi
    
    # Verificar may√∫sculas (deber√≠a ser lowercase)
    if echo "$filename" | grep -q '[A-Z]'; then
      file_issues=$((file_issues + 1))
      issues_detail+=("contains_uppercase")
    fi
    
    # Verificar nombres que empiezan o terminan con gui√≥n/underscore
    if echo "$filename" | grep -qE '^[-_]|[-_]$'; then
      file_issues=$((file_issues + 1))
      issues_detail+=("starts_or_ends_with_separator")
    fi
    
    # Verificar guiones dobles o m√∫ltiples
    if echo "$filename" | grep -qE '--|__'; then
      file_issues=$((file_issues + 1))
      issues_detail+=("multiple_separators")
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      naming_issues=$((naming_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$naming_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$naming_tmp" ]; then
    local files_with_issues=$(wc -l < "$naming_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $naming_issues,"
      echo "    \"naming_compliance_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$naming_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$naming_file" 2>/dev/null || true
    
    rm -f "$naming_tmp"
    
    if [ -f "$naming_file" ]; then
      echo "$naming_file"
      return 0
    fi
  fi
  
  rm -f "$naming_tmp" 2>/dev/null || true
  return 1
}

# An√°lisis de optimizaci√≥n potencial
analyze_optimization_potential() {
  local opt_file="$EXPORT_DIR/optimization_potential.json"
  local opt_tmp=$(mktemp)
  local total_opportunities=0
  
  _log_debug "Analizando potencial de optimizaci√≥n..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo 0)
    local size_kb=$((file_size / 1024))
    
    local opportunities=0
    local suggestions=()
    
    # Oportunidades de optimizaci√≥n
    if [ "$size_kb" -gt 50 ]; then
      opportunities=$((opportunities + 1))
      suggestions+=("large_file:${size_kb}KB")
    fi
    
    # Verificar comentarios (se pueden remover)
    local comments=$(grep -c '<!--' "$svg_file" 2>/dev/null || echo "0")
    if [ "$comments" -gt 0 ]; then
      opportunities=$((opportunities + 1))
      suggestions+=("comments:$comments")
    fi
    
    # Verificar espacios en blanco excesivos
    local blank_lines=$(grep -c '^[[:space:]]*$' "$svg_file" 2>/dev/null || echo "0")
    if [ "$blank_lines" -gt 10 ]; then
      opportunities=$((opportunities + 1))
      suggestions+=("excessive_whitespace:$blank_lines")
    fi
    
    # Verificar si hay estilos inline que podr√≠an moverse a <style>
    local inline_styles=$(grep -o 'style=' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
    if [ "$inline_styles" -gt 5 ]; then
      opportunities=$((opportunities + 1))
      suggestions+=("inline_styles:$inline_styles")
    fi
    
    # Verificar atributos redundantes
    if grep -q 'fill="black"' "$svg_file" 2>/dev/null && ! grep -q '<style>' "$svg_file" 2>/dev/null; then
      opportunities=$((opportunities + 1))
      suggestions+=("redundant_default_attributes")
    fi
    
    # Verificar paths complejos que podr√≠an simplificarse
    local complex_paths=$(grep -oE 'd="[^"]*[ML][^"]*"' "$svg_file" 2>/dev/null | \
      awk -F'[ML]' '{if(NF>20) print NF}' | wc -l | xargs || echo "0")
    if [ "$complex_paths" -gt 0 ]; then
      opportunities=$((opportunities + 1))
      suggestions+=("complex_paths:$complex_paths")
    fi
    
    if [ "$opportunities" -gt 0 ]; then
      total_opportunities=$((total_opportunities + opportunities))
      
      # Calcular potencial de reducci√≥n estimado (en %)
      local estimated_reduction=0
      [ "$comments" -gt 0 ] && estimated_reduction=$((estimated_reduction + 2))
      [ "$blank_lines" -gt 10 ] && estimated_reduction=$((estimated_reduction + 1))
      [ "$inline_styles" -gt 5 ] && estimated_reduction=$((estimated_reduction + 3))
      [ "$size_kb" -gt 50 ] && estimated_reduction=$((estimated_reduction + 5))
      
      echo "${svg_file#$ROOT_DIR/}|$opportunities|$estimated_reduction|${suggestions[*]}" >> "$opt_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$opt_tmp" ]; then
    local files_with_opportunities=$(wc -l < "$opt_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_opportunities\": $files_with_opportunities,"
      echo "    \"total_opportunities\": $total_opportunities,"
      echo "    \"average_opportunities_per_file\": $([ "$files_with_opportunities" -gt 0 ] && echo "$((total_opportunities / files_with_opportunities))" || echo "0")"
      echo "  },"
      echo "  \"files_with_opportunities\": ["
      
      FIRST=true
      sort -t'|' -k2 -nr "$opt_tmp" | head -30 | while IFS='|' read -r file opps reduction suggestions; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"optimization_opportunities\": $opps,"
        echo "      \"estimated_reduction_percent\": $reduction,"
        echo "      \"suggestions\": [$(echo "$suggestions" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$opt_file" 2>/dev/null || true
    
    rm -f "$opt_tmp"
    
    if [ -f "$opt_file" ]; then
      echo "$opt_file"
      return 0
    fi
  fi
  
  rm -f "$opt_tmp" 2>/dev/null || true
  return 1
}

# Detecci√≥n de problemas de accesibilidad de color
detect_color_accessibility() {
  local colora11y_file="$EXPORT_DIR/color_accessibility_issues.json"
  local colora11y_issues=0
  local colora11y_tmp=$(mktemp)
  
  _log_debug "Detectando problemas de accesibilidad de color..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_issues=0
    local issues_detail=()
    
    # Buscar texto con colores que pueden tener problemas de contraste
    local text_elements=$(grep -c '<text' "$svg_file" 2>/dev/null || echo "0")
    if [ "$text_elements" -gt 0 ]; then
      # Detectar texto sin fill expl√≠cito (usa color por defecto, puede ser problema)
      local text_no_fill=$(grep '<text' "$svg_file" 2>/dev/null | grep -v 'fill=' | wc -l | xargs || echo "0")
      if [ "$text_no_fill" -gt 0 ]; then
        file_issues=$((file_issues + 1))
        issues_detail+=("text_without_explicit_color:$text_no_fill")
      fi
      
      # Detectar uso de colores muy claros o muy oscuros sin contraste expl√≠cito
      local light_colors=$(grep -iE 'fill="(white|#fff|#ffffff|#f[0-9a-f]{5})' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
      local dark_colors=$(grep -iE 'fill="(black|#000|#000000|#0[0-9a-f]{5})' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
      
      # Si hay muchos colores monocrom√°ticos sin stroke para contraste
      if [ "$light_colors" -gt 5 ] || [ "$dark_colors" -gt 5 ]; then
        local has_stroke=$(grep -c 'stroke=' "$svg_file" 2>/dev/null || echo "0")
        if [ "$has_stroke" -eq 0 ]; then
          file_issues=$((file_issues + 1))
          issues_detail+=("monochromatic_without_stroke")
        fi
      fi
    fi
    
    # Buscar fondos y texto que puedan tener bajo contraste
    if grep -q '<rect[^>]*fill=' "$svg_file" 2>/dev/null && grep -q '<text' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("potential_contrast_issues")
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      colora11y_issues=$((colora11y_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$colora11y_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$colora11y_tmp" ]; then
    local files_with_issues=$(wc -l < "$colora11y_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $colora11y_issues,"
      echo "    \"color_accessibility_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$colora11y_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$colora11y_file" 2>/dev/null || true
    
    rm -f "$colora11y_tmp"
    
    if [ -f "$colora11y_file" ]; then
      echo "$colora11y_file"
      return 0
    fi
  fi
  
  rm -f "$colora11y_tmp" 2>/dev/null || true
  return 1
}

# An√°lisis de atributos data-* (metadata custom)
analyze_data_attributes() {
  local data_file="$EXPORT_DIR/data_attributes_analysis.json"
  local data_tmp=$(mktemp)
  declare -A data_attrs
  
  _log_debug "Analizando atributos data-*..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    # Extraer atributos data-*
    local data_attrs_in_file=$(grep -oE 'data-[a-zA-Z0-9_-]+="[^"]*"' "$svg_file" 2>/dev/null | \
      sed 's/=".*$//' | sort | uniq)
    
    while IFS= read -r attr; do
      [ -z "$attr" ] && continue
      data_attrs[$attr]=$((${data_attrs[$attr]:-0} + 1))
      echo "$attr|${svg_file#$ROOT_DIR/}" >> "$data_tmp"
    done <<< "$data_attrs_in_file"
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_attrs=${#data_attrs[@]}
  
  if [ "$total_attrs" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"unique_data_attributes\": $total_attrs"
      echo "  },"
      echo "  \"data_attributes\": ["
      
      FIRST=true
      for attr in "${!data_attrs[@]}"; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"attribute\": \"$attr\","
        echo "      \"usage_count\": ${data_attrs[$attr]}"
        echo "    }"
        FIRST=false
      done | sort -t'"' -k6 -nr
      
      echo "  ]"
      echo "}"
    } > "$data_file" 2>/dev/null || true
    
    rm -f "$data_tmp"
    
    if [ -f "$data_file" ]; then
      echo "$data_file"
      return 0
    fi
  fi
  
  rm -f "$data_tmp" 2>/dev/null || true
  return 1
}

# Validaci√≥n de est√°ndares SVG
validate_svg_standards() {
  local standards_file="$EXPORT_DIR/svg_standards_validation.json"
  local standards_issues=0
  local standards_tmp=$(mktemp)
  
  _log_debug "Validando est√°ndares SVG..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_issues=0
    local issues_detail=()
    
    # Verificar declaraci√≥n XML
    if ! head -1 "$svg_file" 2>/dev/null | grep -qE '<?xml|<!DOCTYPE|<svg'; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_xml_declaration")
    fi
    
    # Verificar namespace SVG
    if ! grep -q 'xmlns="http://www.w3.org/2000/svg"' "$svg_file" 2>/dev/null && \
       ! grep -q "xmlns='http://www.w3.org/2000/svg'" "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("missing_svg_namespace")
    fi
    
    # Verificar uso de elementos deprecated
    if grep -qiE '<font|font-face|glyph|hkern|vkern' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("deprecated_font_elements")
    fi
    
    # Verificar uso de atributos deprecated
    if grep -qE 'enable-background|xml:space="preserve"|xml:space='\''preserve'\''' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("deprecated_attributes")
    fi
    
    # Verificar encoding (UTF-8 recomendado)
    if head -1 "$svg_file" 2>/dev/null | grep -q 'encoding=' && \
       ! head -1 "$svg_file" 2>/dev/null | grep -qi 'utf-8'; then
      file_issues=$((file_issues + 1))
      issues_detail+=("non_utf8_encoding")
    fi
    
    # Verificar version de SVG (deber√≠a ser 1.1 o superior, o no especificada)
    if grep -q 'version=' "$svg_file" 2>/dev/null; then
      local svg_version=$(grep -oE 'version="[^"]*"' "$svg_file" 2>/dev/null | sed 's/version="//;s/"$//')
      if [ -n "$svg_version" ]; then
        local major=$(echo "$svg_version" | cut -d. -f1)
        if [ "$major" -lt 1 ]; then
          file_issues=$((file_issues + 1))
          issues_detail+=("old_svg_version:$svg_version")
        fi
      fi
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      standards_issues=$((standards_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$standards_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$standards_tmp" ]; then
    local files_with_issues=$(wc -l < "$standards_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $standards_issues,"
      echo "    \"standards_compliance_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$standards_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$standards_file" 2>/dev/null || true
    
    rm -f "$standards_tmp"
    
    if [ -f "$standards_file" ]; then
      echo "$standards_file"
      return 0
    fi
  fi
  
  rm -f "$standards_tmp" 2>/dev/null || true
  return 1
}

# Detecci√≥n de dependencias circulares
detect_circular_dependencies() {
  local circular_file="$EXPORT_DIR/circular_dependencies.json"
  local circular_count=0
  local circular_tmp=$(mktemp)
  
  _log_debug "Detectando dependencias circulares..."
  
  # An√°lisis b√°sico: buscar referencias que apuntan entre s√≠
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local filename=$(basename "$svg_file" .svg)
    local file_issues=0
    local issues_detail=()
    
    # Buscar referencias a otros archivos SVG
    local refs=$(grep -oE 'href=["'\'']([^"'\'']+\.svg)' "$svg_file" 2>/dev/null | \
      sed 's/href=["'\'']//;s/["'\'']$//' | sort | uniq)
    
    if [ -n "$refs" ]; then
      while IFS= read -r ref; do
        [ -z "$ref" ] && continue
        
        local ref_file=$(basename "$ref" .svg)
        
        # Verificar si el archivo referenciado referencia de vuelta (simplificado)
        local ref_path="$SRC_DIR/$ref"
        if [ -f "$ref_path" ]; then
          if grep -q "$filename" "$ref_path" 2>/dev/null; then
            file_issues=$((file_issues + 1))
            issues_detail+=("potential_circular:$ref_file")
          fi
        fi
      done <<< "$refs"
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      circular_count=$((circular_count + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$circular_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$circular_tmp" ]; then
    local files_with_issues=$(wc -l < "$circular_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_circular_deps\": $files_with_issues,"
      echo "    \"total_circular_references\": $circular_count"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -20 "$circular_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"circular_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$circular_file" 2>/dev/null || true
    
    rm -f "$circular_tmp"
    
    if [ -f "$circular_file" ]; then
      echo "$circular_file"
      return 0
    fi
  fi
  
  rm -f "$circular_tmp" 2>/dev/null || true
  return 1
}

# Detecci√≥n de problemas de impresi√≥n
detect_print_issues() {
  local print_file="$EXPORT_DIR/print_issues.json"
  local print_issues=0
  local print_tmp=$(mktemp)
  
  _log_debug "Detectando problemas de impresi√≥n..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_issues=0
    local issues_detail=()
    
    # Verificar dimensiones muy grandes (pueden causar problemas de impresi√≥n)
    local width=$(grep -oE 'width="([0-9]+)"' "$svg_file" 2>/dev/null | grep -oE '[0-9]+' | head -1)
    local height=$(grep -oE 'height="([0-9]+)"' "$svg_file" 2>/dev/null | grep -oE '[0-9]+' | head -1)
    
    if [ -n "$width" ] && [ "$width" -gt 10000 ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("very_large_width:$width")
    fi
    
    if [ -n "$height" ] && [ "$height" -gt 10000 ]; then
      file_issues=$((file_issues + 1))
      issues_detail+=("very_large_height:$height")
    fi
    
    # Verificar uso de colores CMYK (problem√°ticos para web, pero buenos para print)
    if grep -qiE 'color-profile|cmyk' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("cmyk_color_profile")
    fi
    
    # Verificar uso de @media print
    if grep -qi '@media print' "$svg_file" 2>/dev/null; then
      # Esto es bueno, no es un problema
      : # No hacer nada
    fi
    
    # Verificar si tiene viewBox pero no unidades f√≠sicas (puede ser problema para print)
    if grep -q 'viewBox=' "$svg_file" 2>/dev/null && ! grep -qE 'width="[0-9]+(cm|mm|in|pt)"|height="[0-9]+(cm|mm|in|pt)"' "$svg_file" 2>/dev/null; then
      file_issues=$((file_issues + 1))
      issues_detail+=("no_physical_units")
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      print_issues=$((print_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$print_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$print_tmp" ]; then
    local files_with_issues=$(wc -l < "$print_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $print_issues,"
      echo "    \"print_readiness_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$print_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$print_file" 2>/dev/null || true
    
    rm -f "$print_tmp"
    
    if [ -f "$print_file" ]; then
      echo "$print_file"
      return 0
    fi
  fi
  
  rm -f "$print_tmp" 2>/dev/null || true
  return 1
}

# An√°lisis de scripts embebidos
analyze_embedded_scripts() {
  local scripts_file="$EXPORT_DIR/embedded_scripts_analysis.json"
  local scripts_count=0
  local scripts_tmp=$(mktemp)
  
  _log_debug "Analizando scripts embebidos..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local has_scripts=false
    local script_details=()
    
    # Detectar scripts inline
    if grep -q '<script' "$svg_file" 2>/dev/null; then
      has_scripts=true
      local inline_scripts=$(grep -c '<script' "$svg_file" 2>/dev/null || echo "0")
      script_details+=("inline:$inline_scripts")
      
      # Detectar scripts externos
      local external_scripts=$(grep -oE '<script[^>]*src=["'\'']([^"'\'']+)["'\'']' "$svg_file" 2>/dev/null | wc -l | xargs || echo "0")
      if [ "$external_scripts" -gt 0 ]; then
        script_details+=("external:$external_scripts")
      fi
    fi
    
    # Detectar event handlers inline (onclick, onload, etc.)
    local event_handlers=$(grep -oE 'on[a-z]+=' "$svg_file" 2>/dev/null | sort | uniq | wc -l | xargs || echo "0")
    if [ "$event_handlers" -gt 0 ]; then
      has_scripts=true
      script_details+=("event_handlers:$event_handlers")
    fi
    
    if [ "$has_scripts" = "true" ]; then
      scripts_count=$((scripts_count + 1))
      echo "${svg_file#$ROOT_DIR/}|${script_details[*]}" >> "$scripts_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if [ "$scripts_count" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_scripts\": $scripts_count,"
      echo "    \"script_usage_percent\": $([ "$total_files" -gt 0 ] && echo "$((scripts_count * 100 / total_files))" || echo "0")"
      echo "  },"
      echo "  \"files_with_scripts\": ["
      
      FIRST=true
      head -30 "$scripts_tmp" | while IFS='|' read -r file details; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"script_types\": [$(echo "$details" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$scripts_file" 2>/dev/null || true
    
    rm -f "$scripts_tmp"
    
    if [ -f "$scripts_file" ]; then
      echo "$scripts_file"
      return 0
    fi
  fi
  
  rm -f "$scripts_tmp" 2>/dev/null || true
  return 1
}

# Validaci√≥n de integridad de im√°genes embebidas
validate_embedded_images() {
  local images_file="$EXPORT_DIR/embedded_images_validation.json"
  local images_issues=0
  local images_tmp=$(mktemp)
  
  _log_debug "Validando integridad de im√°genes embebidas..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_issues=0
    local issues_detail=()
    
    # Buscar im√°genes embebidas (base64)
    local base64_images=$(grep -oE 'data:image/[^;]+;base64,[A-Za-z0-9+/=]+' "$svg_file" 2>/dev/null)
    
    if [ -n "$base64_images" ]; then
      while IFS= read -r img_data; do
        [ -z "$img_data" ] && continue
        
        # Verificar formato v√°lido
        if ! echo "$img_data" | grep -qE '^data:image/(png|jpeg|jpg|gif|webp|svg\+xml);base64,'; then
          file_issues=$((file_issues + 1))
          issues_detail+=("invalid_base64_format")
        fi
        
        # Calcular tama√±o aproximado
        local base64_content=$(echo "$img_data" | sed 's/^data:image[^;]*;base64,//')
        local size_approx=$(echo -n "$base64_content" | wc -c | xargs)
        local size_kb=$((size_approx * 3 / 4 / 1024))
        
        if [ "$size_kb" -gt 500 ]; then
          file_issues=$((file_issues + 1))
          issues_detail+=("large_embedded_image:${size_kb}KB")
        fi
      done <<< "$base64_images"
    fi
    
    # Buscar referencias a im√°genes externas rotas
    local image_refs=$(grep -oE '<image[^>]*href=["'\'']([^"'\'']+)["'\'']' "$svg_file" 2>/dev/null | \
      sed 's/.*href=["'\'']//;s/["'\'']$//')
    
    if [ -n "$image_refs" ]; then
      while IFS= read -r img_ref; do
        [ -z "$img_ref" ] && continue
        
        # Si es relativo, verificar si existe
        if echo "$img_ref" | grep -qE '^\.\.?/'; then
          local img_path="$SRC_DIR/$img_ref"
          if [ ! -f "$img_path" ]; then
            file_issues=$((file_issues + 1))
            issues_detail+=("broken_image_reference:$img_ref")
          fi
        fi
      done <<< "$image_refs"
    fi
    
    if [ "$file_issues" -gt 0 ]; then
      images_issues=$((images_issues + file_issues))
      echo "${svg_file#$ROOT_DIR/}|$file_issues|${issues_detail[*]}" >> "$images_tmp"
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  local total_files=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if command -v jq >/dev/null 2>&1 && [ -f "$images_tmp" ]; then
    local files_with_issues=$(wc -l < "$images_tmp" | xargs)
    
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"statistics\": {"
      echo "    \"total_files\": $total_files,"
      echo "    \"files_with_issues\": $files_with_issues,"
      echo "    \"total_issues\": $images_issues,"
      echo "    \"images_integrity_score\": $([ "$total_files" -gt 0 ] && echo "$((100 - (files_with_issues * 100 / total_files)))" || echo "100")"
      echo "  },"
      echo "  \"files_with_issues\": ["
      
      FIRST=true
      head -30 "$images_tmp" | while IFS='|' read -r file count issues; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"issue_count\": $count,"
        echo "      \"issues\": [$(echo "$issues" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')]"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$images_file" 2>/dev/null || true
    
    rm -f "$images_tmp"
    
    if [ -f "$images_file" ]; then
      echo "$images_file"
      return 0
    fi
  fi
  
  rm -f "$images_tmp" 2>/dev/null || true
  return 1
}

# Validar dependencias cr√≠ticas al inicio
check_dependencies() {
  local missing=()
  local tools=("find" "grep" "awk" "sort")
  
  for tool in "${tools[@]}"; do
    if ! command -v "$tool" >/dev/null 2>&1; then
      missing+=("$tool")
    fi
  done
  
  if [ ${#missing[@]} -gt 0 ]; then
    echo "‚ùå ERROR: Dependencias faltantes: ${missing[*]}" >&2
    exit 1
  fi
  
  # Herramientas opcionales pero recomendadas
  [ ! -x "$(command -v svgo)" ] && [ "${QUIET:-false}" != "true" ] && \
    echo "‚ö†Ô∏è  ADVERTENCIA: svgo no encontrado. Optimizaciones deshabilitadas." >&2
  [ ! -x "$(command -v jq)" ] && [ "${GENERATE_JUNIT:-false}" = "true" ] && \
    echo "‚ö†Ô∏è  ADVERTENCIA: jq recomendado para mejor salida JSON/XML." >&2
}

check_dependencies

# Funciones auxiliares mejoradas
log_info() {
  local msg="$1"
  echo "$msg" >> "$REPORT"
  [ "${QUIET:-false}" != "true" ] && echo "$msg"
}

log_section() {
  local section="$1"
  local section_start=$(date +%s)
echo "" >> "$REPORT"
  echo "$section" >> "$REPORT"
  echo "--------------------------------" >> "$REPORT"
  [ "${QUIET:-false}" != "true" ] && echo "$section"
  SECTION_START_TIME=$section_start
}

log_section_end() {
  local section_name="${1:-Secci√≥n}"
  if [ -n "${SECTION_START_TIME:-}" ]; then
    local section_end=$(date +%s)
    local section_duration=$((section_end - SECTION_START_TIME))
    SECTION_TIMES+=("$section_name:$section_duration")
    [ "${QUIET:-false}" != "true" ] && [ "${SHOW_PROGRESS:-true}" = "true" ] && \
      echo "  ‚úì $section_name completado en ${section_duration}s" >&2
  fi
}

# Progress indicator
show_progress() {
  if [ "${SHOW_PROGRESS:-true}" = "true" ] && [ "${QUIET:-false}" != "true" ]; then
    local current="$1"
    local total="$2"
    local label="${3:-Procesando}"
    if [ "$total" -gt 0 ]; then
      local percent=$((current * 100 / total))
      local bar_length=30
      local filled=$((current * bar_length / total))
      local bar=$(printf "%${filled}s" | tr ' ' '=')
      local empty=$(printf "%$((bar_length - filled))s" | tr ' ' '-')
      printf "\r  $label: [%s%s] %d%% (%d/%d)" "$bar" "$empty" "$percent" "$current" "$total" >&2
      [ "$current" -eq "$total" ] && echo >&2
    fi
  fi
}

# Cache functions
cache_key() {
  local key="$1"
  if command -v md5 >/dev/null 2>&1; then
    echo "$CACHE_DIR/$(echo "$key" | md5 -q).cache"
  elif command -v md5sum >/dev/null 2>&1; then
    echo "$CACHE_DIR/$(echo "$key" | md5sum | cut -d' ' -f1).cache"
  else
    echo "$CACHE_DIR/$(echo "$key" | shasum -a 256 | cut -d' ' -f1).cache"
  fi
}

cache_get() {
  local key="$1"
  local cache_file=$(cache_key "$key")
  if [ "${USE_CACHE:-true}" = "true" ] && [ -f "$cache_file" ]; then
    local cache_age
    if command -v stat >/dev/null 2>&1; then
      if stat -f %m "$cache_file" >/dev/null 2>&1; then
        cache_age=$(($(date +%s) - $(stat -f %m "$cache_file")))
      else
        cache_age=$(($(date +%s) - $(stat -c %Y "$cache_file" 2>/dev/null || echo 0)))
      fi
    else
      return 1
    fi
    # Cache v√°lido por 1 hora
    if [ "${cache_age:-999999}" -lt 3600 ]; then
      cat "$cache_file"
      return 0
    fi
  fi
  return 1
}

cache_set() {
  local key="$1"
  local value="$2"
  local cache_file=$(cache_key "$key")
  if [ "${USE_CACHE:-true}" = "true" ]; then
    echo "$value" > "$cache_file"
  fi
}

# Auto-repair functions
auto_repair_empty_svgs() {
  local count=0
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ ! -s "$svg_file" ]; then
      if [ "${AUTO_REPAIR:-false}" = "true" ]; then
        # Intentar recuperar desde git si es posible
        if git rev-parse --git-dir >/dev/null 2>&1; then
          if git checkout -- "$svg_file" 2>/dev/null; then
            log_info "  ‚úì Reparado desde git: ${svg_file#$ROOT_DIR/}"
            count=$((count + 1))
          else
            log_info "  ‚ö†Ô∏è  No se pudo reparar: ${svg_file#$ROOT_DIR/}"
          fi
        else
          log_info "  ‚ö†Ô∏è  No se pudo reparar (- sin git): ${svg_file#$ROOT_DIR/}"
        fi
      fi
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -size 0 -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)
  echo $count
}

count_files() {
  local pattern="$1"
  local dir="${2:-$ROOT_DIR}"
  local cache_key="count_${pattern}_${dir}"
  
  if cache_get "$cache_key" >/dev/null 2>&1; then
    cache_get "$cache_key"
    return 0
  fi
  
  local count=$(find "$dir" -name "$pattern" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
  cache_set "$cache_key" "$count"
  echo "$count"
}

# Sistema de cach√© incremental
CACHE_DIR="${CACHE_DIR:-$ROOT_DIR/.cache/analyze_assets}"
CACHE_FILE="$CACHE_DIR/metadata.json"
CACHE_VALIDITY="${CACHE_VALIDITY:-3600}" # 1 hora por defecto

init_cache() {
  if [ "${USE_CACHE:-true}" = "true" ]; then
    mkdir -p "$CACHE_DIR"
    [ ! -f "$CACHE_FILE" ] && echo '{}' > "$CACHE_FILE"
  fi
}

get_cached() {
  local key="$1"
  if [ "${USE_CACHE:-true}" = "true" ] && [ -f "$CACHE_FILE" ]; then
    if command -v jq >/dev/null 2>&1; then
      local cached_time=$(jq -r ".${key}.timestamp // 0" "$CACHE_FILE" 2>/dev/null || echo "0")
      local now=$(date +%s)
      if [ "$((now - cached_time))" -lt "$CACHE_VALIDITY" ]; then
        jq -r ".${key}.value // empty" "$CACHE_FILE" 2>/dev/null
        return 0
      fi
    fi
  fi
  return 1
}

set_cached() {
  local key="$1"
  local value="$2"
  if [ "${USE_CACHE:-true}" = "true" ] && [ -f "$CACHE_FILE" ] && command -v jq >/dev/null 2>&1; then
    local tmp=$(mktemp)
    jq ".${key} = {timestamp: $(date +%s), value: ${value}}" "$CACHE_FILE" > "$tmp" 2>/dev/null && mv "$tmp" "$CACHE_FILE"
  fi
}

# Barras de progreso
PROGRESS_STEPS=0
PROGRESS_CURRENT=0

init_progress() {
  local total="$1"
  PROGRESS_STEPS=$total
  PROGRESS_CURRENT=0
}

show_progress() {
  local step="$1"
  local message="${2:-}"
  if [ "${SHOW_PROGRESS:-true}" = "true" ] && [ "$PROGRESS_STEPS" -gt 0 ]; then
    PROGRESS_CURRENT=$step
    local percent=$((PROGRESS_CURRENT * 100 / PROGRESS_STEPS))
    local filled=$((percent / 2))
    local empty=$((50 - filled))
    printf "\r[%s%s] %d%% %s" "$(printf '%*s' "$filled" | tr ' ' '#')" "$(printf '%*s' "$empty" | tr ' ' '.')" "$percent" "$message" >&2
    [ "$step" -eq "$PROGRESS_STEPS" ] && echo "" >&2
  fi
}

# Cargar configuraci√≥n de umbrales si existe
load_config() {
  local config="${CONFIG_FILE:-$ROOT_DIR/tools/analyze_assets.config.json}"
  if [ -f "$config" ] && command -v jq >/dev/null 2>&1; then
    MAX_DOM_NODES=$(jq -r '.thresholds.max_dom_nodes // 500' "$config" 2>/dev/null || echo "$MAX_DOM_NODES")
    MAX_FILTERS=$(jq -r '.thresholds.max_filters // 5' "$config" 2>/dev/null || echo "$MAX_FILTERS")
    MAX_GRADIENTS=$(jq -r '.thresholds.max_gradients // 10' "$config" 2>/dev/null || echo "$MAX_GRADIENTS")
    MIN_HEALTH_SCORE=$(jq -r '.thresholds.min_health_score // 75' "$config" 2>/dev/null || echo "$MIN_HEALTH_SCORE")
    CACHE_VALIDITY=$(jq -r '.cache.validity_seconds // 3600' "$config" 2>/dev/null || echo "$CACHE_VALIDITY")
    log_info "‚úÖ Configuraci√≥n cargada desde: $config"
  fi
}

# An√°lisis de diffs con reportes anteriores
diff_analysis() {
  if [ "${DIFF_MODE:-false}" = "true" ]; then
    local prev_report=$(find "$(dirname "$REPORT")" -name "assets_report_*.txt" -not -name "$(basename "$REPORT")" -type f 2>/dev/null | sort -r | head -1)
    if [ -n "$prev_report" ] && [ -f "$prev_report" ]; then
      log_section "üìä An√°lisis de Diferencias"
      
      local prev_total=$(grep -oP 'Total de assets SVG: \K\d+' "$prev_report" 2>/dev/null || echo "0")
      local prev_score=$(grep -oP 'Health Score:\s+\K\d+' "$prev_report" 2>/dev/null || echo "0")
      
      local diff_total=$((TOTAL_SVGS - prev_total))
      local diff_score=$((HEALTH_SCORE - prev_score))
      
      [ "$diff_total" -gt 0 ] && log_info "üìà +$diff_total SVGs nuevos"
      [ "$diff_total" -lt 0 ] && log_info "üìâ $diff_total SVGs eliminados"
      [ "$diff_total" -eq 0 ] && log_info "‚û°Ô∏è  Sin cambios en cantidad"
      
      [ "$diff_score" -gt 5 ] && log_info "‚úÖ Health Score mejor√≥ +$diff_score puntos"
      [ "$diff_score" -lt -5 ] && log_info "‚ö†Ô∏è  Health Score baj√≥ $diff_score puntos"
      [ "$diff_score" -ge -5 ] && [ "$diff_score" -le 5 ] && log_info "‚û°Ô∏è  Health Score estable (¬±5 puntos)"
    fi
  fi
}

# Env√≠o de alertas a Slack/Teams
send_alert() {
  local level="$1"  # "info", "warning", "error"
  local message="$2"
  
  if [ -n "${SLACK_WEBHOOK:-}" ]; then
    local color="good"
    [ "$level" = "warning" ] && color="warning"
    [ "$level" = "error" ] && color="danger"
    
    curl -s -X POST "$SLACK_WEBHOOK" \
      -H 'Content-type: application/json' \
      --data "{\"attachments\":[{\"color\":\"$color\",\"text\":\"$message\",\"footer\":\"Asset Analyzer\",\"ts\":$(date +%s)}]}" >/dev/null 2>&1 || true
  fi
  
  if [ -n "${TEAMS_WEBHOOK:-}" ]; then
    local themeColor="28a745"
    [ "$level" = "warning" ] && themeColor="ffc107"
    [ "$level" = "error" ] && themeColor="dc3545"
    
    curl -s -X POST "$TEAMS_WEBHOOK" \
      -H 'Content-type: application/json' \
      --data "{\"@type\":\"MessageCard\",\"@context\":\"https://schema.org/extensions\",\"themeColor\":\"$themeColor\",\"summary\":\"Asset Analysis\",\"sections\":[{\"activityTitle\":\"Asset Analyzer\",\"text\":\"$message\"}]}" >/dev/null 2>&1 || true
  fi
}

# Inicializar sistemas
init_cache
load_config

# Iniciar reporte
{
  echo "üìä An√°lisis de Assets - Reporte Completo"
  echo "========================================"
  echo "Fecha: $(date '+%Y-%m-%d %H:%M:%S')"
  echo "Directorio ra√≠z: $ROOT_DIR"
  echo ""
} > "$REPORT"

# Resumen ejecutivo
log_section "üìä RESUMEN EJECUTIVO"

# Usar cach√© para conteo de SVGs (operaci√≥n costosa)
TOTAL_SVGS=$(get_cached "total_svgs" 2>/dev/null)
if [ -z "$TOTAL_SVGS" ] || [ "$TOTAL_SVGS" = "null" ] || [ "$TOTAL_SVGS" = "0" ]; then
  if [ "${SHOW_PROGRESS:-true}" = "true" ]; then
    echo "Contando SVGs..." >&2
  fi
  TOTAL_SVGS=$(find "$ROOT_DIR" -name "*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
  set_cached "total_svgs" "$TOTAL_SVGS" 2>/dev/null || true
fi
log_info "Total de assets SVG: $TOTAL_SVGS"

# Contar SVGs por categor√≠a
log_section "üìÅ Archivos SVG por categor√≠a"

# Instagram
if [ -d "$SRC_DIR" ]; then
  INSTAGRAM_FEED=$(find "$SRC_DIR/1080x1080" -name "*.svg" -not -path "*/carousel/*" -not -path "*/variants/*" 2>/dev/null | wc -l | xargs)
  INSTAGRAM_ADS=$(find "$SRC_DIR/1080x1350" -name "*.svg" 2>/dev/null | wc -l | xargs)
  INSTAGRAM_STORIES=$(find "$SRC_DIR/1080x1920" -name "*.svg" 2>/dev/null | wc -l | xargs)
  INSTAGRAM_REELS=$(find "$SRC_DIR/reels" -name "*.svg" 2>/dev/null | wc -l | xargs)
  INSTAGRAM_HIGHLIGHTS=$(find "$SRC_DIR/highlights" -name "*.svg" 2>/dev/null | wc -l | xargs)
  INSTAGRAM_CAROUSEL=$(find "$SRC_DIR/1080x1080/carousel" -name "*.svg" 2>/dev/null | wc -l | xargs)
  INSTAGRAM_VARIANTS=$(find "$SRC_DIR/1080x1080/variants" -name "*.svg" 2>/dev/null | wc -l | xargs)
  
  log_info "  üì± Instagram Feed 1080x1080: $INSTAGRAM_FEED"
  log_info "  üì± Instagram Ads 1080x1350: $INSTAGRAM_ADS"
  log_info "  üì± Instagram Stories 1080x1920: $INSTAGRAM_STORIES"
  log_info "  üì± Instagram Reels: $INSTAGRAM_REELS"
  log_info "  üì± Instagram Highlights: $INSTAGRAM_HIGHLIGHTS"
  log_info "  üì± Instagram Carrusel: $INSTAGRAM_CAROUSEL"
  log_info "  üì± Instagram Variantes: $INSTAGRAM_VARIANTS"
fi

# LinkedIn
LINKEDIN_DIR="$ROOT_DIR/ads/linkedin"
if [ -d "$LINKEDIN_DIR" ]; then
  LINKEDIN_COUNT=$(find "$LINKEDIN_DIR" -name "*.svg" -not -name "tokens.json" 2>/dev/null | wc -l | xargs)
  log_info "  üíº LinkedIn (todos): $LINKEDIN_COUNT"
fi

# Webinars
WEBINAR_DIR="$ROOT_DIR/design/webinars"
if [ -d "$WEBINAR_DIR" ]; then
  WEBINAR_ORG=$(find "$WEBINAR_DIR" -name "*.svg" 2>/dev/null | wc -l | xargs)
  log_info "  üé• Webinars (organizados): $WEBINAR_ORG"
fi
WEBINAR_ROOT=$(find "$ROOT_DIR" -maxdepth 1 -name "webinar-*.svg" 2>/dev/null | wc -l | xargs)
if [ "$WEBINAR_ROOT" -gt 0 ]; then
  log_info "  üé• Webinars (ra√≠z): $WEBINAR_ROOT"
fi

# An√°lisis de tama√±os
log_section "üíæ An√°lisis de Tama√±os"

if [ -d "$SRC_DIR" ]; then
TOTAL_SIZE=$(find "$SRC_DIR" -name "*.svg" -exec du -ch {} + 2>/dev/null | tail -1 | cut -f1)
  log_info "Tama√±o total SVG (Instagram): $TOTAL_SIZE"
  
  # Tama√±o promedio
  SVG_FILES=$(find "$SRC_DIR" -name "*.svg" 2>/dev/null | head -20)
  if [ -n "$SVG_FILES" ]; then
    AVG_SIZE=$(find "$SRC_DIR" -name "*.svg" -exec stat -f%z {} \; 2>/dev/null | awk '{sum+=$1; count++} END {if(count>0) printf "%.0f", sum/count/1024}' || echo "N/A")
    log_info "Tama√±o promedio SVG: ${AVG_SIZE}KB"
  fi
fi

# PNG exportados
if [ -d "$EXPORT_DIR/png/1x" ]; then
  PNG_COUNT=$(find "$EXPORT_DIR/png/1x" -name "*.png" 2>/dev/null | wc -l | xargs)
  PNG_SIZE=$(find "$EXPORT_DIR/png/1x" -name "*.png" -exec du -ch {} + 2>/dev/null | tail -1 | cut -f1)
  log_info "üì∏ PNG exportados (1x): $PNG_COUNT archivos, $PNG_SIZE total"
fi

if [ -d "$EXPORT_DIR/png/2x" ]; then
  PNG_2X_COUNT=$(find "$EXPORT_DIR/png/2x" -name "*.png" 2>/dev/null | wc -l | xargs)
  PNG_2X_SIZE=$(find "$EXPORT_DIR/png/2x" -name "*.png" -exec du -ch {} + 2>/dev/null | tail -1 | cut -f1)
  log_info "üì∏ PNG exportados (2x): $PNG_2X_COUNT archivos, $PNG_2X_SIZE total"
fi

# Verificar tokens
if [ -f "$SRC_DIR/tokens.json" ]; then
  if grep -q "tu-sitio.com\|@tu_marca" "$SRC_DIR/tokens.json"; then
    echo "‚ö†Ô∏è  Tokens a√∫n con valores por defecto" >> "$REPORT"
  else
    echo "‚úÖ Tokens configurados" >> "$REPORT"
  fi
else
  echo "‚ùå tokens.json no encontrado" >> "$REPORT"
fi
echo "" >> "$REPORT"

# Verificar placeholders de logo
if [ -d "$SRC_DIR" ]; then
  LOGO_COUNT=$(grep -r "LOGO\|logo-placeholder" "$SRC_DIR" --include="*.svg" 2>/dev/null | wc -l | xargs)
  log_info "üñºÔ∏è  Placeholders de logo encontrados: $LOGO_COUNT"
fi

# Verificar SVGs vac√≠os o rotos
EMPTY_SVGS=$(find "$ROOT_DIR" -name "*.svg" -size 0 -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
if [ "$EMPTY_SVGS" -gt 0 ]; then
  echo "‚ö†Ô∏è  SVGs vac√≠os detectados: $EMPTY_SVGS" >> "$REPORT"
  find "$ROOT_DIR" -name "*.svg" -size 0 -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -5 | while read -r f; do
    echo "    - ${f#$ROOT_DIR/}" >> "$REPORT"
  done
echo "" >> "$REPORT"
fi

# Verificar rutas rotas en preview
if [ -f "$EXPORT_DIR/preview/index.html" ]; then
  MISSING_PATHS=$(grep -oE '\.\./.*\.svg' "$EXPORT_DIR/preview/index.html" 2>/dev/null | while read -r rel_path; do
    abs_path="$EXPORT_DIR/preview/$rel_path"
    if [ ! -f "$abs_path" ]; then
      echo "$rel_path"
    fi
  done | wc -l | xargs)
  if [ "$MISSING_PATHS" -gt 0 ]; then
    log_info "‚ö†Ô∏è  Rutas rotas en preview: $MISSING_PATHS"
  else
    log_info "‚úÖ No se encontraron rutas rotas en preview"
  fi
fi

# Archivos cr√≠ticos
log_section "‚úÖ Verificaci√≥n de archivos cr√≠ticos"
CRITICAL_FILES=("1080x1080/ig_descuento_curso_ia.svg" "1080x1920/ig_story_descuento_curso_ia.svg")
for f in "${CRITICAL_FILES[@]}"; do
  if [ -f "$SRC_DIR/$f" ]; then
    log_info "  ‚úÖ $f"
  else
    log_info "  ‚ùå $f (FALTA)"
  fi
done

# Estad√≠sticas adicionales
log_section "üìà Estad√≠sticas adicionales"

# Contar tokens no aplicados
if [ -d "$SRC_DIR" ] && [ -f "$SRC_DIR/tokens.json" ]; then
  TOKENS_NOT_USED=$(grep -roh "{{.*}}" "$SRC_DIR" --include="*.svg" 2>/dev/null | sort -u | wc -l | xargs)
  if [ "$TOKENS_NOT_USED" -gt 0 ]; then
    log_info "‚ö†Ô∏è  Tokens sin aplicar: $TOKENS_NOT_USED"
  else
    log_info "‚úÖ Todos los tokens aplicados"
  fi
fi

# Contar assets con QR placeholder
if [ -d "$SRC_DIR" ]; then
QR_PLACEHOLDERS=$(grep -r "qr-placeholder\|QR_PLACEHOLDER" "$SRC_DIR" --include="*.svg" 2>/dev/null | wc -l | xargs)
  log_info "üì± Assets con QR placeholder: $QR_PLACEHOLDERS"
fi

# Contar assets con safe area
if [ -d "$SRC_DIR" ]; then
SAFE_AREAS=$(grep -r "safe-area\|safeArea" "$SRC_DIR" --include="*.svg" 2>/dev/null | wc -l | xargs)
  log_info "üìê Assets con safe area: $SAFE_AREAS"
fi

# An√°lisis de UTMs y tracking
log_section "üîó An√°lisis de UTMs y Tracking"

# Verificar CSVs de tracking
CSV_MASTER="$ROOT_DIR/TEMPLATES_MASTER_CALENDAR.csv"
CSV_IG="$ROOT_DIR/INSTAGRAM_CALENDAR_UTM.csv"
CSV_LINKEDIN="$ROOT_DIR/META_DCO_FEED_TEMPLATE.csv"

CSV_FOUND=0
if [ -f "$CSV_MASTER" ]; then
  CSV_COUNT=$(tail -n +2 "$CSV_MASTER" 2>/dev/null | wc -l | xargs)
  log_info "‚úÖ CSV Maestro encontrado: $CSV_COUNT registros"
  CSV_FOUND=$((CSV_FOUND + 1))
fi
if [ -f "$CSV_IG" ]; then
  CSV_COUNT=$(tail -n +2 "$CSV_IG" 2>/dev/null | wc -l | xargs)
  log_info "‚úÖ CSV Instagram: $CSV_COUNT registros"
  CSV_FOUND=$((CSV_FOUND + 1))
fi
if [ -f "$CSV_LINKEDIN" ]; then
  CSV_COUNT=$(tail -n +2 "$CSV_LINKEDIN" 2>/dev/null | wc -l | xargs)
  log_info "‚úÖ CSV LinkedIn DCO: $CSV_COUNT registros"
  CSV_FOUND=$((CSV_FOUND + 1))
fi

if [ "$CSV_FOUND" -eq 0 ]; then
  log_info "‚ö†Ô∏è  Ning√∫n CSV de tracking encontrado"
fi

# Verificar URLs con UTMs en SVGs
log_section "üîó URLs con UTMs en templates"

# Contar usando find + grep (bash no maneja variables en pipes bien)
SVGS_WITH_URLS=$(grep -rl 'href.*http' "$ROOT_DIR" --include="*.svg" 2>/dev/null | grep -v node_modules | grep -v .git | wc -l | xargs)
SVGS_WITH_UTMS=$(grep -rl 'utm_source\|utm_campaign\|utm_content' "$ROOT_DIR" --include="*.svg" 2>/dev/null | grep -v node_modules | grep -v .git | wc -l | xargs)
SVGS_DEFAULT_URL=$(grep -rl 'tu-sitio\.com\|tusitio\.com\|example\.com' "$ROOT_DIR" --include="*.svg" 2>/dev/null | grep -v node_modules | grep -v .git | wc -l | xargs)

if [ "$SVGS_WITH_URLS" -gt 0 ]; then
  log_info "üìä SVGs con URLs: $SVGS_WITH_URLS"
  log_info "    ‚úÖ Con UTMs: $SVGS_WITH_UTMS"
  
  SVGS_NO_UTMS=$((SVGS_WITH_URLS - SVGS_WITH_UTMS))
  if [ "$SVGS_NO_UTMS" -gt 0 ]; then
    log_info "    ‚ö†Ô∏è  Sin UTMs: $SVGS_NO_UTMS"
  fi
  
  if [ "$SVGS_DEFAULT_URL" -gt 0 ]; then
    log_info "    ‚ö†Ô∏è  Con URL por defecto (necesita actualizaci√≥n): $SVGS_DEFAULT_URL"
  fi
else
  log_info "‚ÑπÔ∏è  No se encontraron SVGs con URLs"
fi

# Verificar naming consistency con utm_content
log_section "üìù Verificaci√≥n naming vs utm_content"

if [ -f "$CSV_MASTER" ]; then
  NAMING_MISMATCH=0
  while IFS=',' read -r fecha plataforma template producto angulo cta dimensiones utm_campaign utm_content utm_term filename rest; do
    # Skip header
    if [ "$template" = "template" ] || [ -z "$template" ]; then
      continue
    fi
    # Verificar que filename contiene template y version (aproximado)
    if [ -n "$filename" ] && [ -n "$utm_content" ]; then
      # Filename deber√≠a contener al menos parte de utm_content
      if ! echo "$filename" | grep -qi "$template"; then
        NAMING_MISMATCH=$((NAMING_MISMATCH + 1))
      fi
    fi
  done < "$CSV_MASTER" 2>/dev/null
  
  if [ "$NAMING_MISMATCH" -eq 0 ]; then
    log_info "‚úÖ Naming coherente con utm_content"
  else
    log_info "‚ö†Ô∏è  Posibles inconsistencias: $NAMING_MISMATCH (revisar manualmente)"
  fi
fi

# An√°lisis de formato por dimensi√≥n
log_section "üìä An√°lisis de formato por dimensi√≥n"

# LinkedIn Ads por formato
if [ -d "$LINKEDIN_DIR" ]; then
  COUNT_1200x627=$(find "$LINKEDIN_DIR" -name "*1200x627*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_1080x1080=$(find "$LINKEDIN_DIR" -name "*1080x1080*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_1080x1920=$(find "$LINKEDIN_DIR" -name "*1080x1920*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_CAROUSEL=$(find "$LINKEDIN_DIR" -name "carousel_*.svg" 2>/dev/null | wc -l | xargs)
  
  log_info "  LinkedIn 1200√ó627 (Rectangular): $COUNT_1200x627"
  log_info "  LinkedIn 1080√ó1080 (Square): $COUNT_1080x1080"
  log_info "  LinkedIn 1080√ó1920 (Vertical): $COUNT_1080x1920"
  log_info "  Carousels: $COUNT_CAROUSEL"
fi

# Webinars por tipo
WEBINAR_COUNT=$(find "$ROOT_DIR" -maxdepth 1 -name "webinar-preroll-*.svg" 2>/dev/null | wc -l | xargs)
if [ "$WEBINAR_COUNT" -gt 0 ]; then
  log_info "  Webinar Prerolls: $WEBINAR_COUNT"
  
  # Analizar tipos de preroll
  PREROLL_SOCIAL=$(find "$ROOT_DIR" -maxdepth 1 -name "webinar-preroll-*social*.svg" 2>/dev/null | wc -l | xargs)
  PREROLL_BENEFITS=$(find "$ROOT_DIR" -maxdepth 1 -name "webinar-preroll-*benefits*.svg" 2>/dev/null | wc -l | xargs)
  PREROLL_URGENT=$(find "$ROOT_DIR" -maxdepth 1 -name "webinar-preroll-*urgent*.svg" 2>/dev/null | wc -l | xargs)
  
  [ "$PREROLL_SOCIAL" -gt 0 ] && log_info "    - Social proof: $PREROLL_SOCIAL"
  [ "$PREROLL_BENEFITS" -gt 0 ] && log_info "    - Benefits: $PREROLL_BENEFITS"
  [ "$PREROLL_URGENT" -gt 0 ] && log_info "    - Urgent: $PREROLL_URGENT"
fi

# Verificar naming consistency
log_section "üîç Verificaci√≥n de naming consistency"

# Buscar archivos que no siguen convenci√≥n
if [ -d "$LINKEDIN_DIR" ]; then
  INCONSISTENT_NAMES=$(find "$LINKEDIN_DIR" -name "*.svg" ! -name "ad_*" ! -name "carousel_*" 2>/dev/null | wc -l | xargs)
  if [ "$INCONSISTENT_NAMES" -gt 0 ]; then
    log_info "‚ö†Ô∏è  $INCONSISTENT_NAMES archivos con naming inconsistente"
    find "$LINKEDIN_DIR" -name "*.svg" ! -name "ad_*" ! -name "carousel_*" 2>/dev/null | head -5 | while read -r f; do
      log_info "    - ${f#$LINKEDIN_DIR/}"
    done
  else
    log_info "‚úÖ Naming consistente"
  fi
fi

# Resumen de productos
log_section "üì¶ Creativos por producto"
if [ -d "$LINKEDIN_DIR" ]; then
  COUNT_IABULK=$(find "$LINKEDIN_DIR" -name "*ia_bulk*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_CURSO=$(find "$LINKEDIN_DIR" -name "*curso*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_SAAS=$(find "$LINKEDIN_DIR" -name "*saas*.svg" 2>/dev/null | wc -l | xargs)
  
  log_info "IA Bulk: $COUNT_IABULK"
  log_info "Curso IA: $COUNT_CURSO"
  log_info "SaaS IA Marketing: $COUNT_SAAS"
fi

# An√°lisis de √°ngulos por plataforma
echo "" >> "$REPORT"
echo "üéØ An√°lisis de √°ngulos por template:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

# LinkedIn: contar por √°ngulo
if [ -d "$LINKEDIN_DIR" ]; then
  COUNT_URGENCY=$(find "$LINKEDIN_DIR" -name "*urgency*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_SOCIAL=$(find "$LINKEDIN_DIR" -name "*social*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_METRICS=$(find "$LINKEDIN_DIR" -name "*metrics*.svg" 2>/dev/null | wc -l | xargs)
  COUNT_V2=$(find "$LINKEDIN_DIR" -name "*_v2.svg" 2>/dev/null | wc -l | xargs)
  
  echo "  LinkedIn √°ngulos:" >> "$REPORT"
  [ "$COUNT_URGENCY" -gt 0 ] && echo "    - Urgency: $COUNT_URGENCY" >> "$REPORT"
  [ "$COUNT_SOCIAL" -gt 0 ] && echo "    - Social Proof: $COUNT_SOCIAL" >> "$REPORT"
  [ "$COUNT_METRICS" -gt 0 ] && echo "    - Metrics: $COUNT_METRICS" >> "$REPORT"
  [ "$COUNT_V2" -gt 0 ] && echo "    - V2 (variantes): $COUNT_V2" >> "$REPORT"
fi

# Instagram templates
IG_TEMPLATES=$(find "$ROOT_DIR" -maxdepth 1 -name "instagram_*.svg" 2>/dev/null | wc -l | xargs)
if [ "$IG_TEMPLATES" -gt 0 ]; then
  echo "  Instagram templates: $IG_TEMPLATES" >> "$REPORT"
fi

# Verificar coherencia entre SVGs y CSVs
echo "" >> "$REPORT"
echo "üîó Coherencia SVGs ‚Üî CSVs:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

if [ -f "$CSV_MASTER" ]; then
  # Contar SVGs totales
  TOTAL_SVGS=$(find "$ROOT_DIR" -name "*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
  CSV_ROWS=$(tail -n +2 "$CSV_MASTER" | wc -l | xargs)
  
  echo "  Total SVGs: $TOTAL_SVGS" >> "$REPORT"
  echo "  Registros en CSV: $CSV_ROWS" >> "$REPORT"
  
  if [ "$CSV_ROWS" -gt 0 ] && [ "$TOTAL_SVGS" -gt 0 ]; then
    COVERAGE=$(( CSV_ROWS * 100 / TOTAL_SVGS )) 2>/dev/null || COVERAGE=0
    echo "  Cobertura CSV: ~${COVERAGE}%" >> "$REPORT"
  fi
fi

# Verificar scripts de ayuda
echo "" >> "$REPORT"
echo "üõ†Ô∏è  Scripts de automatizaci√≥n:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

HELPER_JS="$ROOT_DIR/IG_TEMPLATE_UTM_HELPER.js"
BATCH_UPDATE="$ROOT_DIR/batch_update_svg_urls.js"
CONFIG_EXAMPLE="$ROOT_DIR/TEMPLATE_BATCH_CONFIG.example.json"

if [ -f "$HELPER_JS" ]; then
  echo "  ‚úÖ Helper JS encontrado: IG_TEMPLATE_UTM_HELPER.js" >> "$REPORT"
else
  echo "  ‚ö†Ô∏è  Helper JS no encontrado" >> "$REPORT"
fi

if [ -f "$BATCH_UPDATE" ]; then
  echo "  ‚úÖ Script batch update encontrado: batch_update_svg_urls.js" >> "$REPORT"
else
  echo "  ‚ö†Ô∏è  Script batch update no encontrado" >> "$REPORT"
fi

if [ -f "$CONFIG_EXAMPLE" ]; then
  echo "  ‚úÖ Config ejemplo encontrado: TEMPLATE_BATCH_CONFIG.example.json" >> "$REPORT"
else
  echo "  ‚ÑπÔ∏è  Config ejemplo no encontrado (opcional)" >> "$REPORT"
fi

# An√°lisis de variables editables en SVGs
echo "" >> "$REPORT"
echo "üî§ An√°lisis de Variables Editables ([VAR]):" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

# Extraer todas las variables √∫nicas encontradas
ALL_VARS=$(grep -rho "\[[A-Z_0-9√Ä-√ø]*\]" "$ROOT_DIR" --include="*.svg" -h 2>/dev/null | sort -u | tr '\n' ' ' || echo "")
if [ -n "$ALL_VARS" ] && [ "$ALL_VARS" != " " ]; then
  VAR_COUNT=$(grep -rho "\[[A-Z_0-9√Ä-√ø]*\]" "$ROOT_DIR" --include="*.svg" -h 2>/dev/null | sort -u | wc -l | xargs)
  echo "  Total variables √∫nicas encontradas: $VAR_COUNT" >> "$REPORT"
  echo "  Variables m√°s comunes:" >> "$REPORT"
  grep -rho "\[[A-Z_0-9√Ä-√ø]*\]" "$ROOT_DIR" --include="*.svg" -h 2>/dev/null | sort | uniq -c | sort -rn | head -10 | while read -r count var; do
    if [ "$count" -gt 0 ]; then
      echo "    - $var ($count ocurrencias)" >> "$REPORT"
    fi
  done
else
  echo "  ‚ö†Ô∏è  No se encontraron variables [VAR] en los SVGs" >> "$REPORT"
fi

# Verificar integraci√≥n con workflows/config
echo "" >> "$REPORT"
echo "üîó Integraci√≥n con Workflows/Config:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

# Verificar si existe svg_templates_config.json
CONFIG_JSON="$ROOT_DIR/svg_templates_config.json"
if [ -f "$CONFIG_JSON" ]; then
  echo "  ‚úÖ svg_templates_config.json encontrado" >> "$REPORT"
  
  # Contar templates registrados
  if command -v jq &> /dev/null; then
    REGISTERED_TEMPLATES=$(jq -r '.templates | keys | length' "$CONFIG_JSON" 2>/dev/null || echo "0")
    echo "  üìã Templates registrados en config: $REGISTERED_TEMPLATES" >> "$REPORT"
    
    # Buscar SVGs sin entrada en config
    UNREGISTERED=0
    find "$ROOT_DIR" -maxdepth 1 -name "webinar-*.svg" 2>/dev/null | while read -r svg; do
      basename=$(basename "$svg" .svg)
      if ! jq -e ".templates.\"$basename\"" "$CONFIG_JSON" >/dev/null 2>&1; then
        echo "    ‚ö†Ô∏è  No registrado: $basename.svg" >> "$REPORT"
        ((UNREGISTERED++))
      fi
    done || true
  fi
else
  echo "  ‚ö†Ô∏è  svg_templates_config.json no encontrado" >> "$REPORT"
fi

# Verificar workflow guide
WORKFLOW_GUIDE="$ROOT_DIR/CREATIVES_WORKFLOWS_INTEGRATION.md"
if [ -f "$WORKFLOW_GUIDE" ]; then
  echo "  ‚úÖ Gu√≠a de workflows encontrada" >> "$REPORT"
else
  echo "  ‚ö†Ô∏è  CREATIVES_WORKFLOWS_INTEGRATION.md no encontrado" >> "$REPORT"
fi

# An√°lisis por formato vertical nuevo (1080√ó1920)
echo "" >> "$REPORT"
echo "üì± Formatos Verticales (1080√ó1920):" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

VERTICAL_WEBINAR=$(find "$ROOT_DIR" -maxdepth 1 -name "webinar-vertical-1080x1920.svg" 2>/dev/null | wc -l | xargs)
VERTICAL_ADS=$(find "$ROOT_DIR/ads/linkedin" -name "*1080x1920*.svg" 2>/dev/null | wc -l | xargs)

if [ "$VERTICAL_WEBINAR" -gt 0 ]; then
  echo "  ‚úÖ Webinar vertical: $VERTICAL_WEBINAR" >> "$REPORT"
else
  echo "  ‚ö†Ô∏è  Webinar vertical no encontrado" >> "$REPORT"
fi

if [ "$VERTICAL_ADS" -gt 0 ]; then
  echo "  ‚úÖ LinkedIn Ads verticales: $VERTICAL_ADS" >> "$REPORT"
  
  # Desglosar por producto
  VERTICAL_CURSO=$(find "$ROOT_DIR/ads/linkedin" -name "*curso*1080x1920*.svg" 2>/dev/null | wc -l | xargs)
  VERTICAL_SAAS=$(find "$ROOT_DIR/ads/linkedin" -name "*saas*1080x1920*.svg" 2>/dev/null | wc -l | xargs)
  VERTICAL_BULK=$(find "$ROOT_DIR/ads/linkedin" -name "*bulk*1080x1920*.svg" 2>/dev/null | wc -l | xargs)
  
  echo "    - Curso IA: $VERTICAL_CURSO" >> "$REPORT"
  echo "    - SaaS Marketing: $VERTICAL_SAAS" >> "$REPORT"
  echo "    - IA Bulk: $VERTICAL_BULK" >> "$REPORT"
else
  echo "  ‚ö†Ô∏è  LinkedIn Ads verticales no encontrados" >> "$REPORT"
fi

# An√°lisis de templates nuevos (compare, numbers, benefits, social-proof)
echo "" >> "$REPORT"
echo "üÜï Templates Nuevos Detectados:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

NEW_TEMPLATES=0

for template in "compare" "numbers" "benefits" "social-proof"; do
  COUNT=$(find "$ROOT_DIR" -name "*${template}*.svg" 2>/dev/null | wc -l | xargs)
  if [ "$COUNT" -gt 0 ]; then
    echo "  ‚úÖ ${template}: $COUNT template(s)" >> "$REPORT"
    ((NEW_TEMPLATES++))
  fi
done

if [ "$NEW_TEMPLATES" -eq 0 ]; then
  echo "  ‚ÑπÔ∏è  No se detectaron templates nuevos (compare, numbers, benefits, social-proof)" >> "$REPORT"
fi

# An√°lisis de cobertura por producto y formato
echo "" >> "$REPORT"
echo "üìä Cobertura por Producto y Formato:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

for producto in "curso_ia" "saas_ia_marketing" "ia_bulk"; do
  echo "  $producto:" >> "$REPORT"
  
  # Horizontal
  HORIZONTAL=$(find "$ROOT_DIR/ads/linkedin" -name "*${producto}*1200x627*.svg" 2>/dev/null | wc -l | xargs)
  # Square
  SQUARE=$(find "$ROOT_DIR/ads/linkedin" -name "*${producto}*1080x1080*.svg" 2>/dev/null | wc -l | xargs)
  # Vertical
  VERTICAL=$(find "$ROOT_DIR/ads/linkedin" -name "*${producto}*1080x1920*.svg" 2>/dev/null | wc -l | xargs)
  
  echo "    - Horizontal (1200√ó627): $HORIZONTAL" >> "$REPORT"
  echo "    - Square (1080√ó1080): $SQUARE" >> "$REPORT"
  echo "    - Vertical (1080√ó1920): $VERTICAL" >> "$REPORT"
  
  TOTAL=$((HORIZONTAL + SQUARE + VERTICAL))
  if [ "$TOTAL" -eq 0 ]; then
    echo "    ‚ö†Ô∏è  Sin templates para este producto" >> "$REPORT"
  fi
done

# Verificar UTMs en archivos
echo "" >> "$REPORT"
echo "üîó An√°lisis de UTMs en Archivos:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

UTM_CSV="$ROOT_DIR/OUTREACH_UTM_CATALOG.csv"
if [ -f "$UTM_CSV" ]; then
  CSV_ROWS=$(tail -n +2 "$UTM_CSV" 2>/dev/null | wc -l | xargs || echo "0")
  echo "  ‚úÖ OUTREACH_UTM_CATALOG.csv: $CSV_ROWS entradas" >> "$REPORT"
else
  echo "  ‚ö†Ô∏è  OUTREACH_UTM_CATALOG.csv no encontrado" >> "$REPORT"
fi

# Detectar variables potencialmente sin usar o inconsistentes
echo "" >> "$REPORT"
echo "üîç Variables Potencialmente Sin Usar:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

# Variables comunes esperadas
EXPECTED_VARS=("FECHA" "HORA" "EVENTO" "CTA" "URL" "M√âTRICA" "BENEFICIO" "TESTIMONIO" "PRODUCTO")
for var in "${EXPECTED_VARS[@]}"; do
  VAR_USAGE=$(grep -r "\[${var}\]" "$ROOT_DIR" --include="*.svg" -h 2>/dev/null | wc -l | xargs)
  if [ "$VAR_USAGE" -eq 0 ]; then
    echo "  ‚ÑπÔ∏è  Variable [$var] no encontrada en ning√∫n SVG" >> "$REPORT"
  fi
done

# Validaci√≥n de URLs con UTMs
echo "" >> "$REPORT"
echo "‚úÖ Validaci√≥n de Sintaxis de URLs/UTMs:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

INVALID_URLS=$(find "$ROOT_DIR" -name "*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" -exec grep -l 'href="[^"]*"' {} \; 2>/dev/null | while read -r svg_file; do
  grep -o 'href="[^"]*"' "$svg_file" 2>/dev/null | sed 's/href="//; s/"$//' | while read -r url; do
    if [[ "$url" =~ ^http ]]; then
      if echo "$url" | grep -qi "utm_" && ! echo "$url" | grep -qE "(utm_source|utm_medium|utm_campaign)=[^&]*"; then
        echo "1"
      fi
    fi
  done
done | wc -l | xargs)

if [ "$INVALID_URLS" -gt 0 ]; then
  echo "  ‚ö†Ô∏è  $INVALID_URLS URLs mal formateadas encontradas" >> "$REPORT"
  # Mostrar ejemplos
  find "$ROOT_DIR" -name "*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -3 | while read -r svg_file; do
    grep -o 'href="[^"]*"' "$svg_file" 2>/dev/null | sed 's/href="//; s/"$//' | while read -r url; do
      if [[ "$url" =~ ^http ]] && echo "$url" | grep -qi "utm_" && ! echo "$url" | grep -qE "(utm_source|utm_medium|utm_campaign)=[^&]*"; then
        echo "    - ${svg_file#$ROOT_DIR/}: ${url:0:60}..." >> "$REPORT"
      fi
    done
  done
else
  echo "  ‚úÖ URLs con UTMs bien formateadas" >> "$REPORT"
fi

# Detectar duplicados en CSVs
echo "" >> "$REPORT"
echo "üîÑ Detecci√≥n de Duplicados en CSVs:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

if [ -f "$CSV_MASTER" ]; then
  # Buscar filas duplicadas (ignorando header)
  DUPLICATES=$(tail -n +2 "$CSV_MASTER" | sort | uniq -d | wc -l | xargs)
  if [ "$DUPLICATES" -gt 0 ]; then
    echo "  ‚ö†Ô∏è  $DUPLICATES filas duplicadas encontradas en CSV Maestro" >> "$REPORT"
    tail -n +2 "$CSV_MASTER" | sort | uniq -d | head -3 | while read -r dup; do
      echo "    - ${dup:0:60}..." >> "$REPORT"
    done
  else
    echo "  ‚úÖ Sin duplicados en CSV Maestro" >> "$REPORT"
  fi
  
  # Verificar que las rutas de archivos en CSV existen
  MISSING_FILES=0
  tail -n +2 "$CSV_MASTER" | cut -d',' -f1-10 | while IFS=',' read -r rest; do
    # Buscar campo filename (√∫ltimo campo t√≠picamente)
    filename=$(tail -n +2 "$CSV_MASTER" | head -1 | awk -F',' '{print $NF}')
    if [ -n "$filename" ] && [ ! -f "$ROOT_DIR/$filename" ] && [ ! -f "$ROOT_DIR/ads/linkedin/$filename" ]; then
      ((MISSING_FILES++))
    fi
  done
  
  if [ "$MISSING_FILES" -eq 0 ]; then
    echo "  ‚úÖ Todos los archivos referenciados en CSV existen" >> "$REPORT"
  fi
fi

# Verificar dimensiones en nombres de archivo
echo "" >> "$REPORT"
echo "üìê Verificaci√≥n de Dimensiones en Nombres:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

DIMENSION_ISSUES=0
find "$ROOT_DIR" -name "*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | while read -r svg_file; do
  basename=$(basename "$svg_file")
  # Verificar si el nombre contiene dimensiones pero no coinciden con est√°ndares
  if echo "$basename" | grep -qE "[0-9]+x[0-9]+"; then
    dims=$(echo "$basename" | grep -oE "[0-9]+x[0-9]+" | head -1)
    # Validar contra est√°ndares conocidos
    case "$dims" in
      "1200x627"|"1080x1080"|"1080x1350"|"1080x1920"|"1920x1080")
        # OK
        ;;
      *)
        echo "    ‚ö†Ô∏è  Dimensiones no est√°ndar en ${basename}: $dims" >> "$REPORT"
        ((DIMENSION_ISSUES++))
        ;;
    esac
  fi
done

if [ "$DIMENSION_ISSUES" -eq 0 ]; then
  echo "  ‚úÖ Nombres de archivo con dimensiones est√°ndar" >> "$REPORT"
fi

# An√°lisis de coherencia entre productos esperados y existentes
echo "" >> "$REPORT"
echo "üìã Matriz de Cobertura (Producto √ó Formato):" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

PRODUCTOS=("curso_ia" "saas_ia_marketing" "ia_bulk")
FORMATOS=("1200x627" "1080x1080" "1080x1920")
PLATAFORMAS=("linkedin")

for plataforma in "${PLATAFORMAS[@]}"; do
  PLAT_DIR="$ROOT_DIR/ads/$plataforma"
  if [ ! -d "$PLAT_DIR" ]; then
    continue
  fi
  
  echo "  $plataforma:" >> "$REPORT"
  printf "    %-20s" "Producto/Formato" >> "$REPORT"
  for fmt in "${FORMATOS[@]}"; do
    printf " %-12s" "$fmt" >> "$REPORT"
  done
  echo "" >> "$REPORT"
  
  for prod in "${PRODUCTOS[@]}"; do
    printf "    %-20s" "$prod" >> "$REPORT"
    for fmt in "${FORMATOS[@]}"; do
      COUNT=$(find "$PLAT_DIR" -name "*${prod}*${fmt}*.svg" 2>/dev/null | wc -l | xargs)
      if [ "$COUNT" -gt 0 ]; then
        printf " %-12s" "‚úÖ ($COUNT)" >> "$REPORT"
      else
        printf " %-12s" "‚ùå" >> "$REPORT"
      fi
    done
    echo "" >> "$REPORT"
  done
done

# Generar reporte JSON (si jq est√° disponible)
if command -v jq &> /dev/null; then
  JSON_REPORT="${REPORT%.txt}.json"
  
  {
    echo "{"
    echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
    echo "  \"summary\": {"
    
    # Totales
    TOTAL_SVGS=$(find "$ROOT_DIR" -name "*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
    EMPTY_SVGS=$(find "$ROOT_DIR" -name "*.svg" -size 0 -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
    
    echo "    \"total_svgs\": $TOTAL_SVGS,"
    echo "    \"empty_svgs\": $EMPTY_SVGS,"
    
    # Formatos
    echo "    \"formats\": {"
    echo "      \"horizontal_1920x1080\": $(find "$ROOT_DIR" -maxdepth 1 -name "webinar-preroll-*.svg" 2>/dev/null | wc -l | xargs || echo 0),"
    echo "      \"square_1080x1080\": $(find "$ROOT_DIR" -name "*1080x1080*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs || echo 0),"
    echo "      \"vertical_1080x1920\": $(find "$ROOT_DIR" -name "*1080x1920*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs || echo 0),"
    echo "      \"instagram_1080x1350\": $(find "$ROOT_DIR" -name "*1080x1350*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs || echo 0)"
    echo "    },"
    
    # Productos
    echo "    \"products\": {"
    echo "      \"curso_ia\": $(find "$ROOT_DIR/ads/linkedin" -name "*curso*.svg" 2>/dev/null | wc -l | xargs || echo 0),"
    echo "      \"saas_marketing\": $(find "$ROOT_DIR/ads/linkedin" -name "*saas*.svg" 2>/dev/null | wc -l | xargs || echo 0),"
    echo "      \"ia_bulk\": $(find "$ROOT_DIR/ads/linkedin" -name "*bulk*.svg" 2>/dev/null | wc -l | xargs || echo 0)"
    echo "    },"
    
    # Variables
    VAR_COUNT=$(grep -rho "\[[A-Z_0-9√Ä-√ø]*\]" "$ROOT_DIR" --include="*.svg" -h 2>/dev/null | sort -u | wc -l | xargs || echo 0)
    echo "    \"unique_variables\": $VAR_COUNT"
    
    echo "  }"
    echo "}"
  } > "$JSON_REPORT"
  
  echo "  ‚úÖ Reporte JSON generado: $JSON_REPORT" >> "$REPORT"
fi

# Validaci√≥n avanzada de SVGs
echo "" >> "$REPORT"
echo "üîç Validaci√≥n Avanzada de SVGs:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

INVALID_STRUCTURE=0
INVALID_FILES_LIST=()
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    if ! grep -q "<svg" "$svg_file" 2>/dev/null || ! grep -q "</svg>" "$svg_file" 2>/dev/null; then
      INVALID_STRUCTURE=$((INVALID_STRUCTURE + 1))
      INVALID_FILES_LIST+=("${svg_file#$ROOT_DIR/}")
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

if [ "$INVALID_STRUCTURE" -eq 0 ]; then
  echo "  ‚úÖ Todos los SVGs tienen estructura v√°lida" >> "$REPORT"
else
  echo "  ‚ö†Ô∏è  SVGs con estructura inv√°lida: $INVALID_STRUCTURE" >> "$REPORT"
  for file in "${INVALID_FILES_LIST[@]:0:5}"; do
    echo "    - $file" >> "$REPORT"
  done
  [ ${#INVALID_FILES_LIST[@]} -gt 5 ] && echo "    ... y $((INVALID_STRUCTURE - 5)) m√°s" >> "$REPORT"
fi

# Detecci√≥n de duplicados por hash
echo "" >> "$REPORT"
echo "üîÅ Detecci√≥n de Duplicados:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

DUPLICATE_GROUPS=0
if command -v md5 >/dev/null 2>&1 || command -v md5sum >/dev/null 2>&1; then
  TEMP_HASHES=$(mktemp)
  trap "rm -f $TEMP_HASHES" EXIT
  
  find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | while read -r file; do
    if [ -s "$file" ]; then
      if command -v md5 >/dev/null 2>&1; then
        hash=$(md5 -q "$file" 2>/dev/null) || continue
      else
        hash=$(md5sum "$file" 2>/dev/null | cut -d' ' -f1) || continue
      fi
      echo "$hash|${file#$ROOT_DIR/}" >> "$TEMP_HASHES"
    fi
  done
  
  DUPLICATE_GROUPS=$(sort "$TEMP_HASHES" 2>/dev/null | cut -d'|' -f1 | uniq -d | wc -l | xargs)
  if [ "${DUPLICATE_GROUPS:-0}" -gt 0 ]; then
    echo "  ‚ö†Ô∏è  Grupos de archivos duplicados: $DUPLICATE_GROUPS" >> "$REPORT"
    sort "$TEMP_HASHES" 2>/dev/null | cut -d'|' -f1 | uniq -d | head -3 | while read -r dup_hash; do
      echo "    Hash $dup_hash:" >> "$REPORT"
      grep "^$dup_hash|" "$TEMP_HASHES" 2>/dev/null | cut -d'|' -f2 | head -3 | while read -r dup_file; do
        echo "      - $dup_file" >> "$REPORT"
      done
    done
  else
    echo "  ‚úÖ No se detectaron duplicados" >> "$REPORT"
  fi
  
  rm -f "$TEMP_HASHES" 2>/dev/null || true
else
  echo "  ‚ÑπÔ∏è  md5/md5sum no disponible, saltando detecci√≥n" >> "$REPORT"
fi

# An√°lisis de performance
echo "" >> "$REPORT"
echo "‚ö° An√°lisis de Performance:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

LARGE_COUNT=$(find "$ROOT_DIR" -name "*.svg" -size +500k -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
if [ "${LARGE_COUNT:-0}" -gt 0 ]; then
  echo "  ‚ö†Ô∏è  SVGs grandes (>500KB): $LARGE_COUNT" >> "$REPORT"
  find "$ROOT_DIR" -name "*.svg" -size +500k -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -5 | while read -r f; do
    size=$(du -h "$f" 2>/dev/null | cut -f1)
    echo "    - ${f#$ROOT_DIR/} ($size)" >> "$REPORT"
  done
else
  echo "  ‚úÖ Todos los SVGs tienen tama√±o razonable" >> "$REPORT"
fi

# An√°lisis de im√°genes
IMAGE_DATA_URI=$(grep -rl 'data:image' "$ROOT_DIR" --include="*.svg" 2>/dev/null | grep -v node_modules | grep -v .git | wc -l | xargs)
IMAGE_EXTERNAL=$(grep -rl '<image' "$ROOT_DIR" --include="*.svg" 2>/dev/null | grep -v node_modules | grep -v .git | wc -l | xargs)
BROKEN_IMG=$(grep -rl 'href=""\|href=".*placeholder' "$ROOT_DIR" --include="*.svg" 2>/dev/null | grep -v node_modules | grep -v .git | wc -l | xargs)

echo "  üìä Im√°genes embebidas (data URI): ${IMAGE_DATA_URI:-0}" >> "$REPORT"
echo "  üìä Im√°genes externas: ${IMAGE_EXTERNAL:-0}" >> "$REPORT"
if [ "${BROKEN_IMG:-0}" -gt 0 ]; then
  echo "  ‚ö†Ô∏è  Im√°genes rotas/placeholder: $BROKEN_IMG" >> "$REPORT"
fi

# Resumen ejecutivo
echo "" >> "$REPORT"
echo "üìã Resumen Ejecutivo:" >> "$REPORT"
echo "--------------------------------" >> "$REPORT"

TOTAL_SVG_COUNT=$(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
TOTAL_ISSUES=$((${EMPTY_SVGS:-0} + ${INVALID_STRUCTURE:-0} + ${DUPLICATE_GROUPS:-0} + ${LARGE_COUNT:-0} + ${BROKEN_IMG:-0}))

echo "  üìä Total de SVGs analizados: $TOTAL_SVG_COUNT" >> "$REPORT"
echo "  ‚ö†Ô∏è  Total de problemas: $TOTAL_ISSUES" >> "$REPORT"

if [ "$TOTAL_ISSUES" -eq 0 ]; then
  echo "  ‚úÖ Estado: Excelente - Sin problemas detectados" >> "$REPORT"
elif [ "$TOTAL_ISSUES" -lt 5 ]; then
  echo "  ‚ö†Ô∏è  Estado: Bueno - Revisar problemas menores" >> "$REPORT"
else
  echo "  ‚ùå Estado: Atenci√≥n requerida - M√∫ltiples problemas detectados" >> "$REPORT"
fi

# Calcular tiempo de ejecuci√≥n y generar resumen final
END_TIME=$(date +%s)
ELAPSED=$((END_TIME - START_TIME))

# Resumen final
log_section "üìã Resumen Final"

# Recalcular totales para el resumen
TOTAL_SVGS=$(find "$ROOT_DIR" -name "*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
EMPTY_SVGS=$(find "$ROOT_DIR" -name "*.svg" -size 0 -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
BROKEN_SVGS=$BROKEN_SVGS || 0

log_info "‚è±Ô∏è  Tiempo de ejecuci√≥n: ${ELAPSED}s"
log_info "üìä Total SVGs analizados: $TOTAL_SVGS"
log_info "‚úÖ SVGs v√°lidos: $((TOTAL_SVGS - EMPTY_SVGS - BROKEN_SVGS))"
[ "$EMPTY_SVGS" -gt 0 ] && log_info "‚ö†Ô∏è  SVGs vac√≠os: $EMPTY_SVGS"
[ "$BROKEN_SVGS" -gt 0 ] && log_info "‚ö†Ô∏è  SVGs con errores: $BROKEN_SVGS"
log_info "üìÑ Reporte guardado en: $REPORT"
if [ -n "${JSON_REPORT:-}" ] && [ -f "${JSON_REPORT:-}" ]; then
  log_info "üìÑ Reporte JSON guardado en: $JSON_REPORT"
fi

# An√°lisis estad√≠stico avanzado
log_section "üìà An√°lisis Estad√≠stico Avanzado"

# Calcular distribuci√≥n de formatos
if [ -d "$LINKEDIN_DIR" ]; then
  TOTAL_LINKEDIN=$(find "$LINKEDIN_DIR" -name "*.svg" -not -name "tokens.json" 2>/dev/null | wc -l | xargs)
  
  if [ "$TOTAL_LINKEDIN" -gt 0 ]; then
    PERCENT_1200x627=$(awk "BEGIN {printf \"%.1f\", ($COUNT_1200x627 / $TOTAL_LINKEDIN) * 100}")
    PERCENT_1080x1080=$(awk "BEGIN {printf \"%.1f\", ($COUNT_1080x1080 / $TOTAL_LINKEDIN) * 100}")
    PERCENT_1080x1920=$(awk "BEGIN {printf \"%.1f\", ($COUNT_1080x1920 / $TOTAL_LINKEDIN) * 100}")
    PERCENT_CAROUSEL=$(awk "BEGIN {printf \"%.1f\", ($COUNT_CAROUSEL / $TOTAL_LINKEDIN) * 100}")
    
    log_info "Distribuci√≥n de formatos LinkedIn:"
    [ "$COUNT_1200x627" -gt 0 ] && log_info "  1200√ó627: $PERCENT_1200x627% ($COUNT_1200x627 archivos)"
    [ "$COUNT_1080x1080" -gt 0 ] && log_info "  1080√ó1080: $PERCENT_1080x1080% ($COUNT_1080x1080 archivos)"
    [ "$COUNT_1080x1920" -gt 0 ] && log_info "  1080√ó1920: $PERCENT_1080x1920% ($COUNT_1080x1920 archivos)"
    [ "$COUNT_CAROUSEL" -gt 0 ] && log_info "  Carousel: $PERCENT_CAROUSEL% ($COUNT_CAROUSEL archivos)"
  fi
  
  # An√°lisis de √°ngulos
  if [ "$COUNT_METRICS" -gt 0 ] || [ "$COUNT_SOCIAL" -gt 0 ] || [ "$COUNT_URGENCY" -gt 0 ]; then
    log_info ""
    log_info "Distribuci√≥n de √°ngulos:"
    TOTAL_ANGLE_COUNT=$((COUNT_METRICS + COUNT_SOCIAL + COUNT_URGENCY + COUNT_V2))
    if [ "$TOTAL_ANGLE_COUNT" -gt 0 ]; then
      PERCENT_METRICS=$(awk "BEGIN {printf \"%.1f\", ($COUNT_METRICS / $TOTAL_ANGLE_COUNT) * 100}")
      PERCENT_SOCIAL=$(awk "BEGIN {printf \"%.1f\", ($COUNT_SOCIAL / $TOTAL_ANGLE_COUNT) * 100}")
      PERCENT_URGENCY=$(awk "BEGIN {printf \"%.1f\", ($COUNT_URGENCY / $TOTAL_ANGLE_COUNT) * 100}")
      
      [ "$COUNT_METRICS" -gt 0 ] && log_info "  Metrics: $PERCENT_METRICS% ($COUNT_METRICS archivos)"
      [ "$COUNT_SOCIAL" -gt 0 ] && log_info "  Social Proof: $PERCENT_SOCIAL% ($COUNT_SOCIAL archivos)"
      [ "$COUNT_URGENCY" -gt 0 ] && log_info "  Urgency: $PERCENT_URGENCY% ($COUNT_URGENCY archivos)"
      [ "$COUNT_V2" -gt 0 ] && log_info "  Variantes (v2): $COUNT_V2 archivos"
    fi
  fi
fi

# An√°lisis de productos
log_info ""
log_info "Distribuci√≥n por producto:"
if [ -d "$LINKEDIN_DIR" ]; then
  TOTAL_PRODUCT_COUNT=$((COUNT_IABULK + COUNT_CURSO + COUNT_SAAS))
  if [ "$TOTAL_PRODUCT_COUNT" -gt 0 ]; then
    PERCENT_IABULK=$(awk "BEGIN {printf \"%.1f\", ($COUNT_IABULK / $TOTAL_PRODUCT_COUNT) * 100}")
    PERCENT_CURSO=$(awk "BEGIN {printf \"%.1f\", ($COUNT_CURSO / $TOTAL_PRODUCT_COUNT) * 100}")
    PERCENT_SAAS=$(awk "BEGIN {printf \"%.1f\", ($COUNT_SAAS / $TOTAL_PRODUCT_COUNT) * 100}")
    
    log_info "  IA Bulk: $PERCENT_IABULK% ($COUNT_IABULK archivos)"
    log_info "  Curso IA: $PERCENT_CURSO% ($COUNT_CURSO archivos)"
    log_info "  SaaS IA Marketing: $PERCENT_SAAS% ($COUNT_SAAS archivos)"
  fi
fi

# An√°lisis de complejidad (tama√±o de archivo)
log_section "üî¨ An√°lisis de Complejidad"

if [ -d "$LINKEDIN_DIR" ]; then
  # Calcular estad√≠sticas de tama√±o
  SVG_SIZES=$(find "$LINKEDIN_DIR" -name "*.svg" -not -name "tokens.json" -exec stat -f%z {} \; 2>/dev/null | sort -n)
  
  if [ -n "$SVG_SIZES" ]; then
    SIZE_COUNT=$(echo "$SVG_SIZES" | wc -l | xargs)
    MIN_SIZE=$(echo "$SVG_SIZES" | head -1)
    MAX_SIZE=$(echo "$SVG_SIZES" | tail -1)
    AVG_SIZE=$(echo "$SVG_SIZES" | awk '{sum+=$1; count++} END {if(count>0) printf "%.0f", sum/count}')
    MEDIAN_SIZE=$(echo "$SVG_SIZES" | awk -v count="$SIZE_COUNT" 'NR==int((count+1)/2) {print}')
    
    log_info "Estad√≠sticas de tama√±o (bytes):"
    log_info "  Total archivos analizados: $SIZE_COUNT"
    log_info "  Tama√±o m√≠nimo: $(numfmt --to=iec-i --suffix=B $MIN_SIZE 2>/dev/null || echo "${MIN_SIZE}B")"
    log_info "  Tama√±o m√°ximo: $(numfmt --to=iec-i --suffix=B $MAX_SIZE 2>/dev/null || echo "${MAX_SIZE}B")"
    log_info "  Tama√±o promedio: $(numfmt --to=iec-i --suffix=B $AVG_SIZE 2>/dev/null || echo "${AVG_SIZE}B")"
    if [ -n "$MEDIAN_SIZE" ]; then
      log_info "  Tama√±o mediano: $(numfmt --to=iec-i --suffix=B $MEDIAN_SIZE 2>/dev/null || echo "${MEDIAN_SIZE}B")"
    fi
    
    # Identificar outliers (archivos > 2x la mediana)
    if [ -n "$MEDIAN_SIZE" ] && [ "$MEDIAN_SIZE" -gt 0 ]; then
      OUTLIER_THRESHOLD=$((MEDIAN_SIZE * 2))
      OUTLIERS=$(find "$LINKEDIN_DIR" -name "*.svg" -not -name "tokens.json" -exec stat -f%z {} \; -print 2>/dev/null | awk -v threshold="$OUTLIER_THRESHOLD" '$1 > threshold {print $2}' | wc -l | xargs)
      if [ "$OUTLIERS" -gt 0 ]; then
        log_info "  ‚ö†Ô∏è  Archivos grandes (>2x mediana): $OUTLIERS"
        log_info "     üí° Recomendaci√≥n: Revisar optimizaci√≥n con svgo"
      fi
    fi
  fi
fi

# An√°lisis de coherencia temporal
log_section "‚è∞ An√°lisis Temporal"

if [ -f "$CSV_MASTER" ]; then
  # Contar creativos por mes (si fecha est√° disponible)
  RECENT_CREATIVES=$(grep -c "$(date +%Y-%m)" "$CSV_MASTER" 2>/dev/null || echo 0)
  LAST_MONTH=$(date -v-1m +%Y-%m 2>/dev/null || date -d '1 month ago' +%Y-%m 2>/dev/null || echo "")
  
  if [ -n "$LAST_MONTH" ]; then
    LAST_MONTH_CREATIVES=$(grep -c "$LAST_MONTH" "$CSV_MASTER" 2>/dev/null || echo 0)
    log_info "Actividad reciente:"
    log_info "  Este mes: $RECENT_CREATIVES creativos"
    log_info "  Mes pasado: $LAST_MONTH_CREATIVES creativos"
    
    if [ "$RECENT_CREATIVES" -eq 0 ] && [ "$LAST_MONTH_CREATIVES" -eq 0 ]; then
      log_info "  ‚ö†Ô∏è  Baja actividad reciente - considerar actualizar creativos"
    fi
  fi
fi

# Inicializar variables para health score (si no est√°n definidas)
SVGS_WITHOUT_CSV=${SVGS_WITHOUT_CSV:-0}
CSV_WITHOUT_SVG=${CSV_WITHOUT_SVG:-0}
SVGS_DEFAULT_URL=${SVGS_DEFAULT_URL:-0}

# Score de salud general
log_section "üè• Score de Salud General"

HEALTH_SCORE=100
HEALTH_ISSUES=0
RECOMMENDATIONS=()

# Penalizar por SVGs vac√≠os
if [ "$EMPTY_SVGS" -gt 0 ]; then
  PENALTY=$((EMPTY_SVGS * 2))
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
  RECOMMENDATIONS+=("Eliminar $EMPTY_SVGS SVG(s) vac√≠o(s)")
fi

# Penalizar por SVGs rotos
if [ "$BROKEN_SVGS" -gt 0 ]; then
  PENALTY=$((BROKEN_SVGS * 3))
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
  RECOMMENDATIONS+=("Reparar $BROKEN_SVGS SVG(s) con estructura inv√°lida")
fi

# Penalizar por URLs sin UTMs
if [ "${SVGS_NO_UTMS:-0}" -gt 0 ]; then
  PENALTY=$((SVGS_NO_UTMS * 1))
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
  RECOMMENDATIONS+=("Agregar UTMs a $SVGS_NO_UTMS SVG(s) con URLs")
fi

# Penalizar por URLs por defecto
if [ "$SVGS_DEFAULT_URL" -gt 0 ]; then
  PENALTY=$((SVGS_DEFAULT_URL * 2))
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
  RECOMMENDATIONS+=("Actualizar URLs por defecto en $SVGS_DEFAULT_URL SVG(s)")
fi

# Penalizar por gaps en CSV
if [ -f "$CSV_MASTER" ]; then
  if [ "$SVGS_WITHOUT_CSV" -gt 0 ]; then
    PENALTY=$((SVGS_WITHOUT_CSV * 2))
    HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
    HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
    RECOMMENDATIONS+=("Registrar $SVGS_WITHOUT_CSV SVG(s) en CSV Master")
  fi
  
  if [ "$CSV_WITHOUT_SVG" -gt 0 ]; then
    PENALTY=$((CSV_WITHOUT_SVG * 2))
    HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
    HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
    RECOMMENDATIONS+=("Eliminar $CSV_WITHOUT_SVG entrada(s) hu√©rfana(s) del CSV")
  fi
fi

# Penalizar por tokens sin aplicar
if [ "${TOKENS_NOT_USED:-0}" -gt 0 ]; then
  PENALTY=$((TOKENS_NOT_USED * 1))
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
  RECOMMENDATIONS+=("Aplicar $TOKENS_NOT_USED token(s) pendiente(s)")
fi

# Penalizar por placeholders de logo
if [ "${LOGO_COUNT:-0}" -gt 10 ]; then
  PENALTY=5
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
  RECOMMENDATIONS+=("Reemplazar placeholders de logo ($LOGO_COUNT encontrados)")
fi

# Penalizar por violaciones de naming (se calcular√° despu√©s)
# Se agregar√° en la secci√≥n de validaci√≥n de convenciones

# Nota: Las penalizaciones por accesibilidad, seguridad y calidad se a√±aden despu√©s
# cuando se calculan esos valores

# Determinar nivel de salud
if [ "$HEALTH_SCORE" -ge 90 ]; then
  HEALTH_STATUS="‚úÖ Excelente"
elif [ "$HEALTH_SCORE" -ge 75 ]; then
  HEALTH_STATUS="‚úÖ Bueno"
elif [ "$HEALTH_SCORE" -ge 60 ]; then
  HEALTH_STATUS="‚ö†Ô∏è  Requiere atenci√≥n"
else
  HEALTH_STATUS="‚ùå Cr√≠tico"
fi

log_info "Score: $HEALTH_SCORE/100 - $HEALTH_STATUS"
if [ "$HEALTH_ISSUES" -gt 0 ]; then
  log_info "Problemas detectados: $HEALTH_ISSUES"
  
  # Mostrar recomendaciones
  if [ ${#RECOMMENDATIONS[@]} -gt 0 ]; then
    log_info ""
    log_info "üí° Recomendaciones prioritarias:"
    for i in "${!RECOMMENDATIONS[@]}"; do
      log_info "  $((i + 1)). ${RECOMMENDATIONS[$i]}"
    done
  fi
else
  log_info "‚úÖ ¬°Excelente! No se detectaron problemas cr√≠ticos"
fi

# An√°lisis de accesibilidad
log_section "‚ôø An√°lisis de Accesibilidad"

ACCESSIBILITY_SCORE=0
ARIA_COUNT=0
TITLE_COUNT=0
DESC_COUNT=0
ALT_COUNT=0
NO_ACCESSIBILITY=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    HAS_ARIA=$(grep -q "aria-label\|aria-labelledby\|role=" "$svg_file" 2>/dev/null && echo "1" || echo "0")
    HAS_TITLE=$(grep -q "<title>" "$svg_file" 2>/dev/null && echo "1" || echo "0")
    HAS_DESC=$(grep -q "<desc>" "$svg_file" 2>/dev/null && echo "1" || echo "0")
    HAS_ALT=$(grep -q "alt=" "$svg_file" 2>/dev/null && echo "1" || echo "0")
    
    if [ "$HAS_ARIA" = "1" ]; then
      ARIA_COUNT=$((ARIA_COUNT + 1))
    fi
    if [ "$HAS_TITLE" = "1" ]; then
      TITLE_COUNT=$((TITLE_COUNT + 1))
    fi
    if [ "$HAS_DESC" = "1" ]; then
      DESC_COUNT=$((DESC_COUNT + 1))
    fi
    if [ "$HAS_ALT" = "1" ]; then
      ALT_COUNT=$((ALT_COUNT + 1))
    fi
    
    if [ "$HAS_ARIA" = "0" ] && [ "$HAS_TITLE" = "0" ] && [ "$HAS_DESC" = "0" ]; then
      NO_ACCESSIBILITY=$((NO_ACCESSIBILITY + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

TOTAL_ACCESSIBILITY_CHECKED=$(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)

if [ "$TOTAL_ACCESSIBILITY_CHECKED" -gt 0 ]; then
  PERCENT_ARIA=$(awk "BEGIN {printf \"%.1f\", ($ARIA_COUNT / $TOTAL_ACCESSIBILITY_CHECKED) * 100}")
  PERCENT_TITLE=$(awk "BEGIN {printf \"%.1f\", ($TITLE_COUNT / $TOTAL_ACCESSIBILITY_CHECKED) * 100}")
  PERCENT_DESC=$(awk "BEGIN {printf \"%.1f\", ($DESC_COUNT / $TOTAL_ACCESSIBILITY_CHECKED) * 100}")
  
  log_info "Con ARIA labels: $ARIA_COUNT ($PERCENT_ARIA%)"
  log_info "Con <title>: $TITLE_COUNT ($PERCENT_TITLE%)"
  log_info "Con <desc>: $DESC_COUNT ($PERCENT_DESC%)"
  log_info "Con alt en im√°genes: $ALT_COUNT"
  
  if [ "$NO_ACCESSIBILITY" -gt 0 ]; then
    PERCENT_NO_ACCESS=$(awk "BEGIN {printf \"%.1f\", ($NO_ACCESSIBILITY / $TOTAL_ACCESSIBILITY_CHECKED) * 100}")
    log_info "‚ö†Ô∏è  Sin elementos de accesibilidad: $NO_ACCESSIBILITY ($PERCENT_NO_ACCESS%)"
    log_info "üí° Recomendaci√≥n: A√±ade <title>, <desc> o aria-label para mejor accesibilidad"
    
    # Penalizar si m√°s del 50% no tiene accesibilidad
    if (( $(echo "$PERCENT_NO_ACCESS > 50" | bc -l 2>/dev/null || echo "0") )); then
      PENALTY=5
      HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
      HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
      RECOMMENDATIONS+=("Mejorar accesibilidad en $NO_ACCESSIBILITY SVG(s)")
    fi
  fi
fi

# An√°lisis SEO y metadata
log_section "üîç An√°lisis SEO y Metadata"

METADATA_COUNT=0
DUBLIN_CORE_COUNT=0
OPEN_GRAPH_COUNT=0
NO_METADATA=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    HAS_METADATA=0
    if grep -q "<metadata>\|<dc:" "$svg_file" 2>/dev/null; then
      METADATA_COUNT=$((METADATA_COUNT + 1))
      HAS_METADATA=1
      if grep -q "dc:title\|dc:description\|dc:creator" "$svg_file" 2>/dev/null; then
        DUBLIN_CORE_COUNT=$((DUBLIN_CORE_COUNT + 1))
      fi
    fi
    if grep -qi "og:title\|og:description\|og:image" "$svg_file" 2>/dev/null; then
      OPEN_GRAPH_COUNT=$((OPEN_GRAPH_COUNT + 1))
      HAS_METADATA=1
    fi
    if [ "$HAS_METADATA" = "0" ]; then
      NO_METADATA=$((NO_METADATA + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

log_info "Con metadata: $METADATA_COUNT"
log_info "Con Dublin Core: $DUBLIN_CORE_COUNT"
log_info "Con Open Graph: $OPEN_GRAPH_COUNT"

if [ "$NO_METADATA" -gt 0 ] && [ "$TOTAL_ACCESSIBILITY_CHECKED" -gt 0 ]; then
  PERCENT_NO_META=$(awk "BEGIN {printf \"%.1f\", ($NO_METADATA / $TOTAL_ACCESSIBILITY_CHECKED) * 100}")
  log_info "‚ö†Ô∏è  Sin metadata SEO: $NO_METADATA ($PERCENT_NO_META%)"
  log_info "üí° Recomendaci√≥n: A√±ade <metadata> con Dublin Core para mejor SEO"
fi

# An√°lisis de seguridad
log_section "üîí An√°lisis de Seguridad"

SECURITY_ISSUES=0
SCRIPT_TAGS=0
EXTERNAL_LINKS=0
UNSAFE_ATTRIBUTES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar scripts inline
    if grep -qi "<script>" "$svg_file" 2>/dev/null; then
      SCRIPT_TAGS=$((SCRIPT_TAGS + 1))
      SECURITY_ISSUES=$((SECURITY_ISSUES + 1))
    fi
    # Detectar enlaces externos potencialmente peligrosos
    if grep -qi 'href="http://\|href="javascript:' "$svg_file" 2>/dev/null; then
      EXTERNAL_LINKS=$((EXTERNAL_LINKS + 1))
      SECURITY_ISSUES=$((SECURITY_ISSUES + 1))
    fi
    # Detectar atributos peligrosos
    if grep -qi 'onload=\|onclick=\|onerror=' "$svg_file" 2>/dev/null; then
      UNSAFE_ATTRIBUTES=$((UNSAFE_ATTRIBUTES + 1))
      SECURITY_ISSUES=$((SECURITY_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

if [ "$SECURITY_ISSUES" -eq 0 ]; then
  log_info "‚úÖ No se detectaron problemas de seguridad"
else
  log_info "‚ö†Ô∏è  Problemas de seguridad detectados: $SECURITY_ISSUES"
  [ "$SCRIPT_TAGS" -gt 0 ] && log_info "  - SVGs con <script>: $SCRIPT_TAGS"
  [ "$EXTERNAL_LINKS" -gt 0 ] && log_info "  - Enlaces HTTP inseguros: $EXTERNAL_LINKS"
  [ "$UNSAFE_ATTRIBUTES" -gt 0 ] && log_info "  - Atributos event handlers: $UNSAFE_ATTRIBUTES"
  log_info "üí° Recomendaci√≥n: Revisar y sanitizar estos archivos para producci√≥n"
fi

# An√°lisis de branding y colores
log_section "üé® An√°lisis de Branding y Colores"

BRAND_COLORS=()
CUSTOM_COLORS=0
HEX_COLORS=0
RGB_COLORS=0
NAMED_COLORS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Extraer colores hex
    HEX_MATCHES=$(grep -oE '#[0-9A-Fa-f]{3,6}' "$svg_file" 2>/dev/null | sort -u)
    if [ -n "$HEX_MATCHES" ]; then
      HEX_COUNT=$(echo "$HEX_MATCHES" | wc -l | xargs)
      HEX_COLORS=$((HEX_COLORS + HEX_COUNT))
      while IFS= read -r color; do
        BRAND_COLORS+=("$color")
      done <<< "$HEX_MATCHES"
    fi
    
    # Contar RGB/RGBA
    RGB_COUNT=$(grep -oE 'rgb\([^)]+\)|rgba\([^)]+\)' "$svg_file" 2>/dev/null | wc -l | xargs)
    RGB_COLORS=$((RGB_COLORS + RGB_COUNT))
    
    # Contar colores con nombre
    NAMED_COUNT=$(grep -oiE '\b(red|blue|green|black|white|gray|grey|yellow|orange|purple|pink|brown|cyan|magenta)\b' "$svg_file" 2>/dev/null | wc -l | xargs)
    NAMED_COLORS=$((NAMED_COLORS + NAMED_COUNT))
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

if [ ${#BRAND_COLORS[@]} -gt 0 ]; then
  UNIQUE_COLORS=$(printf '%s\n' "${BRAND_COLORS[@]}" | sort -u | wc -l | xargs)
  log_info "Colores √∫nicos detectados: $UNIQUE_COLORS"
  log_info "Referencias a colores hex: $HEX_COLORS"
  log_info "Referencias RGB/RGBA: $RGB_COLORS"
  log_info "Colores con nombre: $NAMED_COLORS"
  
  if [ "$UNIQUE_COLORS" -gt 20 ]; then
    log_info "‚ö†Ô∏è  Muchos colores √∫nicos ($UNIQUE_COLORS) - considerar paleta de marca unificada"
  fi
  
  # Mostrar paleta m√°s usada
  if [ ${#BRAND_COLORS[@]} -gt 0 ]; then
    log_info ""
    log_info "Colores m√°s frecuentes:"
    printf '%s\n' "${BRAND_COLORS[@]}" | sort | uniq -c | sort -rn | head -5 | while read -r count color; do
      log_info "  $color: $count referencias"
    done
  fi
fi

# An√°lisis de tipograf√≠a
log_section "‚úçÔ∏è  An√°lisis de Tipograf√≠a"

FONT_FAMILIES=()
FONT_WEIGHTS=()
CUSTOM_FONTS=0
WEB_FONTS=0
FALLBACK_FONTS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Extraer font-family
    FONTS=$(grep -oE 'font-family:\s*["'\''][^"'\'']+["'\'']|font-family:\s*[^;]+' "$svg_file" 2>/dev/null || true)
    if [ -n "$FONTS" ]; then
      while IFS= read -r font_line; do
        FONT_FAMILY=$(echo "$font_line" | grep -oE '[^:]+$' | tr -d '";, ' | head -1)
        if [ -n "$FONT_FAMILY" ]; then
          FONT_FAMILIES+=("$FONT_FAMILY")
        fi
      done <<< "$FONTS"
    fi
    
    # Detectar fuentes personalizadas
    if grep -qi "font-face\|@import.*font" "$svg_file" 2>/dev/null; then
      CUSTOM_FONTS=$((CUSTOM_FONTS + 1))
    fi
    
    # Detectar fuentes web (Google Fonts, etc)
    if grep -qi "fonts.googleapis\|fonts.gstatic" "$svg_file" 2>/dev/null; then
      WEB_FONTS=$((WEB_FONTS + 1))
    fi
    
    # Detectar fallbacks
    if echo "$FONTS" | grep -qi "sans-serif\|serif\|monospace"; then
      FALLBACK_FONTS=$((FALLBACK_FONTS + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

if [ ${#FONT_FAMILIES[@]} -gt 0 ]; then
  UNIQUE_FONTS=$(printf '%s\n' "${FONT_FAMILIES[@]}" | sort -u | wc -l | xargs)
  log_info "Fuentes √∫nicas detectadas: $UNIQUE_FONTS"
  log_info "SVGs con fuentes personalizadas: $CUSTOM_FONTS"
  log_info "SVGs con fuentes web: $WEB_FONTS"
  log_info "SVGs con fallbacks: $FALLBACK_FONTS"
  
  if [ "$UNIQUE_FONTS" -gt 10 ]; then
    log_info "‚ö†Ô∏è  Muchas fuentes diferentes ($UNIQUE_FONTS) - considerar sistema tipogr√°fico unificado"
  fi
  
  # Mostrar fuentes m√°s usadas
  log_info ""
  log_info "Fuentes m√°s frecuentes:"
  printf '%s\n' "${FONT_FAMILIES[@]}" | sort | uniq -c | sort -rn | head -5 | while read -r count font; do
    log_info "  $font: $count referencias"
  done
fi

# Validaci√≥n de convenciones de nombres
log_section "üìù Validaci√≥n de Convenciones de Nombres"

NAMING_VIOLATIONS=0
GOOD_NAMING=0

NAMING_PATTERNS=(
  "ad_.*_(curso|saas|ia_bulk).*\\.svg"
  "carousel_.*\\.svg"
  "webinar-preroll-.*\\.svg"
)

while IFS= read -r svg_file; do
  basename_file=$(basename "$svg_file")
  is_valid=0
  
  # Verificar patrones v√°lidos
  for pattern in "${NAMING_PATTERNS[@]}"; do
    if echo "$basename_file" | grep -qiE "$pattern"; then
      is_valid=1
      break
    fi
  done
  
  # Verificar si est√° en subdirectorio v√°lido (linkedin, instagram, etc)
  dir_path=$(dirname "$svg_file")
  if echo "$dir_path" | grep -qiE "(linkedin|instagram|webinar|ads)"; then
    is_valid=1
  fi
  
  if [ "$is_valid" -eq 0 ]; then
    # Ignorar si est√° en variants o carousel
    if ! echo "$svg_file" | grep -qiE "(variants|carousel|node_modules|\\.git)"; then
      NAMING_VIOLATIONS=$((NAMING_VIOLATIONS + 1))
      if [ "$NAMING_VIOLATIONS" -le 5 ]; then
        log_info "‚ö†Ô∏è  Naming irregular: ${svg_file#$ROOT_DIR/}"
      fi
    fi
  else
    GOOD_NAMING=$((GOOD_NAMING + 1))
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -100)

if [ "$NAMING_VIOLATIONS" -eq 0 ]; then
  log_info "‚úÖ Todos los archivos siguen convenciones de nombres"
else
  log_info "‚ö†Ô∏è  Archivos con naming irregular: $NAMING_VIOLATIONS"
  if [ "$NAMING_VIOLATIONS" -gt 5 ]; then
    log_info "    ... y $((NAMING_VIOLATIONS - 5)) m√°s"
  fi
  log_info "üí° Convenci√≥n recomendada: ad_[producto]_[formato]_[angulo]_v[version].svg"
  
  # Actualizar health score (si a√∫n no se ha mostrado)
  if [ "$NAMING_VIOLATIONS" -gt 10 ]; then
    PENALTY=$((NAMING_VIOLATIONS / 5))
    HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
    HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
    RECOMMENDATIONS+=("Corregir naming en $NAMING_VIOLATIONS archivo(s)")
  fi
fi

log_info "‚úÖ Archivos con naming correcto: $GOOD_NAMING"

# An√°lisis de elementos SVG usados
log_section "üîß An√°lisis de Elementos SVG"

ELEMENT_TYPES=()
ANIMATION_COUNT=0
FILTER_COUNT=0
GRADIENT_COUNT=0
CLIP_PATH_COUNT=0
MASK_COUNT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar elementos
    ELEMENTS=$(grep -oE '<[a-z]+[^>]*>' "$svg_file" 2>/dev/null | sed 's/<\([a-z][^ >]*\).*/\1/' | sort -u)
    
    while IFS= read -r elem; do
      if [ -n "$elem" ]; then
        ELEMENT_TYPES+=("$elem")
      fi
    done <<< "$ELEMENTS"
    
    # Contar elementos avanzados
    if grep -qi "<animate\|<animation\|animateTransform\|animateMotion" "$svg_file" 2>/dev/null; then
      ANIMATION_COUNT=$((ANIMATION_COUNT + 1))
    fi
    
    if grep -qi "<filter\|fe" "$svg_file" 2>/dev/null; then
      FILTER_COUNT=$((FILTER_COUNT + 1))
    fi
    
    if grep -qi "<linearGradient\|<radialGradient" "$svg_file" 2>/dev/null; then
      GRADIENT_COUNT=$((GRADIENT_COUNT + 1))
    fi
    
    if grep -qi "<clipPath" "$svg_file" 2>/dev/null; then
      CLIP_PATH_COUNT=$((CLIP_PATH_COUNT + 1))
    fi
    
    if grep -qi "<mask" "$svg_file" 2>/dev/null; then
      MASK_COUNT=$((MASK_COUNT + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

if [ ${#ELEMENT_TYPES[@]} -gt 0 ]; then
  UNIQUE_ELEMENTS=$(printf '%s\n' "${ELEMENT_TYPES[@]}" | sort -u | wc -l | xargs)
  log_info "Tipos de elementos √∫nicos: $UNIQUE_ELEMENTS"
  log_info "SVGs con animaciones: $ANIMATION_COUNT"
  log_info "SVGs con filtros: $FILTER_COUNT"
  log_info "SVGs con gradientes: $GRADIENT_COUNT"
  log_info "SVGs con clipPath: $CLIP_PATH_COUNT"
  log_info "SVGs con m√°scaras: $MASK_COUNT"
  
  # Mostrar elementos m√°s usados
  log_info ""
  log_info "Elementos m√°s frecuentes:"
  printf '%s\n' "${ELEMENT_TYPES[@]}" | sort | uniq -c | sort -rn | head -10 | while read -r count elem; do
    log_info "  <$elem>: $count ocurrencias"
  done
fi

# An√°lisis de calidad de c√≥digo SVG
log_section "üé® An√°lisis de Calidad de C√≥digo"

INLINE_STYLES=0
STYLE_TAGS=0
UNUSED_DEFS=0
INCOMPLETE_PATHS=0
NO_VIEWBOX=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Contar estilos inline
    INLINE_COUNT=$(grep -c 'style="' "$svg_file" 2>/dev/null || echo "0")
    if [ "$INLINE_COUNT" -gt 10 ]; then
      INLINE_STYLES=$((INLINE_STYLES + 1))
    fi
    # Verificar si tiene <style>
    if grep -q "<style>" "$svg_file" 2>/dev/null; then
      STYLE_TAGS=$((STYLE_TAGS + 1))
    fi
    # Verificar viewBox
    if ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      NO_VIEWBOX=$((NO_VIEWBOX + 1))
    fi
    # Detectar paths incompletos
    if grep -q '<path[^>]*d=""' "$svg_file" 2>/dev/null; then
      INCOMPLETE_PATHS=$((INCOMPLETE_PATHS + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

log_info "Con <style> tag: $STYLE_TAGS"
log_info "Con muchos estilos inline (>10): $INLINE_STYLES"
if [ "$NO_VIEWBOX" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Sin viewBox: $NO_VIEWBOX (afecta escalabilidad)"
  log_info "üí° Recomendaci√≥n: A√±ade viewBox para mejor responsividad"
fi
if [ "$INCOMPLETE_PATHS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Con paths incompletos: $INCOMPLETE_PATHS"
fi

# Actualizar health score con nuevas m√©tricas
# Penalizar por problemas de accesibilidad
if [ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && [ "${TOTAL_ACCESSIBILITY_CHECKED:-0}" -gt 0 ]; then
  PENALTY=$(awk "BEGIN {printf \"%.0f\", ($NO_ACCESSIBILITY / $TOTAL_ACCESSIBILITY_CHECKED) * 10}")
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
fi

# Penalizar fuertemente por problemas de seguridad
if [ "${SECURITY_ISSUES:-0}" -gt 0 ]; then
  PENALTY=$((SECURITY_ISSUES * 10))
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
  RECOMMENDATIONS+=("URGENTE: Resolver $SECURITY_ISSUES problema(s) de seguridad")
fi

# Penalizar por falta de viewBox (afecta escalabilidad)
if [ "${NO_VIEWBOX:-0}" -gt 0 ] && [ "${TOTAL_ACCESSIBILITY_CHECKED:-0}" -gt 0 ]; then
  PENALTY=$(awk "BEGIN {printf \"%.0f\", ($NO_VIEWBOX / $TOTAL_ACCESSIBILITY_CHECKED) * 5}")
  HEALTH_SCORE=$((HEALTH_SCORE - PENALTY))
  if [ "$NO_VIEWBOX" -gt 10 ]; then
    HEALTH_ISSUES=$((HEALTH_ISSUES + 1))
    RECOMMENDATIONS+=("A√±adir viewBox a $NO_VIEWBOX SVG(s) para escalabilidad")
  fi
fi

# Asegurar score no negativo (re-calcular despu√©s de nuevas penalizaciones)
if [ "$HEALTH_SCORE" -lt 0 ]; then
  HEALTH_SCORE=0
fi

# Re-calcular nivel de salud con m√©tricas actualizadas
if [ "$HEALTH_SCORE" -ge 90 ]; then
  HEALTH_STATUS="‚úÖ Excelente"
elif [ "$HEALTH_SCORE" -ge 75 ]; then
  HEALTH_STATUS="‚úÖ Bueno"
elif [ "$HEALTH_SCORE" -ge 60 ]; then
  HEALTH_STATUS="‚ö†Ô∏è  Requiere atenci√≥n"
else
  HEALTH_STATUS="‚ùå Cr√≠tico"
fi

# Generar reportes adicionales (HTML y CSV)
log_section "üì§ Generaci√≥n de Reportes Adicionales"

if [ "$OUTPUT_FORMAT" = "all" ] || [ "$OUTPUT_FORMAT" = "html" ]; then
  HTML_REPORT="$EXPORT_DIR/assets_report.html"
  
  {
    echo "<!DOCTYPE html>"
    echo "<html><head>"
    echo "<meta charset='UTF-8'>"
    echo "<title>An√°lisis de Assets - $(date +'%Y-%m-%d')</title>"
    echo "<style>"
    echo "body { font-family: system-ui, sans-serif; max-width: 1200px; margin: 0 auto; padding: 20px; }"
    echo "h1 { color: #333; }"
    echo "h2 { border-bottom: 2px solid #007acc; padding-bottom: 5px; margin-top: 30px; }"
    echo ".metric { background: #f5f5f5; padding: 10px; margin: 5px 0; border-radius: 4px; }"
    echo ".warning { background: #fff3cd; border-left: 4px solid #ffc107; }"
    echo ".success { background: #d4edda; border-left: 4px solid #28a745; }"
    echo ".error { background: #f8d7da; border-left: 4px solid #dc3545; }"
    echo "pre { background: #f5f5f5; padding: 15px; border-radius: 4px; overflow-x: auto; }"
    echo "</style></head><body>"
    echo "<h1>üìä An√°lisis de Assets</h1>"
    echo "<p><strong>Fecha:</strong> $(date)</p>"
    echo "<p><strong>Total SVGs:</strong> $TOTAL_SVG_COUNT</p>"
    echo "<p><strong>Score de Salud:</strong> $HEALTH_SCORE/100 - $HEALTH_STATUS</p>"
    echo "<h2>Resumen</h2>"
    echo "<div class='metric'>"
    echo "<p><strong>SVGs v√°lidos:</strong> $((TOTAL_SVG_COUNT - ${EMPTY_SVGS:-0} - ${INVALID_STRUCTURE:-0}))</p>"
    echo "<p><strong>SVGs vac√≠os:</strong> ${EMPTY_SVGS:-0}</p>"
    echo "<p><strong>SVGs inv√°lidos:</strong> ${INVALID_STRUCTURE:-0}</p>"
    echo "<p><strong>Duplicados:</strong> ${DUPLICATE_GROUPS:-0} grupos</p>"
    echo "</div>"
    echo "<h2>Reporte Completo</h2>"
    echo "<pre>"
    cat "$REPORT" | sed 's/&/\&amp;/g; s/</\&lt;/g; s/>/\&gt;/g'
    echo "</pre>"
    echo "</body></html>"
  } > "$HTML_REPORT"
  
  log_info "‚úÖ Reporte HTML generado: $HTML_REPORT"
fi

if [ "$OUTPUT_FORMAT" = "all" ] || [ "$OUTPUT_FORMAT" = "csv" ]; then
  CSV_REPORT="$ROOT_DIR/exports/assets_summary.csv"
  
  {
    echo "M√©trica,Valor"
    echo "Total SVGs,$TOTAL_SVG_COUNT"
    echo "SVGs vac√≠os,${EMPTY_SVGS:-0}"
    echo "SVGs inv√°lidos,${INVALID_STRUCTURE:-0}"
    echo "Grupos duplicados,${DUPLICATE_GROUPS:-0}"
    echo "SVGs grandes (>500KB),${LARGE_COUNT:-0}"
    echo "Im√°genes rotas,${BROKEN_IMG:-0}"
    echo "Con ARIA labels,$ARIA_COUNT"
    echo "Con metadata,$METADATA_COUNT"
    echo "Problemas de seguridad,$SECURITY_ISSUES"
    echo "Health Score,$HEALTH_SCORE"
    echo "Estado,$HEALTH_STATUS"
    echo "Tiempo de ejecuci√≥n (s),${ELAPSED:-0}"
    echo "Fecha,$(date +'%Y-%m-%d %H:%M:%S')"
  } > "$CSV_REPORT"
  
  log_info "‚úÖ Reporte CSV generado: $CSV_REPORT"
fi

# Resumen final en consola
echo ""
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "‚úÖ An√°lisis completado en ${ELAPSED}s"
echo "üìä Total SVGs analizados: $TOTAL_SVGS"
echo "üè• Health Score: $HEALTH_SCORE/100 - $HEALTH_STATUS"
echo "üìÑ Reporte completo: $REPORT"
[ -n "${JSON_REPORT:-}" ] && [ -f "${JSON_REPORT:-}" ] && echo "üìÑ Reporte JSON: $JSON_REPORT"
[ -n "${HTML_REPORT:-}" ] && [ -f "${HTML_REPORT:-}" ] && echo "üìÑ Reporte HTML: $HTML_REPORT"
[ -n "${CSV_REPORT:-}" ] && [ -f "${CSV_REPORT:-}" ] && echo "üìÑ Reporte CSV: $CSV_REPORT"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo ""

# Mostrar resumen r√°pido si hay problemas cr√≠ticos
if [ "$HEALTH_SCORE" -lt 60 ]; then
  echo "‚ö†Ô∏è  ATENCI√ìN: Se detectaron problemas cr√≠ticos"
  echo "üí° Revisa las recomendaciones en el reporte completo"
  echo ""
fi

# Preguntar si quiere ver el reporte completo (opcional)
if [ -t 0 ]; then
  # Solo si es una terminal interactiva
  echo "Presiona Enter para ver el reporte completo, o Ctrl+C para salir..."
  read -r
fi

# Exportar datos para dashboard HTML
if command -v python3 >/dev/null 2>&1; then
  if [ -f "$ROOT_DIR/tools/generate_assets_dashboard_html.py" ]; then
    echo "" >> "$REPORT"
    echo "üìä Generando dashboard HTML..." >> "$REPORT"
    if python3 "$ROOT_DIR/tools/generate_assets_dashboard_html.py" >> "$REPORT" 2>&1; then
      echo "  ‚úÖ Dashboard HTML generado en exports/assets_dashboard.html" >> "$REPORT"
    else
      echo "  ‚ö†Ô∏è  Error generando dashboard (continuando...)" >> "$REPORT"
    fi
  fi
fi

# Recomendaciones finales
log_section "üí° Recomendaciones Prioritarias"

if [ "$HEALTH_SCORE" -lt 75 ]; then
  log_info "üî¥ PRIORIDAD ALTA:"
  if [ "$EMPTY_SVGS" -gt 0 ]; then
    log_info "   1. Arreglar $EMPTY_SVGS SVG(s) vac√≠o(s): bash tools/fix_broken_svgs.sh"
  fi
  if [ "$BROKEN_SVGS" -gt 0 ]; then
    log_info "   2. Reparar $BROKEN_SVGS SVG(s) con errores"
  fi
  if [ "$SVGS_WITHOUT_CSV" -gt 0 ]; then
    log_info "   3. A√±adir $SVGS_WITHOUT_CSV SVG(s) al CSV Master"
  fi
fi

if [ "$HEALTH_SCORE" -ge 75 ] && [ "$HEALTH_SCORE" -lt 90 ]; then
  log_info "üü° PRIORIDAD MEDIA:"
  if [ "$SVGS_WITHOUT_CSV" -gt 0 ]; then
    log_info "   1. Sincronizar $SVGS_WITHOUT_CSV SVG(s) con CSV"
  fi
  if [ "$OUTLIERS" -gt 0 ] 2>/dev/null; then
    log_info "   2. Optimizar $OUTLIERS archivo(s) grande(s) con svgo"
  fi
fi

if [ "$HEALTH_SCORE" -ge 90 ]; then
  log_info "üü¢ ESTADO √ìPTIMO:"
  log_info "   ‚úÖ Sistema en buen estado. Mant√©n la coherencia continuando con:"
  log_info "      - Validar UTMs al a√±adir nuevos creativos"
  log_info "      - Ejecutar health check semanalmente"
  log_info "      - Revisar gaps mensualmente"
fi

# Auto-fix disponible
if [ "$SVGS_WITHOUT_CSV" -gt 0 ] && command -v python3 >/dev/null 2>&1; then
  log_info ""
  log_info "üîß Auto-fix disponible:"
  log_info "   ‚Ä¢ python3 tools/auto_fix_gaps.py - A√±ade autom√°ticamente SVGs faltantes al CSV"
  log_info "   ‚Ä¢ python3 tools/auto_fix_gaps.py --auto - Sin confirmaci√≥n (modo autom√°tico)"
fi

# Links √∫tiles
log_info ""
log_info "üîó Herramientas relacionadas:"
log_info "   ‚Ä¢ python3 tools/validate_utms.py - Validar UTMs"
log_info "   ‚Ä¢ python3 tools/generate_utm_gaps_report.py - An√°lisis de gaps"
log_info "   ‚Ä¢ python3 tools/compare_creative_performance.py - Comparar performance"
log_info "   ‚Ä¢ python3 tools/generate_assets_dashboard_html.py - Dashboard visual"
log_info "   ‚Ä¢ python3 tools/generate_utm_suggestions.py - Sugerencias de UTMs"
log_info "   ‚Ä¢ python3 tools/auto_fix_gaps.py - Auto-fix de gaps"
log_info "   ‚Ä¢ bash tools/health_check.sh - Health check r√°pido"

# An√°lisis de recursos de video
log_section "üé¨ An√°lisis de Recursos de Video (15s)"

# Detectar scripts de video
VIDEO_SCRIPTS=$(find "$ROOT_DIR" -maxdepth 1 -name "ANUNCIO_VIDEO_*.md" 2>/dev/null | wc -l | xargs)
if [ "$VIDEO_SCRIPTS" -gt 0 ]; then
  log_info "‚úÖ Scripts de video encontrados: $VIDEO_SCRIPTS"
  
  # Contar por producto
  SCRIPT_CURSO=$(find "$ROOT_DIR" -maxdepth 1 -name "ANUNCIO_VIDEO_01_*.md" 2>/dev/null | wc -l | xargs)
  SCRIPT_SAAS=$(find "$ROOT_DIR" -maxdepth 1 -name "ANUNCIO_VIDEO_02_*.md" 2>/dev/null | wc -l | xargs)
  SCRIPT_BULK=$(find "$ROOT_DIR" -maxdepth 1 -name "ANUNCIO_VIDEO_03_*.md" 2>/dev/null | wc -l | xargs)
  
  [ "$SCRIPT_CURSO" -gt 0 ] && log_info "  - Curso IA: $SCRIPT_CURSO script(s)"
  [ "$SCRIPT_SAAS" -gt 0 ] && log_info "  - SaaS Marketing: $SCRIPT_SAAS script(s)"
  [ "$SCRIPT_BULK" -gt 0 ] && log_info "  - IA Bulk: $SCRIPT_BULK script(s)"
else
  log_info "‚ö†Ô∏è  Scripts de video no encontrados"
fi

# Detectar archivos de branding para video
VIDEO_BRANDING=$(find "$ROOT_DIR" -maxdepth 1 -name "*PALETA*BRANDING*.json" -o -name "*PALETA*EXTRAIDA*.json" 2>/dev/null | wc -l | xargs)
if [ "$VIDEO_BRANDING" -gt 0 ]; then
  log_info "‚úÖ Archivos de branding video: $VIDEO_BRANDING"
else
  log_info "‚ö†Ô∏è  Archivos de branding video no encontrados"
fi

# Detectar recursos de video (SRT, CSV markers)
SRT_FILES=$(find "$ROOT_DIR" -name "*.srt" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
CSV_MARKERS=$(find "$ROOT_DIR" -name "*markers*.csv" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
VIDEO_EXPORTS=$(find "$ROOT_DIR" -name "*.mp4" -o -name "*.mov" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)

log_info "üìπ Archivos SRT (subt√≠tulos): $SRT_FILES"
log_info "üìç CSV markers: $CSV_MARKERS"
log_info "üé• Videos exportados: $VIDEO_EXPORTS"

# Verificar estructura de carpetas de video
VIDEO_EXPORTS_DIR="$ROOT_DIR/anuncios_video_15s/exports"
if [ -d "$VIDEO_EXPORTS_DIR" ]; then
  log_info "‚úÖ Directorio exports video encontrado"
  
  # Contar por producto
  for producto in "curso_ia_webinar" "saas_ia_marketing" "ia_bulk_docs"; do
    PRODUCT_DIR="$VIDEO_EXPORTS_DIR/$producto"
    if [ -d "$PRODUCT_DIR" ]; then
      PRODUCT_VIDEOS=$(find "$PRODUCT_DIR" -name "*.mp4" -o -name "*.mov" 2>/dev/null | wc -l | xargs)
      PRODUCT_SRT=$(find "$PRODUCT_DIR" -name "*.srt" 2>/dev/null | wc -l | xargs)
      PRODUCT_CSV=$(find "$PRODUCT_DIR" -name "*.csv" 2>/dev/null | wc -l | xargs)
      
      log_info "  $producto:"
      log_info "    - Videos: $PRODUCT_VIDEOS"
      log_info "    - Subt√≠tulos: $PRODUCT_SRT"
      log_info "    - Markers: $PRODUCT_CSV"
    fi
  done
else
  log_info "‚ö†Ô∏è  Directorio exports video no encontrado (esperado: $VIDEO_EXPORTS_DIR)"
fi

# An√°lisis de coherencia SVG ‚Üî Video
log_section "üîÑ Coherencia SVG ‚Üî Video"

# Verificar si hay SVGs relacionados con productos de video
for producto in "curso_ia" "saas_ia_marketing" "ia_bulk"; do
  SVG_COUNT=$(find "$ROOT_DIR/ads/linkedin" -name "*${producto}*.svg" 2>/dev/null | wc -l | xargs)
  
  case "$producto" in
    "curso_ia")
      VIDEO_SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_01_CURSO_IA_WEBINAR_15s.md"
      ;;
    "saas_ia_marketing")
      VIDEO_SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_02_SAAS_IA_MARKETING_15s.md"
      ;;
    "ia_bulk")
      VIDEO_SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_03_IA_BULK_DOCUMENTOS_15s.md"
      ;;
  esac
  
  if [ -f "$VIDEO_SCRIPT" ]; then
    log_info "‚úÖ $producto: $SVG_COUNT SVG(s) + script video encontrado"
  elif [ "$SVG_COUNT" -gt 0 ]; then
    log_info "‚ö†Ô∏è  $producto: $SVG_COUNT SVG(s) pero script video no encontrado"
  fi
done

# An√°lisis de compliance con pol√≠ticas de plataformas
log_section "‚úÖ Validaci√≥n de Compliance (Plataformas)"

COMPLIANCE_ISSUES=0

validate_platform_compliance() {
  local script_file="$1"
  local prod="$2"
  local issues=0
  
  if [ ! -f "$script_file" ]; then
    return 0
  fi
  
  # Verificar disclaimers mencionados
  if ! grep -qiE "disclaimer|im√°genes simuladas|resultados pueden variar|resultados individuales" "$script_file" 2>/dev/null; then
    echo "    - $prod: Script no menciona disclaimers (requerido para Meta/Instagram)" >> "$REPORT"
    issues=1
  fi
  
  # Verificar claims exagerados (palabras prohibidas)
  if grep -qiE "garantizado|100%|siempre|nunca falla" "$script_file" 2>/dev/null; then
    echo "    - $prod: Script contiene claims potencialmente prohibidos (- verificar compliance)" >> "$REPORT"
    issues=1
  fi
  
  # Verificar que no hay claims garantistas
  if grep -qiE "garant√≠a|promesa|asegura" "$script_file" 2>/dev/null; then
    if ! grep -qiE "disclaimer|condiciones|t√©rminos" "$script_file" 2>/dev/null; then
      echo "    - $prod: Menciones de garant√≠a sin disclaimers apropiados" >> "$REPORT"
      issues=1
    fi
  fi
  
  # Verificar especificaciones de plataforma mencionadas
  if ! grep -qiE "1080.*1920|vertical|9:16|reels|stories" "$script_file" 2>/dev/null; then
    echo "    - $prod: Script no menciona especificaciones de formato para plataformas" >> "$REPORT"
    issues=1
  fi
  
  return $issues
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  case "$prod" in
    "curso_ia_webinar")
      SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_01_CURSO_IA_WEBINAR_15s.md"
      ;;
    "saas_ia_marketing")
      SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_02_SAAS_IA_MARKETING_15s.md"
      ;;
    "ia_bulk_docs")
      SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_03_IA_BULK_DOCUMENTOS_15s.md"
      ;;
    *)
      continue
      ;;
  esac
  
  if [ -f "$SCRIPT" ]; then
    if validate_platform_compliance "$SCRIPT" "$prod"; then
      log_info "  ‚úÖ $prod: compliance con pol√≠ticas OK"
    else
      log_info "  ‚ö†Ô∏è  $prod: posibles issues de compliance (- ver reporte)"
      COMPLIANCE_ISSUES=$((COMPLIANCE_ISSUES + 1))
    fi
  fi
done

if [ "$COMPLIANCE_ISSUES" -eq 0 ]; then
  log_info "‚úÖ Compliance con pol√≠ticas de plataformas OK"
else
  RECOMMENDATIONS+=("Revisar compliance en $COMPLIANCE_ISSUES producto(s) (disclaimers, claims, especificaciones)")
fi

# Detecci√≥n de assets hu√©rfanos (sin referencias)
log_section "üîç Detecci√≥n de Assets Hu√©rfanos"

ORPHAN_VIDEO_ASSETS=0

detect_orphan_video_assets() {
  local prod="$1"
  local exports_dir="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
  local orphan_count=0
  
  if [ ! -d "$exports_dir" ]; then
    return 0
  fi
  
  # Buscar videos que no tengan SRT o markers correspondientes
  while IFS= read -r video_file; do
    if [ -f "$video_file" ]; then
      local basename=$(basename "$video_file" | sed 's/\.\(mp4\|mov\)$//')
      local has_srt=0
      local has_markers=0
      
      # Verificar si existe SRT correspondiente
      if [ -f "$exports_dir/subtitles_es.srt" ]; then
        if grep -qi "$basename\|$(echo "$basename" | sed 's/_v[0-9]*//')" "$exports_dir/subtitles_es.srt" 2>/dev/null; then
          has_srt=1
        fi
      fi
      
      # Verificar si existe markers correspondiente
      if [ -f "$exports_dir/markers.csv" ]; then
        if grep -qi "$basename\|$(echo "$basename" | sed 's/_v[0-9]*//')" "$exports_dir/markers.csv" 2>/dev/null; then
          has_markers=1
        fi
      fi
      
      # Si el video no tiene referencias en SRT ni markers, es hu√©rfano
      if [ "$has_srt" -eq 0 ] && [ "$has_markers" -eq 0 ]; then
        if [ "$orphan_count" -eq 0 ]; then
          echo "  ‚ö†Ô∏è  $prod: videos sin referencias en SRT/markers:" >> "$REPORT"
        fi
        echo "    - $(basename "$video_file")" >> "$REPORT"
        orphan_count=$((orphan_count + 1))
      fi
    fi
  done < <(find "$exports_dir" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null)
  
  if [ "$orphan_count" -gt 0 ]; then
    ORPHAN_VIDEO_ASSETS=$((ORPHAN_VIDEO_ASSETS + orphan_count))
    return 1
  fi
  return 0
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  if detect_orphan_video_assets "$prod"; then
    log_info "  ‚ö†Ô∏è  $prod: assets hu√©rfanos detectados (- ver reporte)"
  else
    log_info "  ‚úÖ $prod: todos los videos tienen referencias"
  fi
done

if [ "$ORPHAN_VIDEO_ASSETS" -eq 0 ]; then
  log_info "‚úÖ Sin assets hu√©rfanos detectados"
else
  RECOMMENDATIONS+=("Revisar $ORPHAN_VIDEO_ASSETS video(s) hu√©rfano(s) sin referencias en SRT/markers")
fi

# An√°lisis de dependencias entre assets
log_section "üîó An√°lisis de Dependencias entre Assets"

ASSET_DEPENDENCIES=0

analyze_asset_dependencies() {
  local missing_deps=0
  
  # Verificar que cada producto tenga sus assets relacionados
  for prod in "${!PRODUCT_DIRS[@]}"; do
    local exports_dir="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
    local missing=0
    
    if [ -d "$exports_dir" ]; then
      # Verificar dependencias cr√≠ticas
      local has_video=$(find "$exports_dir" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null | wc -l | xargs)
      local has_srt=$([ -f "$exports_dir/subtitles_es.srt" ] && echo "1" || echo "0")
      local has_markers=$([ -f "$exports_dir/markers.csv" ] && echo "1" || echo "0")
      
      # Un video sin SRT o sin markers es una dependencia faltante
      if [ "$has_video" -gt 0 ]; then
        if [ "$has_srt" -eq 0 ]; then
          echo "    - $prod: videos encontrados pero falta subtitles_es.srt" >> "$REPORT"
          missing=1
        fi
        if [ "$has_markers" -eq 0 ]; then
          echo "    - $prod: videos encontrados pero falta markers.csv" >> "$REPORT"
          missing=1
        fi
      fi
      
      # Si hay SRT o markers pero no videos, tambi√©n es un issue
      if [ "$has_video" -eq 0 ] && ([ "$has_srt" -eq 1 ] || [ "$has_markers" -eq 1 ]); then
        echo "    - $prod: SRT/markers encontrados pero no hay videos exportados" >> "$REPORT"
        missing=1
      fi
    fi
    
    if [ "$missing" -eq 1 ]; then
      missing_deps=$((missing_deps + 1))
    fi
  done
  
  if [ "$missing_deps" -eq 0 ]; then
    log_info "‚úÖ Dependencias entre assets completas"
  else
    log_info "‚ö†Ô∏è  $missing_deps producto(s) con dependencias incompletas"
    ASSET_DEPENDENCIES=$missing_deps
    RECOMMENDATIONS+=("Completar dependencias faltantes en $missing_deps producto(s)")
  fi
}

analyze_asset_dependencies

# An√°lisis de tendencias temporales
log_section "üìà An√°lisis de Tendencias Temporales"

if [ "${TOTAL_SVGS:-0}" -gt 0 ]; then
  # Calcular tasa de crecimiento de assets (si hay m√∫ltiples ejecuciones)
  if [ -f "$REPORT" ]; then
    # Buscar fechas de modificaci√≥n recientes
    RECENT_SVGS=$(find "$ROOT_DIR" -name "*.svg" -type f -mtime -7 -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
    RECENT_VIDEOS=$(find "$EXPORTS_BASE" -type f \( -name "*.mp4" -o -name "*.mov" \) -mtime -7 2>/dev/null | wc -l | xargs)
    
    if [ "$RECENT_SVGS" -gt 0 ] || [ "$RECENT_VIDEOS" -gt 0 ]; then
      log_info "Assets creados/modificados esta semana:"
      [ "$RECENT_SVGS" -gt 0 ] && log_info "  - SVGs: $RECENT_SVGS"
      [ "$RECENT_VIDEOS" -gt 0 ] && log_info "  - Videos: $RECENT_VIDEOS"
      
      # Calcular tasa de crecimiento semanal estimada
      if [ "$RECENT_SVGS" -gt 0 ] && [ "$TOTAL_SVGS" -gt 0 ]; then
        GROWTH_RATE=$(awk "BEGIN {printf \"%.1f\", ($RECENT_SVGS / $TOTAL_SVGS) * 100}")
        log_info "  - Tasa de crecimiento semanal estimada: ${GROWTH_RATE}%"
      fi
    else
      log_info "‚ÑπÔ∏è  No se detectaron assets nuevos en la √∫ltima semana"
    fi
  fi
fi

# Validaci√≥n de accesibilidad en videos
log_section "‚ôø Validaci√≥n de Accesibilidad (Videos)"

ACCESSIBILITY_VIDEO_ISSUES=0

validate_video_accessibility() {
  local prod="$1"
  local script_file=""
  
  case "$prod" in
    "curso_ia_webinar")
      script_file="$ROOT_DIR/ANUNCIO_VIDEO_01_CURSO_IA_WEBINAR_15s.md"
      ;;
    "saas_ia_marketing")
      script_file="$ROOT_DIR/ANUNCIO_VIDEO_02_SAAS_IA_MARKETING_15s.md"
      ;;
    "ia_bulk_docs")
      script_file="$ROOT_DIR/ANUNCIO_VIDEO_03_IA_BULK_DOCUMENTOS_15s.md"
      ;;
    *)
      return 0
      ;;
  esac
  
  local issues=0
  
  if [ -f "$script_file" ]; then
    if ! grep -qiE "subt√≠tulos|subtitles|srt|captions|closed.*captions" "$script_file" 2>/dev/null; then
      echo "    - $prod: Script no menciona subt√≠tulos (requerido para accesibilidad WCAG)" >> "$REPORT"
      issues=1
    fi
    
    if ! grep -qiE "contraste|contrast|4\.5:1|WCAG|accesibilidad" "$script_file" 2>/dev/null; then
      echo "    - $prod: Script no menciona contraste de texto (WCAG 2.1 AA requiere ‚â•4.5:1)" >> "$REPORT"
      issues=1
    fi
    
    if ! grep -qiE "safe.*zone|safe.*area|150.*px|m√°rgenes.*seguro" "$script_file" 2>/dev/null; then
      echo "    - $prod: Script no menciona safe zones (importante para legibilidad)" >> "$REPORT"
      issues=1
    fi
  fi
  
  local exports_dir="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
  if [ -d "$exports_dir" ]; then
    if [ ! -f "$exports_dir/subtitles_es.srt" ]; then
      echo "    - $prod: Archivo subtitles_es.srt no encontrado (requerido para accesibilidad)" >> "$REPORT"
      issues=1
    fi
  fi
  
  return $issues
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  if validate_video_accessibility "$prod"; then
    log_info "  ‚úÖ $prod: accesibilidad OK"
  else
    log_info "  ‚ö†Ô∏è  $prod: issues de accesibilidad detectados (- ver reporte)"
    ACCESSIBILITY_VIDEO_ISSUES=$((ACCESSIBILITY_VIDEO_ISSUES + 1))
  fi
done

if [ "$ACCESSIBILITY_VIDEO_ISSUES" -eq 0 ]; then
  log_info "‚úÖ Accesibilidad de videos OK (WCAG 2.1 AA)"
else
  RECOMMENDATIONS+=("Mejorar accesibilidad en $ACCESSIBILITY_VIDEO_ISSUES producto(s) (subt√≠tulos, contraste, safe zones)")
fi

# Validaci√≥n de URLs y links en scripts
log_section "üîó Validaci√≥n de URLs y Links"

URL_ISSUES=0

validate_urls_in_scripts() {
  local script_file="$1"
  local prod="$2"
  local issues=0
  
  if [ ! -f "$script_file" ]; then
    return 0
  fi
  
  local urls=$(grep -oiE 'https?://[^\s<>"'"'"']+' "$script_file" 2>/dev/null || true)
  
  if [ -n "$urls" ]; then
    while IFS= read -r url; do
      if ! echo "$url" | grep -qE '^https?://[a-zA-Z0-9.-]+'; then
        echo "    - $prod: URL con formato inv√°lido: $url" >> "$REPORT"
        issues=1
      fi
      
      if echo "$url" | grep -qiE '\[.*\]|placeholder|ejemplo|example|http://example'; then
        echo "    - $prod: URL placeholder no reemplazada: $url" >> "$REPORT"
        issues=1
      fi
      
      if echo "$url" | grep -qE '\?'; then
        if ! echo "$url" | grep -qiE 'utm_source|utm_medium|utm_campaign'; then
          echo "    - $prod: URL sin par√°metros UTM: $url" >> "$REPORT"
          issues=1
        fi
      fi
    done <<< "$urls"
  else
    if grep -qiE "inscr|inscrib|probar|demo|trial|registro|landing|cta.*url" "$script_file" 2>/dev/null; then
      echo "    - $prod: Script menciona CTAs/acciones pero no hay URLs definidas" >> "$REPORT"
      issues=1
    fi
  fi
  
  return $issues
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  case "$prod" in
    "curso_ia_webinar")
      SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_01_CURSO_IA_WEBINAR_15s.md"
      ;;
    "saas_ia_marketing")
      SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_02_SAAS_IA_MARKETING_15s.md"
      ;;
    "ia_bulk_docs")
      SCRIPT="$ROOT_DIR/ANUNCIO_VIDEO_03_IA_BULK_DOCUMENTOS_15s.md"
      ;;
    *)
      continue
      ;;
  esac
  
  if [ -f "$SCRIPT" ]; then
    if validate_urls_in_scripts "$SCRIPT" "$prod"; then
      log_info "  ‚úÖ $prod: URLs v√°lidas"
    else
      log_info "  ‚ö†Ô∏è  $prod: issues en URLs detectados (- ver reporte)"
      URL_ISSUES=$((URL_ISSUES + 1))
    fi
  fi
done

if [ "$URL_ISSUES" -eq 0 ]; then
  log_info "‚úÖ Validaci√≥n de URLs OK"
else
  RECOMMENDATIONS+=("Revisar URLs en $URL_ISSUES producto(s) (formato, placeholders, UTMs)")
fi

# An√°lisis de completitud de workflows
log_section "üìã An√°lisis de Completitud de Workflows"

WORKFLOW_COMPLETENESS=0

analyze_workflow_completeness() {
  local prod="$1"
  local completeness_score=100
  local missing_items=0
  
  local exports_dir="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
  
  local has_script=0
  local has_video=0
  local has_srt=0
  local has_markers=0
  local has_thumbnail=0
  
  case "$prod" in
    "curso_ia_webinar")
      [ -f "$ROOT_DIR/ANUNCIO_VIDEO_01_CURSO_IA_WEBINAR_15s.md" ] && has_script=1
      ;;
    "saas_ia_marketing")
      [ -f "$ROOT_DIR/ANUNCIO_VIDEO_02_SAAS_IA_MARKETING_15s.md" ] && has_script=1
      ;;
    "ia_bulk_docs")
      [ -f "$ROOT_DIR/ANUNCIO_VIDEO_03_IA_BULK_DOCUMENTOS_15s.md" ] && has_script=1
      ;;
  esac
  
  if [ -d "$exports_dir" ]; then
    [ -n "$(find "$exports_dir" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null)" ] && has_video=1
    [ -f "$exports_dir/subtitles_es.srt" ] && has_srt=1
    [ -f "$exports_dir/markers.csv" ] && has_markers=1
  fi
  
  local thumb_dir="$ROOT_DIR/anuncios_video_15s/thumbnails"
  if [ -d "$thumb_dir" ]; then
    [ -n "$(find "$thumb_dir" -iname "*${prod}*" -o -iname "*${PRODUCT_DIRS[$prod]}*" 2>/dev/null)" ] && has_thumbnail=1
  fi
  
  [ "$has_script" -eq 0 ] && completeness_score=$((completeness_score - 20)) && missing_items=$((missing_items + 1))
  [ "$has_video" -eq 0 ] && completeness_score=$((completeness_score - 30)) && missing_items=$((missing_items + 1))
  [ "$has_srt" -eq 0 ] && completeness_score=$((completeness_score - 20)) && missing_items=$((missing_items + 1))
  [ "$has_markers" -eq 0 ] && completeness_score=$((completeness_score - 15)) && missing_items=$((missing_items + 1))
  [ "$has_thumbnail" -eq 0 ] && completeness_score=$((completeness_score - 15)) && missing_items=$((missing_items + 1))
  
  if [ "$missing_items" -gt 0 ]; then
    echo "  ‚ö†Ô∏è  $prod: Workflow incompleto (${completeness_score}/100):" >> "$REPORT"
    [ "$has_script" -eq 0 ] && echo "    - Falta script de video" >> "$REPORT"
    [ "$has_video" -eq 0 ] && echo "    - Falta video exportado" >> "$REPORT"
    [ "$has_srt" -eq 0 ] && echo "    - Falta subtitles_es.srt" >> "$REPORT"
    [ "$has_markers" -eq 0 ] && echo "    - Falta markers.csv" >> "$REPORT"
    [ "$has_thumbnail" -eq 0 ] && echo "    - Falta thumbnail" >> "$REPORT"
    return 1
  fi
  
  return 0
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  if analyze_workflow_completeness "$prod"; then
    log_info "  ‚úÖ $prod: workflow completo"
  else
    log_info "  ‚ö†Ô∏è  $prod: workflow incompleto (- ver reporte)"
    WORKFLOW_COMPLETENESS=$((WORKFLOW_COMPLETENESS + 1))
  fi
done

if [ "$WORKFLOW_COMPLETENESS" -eq 0 ]; then
  log_info "‚úÖ Todos los workflows est√°n completos"
else
  RECOMMENDATIONS+=("Completar workflows en $WORKFLOW_COMPLETENESS producto(s) (script, video, SRT, markers, thumbnail)")
fi

# Verificar recursos de integraci√≥n video
log_section "üîó Recursos de Integraci√≥n Video"

INTEGRATION_FILES=(
  "ANUNCIO_VIDEO_INTEGRACION_ASSETS_EXISTENTES.md"
  "ANUNCIO_VIDEO_ADAPTACION_FORMATOS.md"
  "ANUNCIO_VIDEO_WORKFLOW_INTEGRATION.md"
  "ANUNCIO_VIDEO_TEMPLATES_WEBINAR_PREROLL.md"
)

INTEGRATION_FOUND=0
for file in "${INTEGRATION_FILES[@]}"; do
  if [ -f "$ROOT_DIR/$file" ]; then
    INTEGRATION_FOUND=$((INTEGRATION_FOUND + 1))
    log_info "  ‚úÖ $file"
  fi
done

if [ "$INTEGRATION_FOUND" -eq ${#INTEGRATION_FILES[@]} ]; then
  log_info "‚úÖ Todos los recursos de integraci√≥n encontrados"
else
  log_info "‚ö†Ô∏è  Algunos recursos de integraci√≥n faltantes: $INTEGRATION_FOUND/${#INTEGRATION_FILES[@]}"
fi

# Verificar recursos de automatizaci√≥n video
log_section "ü§ñ Automatizaci√≥n Video"

AUTOMATION_VIDEO="$ROOT_DIR/ANUNCIO_VIDEO_AUTOMATION_SCRIPTS.md"
if [ -f "$AUTOMATION_VIDEO" ]; then
  log_info "‚úÖ Scripts de automatizaci√≥n video encontrados"
  
  # Verificar si los scripts mencionados existen
  PYTHON_SCRIPTS=$(find "$ROOT_DIR" -name "*.py" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
  NODE_VIDEO_SCRIPTS=$(find "$ROOT_DIR" -name "*video*.js" -o -name "*srt*.js" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
  
  log_info "  - Scripts Python: $PYTHON_SCRIPTS"
  log_info "  - Scripts Node.js video: $NODE_VIDEO_SCRIPTS"
else
  log_info "‚ö†Ô∏è  Documentaci√≥n de automatizaci√≥n video no encontrada"
fi

# An√°lisis de formatos verticales para video
log_section "üì± Formatos Verticales (Video 15s)"

VERTICAL_SVGS=$(find "$ROOT_DIR" -name "*1080x1920*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
VERTICAL_VIDEOS=$(find "$ROOT_DIR" -name "*1080x1920*.mp4" -o -name "*1080x1920*.mov" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)

log_info "SVGs verticales (1080√ó1920): $VERTICAL_SVGS"
log_info "Videos verticales (1080√ó1920): $VERTICAL_VIDEOS"

if [ "$VERTICAL_SVGS" -gt 0 ] && [ "$VERTICAL_VIDEOS" -eq 0 ]; then
  log_info "üí° Sugerencia: Tienes SVGs verticales pero no videos exportados - considera producir videos"
elif [ "$VERTICAL_SVGS" -eq 0 ] && [ "$VERTICAL_VIDEOS" -gt 0 ]; then
  log_info "‚úÖ Videos verticales disponibles (pueden haber sido creados desde otros formatos)"
elif [ "$VERTICAL_SVGS" -gt 0 ] && [ "$VERTICAL_VIDEOS" -gt 0 ]; then
  RATIO=$(awk "BEGIN {printf \"%.1f\", ($VERTICAL_VIDEOS / $VERTICAL_SVGS) * 100}")
  log_info "üìä Ratio videos/SVGs: ${RATIO}%"
fi

# Verificar recursos de storyboard y templates
log_section "üìê Storyboards y Templates Video"

STORYBOARD_FILES=$(find "$ROOT_DIR" -name "*STORYBOARD*.md" -o -name "*TEMPLATE*VIDEO*.md" -o -name "*TEMPLATE*SVG*VIDEO*.md" 2>/dev/null | wc -l | xargs)
AFTER_EFFECTS_RESOURCES=$(find "$ROOT_DIR" -name "*EXPRESIONES*AFTER*EFFECTS*.md" -o -name "*AFTER*EFFECTS*.md" 2>/dev/null | wc -l | xargs)

log_info "Storyboards/templates video: $STORYBOARD_FILES"
log_info "Recursos After Effects: $AFTER_EFFECTS_RESOURCES"

# Verificar checklist de producci√≥n
CHECKLIST_VIDEO="$ROOT_DIR/ANUNCIO_VIDEO_CHECKLIST_PRODUCCION_COMPLETA.md"
if [ -f "$CHECKLIST_VIDEO" ]; then
  log_info "‚úÖ Checklist de producci√≥n video encontrado"
else
  log_info "‚ö†Ô∏è  Checklist de producci√≥n video no encontrado"
fi

# Verificar √≠ndice maestro
INDICE_MAESTRO="$ROOT_DIR/ANUNCIO_VIDEO_INDICE_MAESTRO.md"
if [ -f "$INDICE_MAESTRO" ]; then
  log_info "‚úÖ √çndice maestro video encontrado"
else
  log_info "‚ö†Ô∏è  √çndice maestro video no encontrado"
fi

# An√°lisis de hooks y variantes
log_section "üéØ Hooks y Variantes Video"

HOOKS_FILE="$ROOT_DIR/ANUNCIO_VIDEO_VARIANTES_HOOKS_EXTRA.md"
MATRIZ_DECISION="$ROOT_DIR/ANUNCIO_VIDEO_MATRIZ_DECISION_VERSIONES.md"

if [ -f "$HOOKS_FILE" ]; then
  log_info "‚úÖ Archivo de hooks/variantes encontrado"
else
  log_info "‚ö†Ô∏è  Archivo de hooks/variantes no encontrado"
fi

if [ -f "$MATRIZ_DECISION" ]; then
  log_info "‚úÖ Matriz de decisi√≥n encontrada"
else
  log_info "‚ö†Ô∏è  Matriz de decisi√≥n no encontrada"
fi

# An√°lisis de duraci√≥n de videos
log_section "‚è±Ô∏è  An√°lisis de Duraci√≥n Video"

if command -v ffprobe &> /dev/null && [ "$VIDEO_EXPORTS" -gt 0 ]; then
  NON_15S_VIDEOS=0
  TOTAL_DURATION=0
  VIDEO_COUNT=0
  
  while IFS= read -r video_file; do
    if [ -f "$video_file" ]; then
      DURATION=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "$video_file" 2>/dev/null | cut -d. -f1)
      if [ -n "$DURATION" ] && [ "$DURATION" -gt 0 ]; then
        VIDEO_COUNT=$((VIDEO_COUNT + 1))
        TOTAL_DURATION=$((TOTAL_DURATION + DURATION))
        
        # Videos que no son exactamente 15 segundos (con margen de 1 segundo)
        if [ "$DURATION" -lt 14 ] || [ "$DURATION" -gt 16 ]; then
          NON_15S_VIDEOS=$((NON_15S_VIDEOS + 1))
        fi
      fi
    fi
  done < <(find "$ROOT_DIR" -name "*.mp4" -o -name "*.mov" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -20)
  
  if [ "$VIDEO_COUNT" -gt 0 ]; then
    AVG_DURATION=$(awk "BEGIN {printf \"%.1f\", $TOTAL_DURATION / $VIDEO_COUNT}")
    log_info "Videos analizados: $VIDEO_COUNT"
    log_info "Duraci√≥n promedio: ${AVG_DURATION}s"
    
    if [ "$NON_15S_VIDEOS" -gt 0 ]; then
      log_info "‚ö†Ô∏è  Videos fuera de 15s: $NON_15S_VIDEOS"
      log_info "üí° Recomendaci√≥n: Ajusta duraci√≥n a 15s para consistencia"
    else
      log_info "‚úÖ Todos los videos analizados tienen duraci√≥n de 15s (¬±1s)"
    fi
  fi
else
  if [ "$VIDEO_EXPORTS" -gt 0 ]; then
    log_info "‚ÑπÔ∏è  ffprobe no disponible - no se puede analizar duraci√≥n"
  else
    log_info "‚ÑπÔ∏è  No hay videos exportados para analizar"
  fi
fi

# Verificar assets de B-roll
log_section "üì∏ Assets de B-roll"

BROLL_DIR="$ROOT_DIR/anuncios_video_15s/assets/b-roll"
if [ -d "$BROLL_DIR" ]; then
  BROLL_VIDEOS=$(find "$BROLL_DIR" -name "*.mp4" -o -name "*.mov" 2>/dev/null | wc -l | xargs)
  BROLL_IMAGES=$(find "$BROLL_DIR" -name "*.png" -o -name "*.jpg" -o -name "*.jpeg" 2>/dev/null | wc -l | xargs)
  
  log_info "‚úÖ Directorio B-roll encontrado"
  log_info "  - Videos B-roll: $BROLL_VIDEOS"
  log_info "  - Im√°genes B-roll: $BROLL_IMAGES"
  
  if [ "$BROLL_VIDEOS" -eq 0 ] && [ "$BROLL_IMAGES" -eq 0 ]; then
    log_info "‚ö†Ô∏è  Directorio B-roll vac√≠o - considera a√±adir assets"
  fi
else
  log_info "‚ö†Ô∏è  Directorio B-roll no encontrado (esperado: $BROLL_DIR)"
fi

# Verificaci√≥n de thumbnails movida a secci√≥n mejorada m√°s abajo

# Resumen de cobertura video
log_section "üìä Resumen Cobertura Video"

TOTAL_VIDEO_RESOURCES=0
[ -f "$ROOT_DIR/ANUNCIO_VIDEO_01_CURSO_IA_WEBINAR_15s.md" ] && TOTAL_VIDEO_RESOURCES=$((TOTAL_VIDEO_RESOURCES + 1))
[ -f "$ROOT_DIR/ANUNCIO_VIDEO_02_SAAS_IA_MARKETING_15s.md" ] && TOTAL_VIDEO_RESOURCES=$((TOTAL_VIDEO_RESOURCES + 1))
[ -f "$ROOT_DIR/ANUNCIO_VIDEO_03_IA_BULK_DOCUMENTOS_15s.md" ] && TOTAL_VIDEO_RESOURCES=$((TOTAL_VIDEO_RESOURCES + 1))
[ -f "$ROOT_DIR/ANUNCIO_VIDEO_PALETA_BRANDING.json" ] && TOTAL_VIDEO_RESOURCES=$((TOTAL_VIDEO_RESOURCES + 1))
[ -f "$CHECKLIST_VIDEO" ] && TOTAL_VIDEO_RESOURCES=$((TOTAL_VIDEO_RESOURCES + 1))
[ -f "$INDICE_MAESTRO" ] && TOTAL_VIDEO_RESOURCES=$((TOTAL_VIDEO_RESOURCES + 1))

log_info "Recursos de video disponibles: $TOTAL_VIDEO_RESOURCES/6 principales"

if [ "$TOTAL_VIDEO_RESOURCES" -eq 6 ]; then
  log_info "‚úÖ Cobertura completa de recursos video"
elif [ "$TOTAL_VIDEO_RESOURCES" -ge 4 ]; then
  log_info "‚ö†Ô∏è  Cobertura parcial - faltan algunos recursos"
else
  log_info "‚ùå Cobertura incompleta - faltan recursos cr√≠ticos"
fi

# Recomendaciones de workflow video
log_section "üí° Recomendaciones Workflow Video"

RECOMMENDATIONS_COUNT=0

if [ "$VIDEO_EXPORTS" -eq 0 ] && [ "$VIDEO_SCRIPTS" -gt 0 ]; then
  log_info "üí° Tienes scripts pero no videos exportados - considera comenzar producci√≥n"
  RECOMMENDATIONS_COUNT=$((RECOMMENDATIONS_COUNT + 1))
fi

if [ "$SRT_FILES" -eq 0 ] && [ "$VIDEO_EXPORTS" -gt 0 ]; then
  log_info "üí° Videos sin subt√≠tulos - a√±ade SRT para mejor accesibilidad y engagement"
  RECOMMENDATIONS_COUNT=$((RECOMMENDATIONS_COUNT + 1))
fi

if [ "$VERTICAL_SVGS" -gt 0 ] && [ "$VERTICAL_VIDEOS" -eq 0 ]; then
  log_info "üí° Considera convertir SVGs verticales a videos para Reels/Stories"
  RECOMMENDATIONS_COUNT=$((RECOMMENDATIONS_COUNT + 1))
fi

if [ "$TOTAL_VIDEO_RESOURCES" -lt 4 ]; then
  log_info "üí° Faltan recursos cr√≠ticos - revisa ANUNCIO_VIDEO_INDICE_MAESTRO.md"
  RECOMMENDATIONS_COUNT=$((RECOMMENDATIONS_COUNT + 1))
fi

if [ "$RECOMMENDATIONS_COUNT" -eq 0 ]; then
  log_info "‚úÖ Workflow video bien configurado"
fi

# Comparaci√≥n con reportes anteriores (baseline)
log_section "üìä Comparaci√≥n con An√°lisis Anteriores"

PREVIOUS_REPORTS=""
if [ -n "$BASELINE_FILE" ] && [ -f "$BASELINE_FILE" ]; then
  PREVIOUS_REPORTS="$BASELINE_FILE"
  log_info "‚úÖ Usando baseline especificado: $(basename "$BASELINE_FILE")"
elif [ -z "$BASELINE_FILE" ]; then
  # Buscar autom√°ticamente el √∫ltimo reporte si no se especific√≥ baseline
  PREVIOUS_REPORTS=$(find "$(dirname "$REPORT")" -name "assets_report*.txt" -not -name "$(basename "$REPORT")" -type f 2>/dev/null | sort -r | head -1)
fi

if [ -n "$PREVIOUS_REPORTS" ] && [ -f "$PREVIOUS_REPORTS" ]; then
  if [ -z "$BASELINE_FILE" ]; then
    log_info "‚úÖ Reporte anterior encontrado autom√°ticamente: $(basename "$PREVIOUS_REPORTS")"
  fi
  
  # Extraer m√©tricas del reporte anterior (b√∫squeda mejorada)
  PREV_TOTAL=$(grep -E "(Total SVGs:|SVGs encontrados:|Total:)" "$PREVIOUS_REPORTS" 2>/dev/null | grep -oE '[0-9]+' | head -1 || echo "0")
  PREV_SCORE=$(grep -E "(Health Score:|Score:)" "$PREVIOUS_REPORTS" 2>/dev/null | grep -oE '[0-9]+' | head -1 || echo "0")
  PREV_BROKEN=$(grep -E "(SVGs rotos|Broken|Inv√°lidos)" "$PREVIOUS_REPORTS" 2>/dev/null | grep -oE '[0-9]+' | head -1 || echo "0")
  PREV_ACCESS=$(grep -E "(accesibilidad|Accessibility)" "$PREVIOUS_REPORTS" 2>/dev/null | grep -oE '[0-9]+%' | grep -oE '[0-9]+' | head -1 || echo "0")
  
  log_info ""
  log_info "üìä M√©tricas del Baseline:"
  [ "$PREV_TOTAL" != "0" ] && log_info "  - SVGs: $PREV_TOTAL"
  [ "$PREV_SCORE" != "0" ] && log_info "  - Health Score: $PREV_SCORE"
  [ "$PREV_BROKEN" != "0" ] && log_info "  - Archivos rotos: $PREV_BROKEN"
  [ "$PREV_ACCESS" != "0" ] && log_info "  - Accesibilidad: ${PREV_ACCESS}%"
  log_info ""
  log_info "üìà Cambios detectados:"
  
  if [ "$PREV_TOTAL" != "0" ] && [ "$TOTAL_SVGS" != "0" ]; then
    if [ "$TOTAL_SVGS" -gt "$PREV_TOTAL" ]; then
      DIFF=$((TOTAL_SVGS - PREV_TOTAL))
      PERCENT=$(awk "BEGIN {printf \"%.1f\", ($DIFF / $PREV_TOTAL) * 100}" 2>/dev/null || echo "0")
      log_info "  üìà SVGs: +$DIFF nuevos ($PERCENT% incremento)"
    elif [ "$TOTAL_SVGS" -lt "$PREV_TOTAL" ]; then
      DIFF=$((PREV_TOTAL - TOTAL_SVGS))
      PERCENT=$(awk "BEGIN {printf \"%.1f\", ($DIFF / $PREV_TOTAL) * 100}" 2>/dev/null || echo "0")
      log_info "  üìâ SVGs: -$DIFF menos ($PERCENT% reducci√≥n, posible limpieza)"
    else
      log_info "  ‚û°Ô∏è  SVGs: Sin cambios ($TOTAL_SVGS)"
    fi
  fi
  
  if [ "$PREV_SCORE" != "0" ]; then
    SCORE_DIFF=$((HEALTH_SCORE - PREV_SCORE))
    if [ "$SCORE_DIFF" -gt 0 ]; then
      log_info "  ‚úÖ Health Score: +$SCORE_DIFF puntos (mejora)"
    elif [ "$SCORE_DIFF" -lt 0 ]; then
      log_info "  ‚ö†Ô∏è  Health Score: $SCORE_DIFF puntos (regresi√≥n)"
    else
      log_info "  ‚û°Ô∏è  Health Score: Sin cambios ($HEALTH_SCORE)"
    fi
  fi
  
  # Comparar archivos rotos
  if [ "$PREV_BROKEN" != "0" ] || [ "${BROKEN_SVGS:-0}" != "0" ]; then
    BROKEN_DIFF=$((BROKEN_SVGS - PREV_BROKEN))
    if [ "$BROKEN_DIFF" -lt 0 ]; then
      log_info "  ‚úÖ Archivos rotos: $BROKEN_DIFF (corregidos)"
    elif [ "$BROKEN_DIFF" -gt 0 ]; then
      log_info "  ‚ö†Ô∏è  Archivos rotos: +$BROKEN_DIFF (nuevos problemas)"
    fi
  fi
else
  if [ -n "$BASELINE_FILE" ]; then
    log_info "‚ö†Ô∏è  Baseline especificado no encontrado: $BASELINE_FILE"
    log_info "  üí° Verifica la ruta o usa --baseline sin especificar para b√∫squeda autom√°tica"
  else
    log_info "‚ÑπÔ∏è  No se encontraron reportes anteriores para comparar"
    log_info "  üí° Usa --baseline PATH para especificar un reporte de referencia"
    log_info "  üí° Guarda este reporte como referencia para futuras comparaciones"
  fi
fi

# Generar resumen ejecutivo para share
EXEC_SUMMARY="${REPORT%.txt}_executive_summary.txt"
{
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìä RESUMEN EJECUTIVO - An√°lisis de Assets"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo ""
  echo "Fecha: $(date '+%Y-%m-%d %H:%M:%S')"
  echo ""
  echo "M√âTRICAS PRINCIPALES:"
  echo "  ‚Ä¢ Total SVGs: $TOTAL_SVGS"
  echo "  ‚Ä¢ Health Score: $HEALTH_SCORE/100 - $HEALTH_STATUS"
  echo "  ‚Ä¢ Problemas detectados: ${HEALTH_ISSUES:-0}"
  echo ""
  echo "ESTADO POR PRODUCTO:"
  if [ -d "$LINKEDIN_DIR" ]; then
    echo "  ‚Ä¢ IA Bulk: $COUNT_IABULK templates"
    echo "  ‚Ä¢ Curso IA: $COUNT_CURSO templates"
    echo "  ‚Ä¢ SaaS Marketing: $COUNT_SAAS templates"
  fi
  echo ""
  echo "TRACKING Y UTMs:"
  echo "  ‚Ä¢ SVGs con UTMs: ${SVGS_WITH_UTMS:-0}"
  echo "  ‚Ä¢ URLs por actualizar: ${SVGS_DEFAULT_URL:-0}"
  echo ""
  if [ "$HEALTH_SCORE" -lt 75 ]; then
    echo "‚ö†Ô∏è  ACCIONES PRIORITARIAS:"
    [ "$EMPTY_SVGS" -gt 0 ] && echo "  ‚Ä¢ Arreglar $EMPTY_SVGS SVG(s) vac√≠o(s)"
    [ "$BROKEN_SVGS" -gt 0 ] && echo "  ‚Ä¢ Reparar $BROKEN_SVGS SVG(s) con errores"
    [ "${SVGS_WITHOUT_CSV:-0}" -gt 0 ] && echo "  ‚Ä¢ Registrar ${SVGS_WITHOUT_CSV} SVG(s) en CSV"
  fi
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "Reporte completo: $REPORT"
} > "$EXEC_SUMMARY"

log_info "üìÑ Resumen ejecutivo generado: $EXEC_SUMMARY"

# An√°lisis de gaps en matriz producto√óformato√óplataforma
log_section "üìä An√°lisis de Gaps en Cobertura"

PRODUCTOS=("curso_ia" "saas_ia_marketing" "ia_bulk")
FORMATOS=("1200x627" "1080x1080" "1080x1920")
PLATAFORMAS=("linkedin" "instagram")

GAPS_COUNT=0
TOTAL_COMBINATIONS=$((${#PRODUCTOS[@]} * ${#FORMATOS[@]} * ${#PLATAFORMAS[@]}))

log_info "Combinaciones esperadas: $TOTAL_COMBINATIONS"

for producto in "${PRODUCTOS[@]}"; do
  for formato in "${FORMATOS[@]}"; do
    for plataforma in "${PLATAFORMAS[@]}"; do
      PLAT_DIR="$ROOT_DIR/ads/$plataforma"
      if [ ! -d "$PLAT_DIR" ]; then
        continue
      fi
      
      ASSET_COUNT=$(find "$PLAT_DIR" -name "*${producto}*${formato}*.svg" 2>/dev/null | wc -l | xargs)
      
      if [ "$ASSET_COUNT" -eq 0 ]; then
        GAPS_COUNT=$((GAPS_COUNT + 1))
        log_info "‚ö†Ô∏è  Gap: $producto √ó $formato √ó $plataforma (0 assets)"
      fi
    done
  done
done

COVERAGE_PERCENT=$(awk "BEGIN {printf \"%.1f\", (($TOTAL_COMBINATIONS - $GAPS_COUNT) / $TOTAL_COMBINATIONS) * 100}")

log_info "Cobertura total: ${COVERAGE_PERCENT}% ($(($TOTAL_COMBINATIONS - $GAPS_COUNT))/$TOTAL_COMBINATIONS)"
log_info "Gaps detectados: $GAPS_COUNT"

if [ "$GAPS_COUNT" -eq 0 ]; then
  log_info "‚úÖ Cobertura completa - todos los formatos cubiertos"
elif [ "$GAPS_COUNT" -le 5 ]; then
  log_info "‚ö†Ô∏è  Pocos gaps - considera completar formatos faltantes"
else
  log_info "‚ùå M√∫ltiples gaps - revisar estrategia de cobertura"
fi

# An√°lisis de naming conventions
log_section "üè∑Ô∏è  An√°lisis de Naming Conventions"

# Patrones esperados seg√∫n documentaci√≥n
NAMING_PATTERNS=(
  "ad_.*_1200x627.*\.svg"
  "ad_.*_1080x1080.*\.svg"
  "ad_.*_1080x1920.*\.svg"
  "carousel_.*\.svg"
  "webinar-preroll-.*\.svg"
)

NON_STANDARD_NAMES=0
if [ -d "$LINKEDIN_DIR" ]; then
  while IFS= read -r svg_file; do
    basename=$(basename "$svg_file")
    MATCHED=0
    
    for pattern in "${NAMING_PATTERNS[@]}"; do
      if echo "$basename" | grep -qE "$pattern"; then
        MATCHED=1
        break
      fi
    done
    
    if [ "$MATCHED" -eq 0 ]; then
      NON_STANDARD_NAMES=$((NON_STANDARD_NAMES + 1))
    fi
  done < <(find "$LINKEDIN_DIR" -name "*.svg" -not -name "tokens.json" 2>/dev/null | head -10)
fi

if [ "$NON_STANDARD_NAMES" -eq 0 ]; then
  log_info "‚úÖ Naming conventions consistentes"
else
  log_info "‚ö†Ô∏è  Archivos con naming no est√°ndar: $NON_STANDARD_NAMES"
  log_info "üí° Revisar: ad_[producto]_[formato]_[variante].svg"
fi

# An√°lisis de versiones y variantes
log_section "üîÑ An√°lisis de Versiones y Variantes"

VERSION_COUNT=$(find "$ROOT_DIR" -name "*_v[0-9]*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
VARIANT_COUNT=$(find "$ROOT_DIR" -name "*_urgency*.svg" -o -name "*_social*.svg" -o -name "*_metrics*.svg" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)

log_info "Assets con versi√≥n expl√≠cita (_vN): $VERSION_COUNT"
log_info "Assets con variantes (urgency/social/metrics): $VARIANT_COUNT"

# Detecci√≥n de oportunidades de A/B testing
log_section "üß™ Oportunidades de A/B Testing"

AB_OPPORTUNITIES=0

# Productos con m√∫ltiples variantes = oportunidad de testing
for producto in "${PRODUCTOS[@]}"; do
  PRODUCT_VARIANTS=$(find "$ROOT_DIR/ads/linkedin" -name "*${producto}*" -name "*.svg" 2>/dev/null | wc -l | xargs)
  
  if [ "$PRODUCT_VARIANTS" -ge 3 ]; then
    log_info "‚úÖ $producto: $PRODUCT_VARIANTS variantes (ideal para A/B testing)"
    AB_OPPORTUNITIES=$((AB_OPPORTUNITIES + 1))
  elif [ "$PRODUCT_VARIANTS" -eq 2 ]; then
    log_info "‚ö†Ô∏è  $producto: $PRODUCT_VARIANTS variantes (considera a√±adir m√°s)"
  elif [ "$PRODUCT_VARIANTS" -eq 1 ]; then
    log_info "üí° $producto: 1 variante (oportunidad de crear variantes para testing)"
  fi
done

if [ "$AB_OPPORTUNITIES" -ge 2 ]; then
  log_info "‚úÖ M√∫ltiples productos con variantes - ready para A/B testing"
fi

# An√°lisis de optimizaci√≥n de assets
log_section "‚ö° An√°lisis de Optimizaci√≥n"

# Identificar SVGs grandes que podr√≠an optimizarse
LARGE_SVGS=$(find "$ROOT_DIR" -name "*.svg" -size +100k -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
OPTIMIZATION_CANDIDATES=0

if [ "$LARGE_SVGS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  SVGs grandes (>100KB): $LARGE_SVGS"
  log_info "üí° Recomendaci√≥n: Optimizar con svgo"
  
  # Identificar los m√°s grandes
  find "$ROOT_DIR" -name "*.svg" -size +100k -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -5 | while read -r f; do
    size=$(du -h "$f" 2>/dev/null | cut -f1)
    log_info "    - ${f#$ROOT_DIR/} ($size)"
  done
  
  OPTIMIZATION_CANDIDATES=$LARGE_SVGS
fi

# Verificar si hay PNGs optimizados (WebP)
WEBP_COUNT=$(find "$ROOT_DIR/exports" -name "*.webp" 2>/dev/null | wc -l | xargs)
PNG_COUNT_TOTAL=$(find "$ROOT_DIR/exports/png" -name "*.png" 2>/dev/null | wc -l | xargs)

if [ "$PNG_COUNT_TOTAL" -gt 0 ] && [ "$WEBP_COUNT" -eq 0 ]; then
  log_info "üí° Considera exportar a WebP para mejor compresi√≥n (ahorro ~30%)"
fi

# An√°lisis de uso de variables editables
log_section "üî§ An√°lisis de Uso de Variables Editables"

# Variables m√°s comunes esperadas
COMMON_VARS=("FECHA" "HORA" "EVENTO" "CTA" "URL" "M√âTRICA" "BENEFICIO" "TESTIMONIO" "PRODUCTO" "PRECIO" "DESCUENTO")

UNUSED_VARS=0
for var in "${COMMON_VARS[@]}"; do
  VAR_USAGE=$(grep -r "\[${var}\]" "$ROOT_DIR" --include="*.svg" -h 2>/dev/null | wc -l | xargs)
  
  if [ "$VAR_USAGE" -eq 0 ]; then
    UNUSED_VARS=$((UNUSED_VARS + 1))
  else
    log_info "  ‚úÖ [$var]: usado en $VAR_USAGE archivo(s)"
  fi
done

if [ "$UNUSED_VARS" -gt 0 ]; then
  log_info "‚ÑπÔ∏è  $UNUSED_VARS variables comunes no encontradas (puede ser normal si no se usan)"
fi

# Detecci√≥n de assets potencialmente obsoletos
log_section "üóëÔ∏è  Detecci√≥n de Assets Potencialmente Obsoletos"

# Buscar archivos sin modificar en m√°s de 90 d√≠as
OBSOLETE_THRESHOLD=90
OBSOLETE_COUNT=0

if [ -d "$LINKEDIN_DIR" ]; then
  CURRENT_TIME=$(date +%s)
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ]; then
      if [[ "$OSTYPE" == "darwin"* ]]; then
        FILE_TIME=$(stat -f %m "$svg_file" 2>/dev/null || echo "0")
      else
        FILE_TIME=$(stat -c %Y "$svg_file" 2>/dev/null || echo "0")
      fi
      
      if [ "$FILE_TIME" -gt 0 ]; then
        DAYS_OLD=$(( (CURRENT_TIME - FILE_TIME) / 86400 ))
        if [ "$DAYS_OLD" -gt "$OBSOLETE_THRESHOLD" ]; then
          OBSOLETE_COUNT=$((OBSOLETE_COUNT + 1))
        fi
      fi
    fi
  done < <(find "$LINKEDIN_DIR" -name "*.svg" -not -name "tokens.json" 2>/dev/null | head -10)
fi

if [ "$OBSOLETE_COUNT" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Assets sin modificar >$OBSOLETE_THRESHOLD d√≠as: $OBSOLETE_COUNT"
  log_info "üí° Considera revisar si siguen siendo relevantes"
else
  log_info "‚úÖ Assets recientes - sin problemas de obsolescencia"
fi

# An√°lisis de coherencia entre productos
log_section "üìä Coherencia entre Productos"

# Verificar que todos los productos tengan formatos similares
for formato in "${FORMATOS[@]}"; do
  FORMATO_COUNTS=""
  
  for producto in "${PRODUCTOS[@]}"; do
    COUNT=$(find "$ROOT_DIR/ads/linkedin" -name "*${producto}*${formato}*.svg" 2>/dev/null | wc -l | xargs)
    FORMATO_COUNTS="${FORMATO_COUNTS}${producto}:${COUNT} "
  done
  
  # Verificar si hay desbalance
  INCONSISTENT_FORMAT=0
  PREV_COUNT=""
  
  for count_info in $FORMATO_COUNTS; do
    COUNT=$(echo "$count_info" | cut -d: -f2)
    if [ -n "$PREV_COUNT" ] && [ "$COUNT" != "$PREV_COUNT" ]; then
      INCONSISTENT_FORMAT=1
      break
    fi
    PREV_COUNT="$COUNT"
  done
  
  if [ "$INCONSISTENT_FORMAT" -eq 1 ]; then
    log_info "‚ö†Ô∏è  Formato $formato: cobertura inconsistente entre productos"
    for count_info in $FORMATO_COUNTS; do
      PRODUCT=$(echo "$count_info" | cut -d: -f1)
      COUNT=$(echo "$count_info" | cut -d: -f2)
      log_info "    - $PRODUCT: $COUNT"
    done
  fi
done

# Exportaci√≥n de datos estructurados para dashboards
log_section "üì§ Datos para Dashboards"

# Generar CSV con resumen de assets por producto√óformato
DASHBOARD_CSV="$ROOT_DIR/exports/assets_dashboard_data.csv"

{
  echo "Producto,Formato,Plataforma,Count,Status"
  
  for producto in "${PRODUCTOS[@]}"; do
    for formato in "${FORMATOS[@]}"; do
      for plataforma in "${PLATAFORMAS[@]}"; do
        PLAT_DIR="$ROOT_DIR/ads/$plataforma"
        if [ -d "$PLAT_DIR" ]; then
          COUNT=$(find "$PLAT_DIR" -name "*${producto}*${formato}*.svg" 2>/dev/null | wc -l | xargs)
          
          if [ "$COUNT" -gt 0 ]; then
            STATUS="‚úÖ"
          else
            STATUS="‚ùå"
          fi
          
          echo "$producto,$formato,$plataforma,$COUNT,$STATUS"
        fi
      done
    done
  done
} > "$DASHBOARD_CSV"

log_info "‚úÖ Datos de dashboard exportados: $DASHBOARD_CSV"

# An√°lisis de dependencias y referencias
log_section "üîó An√°lisis de Dependencias"

# Verificar referencias a archivos externos en SVGs
EXTERNAL_REFERENCES=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ]; then
    # Buscar referencias a im√°genes externas o links
    if grep -q 'href="http' "$svg_file" 2>/dev/null || grep -q 'xlink:href="http' "$svg_file" 2>/dev/null; then
      EXTERNAL_REFERENCES=$((EXTERNAL_REFERENCES + 1))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -10)

if [ "$EXTERNAL_REFERENCES" -gt 0 ]; then
  log_info "üìä SVGs con referencias externas: $EXTERNAL_REFERENCES"
  log_info "üí° Verificar que los enlaces sean v√°lidos y no caduquen"
fi

# Resumen de mejoras recomendadas
log_section "üí° Resumen de Mejoras Recomendadas"

IMPROVEMENTS=0
IMPROVEMENT_NUM=1

if [ "$GAPS_COUNT" -gt 0 ]; then
  log_info "$IMPROVEMENT_NUM. Completar gaps en cobertura ($GAPS_COUNT gaps)"
  IMPROVEMENT_NUM=$((IMPROVEMENT_NUM + 1))
  IMPROVEMENTS=$((IMPROVEMENTS + 1))
fi

if [ "$LARGE_SVGS" -gt 0 ]; then
  log_info "$IMPROVEMENT_NUM. Optimizar SVGs grandes con svgo ($LARGE_SVGS archivos)"
  IMPROVEMENT_NUM=$((IMPROVEMENT_NUM + 1))
  IMPROVEMENTS=$((IMPROVEMENTS + 1))
fi

if [ "$NON_STANDARD_NAMES" -gt 0 ]; then
  log_info "$IMPROVEMENT_NUM. Estandarizar naming ($NON_STANDARD_NAMES archivos)"
  IMPROVEMENT_NUM=$((IMPROVEMENT_NUM + 1))
  IMPROVEMENTS=$((IMPROVEMENTS + 1))
fi

if [ "$OBSOLETE_COUNT" -gt 5 ]; then
  log_info "$IMPROVEMENT_NUM. Revisar assets obsoletos ($OBSOLETE_COUNT archivos)"
  IMPROVEMENT_NUM=$((IMPROVEMENT_NUM + 1))
  IMPROVEMENTS=$((IMPROVEMENTS + 1))
fi

if [ "$WEBP_COUNT" -eq 0 ] && [ "$PNG_COUNT_TOTAL" -gt 0 ]; then
  log_info "$IMPROVEMENT_NUM. Exportar a WebP para mejor compresi√≥n"
  IMPROVEMENTS=$((IMPROVEMENTS + 1))
fi

if [ "$IMPROVEMENTS" -eq 0 ]; then
  log_info "‚úÖ No se detectaron mejoras cr√≠ticas necesarias"
fi

# An√°lisis de performance web y m√©tricas de carga
log_section "‚ö° Performance Web"

COMPLEX_SVGS=0
HIGH_DOM_NODES=0
ANIMATIONS=0
FILTERS=0
GRADIENTS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Contar nodos DOM aproximados (etiquetas)
    NODE_COUNT=$(grep -oE '<[^/>]+>' "$svg_file" 2>/dev/null | wc -l | xargs)
    if [ "$NODE_COUNT" -gt 500 ]; then
      HIGH_DOM_NODES=$((HIGH_DOM_NODES + 1))
      COMPLEX_SVGS=$((COMPLEX_SVGS + 1))
    fi
    
    # Detectar animaciones
    if grep -qiE '<animate|@keyframes|animation:' "$svg_file" 2>/dev/null; then
      ANIMATIONS=$((ANIMATIONS + 1))
      COMPLEX_SVGS=$((COMPLEX_SVGS + 1))
    fi
    
    # Detectar filtros complejos
    FILTER_COUNT=$(grep -c '<filter>' "$svg_file" 2>/dev/null || echo "0")
    if [ "$FILTER_COUNT" -gt 5 ]; then
      FILTERS=$((FILTERS + 1))
      COMPLEX_SVGS=$((COMPLEX_SVGS + 1))
    fi
    
    # Detectar m√∫ltiples gradientes
    GRADIENT_COUNT=$(grep -c '<linearGradient\|<radialGradient>' "$svg_file" 2>/dev/null || echo "0")
    if [ "$GRADIENT_COUNT" -gt 10 ]; then
      GRADIENTS=$((GRADIENTS + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

if [ "$COMPLEX_SVGS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  SVGs complejos detectados: $COMPLEX_SVGS (pueden afectar performance)"
  [ "$HIGH_DOM_NODES" -gt 0 ] && log_info "  - Con muchos nodos DOM (>500): $HIGH_DOM_NODES"
  [ "$ANIMATIONS" -gt 0 ] && log_info "  - Con animaciones: $ANIMATIONS"
  [ "$FILTERS" -gt 0 ] && log_info "  - Con m√∫ltiples filtros: $FILTERS"
  log_info "üí° Recomendaci√≥n: Simplificar o dividir en componentes m√°s peque√±os"
else
  log_info "‚úÖ SVGs con complejidad razonable para web"
fi

# An√°lisis de compatibilidad de navegadores
log_section "üåê Compatibilidad de Navegadores"

IE_INCOMPATIBLE=0
MODERN_FEATURES=0
PREFIXED_PROPERTIES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar caracter√≠sticas modernas (incompatibles con IE)
    if grep -qiE '<foreignObject>|<mask>|filter:|blend-mode:' "$svg_file" 2>/dev/null; then
      IE_INCOMPATIBLE=$((IE_INCOMPATIBLE + 1))
      MODERN_FEATURES=$((MODERN_FEATURES + 1))
    fi
    
    # Detectar uso de propiedades CSS modernas sin prefijos
    if grep -qiE 'transform:|transition:|opacity:' "$svg_file" 2>/dev/null && ! grep -qiE '-webkit-|-moz-|-ms-' "$svg_file" 2>/dev/null; then
      PREFIXED_PROPERTIES=$((PREFIXED_PROPERTIES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

if [ "$IE_INCOMPATIBLE" -gt 0 ]; then
  PERCENT_MODERN=$(awk "BEGIN {printf \"%.1f\", ($IE_INCOMPATIBLE / $TOTAL_SVGS) * 100}" 2>/dev/null || echo "0")
  log_info "‚ö†Ô∏è  SVGs con caracter√≠sticas modernas (no compatibles con IE): $IE_INCOMPATIBLE ($PERCENT_MODERN%)"
  log_info "üí° Considerar polyfills o fallbacks para navegadores antiguos"
fi

if [ "$PREFIXED_PROPERTIES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  SVGs sin prefijos de navegador: $PREFIXED_PROPERTIES"
  log_info "üí° Recomendaci√≥n: A√±adir prefijos -webkit-, -moz- para mejor compatibilidad"
fi

# Detecci√≥n de problemas de renderizado
log_section "üé® Problemas Potenciales de Renderizado"

RENDER_ISSUES=0
TRANSPARENCY_ISSUES=0
ZOOM_ISSUES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar transparencia con problemas potenciales
    if grep -qE 'opacity="0"|fill-opacity="0"|stroke-opacity="0"' "$svg_file" 2>/dev/null; then
      TRANSPARENCY_ISSUES=$((TRANSPARENCY_ISSUES + 1))
      RENDER_ISSUES=$((RENDER_ISSUES + 1))
    fi
    
    # Detectar elementos con coordenadas fuera de canvas (sin viewBox)
    if ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      if grep -qE 'x="[0-9]{4,}"|y="[0-9]{4,}"|width="[0-9]{4,}"' "$svg_file" 2>/dev/null; then
        ZOOM_ISSUES=$((ZOOM_ISSUES + 1))
        RENDER_ISSUES=$((RENDER_ISSUES + 1))
      fi
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

if [ "$RENDER_ISSUES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Problemas potenciales de renderizado: $RENDER_ISSUES"
  [ "$TRANSPARENCY_ISSUES" -gt 0 ] && log_info "  - Elementos totalmente transparentes: $TRANSPARENCY_ISSUES"
  [ "$ZOOM_ISSUES" -gt 0 ] && log_info "  - Posibles problemas de zoom: $ZOOM_ISSUES"
  log_info "üí° Recomendaci√≥n: Probar renderizado en diferentes navegadores"
else
  log_info "‚úÖ No se detectaron problemas obvios de renderizado"
fi

# An√°lisis de versionado y cambios
log_section "üìù An√°lisis de Versionado"

VERSIONED_SVGS=0
OUTDATED_VERSIONS=0
NO_VERSION=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar version en metadata o comentarios
    if grep -qiE 'version|v[0-9]+\.[0-9]+' "$svg_file" 2>/dev/null; then
      VERSIONED_SVGS=$((VERSIONED_SVGS + 1))
      
      # Detectar versiones antiguas (< 1.0)
      if grep -qiE 'v0\.|version.*0\.[0-9]' "$svg_file" 2>/dev/null; then
        OUTDATED_VERSIONS=$((OUTDATED_VERSIONS + 1))
      fi
    else
      NO_VERSION=$((NO_VERSION + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)

if [ "$TOTAL_SVG_COUNT" -gt 0 ]; then
  PERCENT_VERSIONED=$(awk "BEGIN {printf \"%.1f\", ($VERSIONED_SVGS / $TOTAL_SVG_COUNT) * 100}" 2>/dev/null || echo "0")
  log_info "SVGs con versionado: $VERSIONED_SVGS ($PERCENT_VERSIONED%)"
  
  if [ "$NO_VERSION" -gt 0 ]; then
    PERCENT_NO_VERSION=$(awk "BEGIN {printf \"%.1f\", ($NO_VERSION / $TOTAL_SVG_COUNT) * 100}" 2>/dev/null || echo "0")
    log_info "‚ö†Ô∏è  SVGs sin versionado: $NO_VERSION ($PERCENT_NO_VERSION%)"
    log_info "üí° Recomendaci√≥n: A√±adir versionado en metadata para tracking de cambios"
  fi
  
  if [ "$OUTDATED_VERSIONS" -gt 0 ]; then
    log_info "‚ö†Ô∏è  SVGs con versiones antiguas: $OUTDATED_VERSIONS"
  fi
fi

# An√°lisis de mantenibilidad y deuda t√©cnica
log_section "üîß Mantenibilidad y Deuda T√©cnica"

TECHNICAL_DEBT=0

# Calcular score de deuda t√©cnica
DEBT_SCORE=0

# Penalizar por falta de documentaci√≥n
if [ "${NO_METADATA:-0}" -gt 0 ]; then
  DEBT_SCORE=$((DEBT_SCORE + NO_METADATA / 10))
fi

# Penalizar por anti-patrones
if [ "${ANTI_PATTERNS:-0}" -gt 0 ]; then
  DEBT_SCORE=$((DEBT_SCORE + ANTI_PATTERNS))
fi

# Penalizar por c√≥digo no optimizado
if [ "${UNOPTIMIZED_COUNT:-0}" -gt 0 ]; then
  DEBT_SCORE=$((DEBT_SCORE + UNOPTIMIZED_COUNT / 2))
fi

# Penalizar por problemas de seguridad
if [ "${SECURITY_ISSUES:-0}" -gt 0 ]; then
  DEBT_SCORE=$((DEBT_SCORE + SECURITY_ISSUES * 3))
fi

# Penalizar por falta de accesibilidad
if [ "${NO_ACCESSIBILITY:-0}" -gt 0 ]; then
  DEBT_SCORE=$((DEBT_SCORE + NO_ACCESSIBILITY / 20))
fi

TECHNICAL_DEBT=$DEBT_SCORE

# Clasificar deuda t√©cnica
if [ "$TECHNICAL_DEBT" -eq 0 ]; then
  DEBT_LEVEL="‚úÖ Sin deuda t√©cnica"
elif [ "$TECHNICAL_DEBT" -lt 10 ]; then
  DEBT_LEVEL="üü¢ Baja"
elif [ "$TECHNICAL_DEBT" -lt 30 ]; then
  DEBT_LEVEL="üü° Media"
elif [ "$TECHNICAL_DEBT" -lt 50 ]; then
  DEBT_LEVEL="üü† Alta"
else
  DEBT_LEVEL="üî¥ Cr√≠tica"
fi

log_info "Score de deuda t√©cnica: $TECHNICAL_DEBT - $DEBT_LEVEL"

# Detectar c√≥digo legacy
LEGACY_CODE=0
if [ "${NO_VIEWBOX:-0}" -gt 10 ] || [ "${HARDCODED_COLORS:-0}" -gt 5 ]; then
  LEGACY_CODE=$((NO_VIEWBOX + HARDCODED_COLORS))
  log_info "‚ö†Ô∏è  C√≥digo legacy detectado: $LEGACY_CODE indicadores"
  log_info "üí° Recomendaci√≥n: Plan de modernizaci√≥n gradual"
fi

# Calcular √≠ndice de mantenibilidad (0-100)
MAINTAINABILITY_INDEX=$((100 - (TECHNICAL_DEBT / 2)))
if [ "$MAINTAINABILITY_INDEX" -lt 0 ]; then
  MAINTAINABILITY_INDEX=0
fi

log_info "√çndice de mantenibilidad: ${MAINTAINABILITY_INDEX}/100"

if [ "$MAINTAINABILITY_INDEX" -ge 80 ]; then
  log_info "‚úÖ Excelente mantenibilidad"
elif [ "$MAINTAINABILITY_INDEX" -ge 60 ]; then
  log_info "‚úÖ Buena mantenibilidad"
elif [ "$MAINTAINABILITY_INDEX" -ge 40 ]; then
  log_info "‚ö†Ô∏è  Mantenibilidad aceptable - mejorar documentaci√≥n"
else
  log_info "‚ùå Mantenibilidad baja - requiere refactoring"
fi

# Generar reporte Markdown adicional
log_section "üìù Generaci√≥n de Reporte Markdown"

MARKDOWN_REPORT="${REPORT%.txt}.md"
{
  echo "# üìä An√°lisis de Assets - Reporte Completo"
  echo ""
  echo "**Fecha:** $(date '+%Y-%m-%d %H:%M:%S')"
  echo "**Directorio:** \`$ROOT_DIR\`"
  echo ""
  echo "## üìà Resumen Ejecutivo"
  echo ""
  echo "- **Total SVGs:** $TOTAL_SVGS"
  echo "- **Health Score:** $HEALTH_SCORE/100 - $HEALTH_STATUS"
  echo "- **Mantenibilidad:** ${MAINTAINABILITY_INDEX}/100"
  echo "- **Deuda T√©cnica:** $TECHNICAL_DEBT - $DEBT_LEVEL"
  echo ""
  echo "## üéØ M√©tricas por Producto"
  echo ""
  if [ -d "$LINKEDIN_DIR" ]; then
    echo "| Producto | Count |"
    echo "|----------|-------|"
    echo "| IA Bulk | $COUNT_IABULK |"
    echo "| Curso IA | $COUNT_CURSO |"
    echo "| SaaS Marketing | $COUNT_SAAS |"
  fi
  echo ""
  echo "## ‚ö†Ô∏è Problemas Detectados"
  echo ""
  [ "${EMPTY_SVGS:-0}" -gt 0 ] && echo "- ${EMPTY_SVGS} SVG(s) vac√≠o(s)"
  [ "${BROKEN_SVGS:-0}" -gt 0 ] && echo "- ${BROKEN_SVGS} SVG(s) con errores"
  [ "${SECURITY_ISSUES:-0}" -gt 0 ] && echo "- ${SECURITY_ISSUES} problema(s) de seguridad"
  [ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && echo "- ${NO_ACCESSIBILITY} SVG(s) sin accesibilidad"
  echo ""
  echo "---"
  echo ""
  echo "Para m√°s detalles, ver el reporte completo en formato texto."
} > "$MARKDOWN_REPORT"

log_info "‚úÖ Reporte Markdown generado: $MARKDOWN_REPORT"

# Resumen ejecutivo final mejorado
log_section "üìã Resumen Ejecutivo Final"

log_info "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
log_info "üìä M√âTRICAS PRINCIPALES"
log_info "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
log_info "Total SVGs analizados: $TOTAL_SVGS"
log_info "Health Score: $HEALTH_SCORE/100 - $HEALTH_STATUS"
if [ -n "${QUALITY_SCORE:-}" ]; then
  log_info "Quality Score: ${QUALITY_SCORE}/100"
fi
log_info "Mantenibilidad: ${MAINTAINABILITY_INDEX}/100"
log_info "Deuda T√©cnica: $TECHNICAL_DEBT - $DEBT_LEVEL"
log_info ""
log_info "‚úÖ Logros:"
[ "${INVALID_STRUCTURE:-0}" -eq 0 ] && log_info "  ‚Ä¢ Todos los SVGs tienen estructura v√°lida"
[ "${DUPLICATE_GROUPS:-0}" -eq 0 ] && log_info "  ‚Ä¢ No hay duplicados detectados"
[ "${SECURITY_ISSUES:-0}" -eq 0 ] && log_info "  ‚Ä¢ Sin problemas de seguridad"
[ "${COMPLEX_SVGS:-0}" -eq 0 ] && log_info "  ‚Ä¢ SVGs con complejidad razonable"
log_info ""
log_info "‚ö†Ô∏è  √Åreas de mejora:"
[ "${EMPTY_SVGS:-0}" -gt 0 ] && log_info "  ‚Ä¢ ${EMPTY_SVGS} SVG(s) vac√≠o(s) por eliminar"
[ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && log_info "  ‚Ä¢ ${NO_ACCESSIBILITY} SVG(s) sin accesibilidad"
[ "${NO_METADATA:-0}" -gt 0 ] && log_info "  ‚Ä¢ ${NO_METADATA} SVG(s) sin metadata SEO"
[ "${ANTI_PATTERNS:-0}" -gt 0 ] && log_info "  ‚Ä¢ ${ANTI_PATTERNS} archivo(s) con anti-patrones"
log_info "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

# An√°lisis predictivo y benchmarking avanzado
log_section "üîÆ An√°lisis Predictivo"

# Calcular proyecciones si hay datos hist√≥ricos
if [ -n "$PREVIOUS_REPORTS" ] && [ -f "$PREVIOUS_REPORTS" ]; then
  GROWTH_RATE=$(awk "BEGIN {if($PREV_TOTAL>0) printf \"%.1f\", (($TOTAL_SVGS-$PREV_TOTAL)/$PREV_TOTAL)*100; else print 0}")
  if [ "$(echo "$GROWTH_RATE > 0" | bc 2>/dev/null || echo 0)" = "1" ]; then
    PROJECTED_30D=$(awk "BEGIN {printf \"%.0f\", $TOTAL_SVGS * 1.1}")
    log_info "üìà Proyecci√≥n 30 d√≠as: ~$PROJECTED_30D SVGs (asumiendo crecimiento similar)"
  fi
fi

# Score de mantenimiento predictivo
MAINT_SCORE=100
[ "$EMPTY_SVGS" -gt 0 ] && MAINT_SCORE=$((MAINT_SCORE - EMPTY_SVGS * 5))
[ "$BROKEN_SVGS" -gt 0 ] && MAINT_SCORE=$((MAINT_SCORE - BROKEN_SVGS * 10))
[ "${NO_VIEWBOX:-0}" -gt 0 ] && MAINT_SCORE=$((MAINT_SCORE - NO_VIEWBOX * 2))
[ "$MAINT_SCORE" -lt 0 ] && MAINT_SCORE=0

log_info "üîß Score mantenimiento: $MAINT_SCORE/100"
[ "$MAINT_SCORE" -lt 70 ] && log_info "‚è±Ô∏è  Tiempo estimado correcci√≥n: ~$(awk "BEGIN {printf \"%.1f\", (100-$MAINT_SCORE)/8}")h"

# Benchmarking vs est√°ndares
log_section "üìä Benchmarking"

if [ "$TOTAL_SVGS" -gt 0 ]; then
  EMPTY_PCT=$(awk "BEGIN {printf \"%.1f\", ($EMPTY_SVGS/$TOTAL_SVGS)*100}")
  [ "$(echo "$EMPTY_PCT < 5" | bc 2>/dev/null || echo 0)" = "1" ] && \
    log_info "‚úÖ Vac√≠os: ${EMPTY_PCT}% (benchmark: <5%)" || \
    log_info "‚ö†Ô∏è  Vac√≠os: ${EMPTY_PCT}% (benchmark: <5%)"
fi

# Exportaci√≥n extendida
log_section "üì§ Exportaci√≥n Extendida"

if command -v jq >/dev/null 2>&1 && [ -n "${JSON_REPORT:-}" ]; then
  EXT_JSON="${JSON_REPORT%.json}_extended.json"
  {
    echo "{\"timestamp\":\"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
    echo "\"metrics\":{\"total\":$TOTAL_SVGS,\"health\":$HEALTH_SCORE,\"coverage\":${COVERAGE_PERCENT:-0},"
    echo "\"gaps\":$GAPS_COUNT,\"maintenance\":$MAINT_SCORE}}"
  } > "$EXT_JSON" 2>/dev/null
  log_info "üìä JSON extendido: $EXT_JSON"
fi

# Resumen final mejorado
echo "" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"
echo "üéØ INSIGHTS FINALES" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"
echo "‚Ä¢ Assets: $TOTAL_SVGS | Health: $HEALTH_SCORE/100" >> "$REPORT"
echo "‚Ä¢ Mantenimiento: $MAINT_SCORE/100 | Cobertura: ${COVERAGE_PERCENT:-0}%" >> "$REPORT"
echo "‚Ä¢ Gaps: $GAPS_COUNT | Mejoras: $IMPROVEMENTS" >> "$REPORT"
echo "‚Ä¢ Tiempo: ${ELAPSED}s" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"

# Resumen visual
echo ""
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "‚úÖ AN√ÅLISIS COMPLETADO"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "üìä $TOTAL_SVGS assets | ‚úÖ $VALID_SVGS v√°lidos"
echo "üè• Health: $HEALTH_SCORE/100 ($HEALTH_STATUS)"
echo "üîß Mantenimiento: $MAINT_SCORE/100"
echo "üìà Cobertura: ${COVERAGE_PERCENT:-0}%"
echo "‚è±Ô∏è  ${ELAPSED}s"
echo ""
echo "üìÑ Reportes: $REPORT"
[ -n "${JSON_REPORT:-}" ] && [ -f "${JSON_REPORT:-}" ] && echo "   + JSON: $JSON_REPORT"
[ -f "$DASHBOARD_CSV" ] && echo "   + CSV: $DASHBOARD_CSV"
[ -f "$EXEC_SUMMARY" ] && echo "   + Ejecutivo: $EXEC_SUMMARY"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo ""

# Mostrar reporte completo
if [ "${QUIET:-false}" != "true" ]; then
  # An√°lisis de paletas de colores y consistencia
  log_section "üé® Paletas de Colores y Consistencia"
  UNIQUE_COLORS=0
  TOP_COLORS_TMP=$(mktemp)
  while IFS= read -r svg_file; do
    grep -oE '#[0-9a-fA-F]{3,6}' "$svg_file" 2>/dev/null | tr '[:upper:]' '[:lower:]'
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null) | sort | uniq -c | sort -nr | tee "$TOP_COLORS_TMP" >/dev/null
  UNIQUE_COLORS=$(wc -l < "$TOP_COLORS_TMP" | xargs)
  if [ "$UNIQUE_COLORS" -gt 0 ]; then
    log_info "Colores √∫nicos en uso: $UNIQUE_COLORS"
    log_info "Top 5 colores:" 
    head -5 "$TOP_COLORS_TMP" | awk '{printf "  ‚Ä¢ %s (%s usos)\n", $2, $1}' | while read -r line; do log_info "$line"; done
  else
    log_info "‚ÑπÔ∏è  No se detectaron colores HEX expl√≠citos"
  fi
  # Validaci√≥n contra tokens.json (paleta oficial)
  OUT_OF_PALETTE=0
  if [ -f "$SRC_DIR/tokens.json" ]; then
    ALLOWED_TMP=$(mktemp)
    grep -ioE '#[0-9a-fA-F]{3,6}' "$SRC_DIR/tokens.json" | tr '[:upper:]' '[:lower:]' | sort -u > "$ALLOWED_TMP" 2>/dev/null || true
    if [ -s "$ALLOWED_TMP" ]; then
      OUT_TMP=$(mktemp)
      awk '{print $2}' "$TOP_COLORS_TMP" | sort -u | grep -v -f "$ALLOWED_TMP" 2>/dev/null > "$OUT_TMP" || true
      OUT_OF_PALETTE=$(wc -l < "$OUT_TMP" | xargs)
      if [ "$OUT_OF_PALETTE" -gt 0 ]; then
        log_info "‚ö†Ô∏è  Colores fuera de paleta: $OUT_OF_PALETTE"
        head -5 "$OUT_TMP" | awk '{printf "  ‚Ä¢ %s\n", $1}' | while read -r c; do log_info "$c"; done
        # Exportar JSON y CSV de desviaciones de paleta
        mkdir -p "$EXPORT_DIR"
        PALETTE_JSON="$EXPORT_DIR/palette_deviations.json"
        PALETTE_CSV="$EXPORT_DIR/colors_top.csv"
        {
          echo '{'
          echo '  "generated_at": '"\"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\""','
          echo '  "out_of_palette_count": '"$OUT_OF_PALETTE"','
          echo '  "out_of_palette": ['
          nl -ba "$OUT_TMP" | awk 'BEGIN{first=1}{ if(!first) printf ",\n"; first=0; printf "    \"%s\"", $2 } END{ print "\n  ]" }'
          echo '}'
        } > "$PALETTE_JSON" 2>/dev/null || true
        # CSV de top colores
        {
          echo "color,uses"
          awk '{print $2","$1}' "$TOP_COLORS_TMP"
        } > "$PALETTE_CSV" 2>/dev/null || true
        log_info "üìÑ Desviaciones de paleta: $PALETTE_JSON"
        log_info "üìÑ Top colores: $PALETTE_CSV"
      else
        log_info "‚úÖ Todos los colores est√°n en la paleta definida en tokens.json"
      fi
      rm -f "$OUT_TMP" 2>/dev/null || true
    else
      log_info "‚ÑπÔ∏è  tokens.json no contiene colores hex detectables"
    fi
    rm -f "$ALLOWED_TMP" 2>/dev/null || true
  fi
  rm -f "$TOP_COLORS_TMP" 2>/dev/null || true

  # Detecci√≥n de patrones reutilizables (s√≠mbolos/defs compartidos)
  log_section "‚ôªÔ∏è  Patrones Reutilizables"
  REUSABLE_TMP=$(mktemp)
  while IFS= read -r svg_file; do
    # Hash de trazos de paths y s√≠mbolos para detectar repeticiones
    grep -oE '<path[^>]*d="[^"]+"' "$svg_file" 2>/dev/null | sed 's/.*d="\([^"]\+\)".*/\1/' | md5 2>/dev/null || true
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null) | sort | uniq -d | wc -l | xargs > "$REUSABLE_TMP"
  REUSABLE_COUNT=$(cat "$REUSABLE_TMP" | xargs)
  if [ "${REUSABLE_COUNT:-0}" -gt 0 ]; then
    log_info "Patrones repetidos detectados (candidatos a <symbol>): $REUSABLE_COUNT"
  else
    log_info "‚úÖ Sin repeticiones significativas de paths"
  fi
  rm -f "$REUSABLE_TMP" 2>/dev/null || true

  # Recomendaciones inteligentes (basadas en m√©tricas previas)
  log_section "ü§ñ Recomendaciones Inteligentes"
  SMART_NUM=1
  [ "${UNOPTIMIZED_COUNT:-0}" -gt 0 ] && { log_info "$SMART_NUM. Optimizar ${UNOPTIMIZED_COUNT} archivo(s) con SVGO"; SMART_NUM=$((SMART_NUM+1)); }
  [ "${NO_VIEWBOX:-0}" -gt 0 ] && { log_info "$SMART_NUM. A√±adir viewBox a ${NO_VIEWBOX} SVG(s)"; SMART_NUM=$((SMART_NUM+1)); }
  [ "${SECURITY_ISSUES:-0}" -gt 0 ] && { log_info "$SMART_NUM. Remediar ${SECURITY_ISSUES} problema(s) de seguridad"; SMART_NUM=$((SMART_NUM+1)); }
  [ "${ANTI_PATTERNS:-0}" -gt 0 ] && { log_info "$SMART_NUM. Eliminar anti-patrones en ${ANTI_PATTERNS} archivo(s)"; SMART_NUM=$((SMART_NUM+1)); }
  [ "$SMART_NUM" -eq 1 ] && log_info "‚úÖ Sin recomendaciones cr√≠ticas pendientes"

  # M√©tricas de compliance y est√°ndares
  log_section "‚úîÔ∏è  Compliance y Est√°ndares"
  COPYRIGHT_TAGS=$(grep -rl '¬©\|¬Æ\|‚Ñ¢' "$ROOT_DIR" --include="*.svg" 2>/dev/null | wc -l | xargs)
  LICENSE_TAGS=$(grep -rl 'license\|creativecommons\|by-sa' "$ROOT_DIR" --include="*.svg" 2>/dev/null | wc -l | xargs)
  GDPR_FLAGS=$(grep -rl 'privacy\|gdpr\|datos personales' "$ROOT_DIR" --include="*.svg" 2>/dev/null | wc -l | xargs)
  log_info "SVGs con s√≠mbolos de copyright: $COPYRIGHT_TAGS"
  log_info "SVGs con menciones de licencia: $LICENSE_TAGS"
  [ "$GDPR_FLAGS" -gt 0 ] && log_info "‚ö†Ô∏è  Menciones GDPR/privacidad detectadas: $GDPR_FLAGS"

  # Mostrar reporte (completo o resumen)
  [ "${SUMMARY_ONLY:-false}" = "true" ] && tail -60 "$REPORT" | head -50 || cat "$REPORT"
fi

# C√≥digos de salida opcionales para CI
EXIT_STATUS=0
if [ "${FAIL_ON_ERROR:-false}" = "true" ]; then
  [ "${SECURITY_ISSUES:-0}" -gt 0 ] && EXIT_STATUS=2
  [ "${BROKEN_SVGS:-0}" -gt 0 ] && EXIT_STATUS=2
  [ "${INVALID_STRUCTURE:-0}" -gt 0 ] && EXIT_STATUS=2
fi

if [ "$EXIT_STATUS" -eq 0 ] && [ "${FAIL_ON_WARN:-false}" = "true" ]; then
  [ "${COMPLEX_SVGS:-0}" -gt 0 ] && EXIT_STATUS=1
  [ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && EXIT_STATUS=1
  [ "${OUT_OF_PALETTE:-0}" -gt 0 ] && EXIT_STATUS=1
fi

# Modo estricto de paleta: falla si hay colores fuera de tokens
if [ "$EXIT_STATUS" -eq 0 ] && [ "${PALETTE_STRICT:-false}" = "true" ]; then
  [ "${OUT_OF_PALETTE:-0}" -gt 0 ] && EXIT_STATUS=2
fi

exit "$EXIT_STATUS"

# Verificaci√≥n de plantillas nuevas (Templates y Storyboard)
log_section "üìÑ Plantillas de Video Esperadas"

TEMPLATE_FILES=(
  "$ROOT_DIR/ANUNCIO_VIDEO_TEMPLATE_ANTES_DESPUES.md"
  "$ROOT_DIR/ANUNCIO_VIDEO_TEMPLATE_NUMEROS_GRANDES.md"
  "$ROOT_DIR/ANUNCIO_VIDEO_STORYBOARD_IA_BULK.md"
)

TEMPLATES_MISSING=0
for tf in "${TEMPLATE_FILES[@]}"; do
  if [ -f "$tf" ]; then
    log_info "  ‚úÖ $(basename "$tf")"
  else
    log_info "  ‚ùå $(basename "$tf") (FALTA)"
    TEMPLATES_MISSING=$((TEMPLATES_MISSING + 1))
  fi
done

if [ "$TEMPLATES_MISSING" -eq 0 ]; then
  log_info "‚úÖ Todas las plantillas nuevas presentes"
else
  log_info "‚ö†Ô∏è  Plantillas faltantes: $TEMPLATES_MISSING"
fi

# Validaci√≥n de markers.csv y subtitles_es.srt por producto
log_section "üßæ Recursos por Producto (markers/SRT)"

EXPORTS_BASE="$ROOT_DIR/anuncios_video_15s/exports"

declare -A PRODUCT_DIRS
PRODUCT_DIRS=(
  [curso_ia_webinar]="curso_ia_webinar"
  [saas_ia_marketing]="saas_ia_marketing"
  [ia_bulk_docs]="ia_bulk_docs"
)

MISSING_EXPORT_RESOURCES=0
for prod in "${!PRODUCT_DIRS[@]}"; do
  PDIR="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
  if [ -d "$PDIR" ]; then
    HAS_MARKERS=0
    HAS_SRT=0
    [ -f "$PDIR/markers.csv" ] && HAS_MARKERS=1
    [ -f "$PDIR/subtitles_es.srt" ] && HAS_SRT=1

    if [ "$HAS_MARKERS" -eq 1 ] && [ "$HAS_SRT" -eq 1 ]; then
      log_info "  ‚úÖ $prod: markers.csv + subtitles_es.srt"
    else
      log_info "  ‚ö†Ô∏è  $prod: recursos faltantes -> markers: $HAS_MARKERS, srt: $HAS_SRT"
      MISSING_EXPORT_RESOURCES=$((MISSING_EXPORT_RESOURCES + 1))
    fi
  else
    log_info "  ‚ùå $prod: directorio de exports no encontrado ($PDIR)"
    MISSING_EXPORT_RESOURCES=$((MISSING_EXPORT_RESOURCES + 1))
  fi
done

if [ "$MISSING_EXPORT_RESOURCES" -eq 0 ]; then
  log_info "‚úÖ Recursos de exports completos por producto"
else
  log_info "‚ö†Ô∏è  Productos con recursos incompletos: $MISSING_EXPORT_RESOURCES"
fi

# Validador de SRT b√°sico
log_section "üß™ Validaci√≥n de Subt√≠tulos (SRT)"

SRT_ISSUES=0

validate_srt_file() {
  local srt_file="$1"
  local last_end_ms=0
  local issue=0
  # Validar bloques numeraci√≥n y tiempos
  # Formato tiempo: HH:MM:SS,mmm --> HH:MM:SS,mmm
  local line
  local idx=0
  local start_ms=0
  local end_ms=0
  while IFS= read -r line || [ -n "$line" ]; do
    if echo "$line" | grep -qE '^[0-9]+$'; then
      idx=$line
    elif echo "$line" | grep -qE '^[0-9]{2}:[0-9]{2}:[0-9]{2},[0-9]{3} --> [0-9]{2}:[0-9]{2}:[0-9]{2},[0-9]{3}$'; then
      start=$(echo "$line" | cut -d' ' -f1)
      end=$(echo "$line" | cut -d' ' -f3)
      # Convertir a ms
      h=${start:0:2}; m=${start:3:2}; s=${start:6:2}; ms=${start:9:3}
      start_ms=$((10#$h*3600000 + 10#$m*60000 + 10#$s*1000 + 10#$ms))
      h=${end:0:2}; m=${end:3:2}; s=${end:6:2}; ms=${end:9:3}
      end_ms=$((10#$h*3600000 + 10#$m*60000 + 10#$s*1000 + 10#$ms))
      if [ "$end_ms" -le "$start_ms" ]; then
        echo "    - Tiempo inv√°lido (fin <= inicio) en $(basename "$srt_file") bloque $idx" >> "$REPORT"
        issue=1
      fi
      if [ "$start_ms" -lt "$last_end_ms" ]; then
        echo "    - Overlap con bloque previo en $(basename "$srt_file") bloque $idx" >> "$REPORT"
        issue=1
      fi
      last_end_ms=$end_ms
    fi
  done < "$srt_file"
  return $issue
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  PDIR="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
  SFILE="$PDIR/subtitles_es.srt"
  if [ -f "$SFILE" ]; then
    if validate_srt_file "$SFILE"; then
      log_info "  ‚úÖ $prod: SRT v√°lido"
    else
      log_info "  ‚ö†Ô∏è  $prod: problemas detectados en SRT (- ver reporte)"
      SRT_ISSUES=$((SRT_ISSUES + 1))
    fi
  fi
done

if [ "$SRT_ISSUES" -eq 0 ]; then
  log_info "‚úÖ SRTs v√°lidos (sin errores)"
fi

# Validador de markers.csv
log_section "üìç Validaci√≥n de Markers (CSV)"

MARKERS_ISSUES=0

validate_markers_csv() {
  local csv_file="$1"
  local issue=0
  local prev_time_frames=0
  
  # Verificar que el archivo existe y tiene contenido
  if [ ! -f "$csv_file" ] || [ ! -s "$csv_file" ]; then
    echo "    - Archivo markers.csv vac√≠o o no encontrado: $(basename "$csv_file")" >> "$REPORT"
    return 1
  fi
  
  # Verificar header
  local header=$(head -1 "$csv_file" | tr -d '\r\n' | tr '[:upper:]' '[:lower:]')
  if [ "$header" != "label,time" ]; then
    echo "    - Header inv√°lido en $(basename "$csv_file"): esperado 'label,time', encontrado '$header'" >> "$REPORT"
    issue=1
  fi
  
  # Leer l√≠neas (saltando header y l√≠neas vac√≠as)
  local line_num=0
  local labels_seen=""
  while IFS= read -r line || [ -n "$line" ]; do
    line_num=$((line_num + 1))
    # Saltar header y l√≠neas vac√≠as
    [ "$line_num" -eq 1 ] && continue
    [ -z "$(echo "$line" | tr -d '[:space:]')" ] && continue
    
    # Parsear label,time
    local label=$(echo "$line" | cut -d',' -f1 | tr -d '[:space:]')
    local time_str=$(echo "$line" | cut -d',' -f2 | tr -d '[:space:]')
    
    # Validar formato tiempo: HH:MM:SS:FF
    if ! echo "$time_str" | grep -qE '^[0-9]{2}:[0-9]{2}:[0-9]{2}:[0-9]{2}$'; then
      echo "    - Formato tiempo inv√°lido en $(basename "$csv_file") l√≠nea $line_num: '$time_str' (esperado HH:MM:SS:FF)" >> "$REPORT"
      issue=1
      continue
    fi
    
    # Convertir tiempo a frames (asumiendo 30fps)
    local h=${time_str:0:2}
    local m=${time_str:3:2}
    local s=${time_str:6:2}
    local f=${time_str:9:2}
    local total_frames=$((10#$h*3600*30 + 10#$m*60*30 + 10#$s*30 + 10#$f))
    
    # Validar orden creciente
    if [ "$total_frames" -lt "$prev_time_frames" ]; then
      echo "    - Tiempo no creciente en $(basename "$csv_file") l√≠nea $line_num: $time_str (anterior: $prev_time_str)" >> "$REPORT"
      issue=1
    fi
    
    # Verificar labels duplicados
    if echo "$labels_seen" | grep -q "^$label$"; then
      echo "    - Label duplicado en $(basename "$csv_file") l√≠nea $line_num: '$label'" >> "$REPORT"
      issue=1
    else
      labels_seen="${labels_seen}${labels_seen:+$'\n'}$label"
    fi
    
    prev_time_frames=$total_frames
    prev_time_str="$time_str"
  done < "$csv_file"
  
  return $issue
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  PDIR="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
  MFILE="$PDIR/markers.csv"
  if [ -f "$MFILE" ]; then
    if validate_markers_csv "$MFILE"; then
      log_info "  ‚úÖ $prod: markers.csv v√°lido"
    else
      log_info "  ‚ö†Ô∏è  $prod: problemas detectados en markers.csv (- ver reporte)"
      MARKERS_ISSUES=$((MARKERS_ISSUES + 1))
    fi
  fi
done

if [ "$MARKERS_ISSUES" -eq 0 ]; then
  log_info "‚úÖ Markers CSV v√°lidos (sin errores)"
else
  RECOMMENDATIONS+=("Corregir $MARKERS_ISSUES archivo(s) markers.csv con errores de formato o tiempos")
fi

# Validaci√≥n de sincronizaci√≥n SRT ‚Üî markers.csv
log_section "üîÑ Validaci√≥n de Sincronizaci√≥n SRT ‚Üî Markers"

SYNC_ISSUES=0

validate_sync_srt_markers() {
  local srt_file="$1"
  local markers_file="$2"
  local prod="$3"
  local issue=0
  
  if [ ! -f "$srt_file" ] || [ ! -f "$markers_file" ]; then
    return 0  # Ya se report√≥ como faltante antes
  fi
  
  # Extraer tiempos de SRT (inicios de bloques)
  local srt_times=$(mktemp)
  grep -E '^[0-9]{2}:[0-9]{2}:[0-9]{2},[0-9]{3} -->' "$srt_file" 2>/dev/null | \
    cut -d' ' -f1 | sed 's/,/:/g' > "$srt_times" || true
  
  # Extraer tiempos de markers (convertir frames a tiempo)
  local markers_times=$(mktemp)
  tail -n +2 "$markers_file" 2>/dev/null | grep -v '^[[:space:]]*$' | \
    cut -d',' -f2 | while IFS= read -r time_str; do
    # Convertir HH:MM:SS:FF a HH:MM:SS,mmm (frames 30fps ‚Üí ms)
    local h=${time_str:0:2}
    local m=${time_str:3:2}
    local s=${time_str:6:2}
    local f=${time_str:9:2}
    # Convertir frames a ms (frame * 1000 / 30)
    local ms=$((10#$f * 1000 / 30))
    printf "%02d:%02d:%02d,%03d\n" "$((10#$h))" "$((10#$m))" "$((10#$s))" "$ms"
  done > "$markers_times" 2>/dev/null || true
  
  # Comparar tiempos (permitir diferencia de ¬±1 segundo por redondeo)
  local srt_count=$(wc -l < "$srt_times" | xargs)
  local markers_count=$(wc -l < "$markers_times" | xargs)
  
  if [ "$srt_count" -eq 0 ] || [ "$markers_count" -eq 0 ]; then
    echo "    - No se pudieron extraer tiempos para comparar en $prod" >> "$REPORT"
    issue=1
  elif [ "$srt_count" -ne "$markers_count" ]; then
    echo "    - Desincronizaci√≥n en $prod: SRT tiene $srt_count bloques, markers tiene $markers_count" >> "$REPORT"
    issue=1
  else
    # Comparar tiempos uno a uno (permitir diferencia de ¬±2s por redondeo)
    local idx=1
    while IFS= read -r srt_time && IFS= read -r marker_time <&3; do
      # Convertir a segundos para comparar
      local srt_h=${srt_time:0:2}; local srt_m=${srt_time:3:2}; local srt_s=${srt_time:6:2}
      local srt_total=$((10#$srt_h*3600 + 10#$srt_m*60 + 10#$srt_s))
      
      local m_h=${marker_time:0:2}; local m_m=${marker_time:3:2}; local m_s=${marker_time:6:2}
      local m_total=$((10#$m_h*3600 + 10#$m_m*60 + 10#$m_s))
      
      local diff=$((srt_total > m_total ? srt_total - m_total : m_total - srt_total))
      if [ "$diff" -gt 2 ]; then
        echo "    - Desincronizaci√≥n en $prod bloque $idx: SRT $srt_time vs marker $marker_time (diff: ${diff}s)" >> "$REPORT"
        issue=1
      fi
      idx=$((idx + 1))
    done < "$srt_times" 3< "$markers_times"
  fi
  
  rm -f "$srt_times" "$markers_times" 2>/dev/null || true
  return $issue
}

for prod in "${!PRODUCT_DIRS[@]}"; do
  PDIR="$EXPORTS_BASE/${PRODUCT_DIRS[$prod]}"
  SFILE="$PDIR/subtitles_es.srt"
  MFILE="$PDIR/markers.csv"
  
  if [ -f "$SFILE" ] && [ -f "$MFILE" ]; then
    if validate_sync_srt_markers "$SFILE" "$MFILE" "$prod"; then
      log_info "  ‚úÖ $prod: SRT y markers sincronizados"
    else
      log_info "  ‚ö†Ô∏è  $prod: desincronizaci√≥n detectada (- ver reporte)"
      SYNC_ISSUES=$((SYNC_ISSUES + 1))
    fi
  fi
done

if [ "$SYNC_ISSUES" -eq 0 ]; then
  log_info "‚úÖ Sincronizaci√≥n SRT ‚Üî markers OK"
else
  RECOMMENDATIONS+=("Revisar sincronizaci√≥n SRT/markers en $SYNC_ISSUES producto(s)")
fi

# Verificaci√≥n de metadatos de video (si ffprobe disponible)
log_section "üé• An√°lisis de Metadatos de Video"

VIDEO_METADATA_ISSUES=0

if command -v ffprobe >/dev/null 2>&1; then
  # Est√°ndares esperados para videos de 15s
  EXPECTED_WIDTH=1080
  EXPECTED_HEIGHT=1920  # Vertical format
  EXPECTED_DURATION_MIN=14
  EXPECTED_DURATION_MAX=16
  EXPECTED_CODEC="h264"  # O mp4 compatible
  
  while IFS= read -r video_file; do
    if [ -f "$video_file" ]; then
      # Extraer metadatos con ffprobe
      width=$(ffprobe -v error -select_streams v:0 -show_entries stream=width -of default=noprint_wrappers=1:nokey=1 "$video_file" 2>/dev/null | head -1)
      height=$(ffprobe -v error -select_streams v:0 -show_entries stream=height -of default=noprint_wrappers=1:nokey=1 "$video_file" 2>/dev/null | head -1)
      codec=$(ffprobe -v error -select_streams v:0 -show_entries stream=codec_name -of default=noprint_wrappers=1:nokey=1 "$video_file" 2>/dev/null | head -1)
      bitrate=$(ffprobe -v error -select_streams v:0 -show_entries stream=bit_rate -of default=noprint_wrappers=1:nokey=1 "$video_file" 2>/dev/null | head -1)
      duration=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "$video_file" 2>/dev/null | cut -d. -f1)
      
      local video_issue=0
      
      # Verificar resoluci√≥n
      if [ -n "$width" ] && [ -n "$height" ]; then
        if [ "$width" != "$EXPECTED_WIDTH" ] || [ "$height" != "$EXPECTED_HEIGHT" ]; then
          if [ "$video_issue" -eq 0 ]; then
            echo "  ‚ö†Ô∏è  $(basename "$video_file"):" >> "$REPORT"
            video_issue=1
          fi
          echo "    - Resoluci√≥n: ${width}x${height} (esperado: ${EXPECTED_WIDTH}x${EXPECTED_HEIGHT})" >> "$REPORT"
        fi
      fi
      
      # Verificar duraci√≥n
      if [ -n "$duration" ]; then
        if [ "$duration" -lt "$EXPECTED_DURATION_MIN" ] || [ "$duration" -gt "$EXPECTED_DURATION_MAX" ]; then
          if [ "$video_issue" -eq 0 ]; then
            echo "  ‚ö†Ô∏è  $(basename "$video_file"):" >> "$REPORT"
            video_issue=1
          fi
          echo "    - Duraci√≥n: ${duration}s (esperado: ${EXPECTED_DURATION_MIN}-${EXPECTED_DURATION_MAX}s)" >> "$REPORT"
        fi
      fi
      
      # Verificar codec
      if [ -n "$codec" ] && [ "$codec" != "h264" ] && [ "$codec" != "h265" ] && [ "$codec" != "hevc" ]; then
        if [ "$video_issue" -eq 0 ]; then
          echo "  ‚ö†Ô∏è  $(basename "$video_file"):" >> "$REPORT"
          video_issue=1
        fi
        echo "    - Codec: $codec (recomendado: h264 para m√°xima compatibilidad)" >> "$REPORT"
      fi
      
      # Verificar bitrate (recomendado: 5-10 Mbps para calidad)
      if [ -n "$bitrate" ] && [ "$bitrate" -gt 0 ]; then
        bitrate_mbps=$((bitrate / 1000000))
        if [ "$bitrate_mbps" -gt 15 ]; then
          if [ "$video_issue" -eq 0 ]; then
            echo "  ‚ö†Ô∏è  $(basename "$video_file"):" >> "$REPORT"
            video_issue=1
          fi
          echo "    - Bitrate: ${bitrate_mbps} Mbps (alto, puede afectar carga)" >> "$REPORT"
        elif [ "$bitrate_mbps" -lt 2 ]; then
          if [ "$video_issue" -eq 0 ]; then
            echo "  ‚ö†Ô∏è  $(basename "$video_file"):" >> "$REPORT"
            video_issue=1
          fi
          echo "    - Bitrate: ${bitrate_mbps} Mbps (bajo, puede afectar calidad)" >> "$REPORT"
        fi
      fi
      
      if [ "$video_issue" -eq 1 ]; then
        VIDEO_METADATA_ISSUES=$((VIDEO_METADATA_ISSUES + 1))
      fi
    fi
  done < <(find "$EXPORTS_BASE" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null | head -10)
  
  if [ "$VIDEO_METADATA_ISSUES" -eq 0 ]; then
    log_info "‚úÖ Metadatos de video OK (resoluci√≥n, duraci√≥n, codec)"
  else
    log_info "‚ö†Ô∏è  $VIDEO_METADATA_ISSUES video(s) con metadatos fuera de est√°ndares (- ver reporte)"
    RECOMMENDATIONS+=("Revisar metadatos de $VIDEO_METADATA_ISSUES video(s) (resoluci√≥n 1080x1920, duraci√≥n 14-16s, codec h264)")
  fi
else
  log_info "‚ÑπÔ∏è  ffprobe no disponible - no se puede analizar metadatos de video"
fi

# Verificaci√≥n mejorada de thumbnails
log_section "üñºÔ∏è  An√°lisis de Thumbnails"

THUMBNAIL_DIR="$ROOT_DIR/anuncios_video_15s/thumbnails"
THUMBNAIL_ISSUES=0
THUMBNAIL_COUNT=0
THUMBNAIL_MIN_WIDTH=640
THUMBNAIL_MIN_HEIGHT=360

if [ -d "$THUMBNAIL_DIR" ]; then
  # Contar thumbnails por formato
  THUMBNAIL_PNG=$(find "$THUMBNAIL_DIR" -name "*.png" 2>/dev/null | wc -l | xargs)
  THUMBNAIL_JPG=$(find "$THUMBNAIL_DIR" -name "*.jpg" -o -name "*.jpeg" 2>/dev/null | wc -l | xargs)
  THUMBNAIL_COUNT=$((THUMBNAIL_PNG + THUMBNAIL_JPG))
  
  log_info "Total: $THUMBNAIL_COUNT (PNG: $THUMBNAIL_PNG, JPG: $THUMBNAIL_JPG)"
  
  # Verificar thumbnails por producto
  for prod in "${!PRODUCT_DIRS[@]}"; do
    PROD_THUMBS=$(find "$THUMBNAIL_DIR" -name "*${prod}*" -o -name "*${PRODUCT_DIRS[$prod]}*" 2>/dev/null | wc -l | xargs)
    if [ "$PROD_THUMBS" -eq 0 ]; then
      log_info "  ‚ö†Ô∏è  $prod: sin thumbnails espec√≠ficos"
      THUMBNAIL_ISSUES=$((THUMBNAIL_ISSUES + 1))
    else
      log_info "  ‚úÖ $prod: $PROD_THUMBS thumbnail(s)"
    fi
  done
  
  # Verificar dimensiones (si sips est√° disponible en macOS)
  if command -v sips >/dev/null 2>&1; then
    DIM_ISSUES=0
    while IFS= read -r thumb_file; do
      if [ -f "$thumb_file" ]; then
        width=$(sips -g pixelWidth "$thumb_file" 2>/dev/null | awk '/pixelWidth:/ {print $2}')
        height=$(sips -g pixelHeight "$thumb_file" 2>/dev/null | awk '/pixelHeight:/ {print $2}')
        
        if [ -n "$width" ] && [ -n "$height" ]; then
          if [ "$width" -lt "$THUMBNAIL_MIN_WIDTH" ] || [ "$height" -lt "$THUMBNAIL_MIN_HEIGHT" ]; then
            if [ "$DIM_ISSUES" -eq 0 ]; then
              echo "  ‚ö†Ô∏è  Thumbnails con dimensiones menores a ${THUMBNAIL_MIN_WIDTH}x${THUMBNAIL_MIN_HEIGHT}:" >> "$REPORT"
            fi
            echo "    - $(basename "$thumb_file"): ${width}x${height}" >> "$REPORT"
            DIM_ISSUES=$((DIM_ISSUES + 1))
          fi
        fi
      fi
    done < <(find "$THUMBNAIL_DIR" -type f \( -name "*.png" -o -name "*.jpg" -o -name "*.jpeg" \) 2>/dev/null | head -10)
    
    if [ "$DIM_ISSUES" -gt 0 ]; then
      log_info "  ‚ö†Ô∏è  $DIM_ISSUES thumbnail(s) con dimensiones menores a ${THUMBNAIL_MIN_WIDTH}x${THUMBNAIL_MIN_HEIGHT}"
      THUMBNAIL_ISSUES=$((THUMBNAIL_ISSUES + DIM_ISSUES))
    else
      log_info "  ‚úÖ Dimensiones m√≠nimas cumplidas (${THUMBNAIL_MIN_WIDTH}x${THUMBNAIL_MIN_HEIGHT})"
    fi
  elif command -v identify >/dev/null 2>&1; then
    # Fallback a ImageMagick si est√° disponible
    DIM_ISSUES=0
    while IFS= read -r thumb_file; do
      if [ -f "$thumb_file" ]; then
        dims=$(identify -format "%wx%h" "$thumb_file" 2>/dev/null)
        if [ -n "$dims" ]; then
          width=$(echo "$dims" | cut -d'x' -f1)
          height=$(echo "$dims" | cut -d'x' -f2)
          
          if [ "$width" -lt "$THUMBNAIL_MIN_WIDTH" ] || [ "$height" -lt "$THUMBNAIL_MIN_HEIGHT" ]; then
            if [ "$DIM_ISSUES" -eq 0 ]; then
              echo "  ‚ö†Ô∏è  Thumbnails con dimensiones menores a ${THUMBNAIL_MIN_WIDTH}x${THUMBNAIL_MIN_HEIGHT}:" >> "$REPORT"
            fi
            echo "    - $(basename "$thumb_file"): ${width}x${height}" >> "$REPORT"
            DIM_ISSUES=$((DIM_ISSUES + 1))
          fi
        fi
      fi
    done < <(find "$THUMBNAIL_DIR" -type f \( -name "*.png" -o -name "*.jpg" -o -name "*.jpeg" \) 2>/dev/null | head -10)
    
    if [ "$DIM_ISSUES" -gt 0 ]; then
      log_info "  ‚ö†Ô∏è  $DIM_ISSUES thumbnail(s) con dimensiones menores a ${THUMBNAIL_MIN_WIDTH}x${THUMBNAIL_MIN_HEIGHT}"
      THUMBNAIL_ISSUES=$((THUMBNAIL_ISSUES + DIM_ISSUES))
    else
      log_info "  ‚úÖ Dimensiones m√≠nimas cumplidas (${THUMBNAIL_MIN_WIDTH}x${THUMBNAIL_MIN_HEIGHT})"
    fi
  else
    log_info "  ‚ÑπÔ∏è  No se pudo verificar dimensiones (sips/ImageMagick no disponible)"
  fi
  
  if [ "$THUMBNAIL_ISSUES" -eq 0 ] && [ "$THUMBNAIL_COUNT" -gt 0 ]; then
    log_info "‚úÖ Thumbnails OK"
  fi
else
  log_info "‚ö†Ô∏è  Directorio thumbnails no encontrado (esperado: $THUMBNAIL_DIR)"
  THUMBNAIL_ISSUES=1
fi

# Respetar modo r√°pido para outputs pesados
if [ "${QUICK_MODE:-0}" -eq 1 ]; then
  OUTPUT_FORMAT="text"
fi

# ========================================
# FUNCIONES AVANZADAS DE AN√ÅLISIS
# ========================================

# Detecci√≥n de duplicados por contenido (hash)
detect_content_duplicates() {
  if [ "${DETECT_DUPLICATES:-true}" != "true" ]; then
    return 0
  fi
  
  log_section "üîç Detecci√≥n de Duplicados por Contenido"
  
  local hash_file=$(mktemp)
  local duplicates_found=0
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
      local content_hash
      if command -v md5 >/dev/null 2>&1; then
        content_hash=$(grep -v '^[[:space:]]*$' "$svg_file" | sort | md5 -q 2>/dev/null || echo "")
      elif command -v md5sum >/dev/null 2>&1; then
        content_hash=$(grep -v '^[[:space:]]*$' "$svg_file" | sort | md5sum | cut -d' ' -f1 2>/dev/null || echo "")
      else
        content_hash=$(grep -v '^[[:space:]]*$' "$svg_file" | sort | shasum -a 256 | cut -d' ' -f1 2>/dev/null || echo "")
      fi
      [ -n "$content_hash" ] && echo "$content_hash|$svg_file" >> "$hash_file"
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -100)
  
  if [ -f "$hash_file" ] && [ -s "$hash_file" ]; then
    local dup_groups=$(sort "$hash_file" | cut -d'|' -f1 | uniq -d | wc -l | xargs)
    if [ "$dup_groups" -gt 0 ]; then
      log_info "‚ö†Ô∏è  Se encontraron $dup_groups grupo(s) de duplicados"
      sort "$hash_file" | cut -d'|' -f1 | uniq -d | head -5 | while read -r dup_hash; do
        local files_with_hash=$(grep "^$dup_hash|" "$hash_file" | cut -d'|' -f2-)
        local file_count=$(echo "$files_with_hash" | wc -l | xargs)
        if [ "$file_count" -gt 1 ]; then
          duplicates_found=$((duplicates_found + file_count - 1))
          log_info "  Duplicados ($file_count archivos):"
          echo "$files_with_hash" | head -3 | while read -r f; do
            log_info "    - ${f#$ROOT_DIR/}"
          done
          [ "$file_count" -gt 3 ] && log_info "    ... y $((file_count - 3)) m√°s"
        fi
      done
    else
      log_info "‚úÖ No se encontraron duplicados por contenido"
    fi
  fi
  
  rm -f "$hash_file" 2>/dev/null || true
  echo "$duplicates_found"
}

# Comparaci√≥n hist√≥rica
compare_with_history() {
  if [ "${COMPARE_HISTORY:-true}" != "true" ]; then
    return 0
  fi
  
  log_section "üìä Comparaci√≥n Hist√≥rica"
  
  local history_dir="$ROOT_DIR/.cache/asset_analysis/history"
  mkdir -p "$history_dir"
  
  local current_metrics="$history_dir/current_$(date +%Y%m%d_%H%M%S).json"
  local last_metric=$(ls -t "$history_dir"/*.json 2>/dev/null | grep -v "$(basename "$current_metrics")" | head -1)
  
  {
    echo "{"
    echo "  \"timestamp\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
    echo "  \"total_svgs\": ${TOTAL_SVGS:-0},"
    echo "  \"health_score\": ${HEALTH_SCORE:-0},"
    echo "  \"empty_svgs\": ${EMPTY_SVGS:-0},"
    echo "  \"broken_svgs\": ${BROKEN_SVGS:-0}"
    echo "}"
  } > "$current_metrics" 2>/dev/null || true
  
  if [ -n "$last_metric" ] && [ -f "$last_metric" ] && command -v jq >/dev/null 2>&1; then
    local prev_total=$(jq -r '.total_svgs // 0' "$last_metric" 2>/dev/null || echo "0")
    local prev_health=$(jq -r '.health_score // 0' "$last_metric" 2>/dev/null || echo "0")
    
    if [ "$prev_total" -gt 0 ]; then
      local svg_diff=$((TOTAL_SVGS - prev_total))
      local health_diff=$((HEALTH_SCORE - prev_health))
      
      if [ "$svg_diff" -gt 0 ]; then
        log_info "üìà Aumento: +$svg_diff SVGs desde √∫ltima ejecuci√≥n"
      elif [ "$svg_diff" -lt 0 ]; then
        log_info "üìâ Reducci√≥n: $svg_diff SVGs desde √∫ltima ejecuci√≥n"
      else
        log_info "‚û°Ô∏è  Sin cambios en cantidad de SVGs"
      fi
      
      if [ "$health_diff" -gt 5 ]; then
        log_info "‚úÖ Mejora significativa en Health Score: +$health_diff puntos"
      elif [ "$health_diff" -lt -5 ]; then
        log_info "‚ö†Ô∏è  Degradaci√≥n en Health Score: $health_diff puntos"
      fi
    fi
  else
    log_info "‚ÑπÔ∏è  Primera ejecuci√≥n (no hay datos hist√≥ricos)"
  fi
}

# Generaci√≥n de recomendaciones inteligentes
generate_recommendations() {
  if [ "${GENERATE_RECOMMENDATIONS:-true}" != "true" ]; then
    return 0
  fi
  
  log_section "üí° Recomendaciones Inteligentes"
  
  local rec_count=0
  
  if [ "${LARGE_SVGS:-0}" -gt 0 ]; then
    rec_count=$((rec_count + 1))
    log_info "$rec_count. Optimizar ${LARGE_SVGS} SVG(s) grande(s):"
    log_info "   ‚Üí Ejecutar: svgo -f $SRC_DIR -r"
    log_info "   ‚Üí Ahorro estimado: ~30-50% de tama√±o"
  fi
  
  if [ "${NO_ACCESSIBILITY:-0}" -gt 5 ]; then
    rec_count=$((rec_count + 1))
    log_info "$rec_count. Mejorar accesibilidad en ${NO_ACCESSIBILITY} SVG(s):"
    log_info "   ‚Üí A√±adir <title> y <desc>"
    log_info "   ‚Üí Verificar contraste (WCAG AA)"
  fi
  
  if [ "${GAPS_COUNT:-0}" -gt 0 ]; then
    rec_count=$((rec_count + 1))
    log_info "$rec_count. Completar $GAPS_COUNT gap(s) en cobertura"
  fi
  
  [ "$rec_count" -eq 0 ] && log_info "‚úÖ Sistema √≥ptimo - Sin recomendaciones cr√≠ticas"
}

# Ejecutar an√°lisis avanzados si est√°n habilitados
if [ "${DETECT_DUPLICATES:-true}" = "true" ]; then
  DUPLICATES_COUNT=$(detect_content_duplicates)
fi

if [ "${COMPARE_HISTORY:-true}" = "true" ]; then
  compare_with_history
fi

if [ "${GENERATE_RECOMMENDATIONS:-true}" = "true" ]; then
  generate_recommendations
fi

# Integraci√≥n con herramientas avanzadas
log_section "üîó Herramientas Avanzadas Disponibles"

SCRIPTS_DIR="$SCRIPT_DIR"
ADVANCED_TOOLS=(
  "predict_creative_performance.py:Predicci√≥n de performance"
  "analyze_trends.py:An√°lisis de tendencias temporales"
  "generate_performance_report.py:Reporte completo de performance"
  "optimize_csv_master.py:Optimizaci√≥n del CSV Master"
  "batch_process_creatives.py:Procesamiento batch de operaciones"
)

AVAILABLE_COUNT=0
for tool_info in "${ADVANCED_TOOLS[@]}"; do
  TOOL_FILE="${tool_info%%:*}"
  TOOL_DESC="${tool_info##*:}"
  TOOL_PATH="$SCRIPTS_DIR/$TOOL_FILE"
  
  if [ -f "$TOOL_PATH" ]; then
    log_info "  ‚úÖ $TOOL_FILE - $TOOL_DESC"
    AVAILABLE_COUNT=$((AVAILABLE_COUNT + 1))
  else
    log_info "  ‚ö†Ô∏è  $TOOL_FILE - No disponible"
  fi
done

log_info ""
log_info "üí° Ejecuta herramientas individuales:"
log_info "   python3 $SCRIPTS_DIR/predict_creative_performance.py"
log_info "   python3 $SCRIPTS_DIR/analyze_trends.py"
log_info "   python3 $SCRIPTS_DIR/batch_process_creatives.py [preset]"
log_info ""
log_info "   Presets disponibles: full, quick, optimize, report, fix"
log_info ""

if [ "$AVAILABLE_COUNT" -eq "${#ADVANCED_TOOLS[@]}" ]; then
  log_info "‚úÖ Todas las herramientas avanzadas disponibles"
else
  log_info "‚ö†Ô∏è  $AVAILABLE_COUNT/${#ADVANCED_TOOLS[@]} herramientas disponibles"
fi

# An√°lisis de versionado Git
log_section "üìù An√°lisis de Versionado Git"

if command -v git >/dev/null 2>&1 && [ -d "$ROOT_DIR/.git" ]; then
  UNTRACKED_SVGS=$(git ls-files --others --exclude-standard "$ROOT_DIR" -- "*.svg" 2>/dev/null | wc -l | xargs)
  MODIFIED_SVGS=$(git diff --name-only -- "*.svg" 2>/dev/null | wc -l | xargs)
  STAGED_SVGS=$(git diff --cached --name-only -- "*.svg" 2>/dev/null | wc -l | xargs)
  
  log_info "SVGs sin trackear: $UNTRACKED_SVGS"
  log_info "SVGs modificados: $MODIFIED_SVGS"
  log_info "SVGs en staging: $STAGED_SVGS"
  
  [ "$UNTRACKED_SVGS" -gt 0 ] && log_info "‚ö†Ô∏è  Considerar agregar SVGs nuevos a Git"
  
  LAST_SVG_COMMIT=$(git log -1 --format="%h %s" --all -- "*.svg" 2>/dev/null | head -1)
  [ -n "$LAST_SVG_COMMIT" ] && log_info "√öltimo commit SVGs: $LAST_SVG_COMMIT"
else
  log_info "‚ÑπÔ∏è  Git no disponible o no es un repositorio Git"
fi

# An√°lisis de duplicaci√≥n visual
log_section "üîÑ An√°lisis de Duplicaci√≥n Visual"

HASH_FILE=$(mktemp)
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    VISUAL_HASH=$(grep -oE '<path[^>]*d="[^"]+"|<rect|<circle|<ellipse' "$svg_file" 2>/dev/null | head -20 | md5 2>/dev/null | cut -c1-8)
    [ -n "$VISUAL_HASH" ] && echo "$VISUAL_HASH|$svg_file" >> "$HASH_FILE"
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -100)

DUPE_GROUPS=$(sort "$HASH_FILE" | cut -d'|' -f1 | uniq -d | wc -l | xargs)

if [ "$DUPE_GROUPS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Grupos similares: $DUPE_GROUPS"
  sort "$HASH_FILE" | cut -d'|' -f1 | uniq -d | head -3 | while read -r hash; do
    MATCHES=$(grep "^$hash" "$HASH_FILE" | cut -d'|' -f2 | wc -l | xargs)
    log_info "  - Hash $hash: $MATCHES archivos"
  done
else
  log_info "‚úÖ Sin duplicados visuales detectados"
fi

rm -f "$HASH_FILE" 2>/dev/null || true

# An√°lisis de estructura de carpetas
log_section "üìÅ An√°lisis de Estructura"

MAX_DEPTH=0
FLAT_STRUCTURE=0
DEEP_STRUCTURE=0

while IFS= read -r svg_file; do
  REL_PATH="${svg_file#$ROOT_DIR/}"
  DEPTH=$(echo "$REL_PATH" | tr -cd '/' | wc -c | xargs)
  DEPTH=$((DEPTH + 1))
  
  [ "$DEPTH" -gt "$MAX_DEPTH" ] && MAX_DEPTH=$DEPTH
  [ "$DEPTH" -le 2 ] && FLAT_STRUCTURE=$((FLAT_STRUCTURE + 1))
  [ "$DEPTH" -gt 4 ] && DEEP_STRUCTURE=$((DEEP_STRUCTURE + 1))
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

log_info "Profundidad m√°xima: $MAX_DEPTH niveles"
log_info "Estructura plana (‚â§2): $FLAT_STRUCTURE"
log_info "Estructura profunda (>4): $DEEP_STRUCTURE"
[ "$MAX_DEPTH" -gt 5 ] && log_info "‚ö†Ô∏è  Estructura muy profunda" || log_info "‚úÖ Estructura organizada"

# Cobertura de formatos
log_section "üìê Cobertura de Formatos"

PLATFORM_FORMATS=(
  "linkedin:1200x627"
  "linkedin:1080x1080"
  "linkedin:1080x1920"
  "instagram:1080x1080"
  "instagram:1080x1920"
  "instagram:1080x1350"
)

FORMAT_GAPS=0
for pf in "${PLATFORM_FORMATS[@]}"; do
  PLATFORM="${pf%%:*}"
  FORMAT="${pf##*:}"
  PLAT_DIR="$ROOT_DIR/ads/$PLATFORM"
  
  if [ -d "$PLAT_DIR" ]; then
    COUNT=$(find "$PLAT_DIR" -name "*.svg" -type f 2>/dev/null | grep -E "$FORMAT|${FORMAT//x/_}" | wc -l | xargs)
    if [ "$COUNT" -eq 0 ]; then
      FORMAT_GAPS=$((FORMAT_GAPS + 1))
      log_info "  ‚ö†Ô∏è  $PLATFORM: $FORMAT sin assets"
    else
      log_info "  ‚úÖ $PLATFORM: $FORMAT ($COUNT)"
    fi
  fi
done

[ "$FORMAT_GAPS" -eq 0 ] && log_info "‚úÖ Cobertura completa" || log_info "‚ö†Ô∏è  Formatos faltantes: $FORMAT_GAPS"

# An√°lisis de clases CSS
log_section "üé® An√°lisis de Clases CSS"

CSS_CLASSES=0
INLINE_STYLES=0
UNIQUE_CLASSES=()

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    CLASS_MATCHES=$(grep -oE 'class="[^"]+"' "$svg_file" 2>/dev/null | sed 's/class="\([^"]*\)"/\1/' | tr ' ' '\n' || true)
    if [ -n "$CLASS_MATCHES" ]; then
      while IFS= read -r class; do
        [ -n "$class" ] && CSS_CLASSES=$((CSS_CLASSES + 1)) && UNIQUE_CLASSES+=("$class")
      done <<< "$CLASS_MATCHES"
    fi
    INLINE_COUNT=$(grep -c 'style="' "$svg_file" 2>/dev/null || echo "0")
    INLINE_STYLES=$((INLINE_STYLES + INLINE_COUNT))
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -100)

UNIQUE_CLASS_COUNT=$(printf '%s\n' "${UNIQUE_CLASSES[@]}" | sort -u | wc -l | xargs)

log_info "Clases CSS: $CSS_CLASSES (√∫nicas: $UNIQUE_CLASS_COUNT)"
log_info "Estilos inline: $INLINE_STYLES"
[ "$INLINE_STYLES" -gt "$CSS_CLASSES" ] && log_info "‚ö†Ô∏è  M√°s estilos inline que clases" || log_info "‚úÖ Uso adecuado de clases"

# Detecci√≥n de anti-patrones
log_section "üö´ Detecci√≥n de Anti-patrones"

ANTI_PATTERNS_COUNT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    ISSUES=0
    VIEWBOX_COUNT=$(grep -c 'viewBox=' "$svg_file" 2>/dev/null || echo "0")
    [ "$VIEWBOX_COUNT" -gt 1 ] && ISSUES=$((ISSUES + 1))
    
    if grep -qE 'width="[0-9]+".*height="[0-9]+"' "$svg_file" 2>/dev/null && ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      ISSUES=$((ISSUES + 1))
    fi
    
    SVG_TAG_COUNT=$(grep -c '<svg[^>]*>' "$svg_file" 2>/dev/null || echo "0")
    [ "$SVG_TAG_COUNT" -gt 1 ] && ISSUES=$((ISSUES + 1))
    
    TEXT_ELEMENTS=$(grep -c '<text' "$svg_file" 2>/dev/null || echo "0")
    if [ "$TEXT_ELEMENTS" -gt 0 ] && ! grep -q 'font-family' "$svg_file" 2>/dev/null && ! grep -q '\.text\|\.headline' "$svg_file" 2>/dev/null; then
      ISSUES=$((ISSUES + 1))
    fi
    
    [ "$ISSUES" -gt 0 ] && ANTI_PATTERNS_COUNT=$((ANTI_PATTERNS_COUNT + 1))
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -100)

[ "$ANTI_PATTERNS_COUNT" -gt 0 ] && log_info "‚ö†Ô∏è  SVGs con anti-patrones: $ANTI_PATTERNS_COUNT" || log_info "‚úÖ Sin anti-patrones detectados"

# An√°lisis de complejidad
log_section "üßÆ An√°lisis de Complejidad"

COMPLEX_SVGS_NEW=0
VERY_COMPLEX=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    ELEMENT_COUNT=$(grep -cE '<(path|rect|circle|ellipse|line|polygon|polyline|g|text|image)' "$svg_file" 2>/dev/null || echo "0")
    GROUP_COUNT=$(grep -c '<g' "$svg_file" 2>/dev/null || echo "0")
    FILTER_COUNT=$(grep -c '<filter' "$svg_file" 2>/dev/null || echo "0")
    GRADIENT_COUNT=$(grep -cE '<(linear|radial)Gradient' "$svg_file" 2>/dev/null || echo "0")
    
    COMPLEXITY_SCORE=$((ELEMENT_COUNT + GROUP_COUNT * 2 + FILTER_COUNT * 5 + GRADIENT_COUNT * 3))
    
    if [ "$COMPLEXITY_SCORE" -gt 200 ]; then
      VERY_COMPLEX=$((VERY_COMPLEX + 1))
      COMPLEX_SVGS_NEW=$((COMPLEX_SVGS_NEW + 1))
    elif [ "$COMPLEXITY_SCORE" -gt 100 ]; then
      COMPLEX_SVGS_NEW=$((COMPLEX_SVGS_NEW + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

[ "$VERY_COMPLEX" -gt 0 ] && log_info "‚ö†Ô∏è  SVGs muy complejos (score >200): $VERY_COMPLEX" || [ "$COMPLEX_SVGS_NEW" -gt 0 ] && log_info "‚ÑπÔ∏è  SVGs complejos: $COMPLEX_SVGS_NEW" || log_info "‚úÖ Complejidad razonable"

# Reporte de tendencias
log_section "üìà An√°lisis de Tendencias"

TREND_FILE="$ROOT_DIR/exports/trends_$(date +%Y%m%d).txt"
mkdir -p "$ROOT_DIR/exports" 2>/dev/null || true

{
  echo "TENDENCIAS DE ASSETS - $(date '+%Y-%m-%d %H:%M:%S')"
  echo "=========================================="
  echo ""
  echo "FORMATOS M√ÅS USADOS:"
  find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | sed 's/.*\([0-9]\{3,4\}x[0-9]\{3,4\}\).*/\1/' | sort | uniq -c | sort -rn | head -5 | awk '{printf "  %s: %s assets\n", $2, $1}'
  echo ""
  echo "PRODUCTOS M√ÅS REPRESENTADOS:"
  find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | grep -oE '(curso|saas|ia_bulk|bulk)' | sort | uniq -c | sort -rn | awk '{printf "  %s: %s assets\n", $2, $1}'
  echo ""
  echo "√ÅNGULOS M√ÅS USADOS:"
  find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | grep -oE '(urgency|social|metrics|v[0-9]+)' | sort | uniq -c | sort -rn | head -5 | awk '{printf "  %s: %s assets\n", $2, $1}'
} > "$TREND_FILE" 2>/dev/null || true

[ -f "$TREND_FILE" ] && log_info "‚úÖ Reporte de tendencias: $TREND_FILE"

# An√°lisis de oportunidades de optimizaci√≥n
log_section "‚ö° Oportunidades de Optimizaci√≥n"

OPTIMIZATION_OPPORTUNITIES=0
OPTIMIZATION_SCORE=0

# Assets grandes que se pueden optimizar
LARGE_SVG_FILES=$(find "$ROOT_DIR" -name "*.svg" -size +50k -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -10)
LARGE_COUNT=$(find "$ROOT_DIR" -name "*.svg" -size +50k -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)

if [ "$LARGE_COUNT" -gt 0 ]; then
  OPTIMIZATION_OPPORTUNITIES=$((OPTIMIZATION_OPPORTUNITIES + LARGE_COUNT))
  OPTIMIZATION_SCORE=$((OPTIMIZATION_SCORE + LARGE_COUNT * 5))
  log_info "üì¶ SVGs grandes (>50KB) para optimizar: $LARGE_COUNT"
  echo "$LARGE_SVG_FILES" | head -5 | while read -r f; do
    [ -n "$f" ] && size=$(du -h "$f" 2>/dev/null | cut -f1) && log_info "  - $(basename "$f"): $size"
  done
fi

# SVGs sin optimizar con svgo
UNOPTIMIZED_PATTERNS=$(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -20 | xargs grep -l "<!-- Generator:" 2>/dev/null | wc -l | xargs)
if [ "$UNOPTIMIZED_PATTERNS" -gt 0 ]; then
  OPTIMIZATION_OPPORTUNITIES=$((OPTIMIZATION_OPPORTUNITIES + UNOPTIMIZED_PATTERNS))
  OPTIMIZATION_SCORE=$((OPTIMIZATION_SCORE + UNOPTIMIZED_PATTERNS * 2))
  log_info "üîß SVGs con comentarios de generador (candidatos a optimizar): $UNOPTIMIZED_PATTERNS"
fi

# Assets con mucho whitespace
WHITESPACE_HEAVY=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ]; then
    LINE_COUNT=$(wc -l < "$svg_file" 2>/dev/null | xargs)
    EMPTY_LINES=$(grep -c '^[[:space:]]*$' "$svg_file" 2>/dev/null || echo "0")
    if [ "$LINE_COUNT" -gt 0 ] && [ "$EMPTY_LINES" -gt 0 ]; then
      EMPTY_PERCENT=$(awk "BEGIN {printf \"%.0f\", ($EMPTY_LINES / $LINE_COUNT) * 100}")
      if [ "$EMPTY_PERCENT" -gt 30 ]; then
        WHITESPACE_HEAVY=$((WHITESPACE_HEAVY + 1))
      fi
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

if [ "$WHITESPACE_HEAVY" -gt 0 ]; then
  OPTIMIZATION_OPPORTUNITIES=$((OPTIMIZATION_OPPORTUNITIES + WHITESPACE_HEAVY))
  OPTIMIZATION_SCORE=$((OPTIMIZATION_SCORE + WHITESPACE_HEAVY))
  log_info "üìÑ SVGs con mucho whitespace (>30%): $WHITESPACE_HEAVY"
fi

if [ "$OPTIMIZATION_OPPORTUNITIES" -gt 0 ]; then
  log_info "üí° Score de optimizaci√≥n: $OPTIMIZATION_SCORE (mayor = m√°s oportunidades)"
  log_info "üí° Recomendaci√≥n: Ejecutar svgo para reducir tama√±o y mejorar performance"
else
  log_info "‚úÖ Sin oportunidades de optimizaci√≥n detectadas"
fi

# Validaci√≥n de est√°ndares de marca
log_section "üé® Validaci√≥n de Est√°ndares de Marca"

BRAND_VIOLATIONS=0
BRAND_SCORE=100

# Verificar uso consistente de colores de marca
if [ -f "$SRC_DIR/tokens.json" ]; then
  BRAND_COLORS_FOUND=$(grep -oE '#[0-9a-fA-F]{3,6}' "$SRC_DIR/tokens.json" 2>/dev/null | sort -u | wc -l | xargs)
  if [ "$BRAND_COLORS_FOUND" -gt 0 ]; then
    # Verificar si los SVGs usan colores fuera de la paleta
    if [ "${OUT_OF_PALETTE:-0}" -gt 0 ]; then
      BRAND_VIOLATIONS=$((BRAND_VIOLATIONS + OUT_OF_PALETTE))
      BRAND_SCORE=$((BRAND_SCORE - OUT_OF_PALETTE * 2))
      log_info "‚ö†Ô∏è  Colores fuera de paleta de marca: ${OUT_OF_PALETTE:-0}"
    else
      log_info "‚úÖ Todos los colores est√°n dentro de la paleta de marca"
    fi
  fi
fi

# Verificar tipograf√≠a consistente
TYPEFACE_INCONSISTENT=0
if [ "${UNIQUE_FONTS:-0}" -gt 10 ]; then
  TYPEFACE_INCONSISTENT=$((UNIQUE_FONTS - 10))
  BRAND_VIOLATIONS=$((BRAND_VIOLATIONS + TYPEFACE_INCONSISTENT))
  BRAND_SCORE=$((BRAND_SCORE - TYPEFACE_INCONSISTENT))
  log_info "‚ö†Ô∏è  Demasiadas fuentes diferentes ($UNIQUE_FONTS) - considerar unificar tipograf√≠a de marca"
else
  log_info "‚úÖ Tipograf√≠a consistente"
fi

if [ "$BRAND_SCORE" -lt 0 ]; then
  BRAND_SCORE=0
fi

BRAND_LEVEL=""
if [ "$BRAND_SCORE" -ge 90 ]; then
  BRAND_LEVEL="‚úÖ Excelente"
elif [ "$BRAND_SCORE" -ge 75 ]; then
  BRAND_LEVEL="‚úÖ Bueno"
elif [ "$BRAND_SCORE" -ge 60 ]; then
  BRAND_LEVEL="‚ö†Ô∏è  Regular"
else
  BRAND_LEVEL="‚ùå Necesita atenci√≥n"
fi

log_info "Score de marca: $BRAND_SCORE/100 - $BRAND_LEVEL"
[ "$BRAND_VIOLATIONS" -gt 0 ] && log_info "Violaciones detectadas: $BRAND_VIOLATIONS"

# An√°lisis de dependencias entre assets
log_section "üîó An√°lisis de Dependencias"

ASSET_DEPENDENCIES=0
EXTERNAL_IMAGES=0
INTERNAL_REFERENCES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar referencias a otros assets
    ASSET_REFS=$(grep -oE 'href="[^"]+\.(svg|png|jpg|jpeg)"' "$svg_file" 2>/dev/null | grep -v 'http' || true)
    if [ -n "$ASSET_REFS" ]; then
      INTERNAL_REFERENCES=$((INTERNAL_REFERENCES + 1))
    fi
    
    # Detectar im√°genes externas
    EXTERNAL_IMG_REFS=$(grep -oE 'href="https?://[^"]+\.(svg|png|jpg|jpeg|webp)"' "$svg_file" 2>/dev/null || true)
    if [ -n "$EXTERNAL_IMG_REFS" ]; then
      EXTERNAL_IMAGES=$((EXTERNAL_IMAGES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs con referencias internas: $INTERNAL_REFERENCES"
log_info "SVGs con im√°genes externas: $EXTERNAL_IMAGES"

if [ "$EXTERNAL_IMAGES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Considerar descargar y referenciar localmente para mejor performance"
fi

# M√©tricas de calidad visual
log_section "üëÅÔ∏è  M√©tricas de Calidad Visual"

VISUAL_QUALITY_SCORE=100
QUALITY_ISSUES=0

# Verificar resoluci√≥n adecuada (a trav√©s de viewBox)
LOW_RES_COUNT=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    VIEWBOX=$(grep -oE 'viewBox="[^"]+"' "$svg_file" 2>/dev/null | head -1)
    if [ -n "$VIEWBOX" ]; then
      # Extraer valores del viewBox
      VALUES=$(echo "$VIEWBOX" | grep -oE '[0-9]+(\.[0-9]+)?' | head -4)
      W=$(echo "$VALUES" | sed -n '3p')
      H=$(echo "$VALUES" | sed -n '4p')
      if [ -n "$W" ] && [ -n "$H" ]; then
        # Verificar si es menor que un umbral m√≠nimo
        if [ "$(echo "$W < 100 || $H < 100" | bc 2>/dev/null || echo "0")" = "1" ]; then
          LOW_RES_COUNT=$((LOW_RES_COUNT + 1))
        fi
      fi
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

if [ "$LOW_RES_COUNT" -gt 0 ]; then
  VISUAL_QUALITY_SCORE=$((VISUAL_QUALITY_SCORE - LOW_RES_COUNT * 2))
  QUALITY_ISSUES=$((QUALITY_ISSUES + LOW_RES_COUNT))
  log_info "‚ö†Ô∏è  SVGs con resoluci√≥n baja: $LOW_RES_COUNT"
fi

# Verificar uso de transparencias excesivas
EXCESSIVE_TRANSPARENCY=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    OPACITY_COUNT=$(grep -cE 'opacity="[0-9]\.[0-9]+"' "$svg_file" 2>/dev/null || echo "0")
    if [ "$OPACITY_COUNT" -gt 10 ]; then
      EXCESSIVE_TRANSPARENCY=$((EXCESSIVE_TRANSPARENCY + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

if [ "$EXCESSIVE_TRANSPARENCY" -gt 0 ]; then
  VISUAL_QUALITY_SCORE=$((VISUAL_QUALITY_SCORE - EXCESSIVE_TRANSPARENCY))
  QUALITY_ISSUES=$((QUALITY_ISSUES + EXCESSIVE_TRANSPARENCY))
  log_info "‚ö†Ô∏è  SVGs con muchas transparencias: $EXCESSIVE_TRANSPARENCY"
fi

if [ "$VISUAL_QUALITY_SCORE" -lt 0 ]; then
  VISUAL_QUALITY_SCORE=0
fi

VISUAL_QUALITY_LEVEL=""
if [ "$VISUAL_QUALITY_SCORE" -ge 90 ]; then
  VISUAL_QUALITY_LEVEL="‚úÖ Excelente"
elif [ "$VISUAL_QUALITY_SCORE" -ge 75 ]; then
  VISUAL_QUALITY_LEVEL="‚úÖ Bueno"
else
  VISUAL_QUALITY_LEVEL="‚ö†Ô∏è  Requiere atenci√≥n"
fi

log_info "Score de calidad visual: $VISUAL_QUALITY_SCORE/100 - $VISUAL_QUALITY_LEVEL"
[ "$QUALITY_ISSUES" -gt 0 ] && log_info "Problemas detectados: $QUALITY_ISSUES"

# Detecci√≥n de assets potencialmente no utilizados
log_section "üóëÔ∏è  Assets Potencialmente No Utilizados"

UNUSED_CANDIDATES=0
OLD_THRESHOLD_DAYS=180

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ]; then
    MOD_TIME=$(stat -f "%m" "$svg_file" 2>/dev/null || stat -c "%Y" "$svg_file" 2>/dev/null || echo "0")
    CURRENT_TIME=$(date +%s)
    AGE_DAYS=$(( (CURRENT_TIME - MOD_TIME) / 86400 ))
    
    # Verificar si est√° en CSV (activo)
    basename_file=$(basename "$svg_file")
    if [ -f "$CSV_MASTER" ]; then
      IN_CSV=$(grep -c "$basename_file" "$CSV_MASTER" 2>/dev/null || echo "0")
      if [ "$IN_CSV" -eq 0 ] && [ "$AGE_DAYS" -gt "$OLD_THRESHOLD_DAYS" ]; then
        UNUSED_CANDIDATES=$((UNUSED_CANDIDATES + 1))
        if [ "$UNUSED_CANDIDATES" -le 5 ]; then
          log_info "  ‚ö†Ô∏è  $(basename "$svg_file") (${AGE_DAYS} d√≠as sin modificar, no en CSV)"
        fi
      fi
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$UNUSED_CANDIDATES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Assets candidatos a revisar/eliminar: $UNUSED_CANDIDATES"
  log_info "üí° Revisar si estos assets a√∫n son necesarios"
else
  log_info "‚úÖ No se detectaron assets obviamente no utilizados"
fi

# An√°lisis de coherencia de branding
log_section "üéØ Coherencia de Branding"

BRAND_CONSISTENCY=100
CONSISTENCY_ISSUES=0

# Verificar uso consistente de logos
LOGO_PLACEHOLDERS=$(grep -rl 'LOGO_PLACEHOLDER\|logo-placeholder\|\[LOGO\]' "$ROOT_DIR/ads" --include="*.svg" 2>/dev/null | wc -l | xargs)
if [ "$LOGO_PLACEHOLDERS" -gt 0 ]; then
  BRAND_CONSISTENCY=$((BRAND_CONSISTENCY - LOGO_PLACEHOLDERS))
  CONSISTENCY_ISSUES=$((CONSISTENCY_ISSUES + LOGO_PLACEHOLDERS))
  log_info "‚ö†Ô∏è  SVGs con placeholders de logo: $LOGO_PLACEHOLDERS"
fi

# Verificar uso de colores de marca en CTAs
CTA_WITH_BRAND_COLOR=0
CTA_WITHOUT_BRAND_COLOR=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Buscar elementos que parecen CTAs (botones, enlaces destacados)
    if grep -qiE 'cta|button|btn|link|enlace' "$svg_file" 2>/dev/null; then
      if grep -qE '#[0-9a-fA-F]{3,6}' "$svg_file" 2>/dev/null; then
        CTA_WITH_BRAND_COLOR=$((CTA_WITH_BRAND_COLOR + 1))
      else
        CTA_WITHOUT_BRAND_COLOR=$((CTA_WITHOUT_BRAND_COLOR + 1))
      fi
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -30)

TOTAL_CTAS=$((CTA_WITH_BRAND_COLOR + CTA_WITHOUT_BRAND_COLOR))
if [ "$TOTAL_CTAS" -gt 0 ]; then
  BRAND_PERCENT=$(awk "BEGIN {printf \"%.0f\", ($CTA_WITH_BRAND_COLOR / $TOTAL_CTAS) * 100}")
  if [ "$BRAND_PERCENT" -lt 80 ]; then
    BRAND_CONSISTENCY=$((BRAND_CONSISTENCY - 10))
    CONSISTENCY_ISSUES=$((CONSISTENCY_ISSUES + 1))
    log_info "‚ö†Ô∏è  Solo $BRAND_PERCENT% de CTAs usan colores de marca"
  else
    log_info "‚úÖ $BRAND_PERCENT% de CTAs usan colores de marca"
  fi
fi

if [ "$BRAND_CONSISTENCY" -lt 0 ]; then
  BRAND_CONSISTENCY=0
fi

CONSISTENCY_LEVEL=""
if [ "$BRAND_CONSISTENCY" -ge 90 ]; then
  CONSISTENCY_LEVEL="‚úÖ Excelente"
elif [ "$BRAND_CONSISTENCY" -ge 75 ]; then
  CONSISTENCY_LEVEL="‚úÖ Buena"
else
  CONSISTENCY_LEVEL="‚ö†Ô∏è  Requiere mejora"
fi

log_info "Score de coherencia: $BRAND_CONSISTENCY/100 - $CONSISTENCY_LEVEL"
[ "$CONSISTENCY_ISSUES" -gt 0 ] && log_info "Problemas detectados: $CONSISTENCY_ISSUES"

# Sugerencias automatizadas inteligentes
log_section "ü§ñ Sugerencias Automatizadas"

SUGGESTIONS=()

[ "${EMPTY_SVGS:-0}" -gt 0 ] && SUGGESTIONS+=("Eliminar ${EMPTY_SVGS} SVG(s) vac√≠o(s)")
[ "${BROKEN_SVGS:-0}" -gt 0 ] && SUGGESTIONS+=("Reparar ${BROKEN_SVGS} SVG(s) con errores de estructura")
[ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && SUGGESTIONS+=("A√±adir accesibilidad a ${NO_ACCESSIBILITY} SVG(s)")
[ "${NO_METADATA:-0}" -gt 0 ] && SUGGESTIONS+=("Agregar metadata SEO a ${NO_METADATA} SVG(s)")
[ "${OUT_OF_PALETTE:-0}" -gt 0 ] && SUGGESTIONS+=("Corregir ${OUT_OF_PALETTE} color(es) fuera de paleta")
[ "${FORMAT_GAPS:-0}" -gt 0 ] && SUGGESTIONS+=("Completar ${FORMAT_GAPS} formato(s) faltante(s) por plataforma")
[ "${ANTI_PATTERNS_COUNT:-0}" -gt 0 ] && SUGGESTIONS+=("Corregir anti-patrones en ${ANTI_PATTERNS_COUNT} SVG(s)")
[ "$OPTIMIZATION_OPPORTUNITIES" -gt 0 ] && SUGGESTIONS+=("Optimizar $OPTIMIZATION_OPPORTUNITIES SVG(s) para mejorar performance")
[ "${UNUSED_CANDIDATES:-0}" -gt 0 ] && SUGGESTIONS+=("Revisar ${UNUSED_CANDIDATES} asset(s) potencialmente no utilizados")

if [ ${#SUGGESTIONS[@]} -gt 0 ]; then
  log_info "üí° Acciones recomendadas (priorizadas):"
  for i in "${!SUGGESTIONS[@]}"; do
    log_info "  $((i + 1)). ${SUGGESTIONS[$i]}"
  done
else
  log_info "‚úÖ No hay sugerencias cr√≠ticas - assets en buen estado"
fi

# An√°lisis de preparaci√≥n para A/B testing
log_section "üß™ Preparaci√≥n para A/B Testing"

AB_READY_COUNT=0
AB_VARIANTS=0
INSUFFICIENT_VARIANTS=0

# Buscar productos con m√∫ltiples variantes
for producto in "curso_ia" "saas_ia_marketing" "ia_bulk"; do
  VARIANTS=$(find "$ROOT_DIR/ads" -name "*${producto}*" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  if [ "$VARIANTS" -ge 3 ]; then
    AB_READY_COUNT=$((AB_READY_COUNT + 1))
    AB_VARIANTS=$((AB_VARIANTS + VARIANTS))
    log_info "‚úÖ $producto: $VARIANTS variantes (listo para A/B testing)"
  elif [ "$VARIANTS" -ge 2 ]; then
    log_info "‚ö†Ô∏è  $producto: $VARIANTS variantes (considera a√±adir m√°s para testing)"
    INSUFFICIENT_VARIANTS=$((INSUFFICIENT_VARIANTS + 1))
  elif [ "$VARIANTS" -eq 1 ]; then
    log_info "üí° $producto: 1 variante (crear m√°s para A/B testing)"
    INSUFFICIENT_VARIANTS=$((INSUFFICIENT_VARIANTS + 1))
  fi
done

AB_SCORE=0
[ "$AB_READY_COUNT" -ge 2 ] && AB_SCORE=$((AB_SCORE + 50))
[ "$AB_READY_COUNT" -ge 1 ] && AB_SCORE=$((AB_SCORE + 25))
[ "$INSUFFICIENT_VARIANTS" -eq 0 ] && AB_SCORE=$((AB_SCORE + 25))

log_info "Score de preparaci√≥n A/B: $AB_SCORE/100"
[ "$AB_SCORE" -ge 75 ] && log_info "‚úÖ Bien preparado para A/B testing" || log_info "üí° Mejorar variantes para mejor testing"

# An√°lisis de rutas de exportaci√≥n y naming
log_section "üì§ An√°lisis de Rutas de Exportaci√≥n"

EXPORT_ISSUES=0
MISSING_EXPORT_PATHS=0

# Verificar estructura de exports esperada
EXPECTED_EXPORT_DIRS=(
  "$ROOT_DIR/exports/png"
  "$ROOT_DIR/exports/webp"
  "$ROOT_DIR/exports/jpg"
)

for exp_dir in "${EXPECTED_EXPORT_DIRS[@]}"; do
  if [ ! -d "$exp_dir" ]; then
    MISSING_EXPORT_PATHS=$((MISSING_EXPORT_PATHS + 1))
    EXPORT_ISSUES=$((EXPORT_ISSUES + 1))
  fi
done

if [ "$MISSING_EXPORT_PATHS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Directorios de exportaci√≥n faltantes: $MISSING_EXPORT_PATHS"
  log_info "üí° Crear estructura: exports/{png,webp,jpg}"
else
  log_info "‚úÖ Estructura de exports completa"
fi

# Verificar naming consistente en exports
if [ -d "$ROOT_DIR/exports/png" ]; then
  PNG_EXPORT_COUNT=$(find "$ROOT_DIR/exports/png" -name "*.png" -type f 2>/dev/null | wc -l | xargs)
  SVG_COUNT=$(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
  
  if [ "$SVG_COUNT" -gt 0 ]; then
    COVERAGE_PERCENT=$(awk "BEGIN {printf \"%.1f\", ($PNG_EXPORT_COUNT / $SVG_COUNT) * 100}")
    log_info "PNGs exportados: $PNG_EXPORT_COUNT de $SVG_COUNT SVGs (${COVERAGE_PERCENT}%)"
    
    if [ "$(echo "$COVERAGE_PERCENT < 80" | bc 2>/dev/null || echo "1")" = "1" ]; then
      EXPORT_ISSUES=$((EXPORT_ISSUES + 1))
      log_info "‚ö†Ô∏è  Cobertura de exports baja - considerar exportar SVGs faltantes"
    fi
  fi
fi

[ "$EXPORT_ISSUES" -eq 0 ] && log_info "‚úÖ Rutas de exportaci√≥n OK"

# An√°lisis de rendimiento de carga
log_section "‚ö° An√°lisis de Rendimiento de Carga"

PERFORMANCE_SCORE=100
PERF_ISSUES=0

# Calcular tama√±o total de assets
TOTAL_SIZE=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ]; then
    FILE_SIZE=$(stat -f "%z" "$svg_file" 2>/dev/null || stat -c "%s" "$svg_file" 2>/dev/null || echo "0")
    TOTAL_SIZE=$((TOTAL_SIZE + FILE_SIZE))
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -100)

TOTAL_SIZE_MB=$(awk "BEGIN {printf \"%.2f\", $TOTAL_SIZE / 1048576}")

log_info "Tama√±o total (muestra de 100 SVGs): ${TOTAL_SIZE_MB}MB"

# Verificar si hay assets muy grandes que afecten carga
VERY_LARGE_ASSETS=$(find "$ROOT_DIR/ads" -name "*.svg" -size +200k -type f 2>/dev/null | wc -l | xargs)
if [ "$VERY_LARGE_ASSETS" -gt 0 ]; then
  PERFORMANCE_SCORE=$((PERFORMANCE_SCORE - VERY_LARGE_ASSETS * 5))
  PERF_ISSUES=$((PERF_ISSUES + VERY_LARGE_ASSETS))
  log_info "‚ö†Ô∏è  SVGs muy grandes (>200KB): $VERY_LARGE_ASSETS (afectan tiempo de carga)"
fi

# Verificar uso de im√°genes embebidas grandes
if [ "${LARGE_EMBEDDED:-0}" -gt 0 ]; then
  PERFORMANCE_SCORE=$((PERFORMANCE_SCORE - LARGE_EMBEDDED * 3))
  PERF_ISSUES=$((PERF_ISSUES + LARGE_EMBEDDED))
fi

if [ "$PERFORMANCE_SCORE" -lt 0 ]; then
  PERFORMANCE_SCORE=0
fi

PERF_LEVEL=""
if [ "$PERFORMANCE_SCORE" -ge 90 ]; then
  PERF_LEVEL="‚úÖ Excelente"
elif [ "$PERFORMANCE_SCORE" -ge 75 ]; then
  PERF_LEVEL="‚úÖ Bueno"
else
  PERF_LEVEL="‚ö†Ô∏è  Requiere optimizaci√≥n"
fi

log_info "Score de rendimiento: $PERFORMANCE_SCORE/100 - $PERF_LEVEL"
[ "$PERF_ISSUES" -gt 0 ] && log_info "Problemas detectados: $PERF_ISSUES"

# An√°lisis de uso de recursos externos
log_section "üåê An√°lisis de Recursos Externos"

EXTERNAL_RESOURCES=0
CDN_DEPENDENCIES=0
FONT_DEPENDENCIES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar fuentes externas (Google Fonts, etc)
    if grep -qiE 'fonts\.googleapis|fonts\.gstatic|typekit|adobe-fonts' "$svg_file" 2>/dev/null; then
      FONT_DEPENDENCIES=$((FONT_DEPENDENCIES + 1))
      EXTERNAL_RESOURCES=$((EXTERNAL_RESOURCES + 1))
    fi
    
    # Detectar CDNs
    if grep -qiE 'cdn\.|cloudfront|cloudflare|jsdelivr|unpkg' "$svg_file" 2>/dev/null; then
      CDN_DEPENDENCIES=$((CDN_DEPENDENCIES + 1))
      EXTERNAL_RESOURCES=$((EXTERNAL_RESOURCES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs con fuentes externas: $FONT_DEPENDENCIES"
log_info "SVGs con dependencias CDN: $CDN_DEPENDENCIES"

if [ "$EXTERNAL_RESOURCES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Total dependencias externas: $EXTERNAL_RESOURCES"
  log_info "üí° Considerar localizar recursos para mejor performance y disponibilidad"
else
  log_info "‚úÖ Sin dependencias externas detectadas"
fi

# An√°lisis de uso de animaciones y efectos
log_section "üé¨ An√°lisis de Animaciones y Efectos"

ANIMATIONS_COUNT=0
FILTERS_COUNT=0
TRANSITIONS_COUNT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar animaciones
    if grep -qiE '<animate|<set|<animateTransform|@keyframes|animation:' "$svg_file" 2>/dev/null; then
      ANIMATIONS_COUNT=$((ANIMATIONS_COUNT + 1))
    fi
    
    # Detectar filtros complejos
    FILTER_COUNT=$(grep -c '<filter' "$svg_file" 2>/dev/null || echo "0")
    if [ "$FILTER_COUNT" -gt 0 ]; then
      FILTERS_COUNT=$((FILTERS_COUNT + 1))
    fi
    
    # Detectar transiciones CSS
    if grep -qiE 'transition:|transform:' "$svg_file" 2>/dev/null; then
      TRANSITIONS_COUNT=$((TRANSITIONS_COUNT + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs con animaciones: $ANIMATIONS_COUNT"
log_info "SVGs con filtros: $FILTERS_COUNT"
log_info "SVGs con transiciones CSS: $TRANSITIONS_COUNT"

if [ "$ANIMATIONS_COUNT" -gt 0 ] || [ "$FILTERS_COUNT" -gt 10 ]; then
  log_info "üí° Considerar impacto en performance - animaciones/filtros pueden ser costosos"
fi

# An√°lisis de estructura de datos (metadata estructurada)
log_section "üìä An√°lisis de Metadata Estructurada"

STRUCTURED_METADATA=0
JSON_LD_COUNT=0
MICRODATA_COUNT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar JSON-LD
    if grep -qiE '<script[^>]*type="application/ld\+json"' "$svg_file" 2>/dev/null; then
      JSON_LD_COUNT=$((JSON_LD_COUNT + 1))
      STRUCTURED_METADATA=$((STRUCTURED_METADATA + 1))
    fi
    
    # Detectar microdata
    if grep -qiE 'itemscope|itemtype|itemprop' "$svg_file" 2>/dev/null; then
      MICRODATA_COUNT=$((MICRODATA_COUNT + 1))
      STRUCTURED_METADATA=$((STRUCTURED_METADATA + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs con JSON-LD: $JSON_LD_COUNT"
log_info "SVGs con microdata: $MICRODATA_COUNT"

if [ "$STRUCTURED_METADATA" -eq 0 ]; then
  log_info "üí° Considerar agregar metadata estructurada para mejor SEO"
else
  log_info "‚úÖ Metadata estructurada presente en algunos assets"
fi

# An√°lisis de accesibilidad avanzada
log_section "‚ôø An√°lisis de Accesibilidad Avanzada"

ADVANCED_ACCESSIBILITY=0
ARIA_ROLES=0
ARIA_LABELS=0
FOCUSABLE_ELEMENTS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar roles ARIA
    if grep -qiE 'role="[^"]+"' "$svg_file" 2>/dev/null; then
      ARIA_ROLES=$((ARIA_ROLES + 1))
      ADVANCED_ACCESSIBILITY=$((ADVANCED_ACCESSIBILITY + 1))
    fi
    
    # Detectar labels ARIA
    if grep -qiE 'aria-label=|aria-labelledby=' "$svg_file" 2>/dev/null; then
      ARIA_LABELS=$((ARIA_LABELS + 1))
      ADVANCED_ACCESSIBILITY=$((ADVANCED_ACCESSIBILITY + 1))
    fi
    
    # Detectar elementos focusables (tabindex, links, buttons)
    if grep -qiE 'tabindex|href=|button|onclick' "$svg_file" 2>/dev/null; then
      FOCUSABLE_ELEMENTS=$((FOCUSABLE_ELEMENTS + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs con roles ARIA: $ARIA_ROLES"
log_info "SVGs con labels ARIA: $ARIA_LABELS"
log_info "SVGs con elementos focusables: $FOCUSABLE_ELEMENTS"

if [ "$FOCUSABLE_ELEMENTS" -gt 0 ] && [ "$ARIA_LABELS" -lt "$FOCUSABLE_ELEMENTS" ]; then
  log_info "‚ö†Ô∏è  Algunos elementos focusables sin labels ARIA - mejorar accesibilidad"
fi

# An√°lisis de versionado y changelog
log_section "üìù An√°lisis de Versionado y Changelog"

VERSIONED_ASSETS=0
CHANGELOG_EXISTS=0

# Buscar archivos de changelog
CHANGELOG_FILES=(
  "$ROOT_DIR/CHANGELOG.md"
  "$ROOT_DIR/changelog.txt"
  "$ROOT_DIR/CHANGES.md"
)

for cl_file in "${CHANGELOG_FILES[@]}"; do
  if [ -f "$cl_file" ]; then
    CHANGELOG_EXISTS=1
    log_info "‚úÖ Changelog encontrado: $(basename "$cl_file")"
    break
  fi
done

if [ "$CHANGELOG_EXISTS" -eq 0 ]; then
  log_info "üí° Considerar crear CHANGELOG.md para tracking de cambios en assets"
fi

# Verificar si hay versiones expl√≠citas en nombres de archivo
VERSIONED_BY_NAME=$(find "$ROOT_DIR/ads" -name "*_v[0-9]*.svg" -o -name "*_v[0-9]*.[0-9]*.svg" 2>/dev/null | wc -l | xargs)
if [ "$VERSIONED_BY_NAME" -gt 0 ]; then
  VERSIONED_ASSETS=$((VERSIONED_ASSETS + VERSIONED_BY_NAME))
  log_info "Assets con versi√≥n en nombre: $VERSIONED_BY_NAME"
fi

if [ "$VERSIONED_ASSETS" -gt 0 ] || [ "$CHANGELOG_EXISTS" -eq 1 ]; then
  log_info "‚úÖ Pr√°cticas de versionado presentes"
else
  log_info "üí° Mejorar versionado: a√±adir versiones a nombres o crear changelog"
fi

# Resumen final
log_section "üìä Resumen Final Completo"

echo "" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"
echo "üìä RESUMEN FINAL COMPLETO" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"
echo "Assets: $TOTAL_SVGS | Health: $HEALTH_SCORE/100 ($HEALTH_STATUS)" >> "$REPORT"
echo "Mantenibilidad: ${MAINTAINABILITY_INDEX}/100 | Deuda: $TECHNICAL_DEBT ($DEBT_LEVEL)" >> "$REPORT"
echo "Marca: ${BRAND_SCORE:-100}/100 | Calidad Visual: ${VISUAL_QUALITY_SCORE:-100}/100" >> "$REPORT"
echo "Coherencia: ${BRAND_CONSISTENCY:-100}/100 | Rendimiento: ${PERFORMANCE_SCORE:-100}/100" >> "$REPORT"
echo "Optimizaci√≥n: score ${OPTIMIZATION_SCORE:-0} | A/B Testing: ${AB_SCORE:-0}/100" >> "$REPORT"
echo "Cobertura: ${COVERAGE_PERCENT:-0}% | Gaps: ${GAPS_COUNT:-0} | Formatos: ${FORMAT_GAPS:-0}" >> "$REPORT"
echo "Duplicados visuales: ${DUPE_GROUPS:-0} | Anti-patrones: ${ANTI_PATTERNS_COUNT:-0}" >> "$REPORT"
echo "Oportunidades optimizaci√≥n: ${OPTIMIZATION_OPPORTUNITIES:-0} | Assets no usados: ${UNUSED_CANDIDATES:-0}" >> "$REPORT"
echo "Recursos externos: ${EXTERNAL_RESOURCES:-0} | Animaciones: ${ANIMATIONS_COUNT:-0}" >> "$REPORT"
echo "Metadata estructurada: ${STRUCTURED_METADATA:-0} | Accesibilidad avanzada: ${ADVANCED_ACCESSIBILITY:-0}" >> "$REPORT"
echo "Compliance: ${COMPLIANCE_SCORE:-100}/100 | QA: ${QA_SCORE:-100}/100 | Documentaci√≥n: ${DOCUMENTATION_SCORE:-100}/100" >> "$REPORT"
echo "Patrones reutilizables: ${REUSABLE_COMPONENTS:-0} | C√≥digo muerto: ${UNUSED_CLASSES:-0}" >> "$REPORT"
echo "Assets de alto impacto: ${HIGH_IMPACT_ASSETS:-0} | Errores validaci√≥n: ${VALIDATION_FAILURES:-0}" >> "$REPORT"
echo "Renderizado: ${RENDER_PERFORMANCE:-100}/100 | SEO: ${SEO_SCORE:-100}/100 | Engagement: ${ENGAGEMENT_SCORE:-0}/100" >> "$REPORT"
echo "CTAs: ${CTA_COUNT_VALIDATION:-0} | Sin enlace: ${CTA_WITHOUT_LINK:-0} | Sin UTMs: ${CTA_WITHOUT_UTM:-0}" >> "$REPORT"
echo "Problemas copy: ${COPY_ISSUES:-0} | Enlaces rotos: ${BROKEN_LINK_PATTERNS:-0}" >> "$REPORT"
echo "Tiempo: ${ELAPSED}s" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"

# An√°lisis de documentaci√≥n y comentarios
log_section "üìö An√°lisis de Documentaci√≥n"

DOCUMENTATION_SCORE=100
DOC_ISSUES=0
COMMENTED_SVGS=0
DOCUMENTED_SVGS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar comentarios descriptivos
    COMMENT_COUNT=$(grep -cE '<!--.*-->' "$svg_file" 2>/dev/null || echo "0")
    if [ "$COMMENT_COUNT" -gt 0 ]; then
      COMMENTED_SVGS=$((COMMENTED_SVGS + 1))
    fi
    
    # Verificar si tiene metadata descriptiva (title, desc)
    HAS_DOC=$(grep -qE '<title>|<desc>|<metadata>' "$svg_file" 2>/dev/null && echo "1" || echo "0")
    if [ "$HAS_DOC" = "1" ]; then
      DOCUMENTED_SVGS=$((DOCUMENTED_SVGS + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

TOTAL_DOC_CHECKED=50
if [ "$TOTAL_DOC_CHECKED" -gt 0 ]; then
  DOC_PERCENT=$(awk "BEGIN {printf \"%.1f\", (($COMMENTED_SVGS + $DOCUMENTED_SVGS) / $TOTAL_DOC_CHECKED) * 100}")
  log_info "SVGs con documentaci√≥n: $DOCUMENTED_SVGS"
  log_info "SVGs con comentarios: $COMMENTED_SVGS"
  log_info "Cobertura de documentaci√≥n: ${DOC_PERCENT}%"
  
  if [ "$(echo "$DOC_PERCENT < 50" | bc 2>/dev/null || echo "1")" = "1" ]; then
    DOCUMENTATION_SCORE=$((DOCUMENTATION_SCORE - 20))
    DOC_ISSUES=$((DOC_ISSUES + 1))
    log_info "‚ö†Ô∏è  Baja cobertura de documentaci√≥n - mejorar comentarios y metadata"
  fi
fi

log_info "Score de documentaci√≥n: $DOCUMENTATION_SCORE/100"

# An√°lisis de compliance y est√°ndares
log_section "‚úÖ An√°lisis de Compliance"

COMPLIANCE_SCORE=100
COMPLIANCE_ISSUES=0

# Verificar est√°ndares SVG (W3C)
STANDARD_COMPLIANT=0
NON_STANDARD=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar estructura b√°sica SVG v√°lida
    if grep -q '<svg' "$svg_file" 2>/dev/null && grep -q '</svg>' "$svg_file" 2>/dev/null; then
      STANDARD_COMPLIANT=$((STANDARD_COMPLIANT + 1))
    else
      NON_STANDARD=$((NON_STANDARD + 1))
      COMPLIANCE_SCORE=$((COMPLIANCE_SCORE - 5))
      COMPLIANCE_ISSUES=$((COMPLIANCE_ISSUES + 1))
    fi
    
    # Verificar uso de namespace SVG
    if ! grep -q 'xmlns="http://www.w3.org/2000/svg"' "$svg_file" 2>/dev/null && ! grep -q 'xmlns:svg' "$svg_file" 2>/dev/null; then
      COMPLIANCE_SCORE=$((COMPLIANCE_SCORE - 2))
      COMPLIANCE_ISSUES=$((COMPLIANCE_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "SVGs est√°ndar compliant: $STANDARD_COMPLIANT"
[ "$NON_STANDARD" -gt 0 ] && log_info "‚ö†Ô∏è  SVGs no est√°ndar: $NON_STANDARD"

if [ "$COMPLIANCE_SCORE" -lt 0 ]; then
  COMPLIANCE_SCORE=0
fi

COMPLIANCE_LEVEL=""
if [ "$COMPLIANCE_SCORE" -ge 90 ]; then
  COMPLIANCE_LEVEL="‚úÖ Excelente"
elif [ "$COMPLIANCE_SCORE" -ge 75 ]; then
  COMPLIANCE_LEVEL="‚úÖ Bueno"
else
  COMPLIANCE_LEVEL="‚ö†Ô∏è  Requiere atenci√≥n"
fi

log_info "Score de compliance: $COMPLIANCE_SCORE/100 - $COMPLIANCE_LEVEL"
[ "$COMPLIANCE_ISSUES" -gt 0 ] && log_info "Problemas detectados: $COMPLIANCE_ISSUES"

# An√°lisis de patrones de dise√±o reutilizables
log_section "üé® An√°lisis de Patrones de Dise√±o"

DESIGN_PATTERNS=0
REUSABLE_COMPONENTS=0
SHARED_STYLES=0

# Detectar uso de <defs> para componentes reutilizables
DEFS_USAGE=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    if grep -q '<defs>' "$svg_file" 2>/dev/null; then
      DEFS_USAGE=$((DEFS_USAGE + 1))
      REUSABLE_COMPONENTS=$((REUSABLE_COMPONENTS + 1))
    fi
    
    # Detectar <symbol> para iconos reutilizables
    if grep -q '<symbol' "$svg_file" 2>/dev/null; then
      DESIGN_PATTERNS=$((DESIGN_PATTERNS + 1))
    fi
    
    # Detectar <use> para referencias a componentes
    USE_COUNT=$(grep -c '<use' "$svg_file" 2>/dev/null || echo "0")
    if [ "$USE_COUNT" -gt 0 ]; then
      SHARED_STYLES=$((SHARED_STYLES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs usando <defs>: $DEFS_USAGE"
log_info "SVGs con <symbol>: $DESIGN_PATTERNS"
log_info "SVGs con <use> (referencias): $SHARED_STYLES"

if [ "$REUSABLE_COMPONENTS" -gt 0 ]; then
  log_info "‚úÖ Patrones de dise√±o reutilizables detectados"
else
  log_info "üí° Considerar usar <defs> y <symbol> para componentes reutilizables"
fi

# An√°lisis de c√≥digo muerto o no utilizado
log_section "üóëÔ∏è  An√°lisis de C√≥digo Muerto"

DEAD_CODE=0
UNUSED_STYLES=0
UNUSED_CLASSES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar clases CSS definidas pero no usadas
    if grep -qE '\.([a-zA-Z0-9_-]+)\s*\{' "$svg_file" 2>/dev/null; then
      DEFINED_CLASSES=$(grep -oE '\.([a-zA-Z0-9_-]+)\s*\{' "$svg_file" 2>/dev/null | sed 's/\.\([a-zA-Z0-9_-]*\).*/\1/' || true)
      if [ -n "$DEFINED_CLASSES" ]; then
        while IFS= read -r class_name; do
          if ! grep -q "class=\"[^\"]*$class_name" "$svg_file" 2>/dev/null && ! grep -q "class=\"$class_name" "$svg_file" 2>/dev/null; then
            UNUSED_CLASSES=$((UNUSED_CLASSES + 1))
            DEAD_CODE=$((DEAD_CODE + 1))
          fi
        done <<< "$DEFINED_CLASSES"
      fi
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

if [ "$UNUSED_CLASSES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Clases CSS no utilizadas detectadas: $UNUSED_CLASSES"
  log_info "üí° Considerar limpiar c√≥digo muerto para reducir tama√±o"
else
  log_info "‚úÖ Sin c√≥digo muerto evidente detectado"
fi

# An√°lisis de impacto de cambios
log_section "üìä An√°lisis de Impacto de Cambios"

CHANGE_IMPACT=0
HIGH_IMPACT_ASSETS=0

# Identificar assets que son referenciados por otros
REFERENCED_ASSETS=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ]; then
    basename_file=$(basename "$svg_file")
    # Buscar referencias a este archivo en otros SVGs
    REF_COUNT=$(grep -r "$basename_file" "$ROOT_DIR/ads" --include="*.svg" 2>/dev/null | grep -v "^$(echo "$svg_file" | sed 's/[[\.*^$()+?{|]/\\&/g'):" | wc -l | xargs)
    if [ "$REF_COUNT" -gt 0 ]; then
      REFERENCED_ASSETS=$((REFERENCED_ASSETS + 1))
      HIGH_IMPACT_ASSETS=$((HIGH_IMPACT_ASSETS + 1))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -20)

log_info "Assets referenciados por otros: $REFERENCED_ASSETS"
if [ "$HIGH_IMPACT_ASSETS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  $HIGH_IMPACT_ASSETS asset(s) de alto impacto - cambios afectan m√∫ltiples archivos"
  log_info "üí° Revisar cuidadosamente antes de modificar"
else
  log_info "‚úÖ Sin dependencias cr√≠ticas detectadas"
fi

# An√°lisis de testing y QA
log_section "üß™ An√°lisis de Testing y QA"

QA_SCORE=100
QA_ISSUES=0

# Verificar si hay archivos de prueba o tests
TEST_FILES=$(find "$ROOT_DIR" -name "*test*.svg" -o -name "*spec*.svg" -o -name "*_test.*" -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
if [ "$TEST_FILES" -eq 0 ]; then
  QA_SCORE=$((QA_SCORE - 10))
  QA_ISSUES=$((QA_ISSUES + 1))
  log_info "üí° No se detectaron archivos de prueba - considerar crear tests"
else
  log_info "‚úÖ Archivos de prueba encontrados: $TEST_FILES"
fi

# Verificar validaci√≥n de SVG (b√°sica)
VALIDATION_FAILURES=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Validaci√≥n b√°sica: debe tener tag de apertura y cierre
    OPEN_TAGS=$(grep -c '<svg' "$svg_file" 2>/dev/null || echo "0")
    CLOSE_TAGS=$(grep -c '</svg>' "$svg_file" 2>/dev/null || echo "0")
    
    if [ "$OPEN_TAGS" -ne "$CLOSE_TAGS" ]; then
      VALIDATION_FAILURES=$((VALIDATION_FAILURES + 1))
      QA_SCORE=$((QA_SCORE - 5))
      QA_ISSUES=$((QA_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

if [ "$VALIDATION_FAILURES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  SVGs con errores de validaci√≥n: $VALIDATION_FAILURES"
else
  log_info "‚úÖ Validaci√≥n b√°sica OK"
fi

if [ "$QA_SCORE" -lt 0 ]; then
  QA_SCORE=0
fi

QA_LEVEL=""
if [ "$QA_SCORE" -ge 90 ]; then
  QA_LEVEL="‚úÖ Excelente"
elif [ "$QA_SCORE" -ge 75 ]; then
  QA_LEVEL="‚úÖ Bueno"
else
  QA_LEVEL="‚ö†Ô∏è  Requiere mejora"
fi

log_info "Score de QA: $QA_SCORE/100 - $QA_LEVEL"
[ "$QA_ISSUES" -gt 0 ] && log_info "Problemas detectados: $QA_ISSUES"

# Generaci√≥n de reporte visual mejorado
log_section "üìä Generaci√≥n de Reportes Adicionales"

# Generar reporte JSON estructurado
if command -v jq >/dev/null 2>&1; then
  JSON_REPORT_FILE="${REPORT%.txt}_structured.json"
  {
    echo "{"
    echo "  \"timestamp\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
    echo "  \"metrics\": {"
    echo "    \"total_assets\": $TOTAL_SVGS,"
    echo "    \"health_score\": $HEALTH_SCORE,"
    echo "    \"maintainability\": ${MAINTAINABILITY_INDEX:-0},"
    echo "    \"brand_score\": ${BRAND_SCORE:-100},"
    echo "    \"visual_quality\": ${VISUAL_QUALITY_SCORE:-100},"
    echo "    \"performance\": ${PERFORMANCE_SCORE:-100},"
    echo "    \"ab_testing_readiness\": ${AB_SCORE:-0},"
    echo "    \"compliance\": ${COMPLIANCE_SCORE:-100},"
    echo "    \"qa_score\": ${QA_SCORE:-100},"
    echo "    \"documentation\": ${DOCUMENTATION_SCORE:-100}"
    echo "  },"
    echo "  \"issues\": {"
    echo "    \"empty_svgs\": ${EMPTY_SVGS:-0},"
    echo "    \"broken_svgs\": ${BROKEN_SVGS:-0},"
    echo "    \"security_issues\": ${SECURITY_ISSUES:-0},"
    echo "    \"missing_accessibility\": ${NO_ACCESSIBILITY:-0},"
    echo "    \"out_of_palette\": ${OUT_OF_PALETTE:-0},"
    echo "    \"format_gaps\": ${FORMAT_GAPS:-0},"
    echo "    \"optimization_opportunities\": ${OPTIMIZATION_OPPORTUNITIES:-0}"
    echo "  },"
    echo "  \"coverage\": {"
    echo "    \"percentage\": ${COVERAGE_PERCENT:-0},"
    echo "    \"gaps\": ${GAPS_COUNT:-0},"
    echo "    \"missing_formats\": ${FORMAT_GAPS:-0}"
    echo "  }"
    echo "}"
  } > "$JSON_REPORT_FILE" 2>/dev/null || true
  
  if [ -f "$JSON_REPORT_FILE" ]; then
    log_info "‚úÖ Reporte JSON estructurado: $JSON_REPORT_FILE"
  fi
fi

# Generar reporte de mejoras priorizadas
IMPROVEMENTS_FILE="${REPORT%.txt}_improvements.txt"
{
  echo "MEJORAS PRIORIZADAS - $(date '+%Y-%m-%d %H:%M:%S')"
  echo "=========================================="
  echo ""
  echo "PRIORIDAD ALTA:"
  [ "${BROKEN_SVGS:-0}" -gt 0 ] && echo "‚Ä¢ Reparar ${BROKEN_SVGS} SVG(s) con errores cr√≠ticos"
  [ "${SECURITY_ISSUES:-0}" -gt 0 ] && echo "‚Ä¢ Resolver ${SECURITY_ISSUES} problema(s) de seguridad"
  [ "${VALIDATION_FAILURES:-0}" -gt 0 ] && echo "‚Ä¢ Corregir ${VALIDATION_FAILURES} error(es) de validaci√≥n"
  echo ""
  echo "PRIORIDAD MEDIA:"
  [ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && echo "‚Ä¢ A√±adir accesibilidad a ${NO_ACCESSIBILITY} SVG(s)"
  [ "${OUT_OF_PALETTE:-0}" -gt 0 ] && echo "‚Ä¢ Corregir ${OUT_OF_PALETTE} color(es) fuera de paleta"
  [ "${FORMAT_GAPS:-0}" -gt 0 ] && echo "‚Ä¢ Completar ${FORMAT_GAPS} formato(s) faltante(s)"
  echo ""
  echo "PRIORIDAD BAJA:"
  [ "$OPTIMIZATION_OPPORTUNITIES" -gt 0 ] && echo "‚Ä¢ Optimizar $OPTIMIZATION_OPPORTUNITIES SVG(s)"
  [ "${UNUSED_CLASSES:-0}" -gt 0 ] && echo "‚Ä¢ Limpiar ${UNUSED_CLASSES} clase(s) no utilizada(s)"
  [ "$DOCUMENTATION_SCORE" -lt 90 ] && echo "‚Ä¢ Mejorar documentaci√≥n en SVGs"
} > "$IMPROVEMENTS_FILE" 2>/dev/null || true

[ -f "$IMPROVEMENTS_FILE" ] && log_info "‚úÖ Reporte de mejoras: $IMPROVEMENTS_FILE"

# An√°lisis de performance de renderizado
log_section "‚ö° An√°lisis de Performance de Renderizado"

RENDER_PERFORMANCE=100
RENDER_ISSUES=0

# Detectar SVGs con muchos elementos que pueden afectar renderizado
HEAVY_RENDER_SVGS=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Contar elementos totales
    TOTAL_ELEMENTS=$(grep -cE '<(path|rect|circle|ellipse|line|polygon|polyline|g|text|image|use)' "$svg_file" 2>/dev/null || echo "0")
    # Contar grupos anidados profundos
    NESTED_GROUPS=$(grep -oE '<g[^>]*>' "$svg_file" 2>/dev/null | wc -l | xargs)
    
    # Si tiene muchos elementos o grupos anidados, puede ser pesado
    if [ "$TOTAL_ELEMENTS" -gt 300 ] || [ "$NESTED_GROUPS" -gt 50 ]; then
      HEAVY_RENDER_SVGS=$((HEAVY_RENDER_SVGS + 1))
      RENDER_PERFORMANCE=$((RENDER_PERFORMANCE - 2))
      RENDER_ISSUES=$((RENDER_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

if [ "$HEAVY_RENDER_SVGS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  SVGs pesados para renderizar: $HEAVY_RENDER_SVGS"
  log_info "üí° Considerar simplificar o dividir en componentes m√°s peque√±os"
else
  log_info "‚úÖ SVGs con complejidad razonable para renderizado"
fi

if [ "$RENDER_PERFORMANCE" -lt 0 ]; then
  RENDER_PERFORMANCE=0
fi

log_info "Score de renderizado: $RENDER_PERFORMANCE/100"

# Validaci√≥n de CTAs y enlaces
log_section "üîó Validaci√≥n de CTAs y Enlaces"

CTA_COUNT_VALIDATION=0
CTA_WITHOUT_LINK=0
CTA_WITHOUT_UTM=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar CTAs (texto que sugiere acci√≥n)
    CTA_TEXT=$(grep -oiE '(inscr|registr|compr|agreg|descarg|empez|comenz|visita|conoce|demo|trial|gratis|free)' "$svg_file" 2>/dev/null || true)
    if [ -n "$CTA_TEXT" ]; then
      CTA_COUNT_VALIDATION=$((CTA_COUNT_VALIDATION + 1))
      
      # Verificar si tiene enlace asociado
      if ! grep -qiE 'href=|link|url' "$svg_file" 2>/dev/null; then
        CTA_WITHOUT_LINK=$((CTA_WITHOUT_LINK + 1))
      fi
      
      # Verificar si el enlace tiene UTMs
      if grep -qiE 'href=.*http' "$svg_file" 2>/dev/null && ! grep -qiE 'utm_source|utm_campaign' "$svg_file" 2>/dev/null; then
        CTA_WITHOUT_UTM=$((CTA_WITHOUT_UTM + 1))
      fi
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

log_info "CTAs detectados: $CTA_COUNT_VALIDATION"
if [ "$CTA_WITHOUT_LINK" -gt 0 ]; then
  log_info "‚ö†Ô∏è  CTAs sin enlace: $CTA_WITHOUT_LINK"
  log_info "üí° A√±adir enlaces a los CTAs para mejorar conversi√≥n"
fi

if [ "$CTA_WITHOUT_UTM" -gt 0 ]; then
  log_info "‚ö†Ô∏è  CTAs sin UTMs: $CTA_WITHOUT_UTM"
  log_info "üí° A√±adir UTMs a enlaces para mejor tracking"
fi

if [ "$CTA_COUNT_VALIDATION" -gt 0 ] && [ "$CTA_WITHOUT_LINK" -eq 0 ] && [ "$CTA_WITHOUT_UTM" -eq 0 ]; then
  log_info "‚úÖ Todos los CTAs tienen enlaces y UTMs"
fi

# An√°lisis de mensajes y copy
log_section "‚úçÔ∏è  An√°lisis de Mensajes y Copy"

COPY_ISSUES=0
LONG_HEADLINES=0
SHORT_HEADLINES=0
MISSING_SUBHEADLINES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Extraer headlines (textos grandes, t√≠picamente headlines)
    HEADLINES=$(grep -oE '<text[^>]*class="[^"]*headline[^"]*"[^>]*>.*</text>' "$svg_file" 2>/dev/null | sed 's/<[^>]*>//g' || true)
    if [ -n "$HEADLINES" ]; then
      while IFS= read -r headline; do
        HEADLINE_LEN=${#headline}
        if [ "$HEADLINE_LEN" -gt 60 ]; then
          LONG_HEADLINES=$((LONG_HEADLINES + 1))
          COPY_ISSUES=$((COPY_ISSUES + 1))
        elif [ "$HEADLINE_LEN" -lt 10 ]; then
          SHORT_HEADLINES=$((SHORT_HEADLINES + 1))
        fi
      done <<< "$HEADLINES"
    else
      MISSING_SUBHEADLINES=$((MISSING_SUBHEADLINES + 1))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -30)

log_info "Headlines muy largos (>60 chars): $LONG_HEADLINES"
log_info "Headlines muy cortos (<10 chars): $SHORT_HEADLINES"
log_info "Assets sin headline: $MISSING_SUBHEADLINES"

if [ "$COPY_ISSUES" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Problemas de copy detectados: $COPY_ISSUES"
  log_info "üí° Optimizar longitud de headlines para mejor legibilidad"
else
  log_info "‚úÖ Copy bien estructurado"
fi

# An√°lisis de SEO en assets
log_section "üîç An√°lisis de SEO"

SEO_SCORE=100
SEO_ISSUES=0

# Verificar keywords y descripciones
ASSETS_WITH_KEYWORDS=0
ASSETS_WITH_DESC=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar metadata para SEO
    if grep -qiE 'keywords|description|meta' "$svg_file" 2>/dev/null; then
      ASSETS_WITH_KEYWORDS=$((ASSETS_WITH_KEYWORDS + 1))
    fi
    
    if grep -q '<desc>' "$svg_file" 2>/dev/null; then
      ASSETS_WITH_DESC=$((ASSETS_WITH_DESC + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

TOTAL_SEO_CHECKED=50
if [ "$TOTAL_SEO_CHECKED" -gt 0 ]; then
  SEO_COVERAGE=$(awk "BEGIN {printf \"%.1f\", (($ASSETS_WITH_KEYWORDS + $ASSETS_WITH_DESC) / $TOTAL_SEO_CHECKED) * 100}")
  
  if [ "$(echo "$SEO_COVERAGE < 50" | bc 2>/dev/null || echo "1")" = "1" ]; then
    SEO_SCORE=$((SEO_SCORE - 20))
    SEO_ISSUES=$((SEO_ISSUES + 1))
    log_info "‚ö†Ô∏è  Baja cobertura SEO: ${SEO_COVERAGE}%"
    log_info "üí° A√±adir descripciones y keywords para mejor SEO"
  else
    log_info "‚úÖ Cobertura SEO: ${SEO_COVERAGE}%"
  fi
fi

log_info "Score de SEO: $SEO_SCORE/100"

# An√°lisis de consistencia de branding avanzada
log_section "üé® Consistencia de Branding Avanzada"

BRAND_CONSISTENCY_ADVANCED=100
BRAND_ISSUES_ADVANCED=0

# Verificar uso consistente de logos
LOGO_INCONSISTENCIES=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar diferentes formas de referenciar logo
    LOGO_REF=$(grep -oE 'logo|Logo|LOGO|brand|Brand|BRAND' "$svg_file" 2>/dev/null | head -1 || true)
    if [ -n "$LOGO_REF" ]; then
      # Verificar si hay m√∫ltiples formas diferentes en el mismo archivo
      VARIANTS=$(grep -oE 'logo|Logo|LOGO|brand|Brand|BRAND' "$svg_file" 2>/dev/null | sort -u | wc -l | xargs)
      if [ "$VARIANTS" -gt 1 ]; then
        LOGO_INCONSISTENCIES=$((LOGO_INCONSISTENCIES + 1))
      fi
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -30)

if [ "$LOGO_INCONSISTENCIES" -gt 0 ]; then
  BRAND_CONSISTENCY_ADVANCED=$((BRAND_CONSISTENCY_ADVANCED - LOGO_INCONSISTENCIES))
  BRAND_ISSUES_ADVANCED=$((BRAND_ISSUES_ADVANCED + LOGO_INCONSISTENCIES))
  log_info "‚ö†Ô∏è  Inconsistencias en referencias de logo: $LOGO_INCONSISTENCIES"
fi

# Verificar uso consistente de colores en elementos similares
COLOR_INCONSISTENCIES=0
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Buscar CTAs y verificar si usan colores consistentes
    CTA_COLORS=$(grep -oE '#[0-9a-fA-F]{3,6}' "$svg_file" 2>/dev/null | grep -iE 'cta|button|btn' | sort -u | wc -l | xargs)
    if [ "$CTA_COLORS" -gt 3 ]; then
      COLOR_INCONSISTENCIES=$((COLOR_INCONSISTENCIES + 1))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -20)

if [ "$COLOR_INCONSISTENCIES" -gt 0 ]; then
  BRAND_CONSISTENCY_ADVANCED=$((BRAND_CONSISTENCY_ADVANCED - COLOR_INCONSISTENCIES))
  BRAND_ISSUES_ADVANCED=$((BRAND_ISSUES_ADVANCED + COLOR_INCONSISTENCIES))
  log_info "‚ö†Ô∏è  Inconsistencias de colores en elementos similares: $COLOR_INCONSISTENCIES"
fi

if [ "$BRAND_CONSISTENCY_ADVANCED" -lt 0 ]; then
  BRAND_CONSISTENCY_ADVANCED=0
fi

log_info "Score de consistencia avanzada: $BRAND_CONSISTENCY_ADVANCED/100"
[ "$BRAND_ISSUES_ADVANCED" -gt 0 ] && log_info "Problemas detectados: $BRAND_ISSUES_ADVANCED"

# An√°lisis de validaci√≥n de enlaces
log_section "üîó Validaci√≥n de Enlaces"

LINK_ISSUES=0
BROKEN_LINK_PATTERNS=0
RELATIVE_LINKS=0
ABSOLUTE_LINKS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar enlaces relativos
    REL_COUNT=$(grep -oE 'href="[^"]*"' "$svg_file" 2>/dev/null | grep -v 'http' | grep -v 'mailto' | wc -l | xargs)
    if [ "$REL_COUNT" -gt 0 ]; then
      RELATIVE_LINKS=$((RELATIVE_LINKS + REL_COUNT))
    fi
    
    # Detectar enlaces absolutos
    ABS_COUNT=$(grep -oE 'href="https?://[^"]*"' "$svg_file" 2>/dev/null | wc -l | xargs)
    if [ "$ABS_COUNT" -gt 0 ]; then
      ABSOLUTE_LINKS=$((ABSOLUTE_LINKS + ABS_COUNT))
    fi
    
    # Detectar patrones que podr√≠an indicar links rotos
    if grep -qiE 'href="#|href="javascript:|href="void' "$svg_file" 2>/dev/null; then
      BROKEN_LINK_PATTERNS=$((BROKEN_LINK_PATTERNS + 1))
      LINK_ISSUES=$((LINK_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "Enlaces relativos: $RELATIVE_LINKS"
log_info "Enlaces absolutos: $ABSOLUTE_LINKS"

if [ "$BROKEN_LINK_PATTERNS" -gt 0 ]; then
  log_info "‚ö†Ô∏è  Patrones de enlaces rotos detectados: $BROKEN_LINK_PATTERNS"
  log_info "üí° Revisar enlaces con href='#' o javascript:void"
else
  log_info "‚úÖ Sin patrones de enlaces rotos evidentes"
fi

# An√°lisis de m√©tricas de engagement potencial
log_section "üìà M√©tricas de Engagement Potencial"

ENGAGEMENT_SCORE=0

# Factores que pueden mejorar engagement
HAS_CTA=$CTA_COUNT_VALIDATION
HAS_SOCIAL_PROOF=0
HAS_URGENCY=0
HAS_BENEFITS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar social proof (testimonios, reviews, n√∫meros)
    if grep -qiE 'testimonial|review|cliente|usuario|‚òÖ|‚≠ê|‚òÖ‚òÖ‚òÖ‚òÖ' "$svg_file" 2>/dev/null || grep -qE '[0-9]{1,3}(k|K)\+.*usuario|cliente|persona' "$svg_file" 2>/dev/null; then
      HAS_SOCIAL_PROOF=$((HAS_SOCIAL_PROOF + 1))
    fi
    
    # Detectar urgencia (fechas, tiempo limitado)
    if grep -qiE 'limitado|√∫ltimo|solo|hasta|quedan|d√≠as|horas' "$svg_file" 2>/dev/null; then
      HAS_URGENCY=$((HAS_URGENCY + 1))
    fi
    
    # Detectar beneficios (checkmarks, listas)
    if grep -qiE '‚úì|check|beneficio|incluye|incluye|caracter√≠stica' "$svg_file" 2>/dev/null; then
      HAS_BENEFITS=$((HAS_BENEFITS + 1))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

# Calcular score de engagement
ENGAGEMENT_SCORE=$((HAS_CTA * 20 + HAS_SOCIAL_PROOF * 25 + HAS_URGENCY * 15 + HAS_BENEFITS * 20))
if [ "$ENGAGEMENT_SCORE" -gt 100 ]; then
  ENGAGEMENT_SCORE=100
fi

log_info "Assets con CTA: $HAS_CTA"
log_info "Assets con social proof: $HAS_SOCIAL_PROOF"
log_info "Assets con urgencia: $HAS_URGENCY"
log_info "Assets con beneficios: $HAS_BENEFITS"
log_info "Score de engagement potencial: $ENGAGEMENT_SCORE/100"

if [ "$ENGAGEMENT_SCORE" -ge 70 ]; then
  log_info "‚úÖ Buen potencial de engagement"
elif [ "$ENGAGEMENT_SCORE" -ge 40 ]; then
  log_info "‚ö†Ô∏è  Engagement potencial moderado - considerar a√±adir m√°s elementos persuasivos"
else
  log_info "üí° Mejorar engagement: a√±adir CTAs, social proof, urgencia o beneficios"
fi

# C√≥digos de salida
EXIT_STATUS=0
if [ "${FAIL_ON_ERROR:-false}" = "true" ]; then
  [ "${SECURITY_ISSUES:-0}" -gt 0 ] && EXIT_STATUS=2
  [ "${BROKEN_SVGS:-0}" -gt 0 ] && EXIT_STATUS=2
  [ "${INVALID_STRUCTURE:-0}" -gt 0 ] && EXIT_STATUS=2
fi

if [ "$EXIT_STATUS" -eq 0 ] && [ "${FAIL_ON_WARN:-false}" = "true" ]; then
  [ "${COMPLEX_SVGS:-0}" -gt 0 ] && EXIT_STATUS=1
  [ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && EXIT_STATUS=1
fi

[ "${PALETTE_STRICT:-false}" = "true" ] && [ "${OUT_OF_PALETTE:-0}" -gt 0 ] && EXIT_STATUS=2

# Estad√≠sticas finales del cach√©
if [ "$USE_CACHE" = "true" ] && [ -d "$CACHE_DIR" ]; then
  CACHE_SIZE=$(du -sh "$CACHE_DIR" 2>/dev/null | cut -f1 || echo "0")
  CACHE_FILES=$(find "$CACHE_DIR" -type f 2>/dev/null | wc -l | xargs)
  if [ "$CACHE_FILES" -gt 0 ] && [ "${LOG_LEVEL_NUM:-1}" -le 0 ]; then
    _log_debug "Cach√©: $CACHE_FILES archivos, tama√±o: $CACHE_SIZE"
  fi
fi

# Detectar archivos hu√©rfanos si est√° habilitado
if [ "${DETECT_ORPHANS:-false}" = "true" ]; then
  log_section "üîç Detecci√≥n de Archivos Hu√©rfanos"
  
  if detect_orphan_files; then
    ORPHAN_COUNT=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | wc -l | xargs)
    log_info "‚ö†Ô∏è  Se encontraron archivos hu√©rfanos (no referenciados)"
    log_info "üí° Revisa archivos que no est√°n en CSV ni referenciados en otros archivos"
  else
    log_info "‚úÖ No se encontraron archivos hu√©rfanos"
  fi
fi

# An√°lisis de tendencias si est√° habilitado
if [ "${ANALYZE_TRENDS:-false}" = "true" ]; then
  analyze_trends
fi

# Validar naming conventions si est√° habilitado
if [ "${VALIDATE_NAMING:-false}" = "true" ]; then
  log_section "üìù Validaci√≥n de Convenciones de Nombres"
  
  if validate_naming_conventions; then
    log_info "‚ö†Ô∏è  Se encontraron violaciones de convenciones de nombres"
    log_info "üí° Los nombres deben ser lowercase, sin espacios, sin caracteres especiales"
  else
    log_info "‚úÖ Todos los archivos cumplen con las convenciones de nombres"
  fi
fi

# Generar dashboard interactivo si est√° habilitado
if [ "${GENERATE_DASHBOARD:-false}" = "true" ]; then
  if dashboard_file=$(generate_interactive_dashboard); then
    log_info "‚úÖ Dashboard HTML generado: $dashboard_file"
    log_info "üí° Abre el dashboard en tu navegador para visualizaciones interactivas"
  fi
fi

# Exportar a Markdown si est√° habilitado
if [ "${EXPORT_MARKDOWN:-false}" = "true" ]; then
  if md_file=$(export_to_markdown); then
    log_info "‚úÖ Reporte Markdown generado: $md_file"
  fi
fi

# An√°lisis de dependencias si est√° habilitado
if [ "${ANALYZE_DEPS:-false}" = "true" ]; then
  log_section "üîó An√°lisis de Dependencias"
  
  if deps_file=$(analyze_dependencies); then
    log_info "‚úÖ An√°lisis de dependencias generado: $deps_file"
    log_info "üí° Revisa las relaciones entre archivos para entender el impacto de cambios"
  fi
fi

# Escaneo de seguridad avanzado si est√° habilitado
if [ "${SECURITY_SCAN:-false}" = "true" ]; then
  log_section "üîí Escaneo de Seguridad Avanzado"
  
  if detect_vulnerabilities; then
    log_info "‚ö†Ô∏è  Revisa exports/vulnerabilities.json para detalles"
  else
    log_info "‚úÖ No se detectaron vulnerabilidades de seguridad"
  fi
fi

# An√°lisis de performance avanzado si est√° habilitado
if [ "${PERFORMANCE_ADV:-false}" = "true" ]; then
  log_section "‚ö° An√°lisis Avanzado de Performance"
  
  if analyze_performance_advanced; then
    log_info "‚ö†Ô∏è  Se encontraron archivos con problemas de performance"
    log_info "üí° Considera optimizar archivos grandes o muy complejos"
  else
    log_info "‚úÖ Todos los archivos tienen buen rendimiento"
  fi
fi

# Generar sugerencias de optimizaci√≥n si est√° habilitado
if [ "${OPTIMIZATION_SUGGEST:-false}" = "true" ]; then
  if suggestions_file=$(generate_optimization_suggestions); then
    log_section "üí° Sugerencias de Optimizaci√≥n"
    log_info "‚úÖ Sugerencias generadas: $suggestions_file"
    log_info "üí° Revisa el archivo JSON para acciones recomendadas priorizadas"
  fi
fi

# Exportar a XML si est√° habilitado
if [ "${EXPORT_XML:-false}" = "true" ]; then
  if xml_file=$(export_to_xml); then
    log_info "‚úÖ Reporte XML generado: $xml_file"
    log_info "üí° Formato compatible con herramientas de CI/CD"
  fi
fi

# Exportar a YAML si est√° habilitado
if [ "${EXPORT_YAML:-false}" = "true" ]; then
  if yaml_file=$(export_to_yaml); then
    log_info "‚úÖ Reporte YAML generado: $yaml_file"
  fi
fi

# Validar compliance si est√° habilitado
if [ "${VALIDATE_COMPLIANCE:-false}" = "true" ]; then
  log_section "‚úÖ Validaci√≥n de Compliance"
  
  if compliance_file=$(validate_compliance); then
    log_info "‚úÖ Reporte de compliance generado: $compliance_file"
    log_info "üí° Revisa el cumplimiento con est√°ndares WCAG 2.1 AA"
  fi
fi

# Generar m√©tricas de negocio si est√° habilitado
if [ "${GENERATE_BUSINESS_METRICS:-false}" = "true" ]; then
  log_section "üìà M√©tricas de Negocio"
  
  if business_file=$(generate_business_metrics); then
    log_info "‚úÖ M√©tricas de negocio generadas: $business_file"
    log_info "üí° Incluye √≠ndices de calidad, seguridad y accesibilidad"
  fi
fi

# An√°lisis de cambios con Git si est√° habilitado
if [ "${GIT_ANALYSIS:-false}" = "true" ]; then
  log_section "üìù An√°lisis de Cambios (Git)"
  
  if changes_file=$(analyze_changes_impact); then
    log_info "‚úÖ An√°lisis de cambios generado: $changes_file"
    log_info "üí° Revisa el impacto de cambios en assets"
  else
    log_info "‚ÑπÔ∏è  Git no disponible o no es un repositorio Git"
  fi
fi

# Detectar patrones de dise√±o si est√° habilitado
if [ "${DETECT_PATTERNS:-false}" = "true" ]; then
  log_section "üé® Detecci√≥n de Patrones de Dise√±o"
  
  if patterns_file=$(detect_design_patterns); then
    log_info "‚úÖ Patrones de dise√±o detectados: $patterns_file"
    log_info "üí° Revisa qu√© patrones est√°n m√°s presentes en tus assets"
  fi
fi

# Generar changelog si est√° habilitado
if [ "${GENERATE_CHANGELOG:-false}" = "true" ]; then
  if changelog_file=$(generate_changelog); then
    log_info "‚úÖ Changelog generado: $changelog_file"
    log_info "üí° Historial autom√°tico de cambios y m√©tricas"
  fi
fi

# Exportar para BI si est√° habilitado
if [ "${BI_EXPORT:-false}" = "true" ]; then
  if bi_file=$(export_for_bi); then
    log_info "‚úÖ Exportaci√≥n para BI generada: $bi_file"
    log_info "üí° Compatible con PowerBI, Tableau y otras herramientas de BI"
  fi
fi

# Validar metadatos si est√° habilitado
if [ "${VALIDATE_METADATA:-false}" = "true" ]; then
  log_section "üìù Validaci√≥n de Metadatos"
  
  if metadata_file=$(validate_metadata_complete); then
    log_info "‚úÖ Validaci√≥n de metadatos generada: $metadata_file"
    log_info "üí° Revisa archivos sin metadatos completos"
  fi
fi

# Generar documentaci√≥n autom√°tica si est√° habilitado
if [ "${GENERATE_DOCS:-false}" = "true" ]; then
  if doc_file=$(generate_auto_documentation); then
    log_info "‚úÖ Documentaci√≥n generada: $doc_file"
    log_info "üí° Documentaci√≥n completa de assets y estructura"
  fi
fi

# Validar versionado sem√°ntico si est√° habilitado
if [ "${VALIDATE_VERSIONING:-false}" = "true" ]; then
  log_section "üî¢ Validaci√≥n de Versionado Sem√°ntico"
  
  if versioning_file=$(validate_semantic_versioning); then
    log_info "‚úÖ An√°lisis de versionado generado: $versioning_file"
    log_info "üí° Revisa la consistencia de versionado en nombres de archivos"
  fi
fi

# Ejecutar plugins si est√° habilitado
if [ "${RUN_PLUGINS:-false}" = "true" ]; then
  log_section "üîå Sistema de Plugins"
  
  if run_plugins; then
    log_info "‚úÖ Plugins ejecutados"
    log_info "üí° Revisa outputs de plugins en tools/plugins/"
  else
    log_info "‚ÑπÔ∏è  No se encontraron plugins ejecutables en tools/plugins/"
  fi
fi

# An√°lisis de uso de assets si est√° habilitado
if [ "${ANALYZE_USAGE:-false}" = "true" ]; then
  log_section "üìä An√°lisis de Uso de Assets"
  
  if usage_file=$(analyze_asset_usage); then
    log_info "‚úÖ An√°lisis de uso generado: $usage_file"
    log_info "üí° Identifica assets m√°s referenciados y potencialmente importantes"
  fi
fi

# Detectar assets obsoletos si est√° habilitado
if [ "${DETECT_OBSOLETE:-false}" = "true" ]; then
  log_section "‚è∞ Detecci√≥n de Assets Obsoletos"
  
  if obsolete_file=$(detect_obsolete_assets); then
    log_info "‚úÖ An√°lisis de assets obsoletos generado: $obsolete_file"
    log_info "üí° Considera archivar o eliminar assets sin modificar por m√°s de 1 a√±o"
  else
    log_info "‚úÖ No se encontraron assets obsoletos"
  fi
fi

# Validar branding si est√° habilitado
if [ "${VALIDATE_BRANDING:-false}" = "true" ]; then
  log_section "üé® Validaci√≥n de Branding"
  
  if branding_file=$(validate_branding); then
    log_info "‚úÖ Validaci√≥n de branding generada: $branding_file"
    log_info "üí° Verifica consistencia en uso de colores y elementos de marca"
  fi
fi

# Generar alertas autom√°ticas si est√° habilitado
if [ "${GENERATE_ALERTS:-false}" = "true" ]; then
  log_section "üö® Sistema de Alertas"
  
  if alerts_file=$(generate_alerts); then
    log_info "‚úÖ Alertas generadas: $alerts_file"
    log_info "üí° Revisa alertas cr√≠ticas y warnings para acci√≥n inmediata"
    
    # Mostrar alertas cr√≠ticas en consola
    if [ "$HEALTH_SCORE" -lt "${MIN_HEALTH_SCORE:-75}" ] || [ "${SECURITY_ISSUES:-0}" -gt 0 ]; then
      log_info "‚ö†Ô∏è  ALERTAS CR√çTICAS DETECTADAS - Revisa exports/alerts.json"
    fi
  fi
fi

# Detectar duplicados por contenido si est√° habilitado
if [ "${DETECT_DUPLICATES:-false}" = "true" ]; then
  log_section "üîç Detecci√≥n de Duplicados por Contenido"
  
  if duplicates_file=$(detect_content_duplicates); then
    log_info "‚úÖ An√°lisis de duplicados generado: $duplicates_file"
    log_info "üí° Considera consolidar archivos duplicados para reducir mantenimiento"
  else
    log_info "‚úÖ No se encontraron duplicados por contenido"
  fi
fi

# An√°lisis de complejidad visual si est√° habilitado
if [ "${ANALYZE_COMPLEXITY:-false}" = "true" ]; then
  log_section "üé® An√°lisis de Complejidad Visual"
  
  if complexity_file=$(analyze_visual_complexity); then
    log_info "‚úÖ An√°lisis de complejidad generado: $complexity_file"
    log_info "üí° Identifica assets muy complejos que pueden necesitar optimizaci√≥n"
  fi
fi

# Generar thumbnails si est√° habilitado
if [ "${GENERATE_THUMBNAILS:-false}" = "true" ]; then
  log_section "üñºÔ∏è  Generaci√≥n de Thumbnails"
  
  if thumbnails_dir=$(generate_thumbnails); then
    log_info "‚úÖ Thumbnails generados en: $thumbnails_dir"
    log_info "üí° √ötiles para previews y documentaci√≥n visual"
  else
    log_info "‚ÑπÔ∏è  Generaci√≥n de thumbnails requiere ImageMagick o librsvg"
  fi
fi

# An√°lisis de accesibilidad avanzado si est√° habilitado
if [ "${ACCESSIBILITY_ADV:-false}" = "true" ]; then
  log_section "‚ôø An√°lisis de Accesibilidad Avanzado"
  
  if a11y_file=$(analyze_accessibility_advanced); then
    log_info "‚úÖ An√°lisis de accesibilidad avanzado generado: $a11y_file"
    log_info "üí° Mejora la accesibilidad agregando title, desc, aria-labels"
  fi
fi

# An√°lisis de similitud entre assets si est√° habilitado
if [ "${ANALYZE_SIMILARITY:-false}" = "true" ]; then
  log_section "üîó An√°lisis de Similitud entre Assets"
  
  if similarity_file=$(analyze_asset_similarity); then
    log_info "‚úÖ An√°lisis de similitud generado: $similarity_file"
    log_info "üí° Identifica assets similares que podr√≠an consolidarse"
  else
    log_info "‚úÖ No se encontraron assets similares (threshold: ${SIMILARITY_THRESHOLD:-80}%)"
  fi
fi

# An√°lisis de dependencias externas si est√° habilitado
if [ "${ANALYZE_EXTERNAL_DEPS:-false}" = "true" ]; then
  log_section "üåê An√°lisis de Dependencias Externas"
  
  if deps_file=$(analyze_external_dependencies); then
    log_info "‚úÖ An√°lisis de dependencias externas generado: $deps_file"
    log_info "üí° Identifica dependencias externas que pueden afectar carga y privacidad"
  else
    log_info "‚úÖ No se encontraron dependencias externas"
  fi
fi

# An√°lisis de compatibilidad cross-browser si est√° habilitado
if [ "${BROWSER_COMPATIBILITY:-false}" = "true" ]; then
  log_section "üåç An√°lisis de Compatibilidad Cross-Browser"
  
  if compat_file=$(analyze_browser_compatibility); then
    log_info "‚úÖ An√°lisis de compatibilidad generado: $compat_file"
    log_info "üí° Identifica problemas de compatibilidad con navegadores antiguos"
  else
    log_info "‚úÖ Todos los assets son compatibles con navegadores modernos"
  fi
fi

# Scoring avanzado si est√° habilitado
if [ "${ADVANCED_SCORING:-false}" = "true" ]; then
  log_section "‚≠ê Scoring Avanzado"
  
  if scoring_file=$(generate_advanced_scoring); then
    log_info "‚úÖ Scoring avanzado generado: $scoring_file"
    log_info "üí° Clasificaci√≥n A-F basada en m√∫ltiples m√©tricas de calidad"
  fi
fi

# An√°lisis de cobertura de productos si est√° habilitado
if [ "${PRODUCT_COVERAGE:-false}" = "true" ]; then
  log_section "üì¶ An√°lisis de Cobertura de Productos"
  
  if coverage_file=$(analyze_product_coverage); then
    log_info "‚úÖ An√°lisis de cobertura generado: $coverage_file"
    log_info "üí° Identifica distribuci√≥n de assets por producto/campa√±a"
  fi
fi

# Validaci√≥n SEO si est√° habilitado
if [ "${VALIDATE_SEO:-false}" = "true" ]; then
  log_section "üîç Validaci√≥n SEO"
  
  if seo_file=$(validate_seo); then
    log_info "‚úÖ Validaci√≥n SEO generada: $seo_file"
    log_info "üí° Mejora la indexabilidad agregando t√≠tulos, descripciones y keywords"
  else
    log_info "‚úÖ Todos los assets tienen buena optimizaci√≥n SEO"
  fi
fi

# An√°lisis de animaciones si est√° habilitado
if [ "${ANALYZE_ANIMATIONS:-false}" = "true" ]; then
  log_section "üé¨ An√°lisis de Animaciones"
  
  if anim_file=$(analyze_animations); then
    log_info "‚úÖ An√°lisis de animaciones generado: $anim_file"
    log_info "üí° Identifica tipos de animaciones usadas (SMIL/CSS/JavaScript)"
  else
    log_info "‚úÖ No se encontraron animaciones en los assets"
  fi
fi

# Detecci√≥n de problemas de performance si est√° habilitado
if [ "${DETECT_PERF_ISSUES:-false}" = "true" ]; then
  log_section "‚ö° Detecci√≥n de Problemas de Performance"
  
  if perf_file=$(detect_performance_issues); then
    log_info "‚úÖ An√°lisis de performance generado: $perf_file"
    log_info "üí° Identifica assets con problemas de rendimiento espec√≠ficos"
  else
    log_info "‚úÖ No se detectaron problemas de performance cr√≠ticos"
  fi
fi

# An√°lisis de uso de colores si est√° habilitado
if [ "${ANALYZE_COLORS:-false}" = "true" ]; then
  log_section "üé® An√°lisis de Uso de Colores"
  
  if color_file=$(analyze_color_usage); then
    log_info "‚úÖ An√°lisis de colores generado: $color_file"
    log_info "üí° Identifica colores m√°s usados y consistencia de paleta"
  fi
fi

# Validaci√≥n de estructura SVG si est√° habilitado
if [ "${VALIDATE_STRUCTURE:-false}" = "true" ]; then
  log_section "üèóÔ∏è  Validaci√≥n de Estructura SVG"
  
  if structure_file=$(validate_svg_structure); then
    log_info "‚úÖ Validaci√≥n de estructura generada: $structure_file"
    log_info "üí° Detecta problemas estructurales que pueden causar errores de renderizado"
  else
    log_info "‚úÖ Todas las estructuras SVG son v√°lidas"
  fi
fi

# An√°lisis de uso de fuentes si est√° habilitado
if [ "${ANALYZE_FONTS:-false}" = "true" ]; then
  log_section "üî§ An√°lisis de Uso de Fuentes"
  
  if font_file=$(analyze_font_usage); then
    log_info "‚úÖ An√°lisis de fuentes generado: $font_file"
    log_info "üí° Identifica fuentes utilizadas y su distribuci√≥n"
  else
    log_info "‚úÖ No se encontraron fuentes personalizadas"
  fi
fi

# Detecci√≥n de problemas de responsive si est√° habilitado
if [ "${DETECT_RESPONSIVE:-false}" = "true" ]; then
  log_section "üì± Detecci√≥n de Problemas de Responsive"
  
  if responsive_file=$(detect_responsive_issues); then
    log_info "‚úÖ An√°lisis de responsive generado: $responsive_file"
    log_info "üí° Identifica problemas que afectan la adaptabilidad a diferentes tama√±os"
  else
    log_info "‚úÖ Todos los assets son responsive"
  fi
fi

# An√°lisis de efectos si est√° habilitado
if [ "${ANALYZE_EFFECTS:-false}" = "true" ]; then
  log_section "‚ú® An√°lisis de Efectos y Filtros"
  
  if effects_file=$(analyze_effects_usage); then
    log_info "‚úÖ An√°lisis de efectos generado: $effects_file"
    log_info "üí° Identifica tipos de efectos visuales utilizados (filtros, m√°scaras, transformaciones)"
  else
    log_info "‚úÖ No se encontraron efectos complejos"
  fi
fi

# Detecci√≥n de problemas de legibilidad si est√° habilitado
if [ "${DETECT_READABILITY:-false}" = "true" ]; then
  log_section "üìñ Detecci√≥n de Problemas de Legibilidad"
  
  if readability_file=$(detect_readability_issues); then
    log_info "‚úÖ An√°lisis de legibilidad generado: $readability_file"
    log_info "üí° Identifica problemas que afectan la lectura del texto (tama√±o, contraste, efectos)"
  else
    log_info "‚úÖ Todos los assets tienen buena legibilidad"
  fi
fi

# An√°lisis de metadatos Dublin Core si est√° habilitado
if [ "${ANALYZE_DUBLIN_CORE:-false}" = "true" ]; then
  log_section "üìö An√°lisis de Metadatos Dublin Core"
  
  if dc_file=$(analyze_dublin_core); then
    log_info "‚úÖ An√°lisis de Dublin Core generado: $dc_file"
    log_info "üí° Identifica presencia y uso de metadatos Dublin Core para indexaci√≥n"
  else
    log_info "‚úÖ No se encontraron metadatos Dublin Core"
  fi
fi

# Validaci√≥n avanzada de naming conventions si est√° habilitado
if [ "${VALIDATE_NAMING_ADV:-false}" = "true" ]; then
  log_section "üìù Validaci√≥n Avanzada de Naming Conventions"
  
  if naming_file=$(validate_naming_advanced); then
    log_info "‚úÖ Validaci√≥n avanzada de naming generada: $naming_file"
    log_info "üí° Verifica longitud, caracteres especiales, may√∫sculas y formato de nombres"
  else
    log_info "‚úÖ Todos los nombres cumplen con las convenciones"
  fi
fi

# An√°lisis de reutilizaci√≥n de elementos si est√° habilitado
if [ "${ANALYZE_REUSE:-false}" = "true" ]; then
  log_section "‚ôªÔ∏è  An√°lisis de Reutilizaci√≥n de Elementos"
  
  if reuse_file=$(analyze_element_reuse); then
    log_info "‚úÖ An√°lisis de reutilizaci√≥n generado: $reuse_file"
    log_info "üí° Identifica uso de defs, symbols, patterns y elementos reutilizables"
  fi
fi

# Validaci√≥n de links si est√° habilitado
if [ "${VALIDATE_LINKS:-false}" = "true" ]; then
  log_section "üîó Validaci√≥n de Links y Referencias"
  
  if links_file=$(validate_links); then
    log_info "‚úÖ Validaci√≥n de links generada: $links_file"
    log_info "üí° Detecta referencias rotas, links inv√°lidos y problemas de navegaci√≥n"
  else
    log_info "‚úÖ Todas las referencias y links son v√°lidos"
  fi
fi

# Detecci√≥n de c√≥digo muerto si est√° habilitado
if [ "${DETECT_DEAD_CODE:-false}" = "true" ]; then
  log_section "üßπ Detecci√≥n de C√≥digo Muerto"
  
  if deadcode_file=$(detect_dead_code); then
    log_info "‚úÖ An√°lisis de c√≥digo muerto generado: $deadcode_file"
    log_info "üí° Identifica IDs, clases y elementos definidos pero no utilizados"
  else
    log_info "‚úÖ No se encontr√≥ c√≥digo muerto"
  fi
fi

# An√°lisis de clases CSS si est√° habilitado
if [ "${ANALYZE_CSS_CLASSES:-false}" = "true" ]; then
  log_section "üé® An√°lisis de Clases CSS"
  
  if css_file=$(analyze_css_classes); then
    log_info "‚úÖ An√°lisis de clases CSS generado: $css_file"
    log_info "üí° Identifica clases m√°s utilizadas y patrones de estilo"
  else
    log_info "‚úÖ No se encontraron clases CSS"
  fi
fi

# An√°lisis de optimizaci√≥n potencial si est√° habilitado
if [ "${ANALYZE_OPTIMIZATION:-false}" = "true" ]; then
  log_section "‚ö° An√°lisis de Potencial de Optimizaci√≥n"
  
  if opt_file=$(analyze_optimization_potential); then
    log_info "‚úÖ An√°lisis de optimizaci√≥n generado: $opt_file"
    log_info "üí° Identifica oportunidades de reducci√≥n de tama√±o y mejoras"
  else
    log_info "‚úÖ No se encontraron oportunidades de optimizaci√≥n obvias"
  fi
fi

# Detecci√≥n de problemas de accesibilidad de color si est√° habilitado
if [ "${DETECT_COLOR_A11Y:-false}" = "true" ]; then
  log_section "üé® Detecci√≥n de Problemas de Accesibilidad de Color"
  
  if colora11y_file=$(detect_color_accessibility); then
    log_info "‚úÖ An√°lisis de accesibilidad de color generado: $colora11y_file"
    log_info "üí° Detecta problemas de contraste y accesibilidad relacionados con colores"
  else
    log_info "‚úÖ No se detectaron problemas de accesibilidad de color"
  fi
fi

# An√°lisis de atributos data-* si est√° habilitado
if [ "${ANALYZE_DATA_ATTRS:-false}" = "true" ]; then
  log_section "üìä An√°lisis de Atributos Data-*"
  
  if data_file=$(analyze_data_attributes); then
    log_info "‚úÖ An√°lisis de data attributes generado: $data_file"
    log_info "üí° Identifica uso de atributos data-* para metadata personalizada"
  else
    log_info "‚úÖ No se encontraron atributos data-*"
  fi
fi

# Validaci√≥n de est√°ndares SVG si est√° habilitado
if [ "${VALIDATE_STANDARDS:-false}" = "true" ]; then
  log_section "üìê Validaci√≥n de Est√°ndares SVG"
  
  if standards_file=$(validate_svg_standards); then
    log_info "‚úÖ Validaci√≥n de est√°ndares generada: $standards_file"
    log_info "üí° Detecta uso de elementos/atributos deprecated y problemas de compliance"
  else
    log_info "‚úÖ Todos los assets cumplen con los est√°ndares SVG"
  fi
fi

# Detecci√≥n de dependencias circulares si est√° habilitado
if [ "${DETECT_CIRCULAR:-false}" = "true" ]; then
  log_section "üîÑ Detecci√≥n de Dependencias Circulares"
  
  if circular_file=$(detect_circular_dependencies); then
    log_info "‚úÖ An√°lisis de dependencias circulares generado: $circular_file"
    log_info "üí° Identifica referencias circulares que pueden causar problemas de carga"
  else
    log_info "‚úÖ No se detectaron dependencias circulares"
  fi
fi

# Detecci√≥n de problemas de impresi√≥n si est√° habilitado
if [ "${DETECT_PRINT_ISSUES:-false}" = "true" ]; then
  log_section "üñ®Ô∏è  Detecci√≥n de Problemas de Impresi√≥n"
  
  if print_file=$(detect_print_issues); then
    log_info "‚úÖ An√°lisis de problemas de impresi√≥n generado: $print_file"
    log_info "üí° Identifica problemas que afectan la calidad de impresi√≥n (dimensiones, unidades)"
  else
    log_info "‚úÖ Todos los assets son adecuados para impresi√≥n"
  fi
fi

# An√°lisis de scripts embebidos si est√° habilitado
if [ "${ANALYZE_SCRIPTS:-false}" = "true" ]; then
  log_section "üìú An√°lisis de Scripts Embebidos"
  
  if scripts_file=$(analyze_embedded_scripts); then
    log_info "‚úÖ An√°lisis de scripts generado: $scripts_file"
    log_info "üí° Identifica scripts inline, externos y event handlers"
  else
    log_info "‚úÖ No se encontraron scripts embebidos"
  fi
fi

# Validaci√≥n de im√°genes embebidas si est√° habilitado
if [ "${VALIDATE_IMAGES:-false}" = "true" ]; then
  log_section "üñºÔ∏è  Validaci√≥n de Im√°genes Embebidas"
  
  if images_file=$(validate_embedded_images); then
    log_info "‚úÖ Validaci√≥n de im√°genes generada: $images_file"
    log_info "üí° Detecta problemas con im√°genes base64 y referencias rotas"
  else
    log_info "‚úÖ Todas las im√°genes embebidas son v√°lidas"
  fi
fi

# Enviar notificaciones
if [ -n "$SLACK_WEBHOOK" ] || [ -n "$TEAMS_WEBHOOK" ]; then
  SHOULD_NOTIFY=false
  NOTIFY_MESSAGE=""
  
  if [ "$NOTIFY_ON_ERROR" = "true" ]; then
    if [ "${SECURITY_ISSUES:-0}" -gt 0 ] || [ "${BROKEN_SVGS:-0}" -gt 0 ] || [ "${EXIT_STATUS:-0}" -ge 2 ]; then
      SHOULD_NOTIFY=true
      NOTIFY_MESSAGE="‚ùå *An√°lisis completado con errores cr√≠ticos*\n‚Ä¢ Health Score: $HEALTH_SCORE/100\n‚Ä¢ Errores de seguridad: ${SECURITY_ISSUES:-0}\n‚Ä¢ SVGs rotos: ${BROKEN_SVGS:-0}"
    fi
  elif [ "$NOTIFY_ON_WARN" = "true" ]; then
    if [ "$HEALTH_SCORE" -lt "${MIN_HEALTH_SCORE:-75}" ] || [ "${EXIT_STATUS:-0}" -ge 1 ]; then
      SHOULD_NOTIFY=true
      NOTIFY_MESSAGE="‚ö†Ô∏è *An√°lisis completado con advertencias*\n‚Ä¢ Health Score: $HEALTH_SCORE/100\n‚Ä¢ Total SVGs: $TOTAL_SVGS"
    fi
  else
    SHOULD_NOTIFY=true
    NOTIFY_MESSAGE="‚úÖ *An√°lisis completado*\n‚Ä¢ Health Score: $HEALTH_SCORE/100\n‚Ä¢ Total SVGs: $TOTAL_SVGS\n‚Ä¢ Estado: $HEALTH_STATUS"
  fi
  
  if [ "$SHOULD_NOTIFY" = "true" ]; then
    if [ -n "$SLACK_WEBHOOK" ]; then
      send_slack_notification "$NOTIFY_MESSAGE" && _log_debug "Notificaci√≥n enviada a Slack" || _log_warn "Error enviando notificaci√≥n a Slack"
    fi
    if [ -n "$TEAMS_WEBHOOK" ]; then
      send_teams_notification "$NOTIFY_MESSAGE" && _log_debug "Notificaci√≥n enviada a Teams" || _log_warn "Error enviando notificaci√≥n a Teams"
    fi
  fi
fi

# Resumen de funcionalidades utilizadas
if [ "${SHOW_PERFORMANCE:-true}" = "true" ] && [ "${LOG_LEVEL_NUM:-1}" -le 1 ]; then
  FEATURES=()
  [ "$USE_CACHE" = "true" ] && FEATURES+=("Cach√© inteligente")
  [ "$PARALLEL_ANALYSIS" = "true" ] && FEATURES+=("An√°lisis paralelo")
  [ "$DETECT_DUPLICATES" = "true" ] && FEATURES+=("Detecci√≥n de duplicados")
  [ "$COMPARE_HISTORY" = "true" ] && FEATURES+=("Comparaci√≥n hist√≥rica")
  [ "$GENERATE_RECOMMENDATIONS" = "true" ] && FEATURES+=("Recomendaciones")
  [ "${DETECT_ORPHANS:-false}" = "true" ] && FEATURES+=("Detecci√≥n de hu√©rfanos")
  [ "${ANALYZE_TRENDS:-false}" = "true" ] && FEATURES+=("An√°lisis de tendencias")
  [ "${VALIDATE_NAMING:-false}" = "true" ] && FEATURES+=("Validaci√≥n naming")
  [ "${GENERATE_DASHBOARD:-false}" = "true" ] && FEATURES+=("Dashboard HTML")
  [ "${EXPORT_MARKDOWN:-false}" = "true" ] && FEATURES+=("Export Markdown")
  [ "${ANALYZE_DEPS:-false}" = "true" ] && FEATURES+=("An√°lisis dependencias")
  [ "${SECURITY_SCAN:-false}" = "true" ] && FEATURES+=("Security scan")
  [ "${PERFORMANCE_ADV:-false}" = "true" ] && FEATURES+=("Performance avanzado")
  [ "${OPTIMIZATION_SUGGEST:-false}" = "true" ] && FEATURES+=("Sugerencias optimizaci√≥n")
  [ "${EXPORT_XML:-false}" = "true" ] && FEATURES+=("Export XML")
  [ "${EXPORT_YAML:-false}" = "true" ] && FEATURES+=("Export YAML")
  [ "${VALIDATE_COMPLIANCE:-false}" = "true" ] && FEATURES+=("Compliance WCAG")
  [ "${GENERATE_BUSINESS_METRICS:-false}" = "true" ] && FEATURES+=("Business metrics")
  [ "${GIT_ANALYSIS:-false}" = "true" ] && FEATURES+=("Git analysis")
  [ "${DETECT_PATTERNS:-false}" = "true" ] && FEATURES+=("Design patterns")
  [ "${GENERATE_CHANGELOG:-false}" = "true" ] && FEATURES+=("Auto changelog")
  [ "${BI_EXPORT:-false}" = "true" ] && FEATURES+=("BI export")
  [ -n "$BASELINE_FILE" ] && FEATURES+=("Baseline")
  [ -n "$PROFILE" ] && FEATURES+=("Perfil: $PROFILE")
  [ -n "$SLACK_WEBHOOK" ] && FEATURES+=("Slack")
  [ -n "$TEAMS_WEBHOOK" ] && FEATURES+=("Teams")
  
  if [ ${#FEATURES[@]} -gt 0 ]; then
    _log_info "Funcionalidades: ${FEATURES[*]}"
  fi
fi

# ========================================
# FUNCIONES AVANZADAS ADICIONALES
# ========================================

# An√°lisis SEO y Metadata
analyze_seo_metadata() {
  log_section "üîç An√°lisis SEO y Metadata"
  
  local no_meta_desc=0
  local no_meta_keywords=0
  local no_og_tags=0
  local no_favicon_refs=0
  
  # Buscar en archivos HTML/index si existen
  local html_files=$(find "$ROOT_DIR" -name "*.html" -type f -not -path "*/node_modules/*" 2>/dev/null | head -10)
  
  if [ -n "$html_files" ]; then
    while IFS= read -r html_file; do
      if [ -f "$html_file" ]; then
        ! grep -qi '<meta.*description' "$html_file" 2>/dev/null && no_meta_desc=$((no_meta_desc + 1))
        ! grep -qi '<meta.*keywords' "$html_file" 2>/dev/null && no_meta_keywords=$((no_meta_keywords + 1))
        ! grep -qi '<meta.*property="og:' "$html_file" 2>/dev/null && no_og_tags=$((no_og_tags + 1))
      fi
    done <<< "$html_files"
  fi
  
  # Verificar SVGs con metadata
  local svgs_with_title=0
  local svgs_with_desc=0
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ]; then
      grep -qi '<title>' "$svg_file" 2>/dev/null && svgs_with_title=$((svgs_with_title + 1))
      grep -qi '<desc>' "$svg_file" 2>/dev/null && svgs_with_desc=$((svgs_with_desc + 1))
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | head -30)
  
  log_info "üìä Metadata en SVGs:"
  log_info "  ‚Ä¢ Con <title>: $svgs_with_title/30"
  log_info "  ‚Ä¢ Con <desc>: $svgs_with_desc/30"
  
  if [ -n "$html_files" ]; then
    log_info "üìä Metadata HTML:"
    [ "$no_meta_desc" -gt 0 ] && log_info "  ‚ö†Ô∏è  Sin meta description: $no_meta_desc"
    [ "$no_og_tags" -gt 0 ] && log_info "  ‚ö†Ô∏è  Sin Open Graph tags: $no_og_tags"
  fi
}

# Generaci√≥n de reporte HTML interactivo
generate_interactive_html() {
  if [ "${OUTPUT_FORMAT:-text}" != "html" ] && [ "${OUTPUT_FORMAT:-text}" != "all" ]; then
    return 0
  fi
  
  log_section "üåê Generando Reporte HTML Interactivo"
  
  local html_file="${REPORT%.txt}_interactive.html"
  
  {
    cat <<HTML
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>An√°lisis de Assets - Reporte Interactivo</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f5f5f5; padding: 20px; }
    .container { max-width: 1200px; margin: 0 auto; background: white; border-radius: 8px; padding: 30px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    h1 { color: #333; margin-bottom: 30px; }
    .summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }
    .metric-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 8px; }
    .metric-card h3 { font-size: 14px; opacity: 0.9; margin-bottom: 10px; }
    .metric-card .value { font-size: 32px; font-weight: bold; }
    .section { margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 6px; }
    .section h2 { color: #667eea; margin-bottom: 15px; }
    .badge { display: inline-block; padding: 4px 12px; border-radius: 12px; font-size: 12px; font-weight: 600; margin: 5px; }
    .badge-success { background: #10b981; color: white; }
    .badge-warning { background: #f59e0b; color: white; }
    .badge-error { background: #ef4444; color: white; }
    table { width: 100%; border-collapse: collapse; margin-top: 15px; }
    th, td { padding: 12px; text-align: left; border-bottom: 1px solid #e5e5e5; }
    th { background: #667eea; color: white; }
    tr:hover { background: #f5f5f5; }
    .chart { height: 200px; margin: 20px 0; background: #f0f0f0; border-radius: 6px; display: flex; align-items: center; justify-content: center; color: #666; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üìä An√°lisis de Assets - Reporte Interactivo</h1>
    <p style="color: #666; margin-bottom: 30px;">Generado: $(date '+%Y-%m-%d %H:%M:%S')</p>
    
    <div class="summary">
      <div class="metric-card">
        <h3>Total SVGs</h3>
        <div class="value">${TOTAL_SVGS:-0}</div>
      </div>
      <div class="metric-card">
        <h3>Health Score</h3>
        <div class="value">${HEALTH_SCORE:-0}</div>
      </div>
      <div class="metric-card">
        <h3>Accessibility</h3>
        <div class="value">${ACCESSIBILITY_SCORE:-0}</div>
      </div>
      <div class="metric-card">
        <h3>Performance</h3>
        <div class="value">${PERFORMANCE_SCORE:-0}</div>
      </div>
    </div>
    
    <div class="section">
      <h2>üìà Resumen Ejecutivo</h2>
      <p><strong>Assets analizados:</strong> ${TOTAL_SVGS:-0}</p>
      <p><strong>Cobertura:</strong> ${COVERAGE_PERCENT:-0}%</p>
      <p><strong>Problemas detectados:</strong> ${EMPTY_SVGS:-0} vac√≠os, ${BROKEN_SVGS:-0} rotos</p>
      <p><strong>Issues de seguridad:</strong> ${SECURITY_ISSUES_COUNT:-0}</p>
    </div>
    
    <div class="section">
      <h2>üéØ M√©tricas Clave</h2>
      <table>
        <tr><th>M√©trica</th><th>Valor</th><th>Estado</th></tr>
        <tr><td>Health Score</td><td>${HEALTH_SCORE:-0}/100</td><td><span class="badge $([ "${HEALTH_SCORE:-0}" -ge 75 ] && echo 'badge-success' || echo 'badge-warning')">$([ "${HEALTH_SCORE:-0}" -ge 75 ] && echo '‚úÖ' || echo '‚ö†Ô∏è')</span></td></tr>
        <tr><td>Accessibility Score</td><td>${ACCESSIBILITY_SCORE:-0}/100</td><td><span class="badge $([ "${ACCESSIBILITY_SCORE:-0}" -ge 80 ] && echo 'badge-success' || [ "${ACCESSIBILITY_SCORE:-0}" -ge 60 ] && echo 'badge-warning' || echo 'badge-error')">$([ "${ACCESSIBILITY_SCORE:-0}" -ge 80 ] && echo '‚úÖ' || [ "${ACCESSIBILITY_SCORE:-0}" -ge 60 ] && echo '‚ö†Ô∏è' || echo '‚ùå')</span></td></tr>
        <tr><td>Performance Score</td><td>${PERFORMANCE_SCORE:-0}/100</td><td><span class="badge $([ "${PERFORMANCE_SCORE:-0}" -ge 80 ] && echo 'badge-success' || echo 'badge-warning')">$([ "${PERFORMANCE_SCORE:-0}" -ge 80 ] && echo '‚úÖ' || echo '‚ö†Ô∏è')</span></td></tr>
        <tr><td>Security Issues</td><td>${SECURITY_ISSUES_COUNT:-0}</td><td><span class="badge $([ "${SECURITY_ISSUES_COUNT:-0}" -eq 0 ] && echo 'badge-success' || echo 'badge-error')">$([ "${SECURITY_ISSUES_COUNT:-0}" -eq 0 ] && echo '‚úÖ' || echo '‚ùå')</span></td></tr>
      </table>
    </div>
    
    <div class="section">
      <h2>üí° Recomendaciones</h2>
      <ul style="line-height: 2;">
HTML
    
    [ "${LARGE_SVGS:-0}" -gt 0 ] && echo "        <li>üîß Optimizar ${LARGE_SVGS} SVG(s) grande(s) con <code>svgo -f $SRC_DIR -r</code></li>"
    [ "${NO_ACCESSIBILITY:-0}" -gt 5 ] && echo "        <li>‚ôø Mejorar accesibilidad en ${NO_ACCESSIBILITY} SVG(s) a√±adiendo &lt;title&gt; y &lt;desc&gt;</li>"
    [ "${GAPS_COUNT:-0}" -gt 0 ] && echo "        <li>üìê Completar $GAPS_COUNT gap(s) en cobertura de formatos</li>"
    [ "${SECURITY_ISSUES_COUNT:-0}" -gt 0 ] && echo "        <li>üîí Revisar ${SECURITY_ISSUES_COUNT} issue(s) de seguridad detectado(s)</li>"
    
    cat <<HTML
      </ul>
    </div>
    
    <div class="section">
      <h2>üìÑ Reporte Completo</h2>
      <p>Ver el reporte completo en formato texto: <a href="$(basename "$REPORT")">$(basename "$REPORT")</a></p>
    </div>
  </div>
  
  <script>
    // Simple interactivity
    document.querySelectorAll('.metric-card').forEach(card => {
      card.addEventListener('click', function() {
        this.style.transform = 'scale(0.98)';
        setTimeout(() => { this.style.transform = 'scale(1)'; }, 150);
      });
    });
  </script>
</body>
</html>
HTML
  } > "$html_file" 2>/dev/null || true
  
  log_info "‚úÖ Reporte HTML interactivo generado: $html_file"
}

# An√°lisis de consistencia de branding
analyze_branding_consistency() {
  log_section "üé® An√°lisis de Consistencia de Branding"
  
  local logo_usage=0
  local color_inconsistencies=0
  local font_inconsistencies=0
  
  # Buscar uso de logos
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
      if grep -qiE 'logo|brand|marca' "$svg_file" 2>/dev/null; then
        logo_usage=$((logo_usage + 1))
      fi
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | head -30)
  
  # Verificar colores contra paleta (si existe tokens.json)
  if [ -f "$SRC_DIR/tokens.json" ] && command -v jq >/dev/null 2>&1; then
    local palette_colors=$(jq -r '.colors // {}' "$SRC_DIR/tokens.json" 2>/dev/null | jq -r '.[] // empty' 2>/dev/null | wc -l | xargs)
    if [ "$palette_colors" -gt 0 ]; then
      log_info "‚úÖ Paleta de colores definida: $palette_colors colores"
    else
      log_info "‚ö†Ô∏è  Paleta de colores no encontrada en tokens.json"
    fi
  fi
  
  log_info "üìä Uso de branding:"
  log_info "  ‚Ä¢ SVGs con referencias a logo/brand: $logo_usage/30"
  
  if [ "$logo_usage" -lt 10 ]; then
    log_info "  ‚ö†Ô∏è  Bajo uso de elementos de branding"
  else
    log_info "  ‚úÖ Uso consistente de branding"
  fi
}

# Validaci√≥n de compliance WCAG (accesibilidad web)
validate_wcag_compliance() {
  log_section "‚ôø Validaci√≥n de Compliance WCAG 2.1"
  
  local wcag_issues=0
  local level="${1:-AA}"
  local total_checked=0
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
      total_checked=$((total_checked + 1))
      local issues=0
      
      local has_title=$(grep -q "<title>" "$svg_file" 2>/dev/null && echo "1" || echo "0")
      local has_desc=$(grep -q "<desc>" "$svg_file" 2>/dev/null && echo "1" || echo "0")
      local has_aria=$(grep -qE 'aria-label|aria-labelledby' "$svg_file" 2>/dev/null && echo "1" || echo "0")
      
      if [ "$has_title" = "0" ] && [ "$has_desc" = "0" ] && [ "$has_aria" = "0" ]; then
        issues=$((issues + 1))
      fi
      
      local light_colors=$(grep -oE '#[fF][eEfF]{5}|rgb\(25[0-5],\s*25[0-5],\s*25[0-5]\)' "$svg_file" 2>/dev/null | wc -l | xargs)
      if [ "$light_colors" -gt 5 ]; then
        issues=$((issues + 1))
      fi
      
      local links=$(grep -oE '<a[^>]*>' "$svg_file" 2>/dev/null | wc -l | xargs)
      local links_with_text=$(grep -oE '<a[^>]*>.*</a>' "$svg_file" 2>/dev/null | wc -l | xargs)
      if [ "$links" -gt 0 ] && [ "$links" -gt "$links_with_text" ]; then
        issues=$((issues + 1))
      fi
      
      [ "$issues" -gt 0 ] && wcag_issues=$((wcag_issues + 1))
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)
  
  if [ "$wcag_issues" -eq 0 ]; then
    log_info "‚úÖ Cumplimiento WCAG $level: Sin problemas en $total_checked SVGs"
  else
    local percent=$(awk "BEGIN {printf \"%.1f\", ($wcag_issues / $total_checked) * 100}")
    log_info "‚ö†Ô∏è  WCAG $level: $wcag_issues/$total_checked SVGs con problemas (${percent}%)"
  fi
  
  echo "$wcag_issues"
}

# Detecci√≥n de vulnerabilidades conocidas
detect_svg_vulnerabilities() {
  log_section "üîí Detecci√≥n de Vulnerabilidades SVG"
  
  local vulnerabilities=0
  local vuln_types=()
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
      if grep -qiE '<!ENTITY|SYSTEM "http|file://' "$svg_file" 2>/dev/null; then
        vulnerabilities=$((vulnerabilities + 1))
        vuln_types+=("XXE")
        log_info "‚ö†Ô∏è  Posible XXE en: ${svg_file#$ROOT_DIR/}"
      fi
      
      if grep -qiE '<script[^>]*>|javascript:|onerror=|onload=' "$svg_file" 2>/dev/null; then
        vulnerabilities=$((vulnerabilities + 1))
        vuln_types+=("XSS")
        log_info "‚ö†Ô∏è  Posible XSS en: ${svg_file#$ROOT_DIR/}"
      fi
      
      if grep -qiE 'href="http://[^"]*\.(exe|bat|sh|js)|xlink:href="http://[^"]*\.(exe|bat|sh|js)' "$svg_file" 2>/dev/null; then
        vulnerabilities=$((vulnerabilities + 1))
        vuln_types+=("External Resource")
      fi
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)
  
  if [ "$vulnerabilities" -eq 0 ]; then
    log_info "‚úÖ No se detectaron vulnerabilidades conocidas"
  else
    log_info "üö® Vulnerabilidades detectadas: $vulnerabilities"
    log_info "   Tipos: $(printf '%s, ' "${vuln_types[@]}" | sed 's/, $//')"
    log_info "üí° ACCI√ìN REQUERIDA: Revisar y sanitizar antes de producci√≥n"
  fi
  
  echo "$vulnerabilities"
}

# An√°lisis avanzado de performance
analyze_performance_advanced() {
  log_section "‚ö° An√°lisis Avanzado de Performance"
  
  local performance_score=100
  local issues=()
  local complex_paths=0
  local heavy_filters=0
  local large_doms=0
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
      local path_avg_length=$(grep -oE '<path[^>]*d="[^"]+"' "$svg_file" 2>/dev/null | awk -F'd="' '{print length($2)}' | awk '{sum+=$1; count++} END {if(count>0) print int(sum/count); else print 0}' || echo "0")
      local path_count=$(grep -c '<path' "$svg_file" 2>/dev/null || echo "0")
      
      if [ "$path_avg_length" -gt 500 ] && [ "$path_count" -gt 0 ]; then
        complex_paths=$((complex_paths + 1))
      fi
      
      local filter_count=$(grep -c '<filter' "$svg_file" 2>/dev/null || echo "0")
      local fe_count=$(grep -c '<fe[A-Z]' "$svg_file" 2>/dev/null || echo "0")
      if [ "$filter_count" -gt 3 ] || [ "$fe_count" -gt 10 ]; then
        heavy_filters=$((heavy_filters + 1))
      fi
      
      local dom_nodes=$(grep -oE '<[^/>]+>' "$svg_file" 2>/dev/null | wc -l | xargs)
      if [ "$dom_nodes" -gt 1000 ]; then
        large_doms=$((large_doms + 1))
      fi
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)
  
  [ "$complex_paths" -gt 5 ] && performance_score=$((performance_score - 10))
  [ "$heavy_filters" -gt 3 ] && performance_score=$((performance_score - 15))
  [ "$large_doms" -gt 2 ] && performance_score=$((performance_score - 20))
  [ "$performance_score" -lt 0 ] && performance_score=0
  
  if [ "$performance_score" -ge 80 ]; then
    log_info "‚úÖ Performance Score: $performance_score/100 (Excelente)"
  elif [ "$performance_score" -ge 60 ]; then
    log_info "‚ö†Ô∏è  Performance Score: $performance_score/100 (Aceptable)"
  else
    log_info "‚ùå Performance Score: $performance_score/100 (Requiere optimizaci√≥n)"
  fi
  
  echo "$performance_score"
}

# Detecci√≥n de assets hu√©rfanos
detect_orphan_assets() {
  log_section "üîç Detecci√≥n de Assets Hu√©rfanos"
  
  local orphans=0
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ]; then
      local basename_svg=$(basename "$svg_file")
      local name_without_ext="${basename_svg%.svg}"
      local found_in_csv=$(grep -rl "$name_without_ext\|$basename_svg" "$ROOT_DIR" --include="*.csv" 2>/dev/null | wc -l | xargs)
      local found_in_docs=$(grep -rl "$name_without_ext\|$basename_svg" "$ROOT_DIR" --include="*.md" 2>/dev/null | wc -l | xargs)
      local found_in_configs=$(grep -rl "$name_without_ext\|$basename_svg" "$ROOT_DIR" --include="*.json" 2>/dev/null | wc -l | xargs)
      
      if [ "$found_in_csv" -eq 0 ] && [ "$found_in_docs" -eq 0 ] && [ "$found_in_configs" -eq 0 ]; then
        orphans=$((orphans + 1))
      fi
    fi
  done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)
  
  if [ "$orphans" -eq 0 ]; then
    log_info "‚úÖ No se detectaron assets hu√©rfanos"
  else
    log_info "‚ö†Ô∏è  Assets hu√©rfanos detectados: $orphans"
    log_info "üí° Revisar si estos assets son necesarios"
  fi
  
  echo "$orphans"
}

# Generaci√≥n de reporte Markdown
generate_markdown_report() {
  local md_file="${1:-$ROOT_DIR/exports/assets_report.md}"
  mkdir -p "$(dirname "$md_file")"
  
  {
    echo "# üìä An√°lisis de Assets"
    echo ""
    echo "**Fecha:** $(date '+%Y-%m-%d %H:%M:%S')"
    echo ""
    echo "## üìà Resumen"
    echo ""
    echo "| M√©trica | Valor |"
    echo "|---------|-------|"
    echo "| Total SVGs | $TOTAL_SVGS |"
    echo "| Health Score | $HEALTH_SCORE/100 |"
    echo "| Cobertura | ${COVERAGE_PERCENT:-0}% |"
    echo ""
  } > "$md_file"
  
  log_info "üìÑ Reporte Markdown: $md_file"
}

# Auto-reparaci√≥n de problemas comunes
auto_fix_common_issues() {
  if [ "${AUTO_REPAIR:-false}" != "true" ]; then
    return 0
  fi
  
  log_section "üîß Auto-Reparaci√≥n"
  
  local fixed=0
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ] && ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      local width=$(grep -oE 'width="[^"]+"' "$svg_file" 2>/dev/null | head -1 | sed 's/width="\([^"]*\)"/\1/')
      local height=$(grep -oE 'height="[^"]+"' "$svg_file" 2>/dev/null | head -1 | sed 's/height="\([^"]*\)"/\1/')
      local width_num=$(echo "$width" | grep -oE '[0-9]+' | head -1)
      local height_num=$(echo "$height" | grep -oE '[0-9]+' | head -1)
      
      if [ -n "$width_num" ] && [ -n "$height_num" ]; then
        sed -i.bak "s|<svg|<svg viewBox=\"0 0 $width_num $height_num\"|" "$svg_file" 2>/dev/null && {
          rm -f "${svg_file}.bak" 2>/dev/null || true
          fixed=$((fixed + 1))
        }
      fi
    fi
  done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -5)
  
  [ "$fixed" -gt 0 ] && log_info "üîß Reparados: $fixed"
}

# An√°lisis de dependencias entre assets
analyze_asset_dependencies() {
  log_section "üîó An√°lisis de Dependencias entre Assets"
  
  local dependencies=0
  local dep_map=$(mktemp)
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
      local basename_file=$(basename "$svg_file" .svg)
      
      # Buscar referencias a otros assets en el contenido
      grep -oE '[a-zA-Z0-9_-]+\.svg|[a-zA-Z0-9_-]+\.png|[a-zA-Z0-9_-]+\.jpg' "$svg_file" 2>/dev/null | while read -r ref; do
        local ref_basename="${ref%.*}"
        if [ "$ref_basename" != "$basename_file" ]; then
          echo "${svg_file#$ROOT_DIR/}|$ref_basename" >> "$dep_map"
          dependencies=$((dependencies + 1))
        fi
      done
      
      # Buscar referencias por ID o href
      grep -oE 'href="#[^"]+"|xlink:href="#[^"]+"|id="[^"]+"' "$svg_file" 2>/dev/null | while read -r id_ref; do
        local id_value=$(echo "$id_ref" | grep -oE '"[^"]+"' | tr -d '"')
        if [ -n "$id_value" ]; then
          echo "${svg_file#$ROOT_DIR/}|$id_value" >> "$dep_map"
        fi
      done
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)
  
  if [ "$dependencies" -gt 0 ]; then
    log_info "üìä Dependencias detectadas: $dependencies"
    log_info "   (Relaciones entre assets encontradas)"
    
    # Mostrar top 5 dependencias
    if [ -s "$dep_map" ]; then
      log_info "   Top dependencias:"
      cut -d'|' -f2 "$dep_map" | sort | uniq -c | sort -nr | head -5 | while read -r count name; do
        log_info "     ‚Ä¢ $name: referenciado $count vez(es)"
      done
    fi
  else
    log_info "‚úÖ Assets independientes (sin dependencias cruzadas)"
  fi
  
  rm -f "$dep_map" 2>/dev/null || true
  echo "$dependencies"
}

# Generaci√≥n de badges para CI/CD
generate_ci_badges() {
  log_section "üéñÔ∏è  Generaci√≥n de Badges para CI/CD"
  
  local badges_dir="$ROOT_DIR/exports/badges"
  mkdir -p "$badges_dir"
  
  # Badge de Health Score
  local health_color="red"
  if [ "$HEALTH_SCORE" -ge 90 ]; then
    health_color="brightgreen"
  elif [ "$HEALTH_SCORE" -ge 75 ]; then
    health_color="green"
  elif [ "$HEALTH_SCORE" -ge 60 ]; then
    health_color="yellow"
  elif [ "$HEALTH_SCORE" -ge 50 ]; then
    health_color="orange"
  fi
  
  local health_badge="https://img.shields.io/badge/Health_Score-${HEALTH_SCORE}%2F100-${health_color}?style=flat-square"
  echo "$health_badge" > "$badges_dir/health_score.txt"
  
  # Badge de Coverage
  local coverage_color="red"
  if [ "${COVERAGE_PERCENT:-0}" -ge 90 ]; then
    coverage_color="brightgreen"
  elif [ "${COVERAGE_PERCENT:-0}" -ge 75 ]; then
    coverage_color="green"
  elif [ "${COVERAGE_PERCENT:-0}" -ge 50 ]; then
    coverage_color="yellow"
  else
    coverage_color="orange"
  fi
  
  local coverage_badge="https://img.shields.io/badge/Coverage-${COVERAGE_PERCENT:-0}%25-${coverage_color}?style=flat-square"
  echo "$coverage_badge" > "$badges_dir/coverage.txt"
  
  # Badge de Security
  local security_color="brightgreen"
  local security_text="Secure"
  if [ "${SECURITY_ISSUES:-0}" -gt 0 ]; then
    security_color="red"
    security_text="${SECURITY_ISSUES}_Issues"
  fi
  
  local security_badge="https://img.shields.io/badge/Security-${security_text}-${security_color}?style=flat-square"
  echo "$security_badge" > "$badges_dir/security.txt"
  
  # Badge de Total Assets
  local assets_badge="https://img.shields.io/badge/Assets-${TOTAL_SVGS}-blue?style=flat-square"
  echo "$assets_badge" > "$badges_dir/assets_count.txt"
  
  log_info "‚úÖ Badges generados en: $badges_dir"
  log_info "   Ejemplo para README.md:"
  log_info "   ![](https://img.shields.io/badge/Health_Score-${HEALTH_SCORE}%2F100-${health_color}?style=flat-square)"
}

# An√°lisis de similitud visual (b√°sico)
analyze_visual_similarity() {
  log_section "üëÅÔ∏è  An√°lisis de Similitud Visual"
  
  local similar_groups=0
  local similarity_threshold="${SIMILARITY_THRESHOLD:-80}" # Porcentaje
  
  # Extraer caracter√≠sticas visuales b√°sicas (estructura, colores principales)
  local features_file=$(mktemp)
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
      # Crear "fingerprint" visual b√°sico
      local path_count=$(grep -c '<path' "$svg_file" 2>/dev/null || echo "0")
      local rect_count=$(grep -c '<rect' "$svg_file" 2>/dev/null || echo "0")
      local circle_count=$(grep -c '<circle' "$svg_file" 2>/dev/null || echo "0")
      local main_colors=$(grep -oE '#[0-9a-fA-F]{6}' "$svg_file" 2>/dev/null | sort | uniq | head -3 | tr '\n' ',' | sed 's/,$//')
      
      local fingerprint="${path_count}_${rect_count}_${circle_count}_${main_colors}"
      echo "${svg_file#$ROOT_DIR/}|$fingerprint" >> "$features_file"
    fi
  done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -20)
  
  # Encontrar grupos similares
  if [ -s "$features_file" ]; then
    local similar_count=$(cut -d'|' -f2 "$features_file" | sort | uniq -d | wc -l | xargs)
    if [ "$similar_count" -gt 0 ]; then
      similar_groups=$similar_count
      log_info "‚ö†Ô∏è  Grupos de assets visualmente similares: $similar_groups"
      log_info "üí° Considera consolidar o diferenciar m√°s estos assets"
      
      # Mostrar algunos ejemplos
      cut -d'|' -f2 "$features_file" | sort | uniq -d | head -3 | while read -r fingerprint; do
        local matches=$(grep "|$fingerprint" "$features_file" | cut -d'|' -f1 | wc -l | xargs)
        log_info "   ‚Ä¢ $matches asset(s) con patr√≥n similar"
      done
    else
      log_info "‚úÖ Assets con suficiente diferenciaci√≥n visual"
    fi
  fi
  
  rm -f "$features_file" 2>/dev/null || true
  echo "$similar_groups"
}

# Generaci√≥n de gr√°fico ASCII de m√©tricas
generate_ascii_chart() {
  log_section "üìä Gr√°fico ASCII de M√©tricas"
  
  local max_value=100
  local health_bar_len=$((HEALTH_SCORE * 50 / max_value))
  local coverage_bar_len=$(((${COVERAGE_PERCENT:-0} * 50) / max_value))
  
  {
    echo ""
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë          GR√ÅFICO DE M√âTRICAS PRINCIPALES          ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo ""
    echo "Health Score:"
    printf "  [%s%s] %d/100\n" "$(printf '%*s' "$health_bar_len" | tr ' ' '‚ñà')" "$(printf '%*s' $((50 - health_bar_len)) | tr ' ' '‚ñë')" "$HEALTH_SCORE"
    echo ""
    echo "Coverage:"
    printf "  [%s%s] %d%%\n" "$(printf '%*s' "$coverage_bar_len" | tr ' ' '‚ñà')" "$(printf '%*s' $((50 - coverage_bar_len)) | tr ' ' '‚ñë')" "${COVERAGE_PERCENT:-0}"
    echo ""
    echo "Total Assets: $TOTAL_SVGS"
    echo "Security Issues: ${SECURITY_ISSUES:-0}"
    echo ""
  } >> "$REPORT"
  
  log_info "üìä Gr√°fico ASCII a√±adido al reporte"
}

# Exportaci√≥n de resumen ejecutivo a diferentes formatos
export_executive_summary() {
  log_section "üìÑ Exportaci√≥n de Resumen Ejecutivo"
  
  local summary_dir="$ROOT_DIR/exports/executive_summary"
  mkdir -p "$summary_dir"
  
  # Formato JSON
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"timestamp\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"metrics\": {"
      echo "    \"total_assets\": $TOTAL_SVGS,"
      echo "    \"health_score\": $HEALTH_SCORE,"
      echo "    \"coverage_percent\": ${COVERAGE_PERCENT:-0},"
      echo "    \"security_issues\": ${SECURITY_ISSUES:-0},"
      echo "    \"broken_assets\": ${BROKEN_SVGS:-0},"
      echo "    \"empty_assets\": ${EMPTY_SVGS:-0}"
      echo "  },"
      echo "  \"status\": \"$( [ "$HEALTH_SCORE" -ge 75 ] && echo "healthy" || echo "needs_attention" )\""
      echo "}"
    } > "$summary_dir/executive_summary.json"
    log_info "‚úÖ Resumen ejecutivo JSON: $summary_dir/executive_summary.json"
  fi
  
  # Formato YAML (simple)
  {
    echo "---"
    echo "timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
    echo "metrics:"
    echo "  total_assets: $TOTAL_SVGS"
    echo "  health_score: $HEALTH_SCORE"
    echo "  coverage_percent: ${COVERAGE_PERCENT:-0}"
    echo "  security_issues: ${SECURITY_ISSUES:-0}"
    echo "status: $([ "$HEALTH_SCORE" -ge 75 ] && echo "healthy" || echo "needs_attention")"
  } > "$summary_dir/executive_summary.yaml"
  
  log_info "‚úÖ Resumen ejecutivo YAML: $summary_dir/executive_summary.yaml"
}

# Validaci√≥n estricta de naming conventions
validate_naming_strict() {
  log_section "üè∑Ô∏è  Validaci√≥n Estricta de Naming Conventions"
  
  local naming_errors=0
  local naming_pattern="${NAMING_PATTERN:-^ad_[a-z0-9_]+_[0-9]+x[0-9]+.*\\.svg$}"
  
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ]; then
      local basename_file=$(basename "$svg_file")
      
      # Validar contra patr√≥n
      if ! echo "$basename_file" | grep -qE "$naming_pattern"; then
        naming_errors=$((naming_errors + 1))
        if [ "$naming_errors" -le 10 ]; then
          log_info "‚ö†Ô∏è  Naming no conforme: ${svg_file#$ROOT_DIR/}"
        fi
      fi
      
      # Validar longitud m√°xima
      if [ "${#basename_file}" -gt 100 ]; then
        naming_errors=$((naming_errors + 1))
        log_info "‚ö†Ô∏è  Nombre muy largo (>100 chars): ${svg_file#$ROOT_DIR/}"
      fi
      
      # Validar caracteres especiales
      if echo "$basename_file" | grep -qE '[^a-zA-Z0-9._-]'; then
        naming_errors=$((naming_errors + 1))
        log_info "‚ö†Ô∏è  Caracteres no permitidos: ${svg_file#$ROOT_DIR/}"
      fi
    fi
  done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)
  
  if [ "$naming_errors" -eq 0 ]; then
    log_info "‚úÖ Naming conventions cumplidas"
  else
    local total_checked=$(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50 | wc -l | xargs)
    local error_pct=$(awk "BEGIN {printf \"%.1f\", ($naming_errors / $total_checked) * 100}")
    log_info "‚ö†Ô∏è  Naming errors: $naming_errors/$total_checked (${error_pct}%)"
    log_info "üí° Patr√≥n esperado: $naming_pattern"
  fi
  
  echo "$naming_errors"
}

# An√°lisis de impacto de cambios (Git-based)
analyze_change_impact() {
  if ! command -v git >/dev/null 2>&1 || [ ! -d "$ROOT_DIR/.git" ]; then
    return 0
  fi
  
  log_section "üìä An√°lisis de Impacto de Cambios"
  
  local changed_svgs=$(git -C "$ROOT_DIR" diff --name-only HEAD 2>/dev/null | grep -E '\.svg$' | wc -l | xargs)
  local modified_svgs=$(git -C "$ROOT_DIR" diff --cached --name-only 2>/dev/null | grep -E '\.svg$' | wc -l | xargs)
  
  if [ "$changed_svgs" -gt 0 ] || [ "$modified_svgs" -gt 0 ]; then
    log_info "üìù SVGs modificados: $((changed_svgs + modified_svgs))"
    
    # Analizar tipo de cambios
    local size_changes=0
    local content_changes=0
    
    git -C "$ROOT_DIR" diff --stat HEAD -- "*.svg" 2>/dev/null | grep -E '\.svg' | while read -r line; do
      if echo "$line" | grep -qE '[0-9]+\s+[+-]'; then
        content_changes=$((content_changes + 1))
      fi
    done
    
    log_info "   Cambios de contenido detectados: $content_changes"
    
    # Advertencia si hay muchos cambios
    if [ "$((changed_svgs + modified_svgs))" -gt 10 ]; then
      log_info "‚ö†Ô∏è  Muchos cambios detectados - considerar revisi√≥n completa"
    fi
  else
    log_info "‚úÖ Sin cambios pendientes en SVGs"
  fi
}

# Exportaci√≥n CSV detallada
export_detailed_csv() {
  if [ "${OUTPUT_FORMAT:-text}" != "csv" ] && [ "${OUTPUT_FORMAT:-text}" != "all" ]; then
    return 0
  fi
  
  log_section "üìä Generando CSV Detallado"
  
  local csv_file="${REPORT%.txt}_detailed.csv"
  
  {
    echo "Archivo,Producto,Formato,Plataforma,Tama√±o,Health,Accessibility,Performance,Security Issues,Status"
    
    while IFS= read -r svg_file; do
      if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
        local rel_path="${svg_file#$ROOT_DIR/}"
        local size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo "0")
        local has_title=$(grep -qi '<title>' "$svg_file" && echo "yes" || echo "no")
        local has_desc=$(grep -qi '<desc>' "$svg_file" && echo "yes" || echo "no")
        local has_scripts=$(grep -qi '<script' "$svg_file" && echo "yes" || echo "no")
        
        # Detectar producto y formato desde path
        local producto="unknown"
        local formato="unknown"
        local plataforma="unknown"
        
        echo "$rel_path" | grep -qi "curso" && producto="curso_ia"
        echo "$rel_path" | grep -qi "saas" && producto="saas_ia_marketing"
        echo "$rel_path" | grep -qi "bulk" && producto="ia_bulk"
        echo "$rel_path" | grep -qi "linkedin" && plataforma="linkedin"
        echo "$rel_path" | grep -qi "instagram" && plataforma="instagram"
        echo "$rel_path" | grep -qiE "1080x1080|1200x627|1080x1920" && formato=$(echo "$rel_path" | grep -oE "1080x1080|1200x627|1080x1920" | head -1)
        
        local health="good"
        [ "$has_scripts" = "yes" ] && health="security_risk"
        [ "$has_title" = "no" ] && health="needs_improvement"
        
        echo "$rel_path,$producto,$formato,$plataforma,$size,$health,$has_title,$has_desc,$has_scripts,$health"
      fi
    done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | head -100)
  } > "$csv_file" 2>/dev/null || true
  
  log_info "‚úÖ CSV detallado exportado: $csv_file"
}

# Auto-fix avanzado con m√∫ltiples estrategias
advanced_auto_fix() {
  if [ "${AUTO_REPAIR:-false}" != "true" ]; then
    return 0
  fi
  
  log_section "üîß Auto-reparaci√≥n Avanzada"
  
  local fixed_count=0
  
  # Estrategia 1: Reparar SVGs vac√≠os desde git
  fixed_count=$((fixed_count + $(auto_repair_empty_svgs)))
  
  # Estrategia 2: A√±adir viewBox faltante
  local no_viewbox=$(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | while read -r f; do
    [ -f "$f" ] && ! grep -q 'viewBox=' "$f" 2>/dev/null && echo "$f"
  done | head -5)
  
  if [ -n "$no_viewbox" ] && [ "${AUTO_REPAIR:-false}" = "true" ]; then
    log_info "üí° Se encontraron SVGs sin viewBox (requiere intervenci√≥n manual)"
    echo "$no_viewbox" | head -3 | while read -r f; do
      log_info "    - ${f#$ROOT_DIR/}"
    done
  fi
  
  # Estrategia 3: Optimizaci√≥n autom√°tica con SVGO si est√° disponible
  if command -v svgo >/dev/null 2>&1 && [ "${AUTO_REPAIR:-false}" = "true" ] && [ "${LARGE_SVGS:-0}" -gt 0 ]; then
    log_info "üí° SVGO disponible - Puede optimizar autom√°ticamente"
    log_info "   Ejecutar: svgo -f $SRC_DIR -r --multipass"
  fi
  
  log_info "‚úÖ Auto-reparaci√≥n completada: $fixed_count archivo(s) reparado(s)"
}

# An√°lisis de versionado y control de cambios
analyze_versioning() {
  log_section "üìù An√°lisis de Versionado"
  
  local versioned_files=0
  local unversioned_files=0
  local git_tracked=0
  
  # Verificar si estamos en un repositorio Git
  if git rev-parse --git-dir >/dev/null 2>&1; then
    while IFS= read -r svg_file; do
      if [ -f "$svg_file" ]; then
        # Verificar si est√° trackeado en Git
        if git ls-files --error-unmatch "$svg_file" >/dev/null 2>&1; then
          git_tracked=$((git_tracked + 1))
          
          # Verificar si tiene versiones (archivos con _v1, _v2, etc.)
          if echo "$svg_file" | grep -qiE '_v[0-9]+'; then
            versioned_files=$((versioned_files + 1))
          else
            unversioned_files=$((unversioned_files + 1))
          fi
        fi
      fi
    done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | head -50)
    
    log_info "üìä Control de versiones:"
    log_info "  ‚Ä¢ Archivos en Git: $git_tracked/50"
    log_info "  ‚Ä¢ Con versionado expl√≠cito: $versioned_files"
    log_info "  ‚Ä¢ Sin versionado: $unversioned_files"
    
    # Verificar commits recientes
    local recent_commits=$(git log --oneline --since="7 days ago" -- "*.svg" 2>/dev/null | wc -l | xargs)
    if [ "$recent_commits" -gt 0 ]; then
      log_info "  ‚Ä¢ Commits SVG √∫ltimos 7 d√≠as: $recent_commits"
    fi
  else
    log_info "‚ÑπÔ∏è  No es un repositorio Git - saltando an√°lisis de versionado"
  fi
}

# An√°lisis comparativo entre productos
analyze_product_comparison() {
  log_section "üìä An√°lisis Comparativo por Producto"
  
  declare -A product_counts
  declare -A product_sizes
  declare -A product_health
  
  local products=("curso_ia" "saas_ia_marketing" "ia_bulk")
  
  for product in "${products[@]}"; do
    local product_files=$(find "$ROOT_DIR" -name "*${product}*" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | wc -l | xargs)
    product_counts[$product]=$product_files
    
    local total_size=0
    local file_count=0
    while IFS= read -r svg_file; do
      if [ -f "$svg_file" ]; then
        local size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo "0")
        total_size=$((total_size + size))
        file_count=$((file_count + 1))
      fi
    done < <(find "$ROOT_DIR" -name "*${product}*" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | head -20)
    
    [ "$file_count" -gt 0 ] && product_sizes[$product]=$((total_size / file_count)) || product_sizes[$product]=0
  done
  
  log_info "üìä Comparativa por producto:"
  for product in "${products[@]}"; do
    local count=${product_counts[$product]:-0}
    local avg_size=${product_sizes[$product]:-0}
    log_info "  ‚Ä¢ ${product}: $count archivos, tama√±o promedio: ${avg_size} bytes"
  done
  
  # Identificar desequilibrios
  local max_count=0
  local min_count=9999
  for product in "${products[@]}"; do
    local count=${product_counts[$product]:-0}
    [ "$count" -gt "$max_count" ] && max_count=$count
    [ "$count" -lt "$min_count" ] && min_count=$count
  done
  
  if [ "$max_count" -gt 0 ] && [ $((max_count - min_count)) -gt 10 ]; then
    log_info "‚ö†Ô∏è  Desequilibrio detectado: diferencia de $((max_count - min_count)) archivos entre productos"
  else
    log_info "‚úÖ Distribuci√≥n equilibrada entre productos"
  fi
}

# Sistema de alertas configurable
generate_alerts() {
  log_section "üö® Sistema de Alertas"
  
  local alerts=0
  local critical_alerts=0
  local warning_alerts=0
  
  # Alertas cr√≠ticas
  if [ "${SECURITY_ISSUES_COUNT:-0}" -gt 0 ]; then
    critical_alerts=$((critical_alerts + 1))
    log_info "üî¥ CR√çTICO: ${SECURITY_ISSUES_COUNT} issue(s) de seguridad detectado(s)"
    alerts=$((alerts + 1))
  fi
  
  if [ "${BROKEN_SVGS:-0}" -gt 5 ]; then
    critical_alerts=$((critical_alerts + 1))
    log_info "üî¥ CR√çTICO: ${BROKEN_SVGS} SVG(s) roto(s) - acci√≥n inmediata requerida"
    alerts=$((alerts + 1))
  fi
  
  if [ "${HEALTH_SCORE:-100}" -lt 50 ]; then
    critical_alerts=$((critical_alerts + 1))
    log_info "üî¥ CR√çTICO: Health Score muy bajo (${HEALTH_SCORE}/100)"
    alerts=$((alerts + 1))
  fi
  
  # Alertas de advertencia
  if [ "${EMPTY_SVGS:-0}" -gt 10 ]; then
    warning_alerts=$((warning_alerts + 1))
    log_info "üü° ADVERTENCIA: ${EMPTY_SVGS} SVG(s) vac√≠o(s)"
    alerts=$((alerts + 1))
  fi
  
  if [ "${ACCESSIBILITY_SCORE:-100}" -lt 60 ]; then
    warning_alerts=$((warning_alerts + 1))
    log_info "üü° ADVERTENCIA: Accesibilidad baja (${ACCESSIBILITY_SCORE}/100)"
    alerts=$((alerts + 1))
  fi
  
  if [ "${PERFORMANCE_SCORE:-100}" -lt 70 ]; then
    warning_alerts=$((warning_alerts + 1))
    log_info "üü° ADVERTENCIA: Rendimiento mejorable (${PERFORMANCE_SCORE}/100)"
    alerts=$((alerts + 1))
  fi
  
  if [ "${GAPS_COUNT:-0}" -gt 10 ]; then
    warning_alerts=$((warning_alerts + 1))
    log_info "üü° ADVERTENCIA: $GAPS_COUNT gap(s) en cobertura"
    alerts=$((alerts + 1))
  fi
  
  # Resumen de alertas
  if [ "$alerts" -eq 0 ]; then
    log_info "‚úÖ Sin alertas - sistema en buen estado"
  else
    log_info "üìä Resumen de alertas:"
    log_info "  ‚Ä¢ Cr√≠ticas: $critical_alerts"
    log_info "  ‚Ä¢ Advertencias: $warning_alerts"
    log_info "  ‚Ä¢ Total: $alerts"
    
    # Enviar a Slack/Teams si est√° configurado
    if [ -n "${SLACK_WEBHOOK:-}" ] && [ "$critical_alerts" -gt 0 ]; then
      send_slack_alert "$critical_alerts" "$warning_alerts" || true
    fi
    
    if [ -n "${TEAMS_WEBHOOK:-}" ] && [ "$critical_alerts" -gt 0 ]; then
      send_teams_alert "$critical_alerts" "$warning_alerts" || true
    fi
  fi
}

# Enviar alerta a Slack
send_slack_alert() {
  local critical="$1"
  local warnings="$2"
  
  local payload=$(cat <<JSON
{
  "text": "üö® Alertas de An√°lisis de Assets",
  "blocks": [
    {
      "type": "header",
      "text": {
        "type": "plain_text",
        "text": "üö® Alertas de An√°lisis de Assets"
      }
    },
    {
      "type": "section",
      "fields": [
        {
          "type": "mrkdwn",
          "text": "*Alertas Cr√≠ticas:*\nüî¥ $critical"
        },
        {
          "type": "mrkdwn",
          "text": "*Advertencias:*\nüü° $warnings"
        }
      ]
    },
    {
      "type": "section",
      "text": {
        "type": "mrkdwn",
        "text": "Health Score: ${HEALTH_SCORE:-0}/100\n<${REPORT}|Ver reporte completo>"
      }
    }
  ]
}
JSON
)
  
  curl -X POST -H 'Content-type: application/json' \
    --data "$payload" \
    "$SLACK_WEBHOOK" 2>/dev/null || return 1
}

# Enviar alerta a Teams
send_teams_alert() {
  local critical="$1"
  local warnings="$2"
  
  local payload=$(cat <<JSON
{
  "@type": "MessageCard",
  "@context": "https://schema.org/extensions",
  "summary": "Alertas de An√°lisis de Assets",
  "themeColor": "FF0000",
  "title": "üö® Alertas de An√°lisis de Assets",
  "sections": [
    {
      "facts": [
        {
          "name": "Alertas Cr√≠ticas:",
          "value": "$critical"
        },
        {
          "name": "Advertencias:",
          "value": "$warnings"
        },
        {
          "name": "Health Score:",
          "value": "${HEALTH_SCORE:-0}/100"
        }
      ]
    }
  ]
}
JSON
)
  
  curl -X POST -H 'Content-type: application/json' \
    --data "$payload" \
    "$TEAMS_WEBHOOK" 2>/dev/null || return 1
}

# An√°lisis de compliance (GDPR, WCAG, etc.)
analyze_compliance() {
  log_section "‚úÖ An√°lisis de Compliance"
  
  local gdpr_compliant=0
  local wcag_compliant=0
  local total_checked=0
  
  # Verificar WCAG compliance (ya analizado antes, consolidamos)
  if [ "${ACCESSIBILITY_SCORE:-100}" -ge 80 ]; then
    wcag_compliant=1
  fi
  
  # Verificar GDPR (buscando data collection, tracking, etc.)
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ]; then
      total_checked=$((total_checked + 1))
      # Verificar si hay scripts de tracking embebidos
      if ! grep -qiE 'analytics|tracking|pixel|beacon' "$svg_file" 2>/dev/null; then
        gdpr_compliant=$((gdpr_compliant + 1))
      fi
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | head -30)
  
  log_info "üìä Estado de Compliance:"
  [ "$wcag_compliant" -eq 1 ] && log_info "  ‚úÖ WCAG 2.1 AA: Compliant (Accessibility Score ‚â•80)" || log_info "  ‚ö†Ô∏è  WCAG 2.1 AA: No compliant (Accessibility Score <80)"
  
  local gdpr_pct=$((gdpr_compliant * 100 / total_checked))
  if [ "$gdpr_pct" -ge 90 ]; then
    log_info "  ‚úÖ GDPR: Compliant ($gdpr_pct% sin tracking embebido)"
  else
    log_info "  ‚ö†Ô∏è  GDPR: Revisar ($gdpr_pct% sin tracking embebido)"
  fi
}

# Generar dashboard ejecutivo consolidado
generate_executive_dashboard() {
  log_section "üìä Dashboard Ejecutivo Consolidado"
  
  local dashboard_file="${REPORT%.txt}_executive_dashboard.txt"
  
  {
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë        DASHBOARD EJECUTIVO - AN√ÅLISIS DE ASSETS           ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo ""
    echo "üìÖ Fecha: $(date '+%Y-%m-%d %H:%M:%S')"
    echo ""
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo "üìä M√âTRICAS PRINCIPALES"
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo ""
    echo "  Total Assets:        ${TOTAL_SVGS:-0}"
    echo "  Health Score:        ${HEALTH_SCORE:-0}/100"
    echo "  Accessibility:       ${ACCESSIBILITY_SCORE:-0}/100"
    echo "  Performance:         ${PERFORMANCE_SCORE:-0}/100"
    echo "  Security Issues:     ${SECURITY_ISSUES_COUNT:-0}"
    echo "  Coverage:            ${COVERAGE_PERCENT:-0}%"
    echo ""
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo "üéØ ESTADO GENERAL"
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo ""
    
    local overall_status="üü¢ EXCELENTE"
    [ "${HEALTH_SCORE:-100}" -lt 75 ] && overall_status="üü° MEJORABLE"
    [ "${HEALTH_SCORE:-100}" -lt 50 ] && overall_status="üî¥ CR√çTICO"
    
    echo "  Estado: $overall_status"
    echo ""
    echo "  ‚úÖ Fortalezas:"
    [ "${SECURITY_ISSUES_COUNT:-0}" -eq 0 ] && echo "    ‚Ä¢ Sin problemas de seguridad"
    [ "${ACCESSIBILITY_SCORE:-0}" -ge 80 ] && echo "    ‚Ä¢ Buena accesibilidad (WCAG compliant)"
    [ "${COVERAGE_PERCENT:-0}" -ge 80 ] && echo "    ‚Ä¢ Buena cobertura de formatos"
    echo ""
    echo "  ‚ö†Ô∏è  √Åreas de mejora:"
    [ "${EMPTY_SVGS:-0}" -gt 0 ] && echo "    ‚Ä¢ ${EMPTY_SVGS} SVG(s) vac√≠o(s) por eliminar"
    [ "${BROKEN_SVGS:-0}" -gt 0 ] && echo "    ‚Ä¢ ${BROKEN_SVGS} SVG(s) roto(s) por reparar"
    [ "${LARGE_SVGS:-0}" -gt 0 ] && echo "    ‚Ä¢ ${LARGE_SVGS} SVG(s) grande(s) por optimizar"
    [ "${GAPS_COUNT:-0}" -gt 0 ] && echo "    ‚Ä¢ $GAPS_COUNT gap(s) en cobertura"
    echo ""
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo "üí° ACCIONES RECOMENDADAS (Prioridad)"
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo ""
    
    local priority=1
    [ "${SECURITY_ISSUES_COUNT:-0}" -gt 0 ] && echo "  $((priority++)). üîí URGENTE: Revisar ${SECURITY_ISSUES_COUNT} issue(s) de seguridad"
    [ "${BROKEN_SVGS:-0}" -gt 5 ] && echo "  $((priority++)). üîß Reparar ${BROKEN_SVGS} SVG(s) roto(s)"
    [ "${LARGE_SVGS:-0}" -gt 0 ] && echo "  $((priority++)). ‚ö° Optimizar ${LARGE_SVGS} SVG(s) con svgo"
    [ "${NO_ACCESSIBILITY:-0}" -gt 5 ] && echo "  $((priority++)). ‚ôø Mejorar accesibilidad en ${NO_ACCESSIBILITY} SVG(s)"
    [ "${GAPS_COUNT:-0}" -gt 0 ] && echo "  $((priority++)). üìê Completar $GAPS_COUNT gap(s) en cobertura"
    
    echo ""
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo "üìÑ Reportes completos disponibles:"
    echo "   ‚Ä¢ Texto: $REPORT"
    [ "${OUTPUT_FORMAT:-text}" = "all" ] || [ "${OUTPUT_FORMAT:-text}" = "html" ] && echo "   ‚Ä¢ HTML: ${REPORT%.txt}_interactive.html"
    [ "${OUTPUT_FORMAT:-text}" = "all" ] || [ "${OUTPUT_FORMAT:-text}" = "csv" ] && echo "   ‚Ä¢ CSV: ${REPORT%.txt}_detailed.csv"
    [ "${OUTPUT_FORMAT:-text}" = "all" ] || [ "${OUTPUT_FORMAT:-text}" = "json" ] && echo "   ‚Ä¢ JSON: ${REPORT%.txt}_enhanced.json"
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  } > "$dashboard_file" 2>/dev/null || true
  
  log_info "‚úÖ Dashboard ejecutivo generado: $dashboard_file"
}

# An√°lisis de responsividad y viewports
log_section "üì± An√°lisis de Responsividad y Viewports"

RESPONSIVE_SCORE=100
RESPONSIVE_ISSUES=0
MISSING_VIEWBOX=0
FIXED_DIMENSIONS=0
MULTIPLE_VIEWPORTS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar viewBox (esencial para responsividad)
    if ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      MISSING_VIEWBOX=$((MISSING_VIEWBOX + 1))
      RESPONSIVE_SCORE=$((RESPONSIVE_SCORE - 5))
      RESPONSIVE_ISSUES=$((RESPONSIVE_ISSUES + 1))
    fi
    
    # Verificar si tiene dimensiones fijas (width/height sin %)
    if grep -qE 'width="[0-9]+"|height="[0-9]+"' "$svg_file" 2>/dev/null && ! grep -q 'width="100%"\|height="100%"' "$svg_file" 2>/dev/null; then
      FIXED_DIMENSIONS=$((FIXED_DIMENSIONS + 1))
    fi
    
    # Detectar m√∫ltiples definiciones de viewport
    VIEWPORT_COUNT=$(grep -cE 'viewBox=|preserveAspectRatio=' "$svg_file" 2>/dev/null || echo "0")
    if [ "$VIEWPORT_COUNT" -gt 2 ]; then
      MULTIPLE_VIEWPORTS=$((MULTIPLE_VIEWPORTS + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs sin viewBox: $MISSING_VIEWBOX"
log_info "SVGs con dimensiones fijas: $FIXED_DIMENSIONS"
log_info "SVGs con m√∫ltiples viewports: $MULTIPLE_VIEWPORTS"

if [ "$RESPONSIVE_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de responsividad: $RESPONSIVE_SCORE/100 (Excelente)"
elif [ "$RESPONSIVE_SCORE" -ge 75 ]; then
  log_info "‚ö†Ô∏è  Score de responsividad: $RESPONSIVE_SCORE/100 (Mejorable)"
else
  log_info "‚ùå Score de responsividad: $RESPONSIVE_SCORE/100 (Requiere atenci√≥n)"
fi

# An√°lisis de internacionalizaci√≥n (i18n)
log_section "üåç An√°lisis de Internacionalizaci√≥n"

I18N_SCORE=100
I18N_ISSUES=0
HARDCODED_TEXT=0
MULTILINGUAL_SUPPORT=0
LOCALIZED_ASSETS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar texto hardcodeado (sin uso de variables o atributos de traducci√≥n)
    TEXT_COUNT=$(grep -cE '<text[^>]*>' "$svg_file" 2>/dev/null || echo "0")
    if [ "$TEXT_COUNT" -gt 0 ]; then
      # Verificar si tiene atributos de traducci√≥n
      if ! grep -qiE 'data-i18n|data-translate|xml:lang|lang=' "$svg_file" 2>/dev/null; then
        HARDCODED_TEXT=$((HARDCODED_TEXT + 1))
        I18N_SCORE=$((I18N_SCORE - 2))
      else
        LOCALIZED_ASSETS=$((LOCALIZED_ASSETS + 1))
      fi
    fi
    
    # Detectar m√∫ltiples idiomas en nombre de archivo
    if echo "$svg_file" | grep -qiE '_(en|es|fr|de|pt|it|ja|zh)[_-]'; then
      MULTILINGUAL_SUPPORT=$((MULTILINGUAL_SUPPORT + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)

log_info "SVGs con texto hardcodeado: $HARDCODED_TEXT"
log_info "SVGs con soporte i18n: $LOCALIZED_ASSETS"
log_info "Assets multiidioma detectados: $MULTILINGUAL_SUPPORT"

if [ "$I18N_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score i18n: $I18N_SCORE/100 - Preparado para m√∫ltiples idiomas"
else
  log_info "üí° Mejorar i18n: usar atributos data-i18n o variables para texto"
fi

# An√°lisis de contraste de colores (accesibilidad)
log_section "üé® An√°lisis de Contraste de Colores"

CONTRAST_SCORE=100
CONTRAST_ISSUES=0
LOW_CONTRAST_COLORS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar colores muy similares (contraste bajo)
    # Buscar patrones de colores cercanos (por ejemplo, #fff y #fefefe)
    SIMILAR_COLORS=$(grep -oE '#[fF]{3,6}|#[eE]{3,6}|rgb\(25[0-5],\s*25[0-5],\s*25[0-5]\)' "$svg_file" 2>/dev/null | sort -u | wc -l | xargs)
    
    # Detectar texto blanco sobre fondo claro o texto oscuro sobre fondo oscuro
    LIGHT_TEXT=$(grep -oE 'fill="(white|#fff|#ffffff|rgb\(255,255,255\))' "$svg_file" 2>/dev/null | wc -l | xargs)
    LIGHT_BG=$(grep -oE 'fill="(white|#fff|#ffffff|rgb\(255,255,255\))|background.*(white|#fff)' "$svg_file" 2>/dev/null | wc -l | xargs)
    
    if [ "$SIMILAR_COLORS" -gt 5 ] && [ "$LIGHT_TEXT" -gt 0 ] && [ "$LIGHT_BG" -gt 0 ]; then
      LOW_CONTRAST_COLORS=$((LOW_CONTRAST_COLORS + 1))
      CONTRAST_SCORE=$((CONTRAST_SCORE - 5))
      CONTRAST_ISSUES=$((CONTRAST_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "SVGs con posible bajo contraste: $LOW_CONTRAST_COLORS"

if [ "$CONTRAST_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de contraste: $CONTRAST_SCORE/100"
else
  log_info "‚ö†Ô∏è  Score de contraste: $CONTRAST_SCORE/100 - Verificar contraste WCAG AA (4.5:1)"
  log_info "üí° Usar herramientas como WebAIM Contrast Checker para validar"
fi

# An√°lisis de estructura de archivos y organizaci√≥n
log_section "üìÅ An√°lisis de Estructura de Archivos"

STRUCTURE_SCORE=100
STRUCTURE_ISSUES=0
DEEP_NESTING=0
FLAT_STRUCTURE=0

# Analizar profundidad de directorios
while IFS= read -r svg_file; do
  if [ -f "$svg_file" ]; then
    local depth=$(echo "$svg_file" | grep -o '/' | wc -l | xargs)
    if [ "$depth" -gt 5 ]; then
      DEEP_NESTING=$((DEEP_NESTING + 1))
      STRUCTURE_SCORE=$((STRUCTURE_SCORE - 2))
    elif [ "$depth" -lt 3 ]; then
      FLAT_STRUCTURE=$((FLAT_STRUCTURE + 1))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

log_info "Archivos con anidaci√≥n profunda (>5 niveles): $DEEP_NESTING"
log_info "Archivos en estructura plana (<3 niveles): $FLAT_STRUCTURE"

if [ "$STRUCTURE_SCORE" -ge 80 ]; then
  log_info "‚úÖ Score de estructura: $STRUCTURE_SCORE/100"
else
  log_info "üí° Considerar reorganizar estructura: ideal 3-5 niveles de profundidad"
fi

# An√°lisis de patrones de nombres
log_section "üè∑Ô∏è  An√°lisis de Patrones de Nombres"

NAMING_SCORE=100
NAMING_ISSUES=0
INCONSISTENT_NAMING=0
SPECIAL_CHARS=0
SPACES_IN_NAMES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ]; then
    local basename_file=$(basename "$svg_file")
    
    # Detectar espacios en nombres
    if echo "$basename_file" | grep -q ' '; then
      SPACES_IN_NAMES=$((SPACES_IN_NAMES + 1))
      NAMING_SCORE=$((NAMING_SCORE - 3))
      NAMING_ISSUES=$((NAMING_ISSUES + 1))
    fi
    
    # Detectar caracteres especiales problem√°ticos
    if echo "$basename_file" | grep -qE '[^a-zA-Z0-9._-]'; then
      SPECIAL_CHARS=$((SPECIAL_CHARS + 1))
      NAMING_SCORE=$((NAMING_SCORE - 2))
    fi
    
    # Verificar consistencia (todos lowercase, snake_case, etc.)
    if echo "$basename_file" | grep -qE '[A-Z]'; then
      INCONSISTENT_NAMING=$((INCONSISTENT_NAMING + 1))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

log_info "Archivos con espacios en nombre: $SPACES_IN_NAMES"
log_info "Archivos con caracteres especiales: $SPECIAL_CHARS"
log_info "Archivos con naming inconsistente: $INCONSISTENT_NAMING"

if [ "$NAMING_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de naming: $NAMING_SCORE/100 - Convenciones consistentes"
else
  log_info "üí° Mejorar naming: usar lowercase, snake_case, sin espacios ni caracteres especiales"
fi

# An√°lisis de optimizaci√≥n de colores
log_section "üé® An√°lisis de Optimizaci√≥n de Colores"

COLOR_OPTIMIZATION_SCORE=100
COLOR_ISSUES=0
LONG_HEX_COLORS=0
RGB_COLORS=0
NAMED_COLORS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Contar colores en formato largo (#ffffff vs #fff)
    LONG_HEX=$(grep -oE '#[0-9a-fA-F]{6}' "$svg_file" 2>/dev/null | grep -vE '#[0-9a-f]{2}([0-9a-f])\1{2}' | wc -l | xargs)
    if [ "$LONG_HEX" -gt 0 ]; then
      LONG_HEX_COLORS=$((LONG_HEX_COLORS + LONG_HEX))
    fi
    
    # Contar RGB vs hex
    RGB_COUNT=$(grep -oE 'rgb\([^)]+\)' "$svg_file" 2>/dev/null | wc -l | xargs)
    if [ "$RGB_COUNT" -gt 0 ]; then
      RGB_COLORS=$((RGB_COLORS + RGB_COUNT))
    fi
    
    # Contar colores nombrados (red, blue, etc. - menos eficientes)
    NAMED_COUNT=$(grep -oE '\b(red|blue|green|yellow|black|white|gray|grey)\b' "$svg_file" 2>/dev/null | wc -l | xargs)
    if [ "$NAMED_COUNT" -gt 0 ]; then
      NAMED_COLORS=$((NAMED_COLORS + NAMED_COUNT))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Colores hex largos optimizables: $LONG_HEX_COLORS"
log_info "Colores RGB (convertir a hex): $RGB_COLORS"
log_info "Colores nombrados (ineficientes): $NAMED_COLORS"

if [ "$LONG_HEX_COLORS" -gt 10 ] || [ "$RGB_COLORS" -gt 5 ] || [ "$NAMED_COLORS" -gt 5 ]; then
  COLOR_OPTIMIZATION_SCORE=$((COLOR_OPTIMIZATION_SCORE - 15))
  log_info "üí° Optimizar colores: usar hex corto (#fff vs #ffffff), evitar RGB y nombres"
else
  log_info "‚úÖ Colores bien optimizados"
fi

log_info "Score de optimizaci√≥n de colores: $COLOR_OPTIMIZATION_SCORE/100"

# An√°lisis de uso de variables CSS
log_section "üîß An√°lisis de Variables CSS"

CSS_VARIABLES_SCORE=0
CSS_VARIABLES_USED=0
HARDCODED_VALUES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar uso de variables CSS (--variable-name)
    if grep -qE 'var\(--[a-zA-Z0-9_-]+\)|--[a-zA-Z0-9_-]+:' "$svg_file" 2>/dev/null; then
      CSS_VARIABLES_USED=$((CSS_VARIABLES_USED + 1))
      CSS_VARIABLES_SCORE=$((CSS_VARIABLES_SCORE + 5))
    fi
    
    # Detectar valores hardcodeados m√∫ltiples veces
    if grep -oE '#[0-9a-fA-F]{3,6}' "$svg_file" 2>/dev/null | sort | uniq -c | awk '$1 > 3 {count++} END {if(count>0) print count; else print 0}' | grep -q '[1-9]'; then
      HARDCODED_VALUES=$((HARDCODED_VALUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "SVGs usando variables CSS: $CSS_VARIABLES_USED"
log_info "SVGs con valores hardcodeados repetidos: $HARDCODED_VALUES"

if [ "$CSS_VARIABLES_SCORE" -gt 0 ]; then
  log_info "‚úÖ Uso de variables CSS detectado - facilita mantenimiento"
else
  log_info "üí° Considerar usar CSS variables (--color-primary) para valores repetidos"
fi

# An√°lisis de compatibilidad de navegadores
log_section "üåê An√°lisis de Compatibilidad de Navegadores"

BROWSER_COMPAT_SCORE=100
BROWSER_ISSUES=0
MODERN_FEATURES=0
FALLBACKS_MISSING=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar features modernas sin fallback
    if grep -qiE '<filter|<mask|<clipPath' "$svg_file" 2>/dev/null; then
      MODERN_FEATURES=$((MODERN_FEATURES + 1))
      # Verificar si tiene fallback
      if ! grep -qiE 'fallback|polyfill|@supports' "$svg_file" 2>/dev/null; then
        FALLBACKS_MISSING=$((FALLBACKS_MISSING + 1))
        BROWSER_COMPAT_SCORE=$((BROWSER_COMPAT_SCORE - 3))
        BROWSER_ISSUES=$((BROWSER_ISSUES + 1))
      fi
    fi
    
    # Detectar uso de SVG 2.0 features en navegadores antiguos
    if grep -qiE 'href=|<textPath' "$svg_file" 2>/dev/null && ! grep -qiE 'xlink:href' "$svg_file" 2>/dev/null; then
      FALLBACKS_MISSING=$((FALLBACKS_MISSING + 1))
      BROWSER_COMPAT_SCORE=$((BROWSER_COMPAT_SCORE - 2))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "SVGs con features modernas: $MODERN_FEATURES"
log_info "SVGs sin fallbacks: $FALLBACKS_MISSING"

if [ "$BROWSER_COMPAT_SCORE" -ge 90 ]; then
  log_info "‚úÖ Compatibilidad de navegadores: $BROWSER_COMPAT_SCORE/100 (Excelente)"
else
  log_info "‚ö†Ô∏è  Compatibilidad: $BROWSER_COMPAT_SCORE/100 - Considerar fallbacks para IE11/navegadores antiguos"
fi

# An√°lisis de uso de recursos externos detallado
log_section "üîó An√°lisis Detallado de Recursos Externos"

EXTERNAL_DEPENDENCIES_SCORE=100
EXTERNAL_ISSUES=0
UNSECURE_LINKS=0
CDN_DEPENDENCIES_COUNT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar enlaces HTTP (inseguros)
    if grep -qiE 'http://[^"]' "$svg_file" 2>/dev/null; then
      UNSECURE_LINKS=$((UNSECURE_LINKS + 1))
      EXTERNAL_DEPENDENCIES_SCORE=$((EXTERNAL_DEPENDENCIES_SCORE - 5))
      EXTERNAL_ISSUES=$((EXTERNAL_ISSUES + 1))
    fi
    
    # Contar dependencias de CDN
    CDN_COUNT=$(grep -oE '(cdn|cloudfront|cloudflare|jsdelivr|unpkg|cdnjs)' "$svg_file" 2>/dev/null | wc -l | xargs)
    if [ "$CDN_COUNT" -gt 0 ]; then
      CDN_DEPENDENCIES_COUNT=$((CDN_DEPENDENCIES_COUNT + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Enlaces HTTP (inseguros): $UNSECURE_LINKS"
log_info "Dependencias de CDN: $CDN_DEPENDENCIES_COUNT"

if [ "$EXTERNAL_DEPENDENCIES_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de dependencias externas: $EXTERNAL_DEPENDENCIES_SCORE/100"
else
  log_info "‚ö†Ô∏è  Usar HTTPS, considerar localizar recursos para mejor seguridad y performance"
fi

# Actualizar resumen final con nuevas m√©tricas
echo "Responsividad: ${RESPONSIVE_SCORE:-100}/100 | i18n: ${I18N_SCORE:-100}/100 | Contraste: ${CONTRAST_SCORE:-100}/100" >> "$REPORT"
echo "Estructura: ${STRUCTURE_SCORE:-100}/100 | Naming: ${NAMING_SCORE:-100}/100 | Optimizaci√≥n colores: ${COLOR_OPTIMIZATION_SCORE:-100}/100" >> "$REPORT"
echo "Variables CSS: ${CSS_VARIABLES_USED:-0} | Compatibilidad navegadores: ${BROWSER_COMPAT_SCORE:-100}/100" >> "$REPORT"

# Ejecutar an√°lisis adicionales
analyze_seo_metadata
analyze_branding_consistency
analyze_versioning
analyze_product_comparison
analyze_compliance

# Generar alertas
generate_alerts

# Generar dashboard ejecutivo
generate_executive_dashboard

# Generar reportes avanzados
generate_interactive_html
export_detailed_csv

# Auto-fix avanzado si est√° habilitado
advanced_auto_fix

# Validaci√≥n de compliance WCAG (si est√° habilitado)
if [ "${VALIDATE_WCAG:-false}" = "true" ]; then
  WCAG_ISSUES=$(validate_wcag_compliance)
fi

# Detecci√≥n de vulnerabilidades SVG (si est√° habilitado)
if [ "${DETECT_VULNERABILITIES:-false}" = "true" ]; then
  VULN_COUNT=$(detect_svg_vulnerabilities)
fi

# An√°lisis avanzado de performance (si est√° habilitado)
if [ "${ADVANCED_PERFORMANCE:-false}" = "true" ]; then
  PERF_SCORE=$(analyze_performance_advanced)
fi

# Detecci√≥n de assets hu√©rfanos (si est√° habilitado)
if [ "${DETECT_ORPHANS:-false}" = "true" ]; then
  ORPHANS_COUNT=$(detect_orphan_assets)
fi

# Generaci√≥n de reporte Markdown (si est√° habilitado)
if [ "${GENERATE_MARKDOWN:-false}" = "true" ]; then
  generate_markdown_report
fi

# Auto-reparaci√≥n de problemas comunes
auto_fix_common_issues

# Exportar resumen JSON de m√©tricas de video (para dashboards)
if command -v jq >/dev/null 2>&1 && [ -n "${EXPORT_DIR:-}" ]; then
  VIDEO_METRICS_JSON="$EXPORT_DIR/video_metrics_summary.json"
  mkdir -p "$EXPORT_DIR" 2>/dev/null || true
  
  {
    echo '{'
    echo '  "timestamp": '"\"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\""','
    echo '  "video_assets": {'
    echo '    "total_videos": '"${VIDEO_EXPORTS:-0}"','
    echo '    "total_srt": '"${SRT_FILES:-0}"','
    echo '    "total_markers": '"${CSV_MARKERS:-0}"','
    echo '    "thumbnails_count": '"${THUMBNAIL_COUNT:-0}"','
    echo '    "broll_videos": '"${BROLL_VIDEOS:-0}"','
    echo '    "broll_images": '"${BROLL_IMAGES:-0}"''
    echo '  },'
    echo '  "validation": {'
    echo '    "srt_issues": '"${SRT_ISSUES:-0}"','
    echo '    "markers_issues": '"${MARKERS_ISSUES:-0}"','
    echo '    "sync_issues": '"${SYNC_ISSUES:-0}"','
    echo '    "thumbnail_issues": '"${THUMBNAIL_ISSUES:-0}"','
    echo '    "video_metadata_issues": '"${VIDEO_METADATA_ISSUES:-0}"','
    echo '    "duplicate_video_svg": '"${DUPLICATE_VIDEO_SVG:-0}"','
    echo '    "script_asset_issues": '"${SCRIPT_ASSET_ISSUES:-0}"','
    echo '    "compliance_issues": '"${COMPLIANCE_ISSUES:-0}"','
    echo '    "accessibility_video_issues": '"${ACCESSIBILITY_VIDEO_ISSUES:-0}"','
    echo '    "url_issues": '"${URL_ISSUES:-0}"','
    echo '    "workflow_completeness": '"${WORKFLOW_COMPLETENESS:-0}"','
    echo '    "branding_issues": '"${BRANDING_ISSUES:-0}"','
    echo '    "directory_issues": '"${DIRECTORY_ISSUES:-0}"','
    echo '    "product_comparison_issues": '"${PRODUCT_COMPARISON_ISSUES:-0}"','
    echo '    "ab_test_issues": '"${AB_TEST_ISSUES:-0}"','
    echo '    "naming_video_issues": '"${NAMING_VIDEO_ISSUES:-0}"','
    echo '    "video_size_issues": '"${VIDEO_SIZE_ISSUES:-0}"','
    echo '    "message_consistency_issues": '"${MESSAGE_CONSISTENCY_ISSUES:-0}"','
    echo '    "obsolete_content": '"${OBSOLETE_CONTENT:-0}"','
    echo '    "resource_usage_issues": '"${RESOURCE_USAGE_ISSUES:-0}"','
    echo '    "orphan_video_assets": '"${ORPHAN_VIDEO_ASSETS:-0}"','
    echo '    "asset_dependencies": '"${ASSET_DEPENDENCIES:-0}"','
    echo '    "copy_consistency_issues": '"${COPY_CONSISTENCY_ISSUES:-0}"','
    echo '    "platform_coverage_gaps": '"${PLATFORM_COVERAGE_GAPS:-0}"','
    echo '    "versioning_issues": '"${VERSIONING_ISSUES:-0}"','
    echo '    "storage_optimization": '"${STORAGE_OPTIMIZATION:-0}"''
    echo '  },'
    echo '  "coverage": {'
    echo '    "products_with_videos": '"$(for p in "${!PRODUCT_DIRS[@]}" 2>/dev/null; do [ -d "${EXPORTS_BASE:-$ROOT_DIR/anuncios_video_15s/exports}/${PRODUCT_DIRS[$p]}" ] && echo "$p"; done 2>/dev/null | wc -l | xargs || echo 0)"','
    echo '    "products_with_srt": '"$(for p in "${!PRODUCT_DIRS[@]}" 2>/dev/null; do [ -f "${EXPORTS_BASE:-$ROOT_DIR/anuncios_video_15s/exports}/${PRODUCT_DIRS[$p]}/subtitles_es.srt" ] && echo "$p"; done 2>/dev/null | wc -l | xargs || echo 0)"','
    echo '    "products_with_markers": '"$(for p in "${!PRODUCT_DIRS[@]}" 2>/dev/null; do [ -f "${EXPORTS_BASE:-$ROOT_DIR/anuncios_video_15s/exports}/${PRODUCT_DIRS[$p]}/markers.csv" ] && echo "$p"; done 2>/dev/null | wc -l | xargs || echo 0)"''
    echo '  },'
    echo '  "health": {'
    echo '    "video_health_score": '"$(awk "BEGIN {score=100; score-=${SRT_ISSUES:-0}*5; score-=${MARKERS_ISSUES:-0}*5; score-=${SYNC_ISSUES:-0}*10; score-=${THUMBNAIL_ISSUES:-0}*3; score-=${VIDEO_METADATA_ISSUES:-0}*5; score-=${SCRIPT_ASSET_ISSUES:-0}*5; score-=${COMPLIANCE_ISSUES:-0}*8; score-=${ACCESSIBILITY_VIDEO_ISSUES:-0}*7; score-=${URL_ISSUES:-0}*3; score-=${WORKFLOW_COMPLETENESS:-0}*5; score-=${BRANDING_ISSUES:-0}*4; score-=${DIRECTORY_ISSUES:-0}*2; score-=${AB_TEST_ISSUES:-0}*3; score-=${NAMING_VIDEO_ISSUES:-0}*2; score-=${VIDEO_SIZE_ISSUES:-0}*3; score-=${MESSAGE_CONSISTENCY_ISSUES:-0}*3; score-=${OBSOLETE_CONTENT:-0}*2; score-=${RESOURCE_USAGE_ISSUES:-0}*2; score-=${ORPHAN_VIDEO_ASSETS:-0}*4; score-=${ASSET_DEPENDENCIES:-0}*3; score-=${COPY_CONSISTENCY_ISSUES:-0}*3; score-=${PLATFORM_COVERAGE_GAPS:-0}*2; score-=${VERSIONING_ISSUES:-0}*2; score-=${STORAGE_OPTIMIZATION:-0}*1; if(score<0) score=0; printf \"%.0f\", score}" 2>/dev/null || echo 100)"','
    echo '    "status": '"$(awk "BEGIN {score=100; score-=${SRT_ISSUES:-0}*5; score-=${MARKERS_ISSUES:-0}*5; score-=${SYNC_ISSUES:-0}*10; score-=${THUMBNAIL_ISSUES:-0}*3; score-=${VIDEO_METADATA_ISSUES:-0}*5; score-=${SCRIPT_ASSET_ISSUES:-0}*5; if(score<0) score=0; if(score>=90) print \"\\\"excellent\\\"\"; else if(score>=75) print \"\\\"good\\\"\"; else if(score>=60) print \"\\\"needs_attention\\\"\"; else print \"\\\"critical\\\"\"}" 2>/dev/null || echo "\"unknown\"")"'
    echo '  }'
    echo '}'
  } > "$VIDEO_METRICS_JSON" 2>/dev/null || true
  
  if [ -f "$VIDEO_METRICS_JSON" ] && [ -s "$VIDEO_METRICS_JSON" ]; then
    log_info "üìä M√©tricas de video exportadas a JSON: $VIDEO_METRICS_JSON"
  fi
fi

# An√°lisis de accesibilidad avanzada con WCAG 2.2
log_section "‚ôø An√°lisis de Accesibilidad WCAG 2.2"

WCAG_22_SCORE=100
WCAG_22_ISSUES=0
MISSING_ARIA=0
LOW_CONTRAST_DETECTED=0
FOCUS_ISSUES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar ARIA labels para elementos interactivos
    local interactive_count=$(grep -cE 'onclick=|href=|button|tabindex' "$svg_file" 2>/dev/null || echo "0")
    local aria_count=$(grep -cE 'aria-label|aria-labelledby|aria-describedby' "$svg_file" 2>/dev/null || echo "0")
    
    if [ "$interactive_count" -gt 0 ] && [ "$aria_count" -lt "$interactive_count" ]; then
      MISSING_ARIA=$((MISSING_ARIA + 1))
      WCAG_22_SCORE=$((WCAG_22_SCORE - 5))
      WCAG_22_ISSUES=$((WCAG_22_ISSUES + 1))
    fi
    
    # Verificar focus visible
    local focusable=$(grep -cE 'tabindex|href=' "$svg_file" 2>/dev/null || echo "0")
    local focus_visible=$(grep -cE ':focus-visible|outline|focus' "$svg_file" 2>/dev/null || echo "0")
    
    if [ "$focusable" -gt 0 ] && [ "$focus_visible" -eq 0 ]; then
      FOCUS_ISSUES=$((FOCUS_ISSUES + 1))
      WCAG_22_SCORE=$((WCAG_22_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "SVGs sin ARIA en elementos interactivos: $MISSING_ARIA"
log_info "SVGs sin focus visible: $FOCUS_ISSUES"

if [ "$WCAG_22_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score WCAG 2.2: $WCAG_22_SCORE/100"
else
  log_info "üí° Mejorar accesibilidad WCAG 2.2: a√±adir ARIA labels y estilos focus-visible"
fi

# An√°lisis de impacto en Core Web Vitals
log_section "‚ö° An√°lisis de Core Web Vitals"

CWV_SCORE=100
CWV_ISSUES=0
LCP_ISSUES=0
FID_ISSUES=0
CLS_ISSUES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local file_size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo "0")
    
    # LCP (Largest Contentful Paint) - archivos grandes afectan
    if [ "$file_size" -gt 51200 ]; then  # >50KB
      LCP_ISSUES=$((LCP_ISSUES + 1))
      CWV_SCORE=$((CWV_SCORE - 3))
      CWV_ISSUES=$((CWV_ISSUES + 1))
    fi
    
    # FID (First Input Delay) - muchos event listeners afectan
    local event_listeners=$(grep -cE 'onclick|onmouse|onevent' "$svg_file" 2>/dev/null || echo "0")
    if [ "$event_listeners" -gt 10 ]; then
      FID_ISSUES=$((FID_ISSUES + 1))
      CWV_SCORE=$((CWV_SCORE - 2))
    fi
    
    # CLS (Cumulative Layout Shift) - SVGs sin dimensiones fijas
    if ! grep -qE 'width=|height=|viewBox=' "$svg_file" 2>/dev/null; then
      CLS_ISSUES=$((CLS_ISSUES + 1))
      CWV_SCORE=$((CWV_SCORE - 4))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Problemas LCP detectados: $LCP_ISSUES"
log_info "Problemas FID detectados: $FID_ISSUES"
log_info "Problemas CLS detectados: $CLS_ISSUES"

if [ "$CWV_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score Core Web Vitals: $CWV_SCORE/100"
else
  log_info "üí° Optimizar Core Web Vitals: reducir tama√±o, minimizar listeners, definir dimensiones"
fi

# An√°lisis de dark mode support
log_section "üåô An√°lisis de Soporte Dark Mode"

DARK_MODE_SCORE=0
MEDIA_QUERIES=0
CSS_VARS_DARK=0
DARK_READY=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar media queries para dark mode
    if grep -qiE '@media.*prefers-color-scheme.*dark|prefers-color-scheme: dark' "$svg_file" 2>/dev/null; then
      MEDIA_QUERIES=$((MEDIA_QUERIES + 1))
      DARK_READY=$((DARK_READY + 1))
      DARK_MODE_SCORE=$((DARK_MODE_SCORE + 30))
    fi
    
    # Detectar variables CSS que cambian en dark mode
    if grep -qiE '--.*-dark|var\(--.*\)' "$svg_file" 2>/dev/null; then
      CSS_VARS_DARK=$((CSS_VARS_DARK + 1))
      DARK_MODE_SCORE=$((DARK_MODE_SCORE + 20))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

if [ "$DARK_MODE_SCORE" -gt 100 ]; then
  DARK_MODE_SCORE=100
fi

log_info "SVGs con media queries dark mode: $MEDIA_QUERIES"
log_info "SVGs con variables CSS para dark: $CSS_VARS_DARK"
log_info "Total assets dark mode ready: $DARK_READY"

if [ "$DARK_MODE_SCORE" -ge 50 ]; then
  log_info "‚úÖ Score dark mode: $DARK_MODE_SCORE/100"
else
  log_info "üí° A√±adir soporte dark mode: usar @media (prefers-color-scheme: dark) o CSS variables"
fi

# An√°lisis de progressive enhancement
log_section "üìà An√°lisis de Progressive Enhancement"

PE_SCORE=100
PE_ISSUES=0
NO_FALLBACKS=0
JAVASCRIPT_DEPENDENT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar dependencia de JavaScript
    if grep -qiE '<script|javascript:|onclick|addEventListener' "$svg_file" 2>/dev/null; then
      JAVASCRIPT_DEPENDENT=$((JAVASCRIPT_DEPENDENT + 1))
      
      # Verificar si tiene fallback sin JS
      if ! grep -qiE 'noscript|<noscript>|fallback' "$svg_file" 2>/dev/null; then
        NO_FALLBACKS=$((NO_FALLBACKS + 1))
        PE_SCORE=$((PE_SCORE - 5))
        PE_ISSUES=$((PE_ISSUES + 1))
      fi
    fi
    
    # Verificar si usa features modernas sin fallback
    if grep -qiE '<filter|<mask|SVG2|SVG 2' "$svg_file" 2>/dev/null && ! grep -qiE 'fallback|polyfill|@supports' "$svg_file" 2>/dev/null; then
      NO_FALLBACKS=$((NO_FALLBACKS + 1))
      PE_SCORE=$((PE_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "SVGs dependientes de JavaScript: $JAVASCRIPT_DEPENDENT"
log_info "SVGs sin fallbacks: $NO_FALLBACKS"

if [ "$PE_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score progressive enhancement: $PE_SCORE/100"
else
  log_info "üí° Mejorar progressive enhancement: a√±adir fallbacks, usar @supports, evitar dependencia de JS"
fi

# An√°lisis de mantenibilidad de c√≥digo
log_section "üîß An√°lisis de Mantenibilidad de C√≥digo"

MAINTAINABILITY_SCORE=100
MAINTAINABILITY_ISSUES=0
MAGIC_NUMBERS=0
LONG_FUNCTIONS=0
DUPLICATE_CODE=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar n√∫meros m√°gicos (valores hardcodeados sin variables)
    local magic=$(grep -oE 'width="[0-9]{3,}"|height="[0-9]{3,}"|cx="[0-9]{3,}"|cy="[0-9]{3,}"|r="[0-9]{3,}"' "$svg_file" 2>/dev/null | wc -l | xargs)
    if [ "$magic" -gt 10 ]; then
      MAGIC_NUMBERS=$((MAGIC_NUMBERS + 1))
      MAINTAINABILITY_SCORE=$((MAINTAINABILITY_SCORE - 2))
    fi
    
    # Detectar c√≥digo muy largo (l√≠neas >1000)
    local line_count=$(wc -l < "$svg_file" 2>/dev/null | xargs)
    if [ "$line_count" -gt 1000 ]; then
      LONG_FUNCTIONS=$((LONG_FUNCTIONS + 1))
      MAINTAINABILITY_SCORE=$((MAINTAINABILITY_SCORE - 5))
      MAINTAINABILITY_ISSUES=$((MAINTAINABILITY_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

# Detectar c√≥digo duplicado (mismo path data repetido)
DUPLICATE_PATHS=$(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" 2>/dev/null | while read f; do
  grep -oE 'd="[^"]{50,}"' "$f" 2>/dev/null | sort | uniq -d | head -1
done | wc -l | xargs)

if [ "$DUPLICATE_PATHS" -gt 5 ]; then
  DUPLICATE_CODE=$((DUPLICATE_CODE + DUPLICATE_PATHS))
  MAINTAINABILITY_SCORE=$((MAINTAINABILITY_SCORE - 3))
fi

log_info "SVGs con n√∫meros m√°gicos: $MAGIC_NUMBERS"
log_info "SVGs muy largos - mas de 1000 lineas: $LONG_FUNCTIONS"
log_info "Patrones duplicados detectados: $DUPLICATE_CODE"

if [ "$MAINTAINABILITY_SCORE" -ge 85 ]; then
  log_info "‚úÖ Score de mantenibilidad: $MAINTAINABILITY_SCORE/100"
else
  log_info "üí° Mejorar mantenibilidad: usar variables, dividir archivos grandes, eliminar duplicaci√≥n"
fi

# An√°lisis de testing y cobertura
log_section "üß™ An√°lisis de Testing y Cobertura"

TESTING_SCORE=0
TEST_FILES_COUNT=0
COVERAGE_SCORE=0

# Buscar archivos de test
TEST_FILES_COUNT=$(find "$ROOT_DIR" -name "*test*.svg" -o -name "*spec*.svg" -o -name "*.test.*" -not -path "*/node_modules/*" 2>/dev/null | wc -l | xargs)

if [ "$TEST_FILES_COUNT" -gt 0 ]; then
  TESTING_SCORE=$((TESTING_SCORE + 30))
  log_info "‚úÖ Archivos de test encontrados: $TEST_FILES_COUNT"
else
  log_info "üí° No se encontraron archivos de test - considerar crear tests"
fi

# Calcular cobertura aproximada
if [ "$TOTAL_SVGS" -gt 0 ]; then
  COVERAGE_SCORE=$((TEST_FILES_COUNT * 100 / TOTAL_SVGS))
  if [ "$COVERAGE_SCORE" -gt 100 ]; then
    COVERAGE_SCORE=100
  fi
fi

log_info "Cobertura de testing estimada: ${COVERAGE_SCORE}%"

if [ "$TESTING_SCORE" -ge 30 ]; then
  log_info "‚úÖ Score de testing: $TESTING_SCORE/100"
else
  log_info "üí° Mejorar testing: crear archivos de test, aumentar cobertura"
fi

# An√°lisis de documentaci√≥n t√©cnica
log_section "üìö An√°lisis de Documentaci√≥n T√©cnica"

DOC_TECH_SCORE=100
DOC_TECH_ISSUES=0
NO_COMMENTS=0
NO_README=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar comentarios en el c√≥digo
    local comments=$(grep -cE '<!--.*-->' "$svg_file" 2>/dev/null || echo "0")
    if [ "$comments" -eq 0 ] && [ -s "$svg_file" ]; then
      NO_COMMENTS=$((NO_COMMENTS + 1))
      DOC_TECH_SCORE=$((DOC_TECH_SCORE - 2))
      DOC_TECH_ISSUES=$((DOC_TECH_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

# Verificar README
if [ ! -f "$ROOT_DIR/README.md" ] && [ ! -f "$SRC_DIR/README.md" ]; then
  NO_README=1
  DOC_TECH_SCORE=$((DOC_TECH_SCORE - 10))
fi

log_info "SVGs sin comentarios: $NO_COMMENTS"
[ "$NO_README" -eq 1 ] && log_info "‚ö†Ô∏è  No se encontr√≥ README.md"

if [ "$DOC_TECH_SCORE" -ge 85 ]; then
  log_info "‚úÖ Score de documentaci√≥n t√©cnica: $DOC_TECH_SCORE/100"
else
  log_info "üí° Mejorar documentaci√≥n: a√±adir comentarios, crear README.md"
fi

# An√°lisis de coherencia de mensajes entre productos
log_section "üí¨ An√°lisis de Coherencia de Mensajes"

MESSAGE_CONSISTENCY_ISSUES=0

analyze_message_consistency() {
  local issues=0
  local all_ctas=()
  local all_hooks=()
  
  # Extraer CTAs y hooks de todos los scripts
  for prod in "${!PRODUCT_DIRS[@]}"; do
    local script_file=""
    case "$prod" in
      "curso_ia_webinar")
        script_file="$ROOT_DIR/ANUNCIO_VIDEO_01_CURSO_IA_WEBINAR_15s.md"
        ;;
      "saas_ia_marketing")
        script_file="$ROOT_DIR/ANUNCIO_VIDEO_02_SAAS_IA_MARKETING_15s.md"
        ;;
      "ia_bulk_docs")
        script_file="$ROOT_DIR/ANUNCIO_VIDEO_03_IA_BULK_DOCUMENTOS_15s.md"
        ;;
    esac
    
    if [ -f "$script_file" ]; then
      # Extraer CTAs
      local ctas=$(grep -iE "CTA|call.*action|bot√≥n|button|inscr|probar|registro" "$script_file" 2>/dev/null | head -3)
      if [ -n "$ctas" ]; then
        all_ctas+=("$prod: $ctas")
      fi
      
      # Extraer hooks
      local hooks=$(grep -iE "hook|gancho|primer.*segundo|inicio" "$script_file" 2>/dev/null | head -2)
      if [ -n "$hooks" ]; then
        all_hooks+=("$prod: $hooks")
      fi
    fi
  done
  
  # Verificar consistencia de tono y mensaje principal
  if [ ${#all_ctas[@]} -gt 0 ]; then
    # Verificar que CTAs sean coherentes (mismo nivel de urgencia/directo)
    local urgent_count=0
    local soft_count=0
    
    for cta_item in "${all_ctas[@]}"; do
      if echo "$cta_item" | grep -qiE "hoy|ahora|urgente|inmediato"; then
        urgent_count=$((urgent_count + 1))
      elif echo "$cta_item" | grep -qiE "probar|ver|explorar|descubrir"; then
        soft_count=$((soft_count + 1))
      fi
    done
    
    if [ "$urgent_count" -gt 0 ] && [ "$soft_count" -gt 0 ]; then
      echo "  ‚ö†Ô∏è  Inconsistencia en tono de CTAs: mezcla de urgente y suave" >> "$REPORT"
      issues=1
    fi
  fi
  
  if [ "$issues" -eq 0 ]; then
    log_info "‚úÖ Coherencia de mensajes OK"
  else
    log_info "‚ö†Ô∏è  Issues de coherencia detectados - ver reporte"
    MESSAGE_CONSISTENCY_ISSUES=$((MESSAGE_CONSISTENCY_ISSUES + issues))
    RECOMMENDATIONS+=("Revisar coherencia de mensajes entre productos - CTAs hooks tono")
  fi
}

analyze_message_consistency

# Detecci√≥n de contenido obsoleto o no utilizado
log_section "üóëÔ∏è  Detecci√≥n de Contenido Obsoleto"

OBSOLETE_CONTENT=0

detect_obsolete_content() {
  local obsolete_count=0
  local old_threshold_days=90
  
  # Buscar videos muy antiguos (m√°s de 90 d√≠as sin modificar)
  while IFS= read -r video_file; do
    if [ -f "$video_file" ]; then
      local file_age=$(find "$video_file" -mtime +$old_threshold_days 2>/dev/null | wc -l | xargs)
      if [ "$file_age" -gt 0 ]; then
        if [ "$obsolete_count" -eq 0 ]; then
          echo "  ‚ö†Ô∏è  Videos sin modificar en mas de $old_threshold_days dias - posible contenido obsoleto:" >> "$REPORT"
        fi
        local mod_date=$(stat -f "%Sm" -t "%Y-%m-%d" "$video_file" 2>/dev/null || stat -c "%y" "$video_file" 2>/dev/null | cut -d' ' -f1)
        echo "    - $(basename "$video_file")  - ultima modificaci√≥n: $mod_date)" >> "$REPORT"
        obsolete_count=$((obsolete_count + 1))
      fi
    fi
  done < <(find "$EXPORTS_BASE" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null | head -20)
  
  # Buscar SRT sin video correspondiente
  while IFS= read -r srt_file; do
    if [ -f "$srt_file" ]; then
      local srt_dir=$(dirname "$srt_file")
      local srt_basename=$(basename "$srt_file" .srt)
      local has_video=0
      
      # Verificar si hay video en el mismo directorio
      if [ -n "$(find "$srt_dir" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null)" ]; then
        has_video=1
      fi
      
      if [ "$has_video" -eq 0 ]; then
        if [ "$obsolete_count" -eq 0 ]; then
          echo "  ‚ö†Ô∏è  Contenido sin referencias (- posible obsoleto):" >> "$REPORT"
        fi
        echo "    - $(basename "$srt_file") sin video correspondiente" >> "$REPORT"
        obsolete_count=$((obsolete_count + 1))
      fi
    fi
  done < <(find "$EXPORTS_BASE" -name "*.srt" 2>/dev/null | head -10)
  
  if [ "$obsolete_count" -gt 0 ]; then
    OBSOLETE_CONTENT=$obsolete_count
    log_info "‚ö†Ô∏è  $obsolete_count item(s) posiblemente obsoleto(s) detectado(s) (- ver reporte)"
    RECOMMENDATIONS+=("Revisar $obsolete_count item(s) posiblemente obsoleto(s) (videos antiguos, SRT sin video)")
  else
    log_info "‚úÖ Sin contenido obsoleto detectado"
  fi
}

detect_obsolete_content

# An√°lisis de frecuencia de uso y modificaci√≥n
log_section "üìÖ An√°lisis de Frecuencia de Modificaci√≥n"

if [ "${TOTAL_SVGS:-0}" -gt 0 ] || [ "${VIDEO_EXPORTS:-0}" -gt 0 ]; then
  # Calcular d√≠as desde √∫ltima modificaci√≥n
  RECENT_30_DAYS=0
  RECENT_7_DAYS=0
  OLD_90_DAYS=0
  
  # Analizar SVGs
  while IFS= read -r svg_file; do
    if [ -f "$svg_file" ]; then
      local file_age_days=$(find "$svg_file" -mtime -30 2>/dev/null | wc -l | xargs)
      [ "$file_age_days" -gt 0 ] && RECENT_30_DAYS=$((RECENT_30_DAYS + 1))
      
      file_age_days=$(find "$svg_file" -mtime -7 2>/dev/null | wc -l | xargs)
      [ "$file_age_days" -gt 0 ] && RECENT_7_DAYS=$((RECENT_7_DAYS + 1))
      
      file_age_days=$(find "$svg_file" -mtime +90 2>/dev/null | wc -l | xargs)
      [ "$file_age_days" -gt 0 ] && OLD_90_DAYS=$((OLD_90_DAYS + 1))
    fi
  done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -50)
  
  # Analizar videos
  while IFS= read -r video_file; do
    if [ -f "$video_file" ]; then
      local file_age_days=$(find "$video_file" -mtime -30 2>/dev/null | wc -l | xargs)
      [ "$file_age_days" -gt 0 ] && RECENT_30_DAYS=$((RECENT_30_DAYS + 1))
      
      file_age_days=$(find "$video_file" -mtime -7 2>/dev/null | wc -l | xargs)
      [ "$file_age_days" -gt 0 ] && RECENT_7_DAYS=$((RECENT_7_DAYS + 1))
      
      file_age_days=$(find "$video_file" -mtime +90 2>/dev/null | wc -l | xargs)
      [ "$file_age_days" -gt 0 ] && OLD_90_DAYS=$((OLD_90_DAYS + 1))
    fi
  done < <(find "$EXPORTS_BASE" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null | head -20)
  
  log_info "Actividad reciente:"
  log_info "  - √öltimos 7 d√≠as: $RECENT_7_DAYS archivo(s) modificado(s)"
  log_info "  - √öltimos 30 d√≠as: $RECENT_30_DAYS archivo(s) modificado(s)"
  log_info "  - M√°s de 90 d√≠as sin modificar: $OLD_90_DAYS archivo(s)"
  
  if [ "$OLD_90_DAYS" -gt 10 ]; then
    log_info "üí° Sugerencia: $OLD_90_DAYS archivo(s) muy antiguo(s) - considera revisar si siguen siendo relevantes"
  fi
fi

# An√°lisis de uso de recursos por tipo
log_section "üìà An√°lisis de Uso de Recursos por Tipo"

RESOURCE_USAGE_ISSUES=0

analyze_resource_usage() {
  local total_resources=0
  local by_type=()
  
  # Contar recursos por tipo
  local svg_count=$(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | wc -l | xargs)
  local video_count=$(find "$EXPORTS_BASE" -type f \( -name "*.mp4" -o -name "*.mov" \) 2>/dev/null | wc -l | xargs)
  local srt_count=$(find "$EXPORTS_BASE" -name "*.srt" 2>/dev/null | wc -l | xargs)
  local marker_count=$(find "$EXPORTS_BASE" -name "*.csv" 2>/dev/null | wc -l | xargs)
  local thumbnail_count=$(find "$ROOT_DIR/anuncios_video_15s/thumbnails" -type f \( -name "*.png" -o -name "*.jpg" \) 2>/dev/null | wc -l | xargs)
  
  total_resources=$((svg_count + video_count + srt_count + marker_count + thumbnail_count))
  
  if [ "$total_resources" -gt 0 ]; then
    log_info "Distribuci√≥n de recursos:"
    log_info "  - SVGs: $svg_count ($(awk "BEGIN {printf \"%.1f\", ($svg_count/$total_resources)*100}")%)"
    log_info "  - Videos: $video_count ($(awk "BEGIN {printf \"%.1f\", ($video_count/$total_resources)*100}")%)"
    log_info "  - SRT: $srt_count ($(awk "BEGIN {printf \"%.1f\", ($srt_count/$total_resources)*100}")%)"
    log_info "  - Markers: $marker_count ($(awk "BEGIN {printf \"%.1f\", ($marker_count/$total_resources)*100}")%)"
    log_info "  - Thumbnails: $thumbnail_count ($(awk "BEGIN {printf \"%.1f\", ($thumbnail_count/$total_resources)*100}")%)"
    
    # Verificar balance (videos deber√≠an tener SRT correspondientes)
    if [ "$video_count" -gt 0 ] && [ "$srt_count" -lt "$video_count" ]; then
      local missing_srt=$((video_count - srt_count))
      echo "  ‚ö†Ô∏è  Desbalance: $missing_srt video(s) sin SRT correspondiente" >> "$REPORT"
      RESOURCE_USAGE_ISSUES=$((RESOURCE_USAGE_ISSUES + 1))
      RECOMMENDATIONS+=("A√±adir SRT faltantes para $missing_srt video(s)")
    fi
  fi
}

analyze_resource_usage

if [ "$RESOURCE_USAGE_ISSUES" -eq 0 ]; then
  log_info "‚úÖ Uso de recursos balanceado"
fi

# An√°lisis de arquitectura y dise√±o de sistema
log_section "üèóÔ∏è  An√°lisis de Arquitectura y Dise√±o de Sistema"

ARCHITECTURE_SCORE=100
ARCHITECTURE_ISSUES=0
MONOLITHIC_PATTERNS=0
MODULAR_DESIGN=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar uso de componentes reutilizables (dise√±o modular)
    if grep -qiE '<defs>|<symbol>|<use' "$svg_file" 2>/dev/null; then
      MODULAR_DESIGN=$((MODULAR_DESIGN + 1))
      ARCHITECTURE_SCORE=$((ARCHITECTURE_SCORE + 2))
    fi
    
    # Detectar patrones monol√≠ticos (todo en un archivo)
    local element_count=$(grep -cE '<path|<rect|<circle|<g' "$svg_file" 2>/dev/null || echo "0")
    if [ "$element_count" -gt 500 ]; then
      MONOLITHIC_PATTERNS=$((MONOLITHIC_PATTERNS + 1))
      ARCHITECTURE_SCORE=$((ARCHITECTURE_SCORE - 5))
      ARCHITECTURE_ISSUES=$((ARCHITECTURE_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con dise√±o modular: $MODULAR_DESIGN"
log_info "Assets con patrones monol√≠ticos: $MONOLITHIC_PATTERNS"

if [ "$ARCHITECTURE_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de arquitectura: $ARCHITECTURE_SCORE/100"
else
  log_info "üí° Mejorar arquitectura: usar componentes reutilizables, evitar patrones monol√≠ticos"
fi

# An√°lisis de consistencia de dise√±o
log_section "üé® An√°lisis de Consistencia de Dise√±o"

DESIGN_CONSISTENCY_SCORE=100
DESIGN_CONSISTENCY_ISSUES=0
MIXED_UNITS=0
INCONSISTENT_SPACING=0
COLOR_VARIATIONS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar unidades mixtas (px, em, rem, %)
    local px_count=$(grep -cE '[0-9]+px' "$svg_file" 2>/dev/null || echo "0")
    local em_count=$(grep -cE '[0-9]+em' "$svg_file" 2>/dev/null || echo "0")
    local rem_count=$(grep -cE '[0-9]+rem' "$svg_file" 2>/dev/null || echo "0")
    local percent_count=$(grep -cE '[0-9]+%' "$svg_file" 2>/dev/null || echo "0")
    
    local unit_types=0
    [ "$px_count" -gt 0 ] && unit_types=$((unit_types + 1))
    [ "$em_count" -gt 0 ] && unit_types=$((unit_types + 1))
    [ "$rem_count" -gt 0 ] && unit_types=$((unit_types + 1))
    [ "$percent_count" -gt 0 ] && unit_types=$((unit_types + 1))
    
    if [ "$unit_types" -gt 2 ]; then
      MIXED_UNITS=$((MIXED_UNITS + 1))
      DESIGN_CONSISTENCY_SCORE=$((DESIGN_CONSISTENCY_SCORE - 2))
    fi
    
    # Detectar variaciones excesivas de color
    local unique_colors=$(grep -oE '#[0-9a-fA-F]{3,6}|rgb\([^)]+\)' "$svg_file" 2>/dev/null | sort -u | wc -l | xargs)
    if [ "$unique_colors" -gt 20 ]; then
      COLOR_VARIATIONS=$((COLOR_VARIATIONS + 1))
      DESIGN_CONSISTENCY_SCORE=$((DESIGN_CONSISTENCY_SCORE - 3))
      DESIGN_CONSISTENCY_ISSUES=$((DESIGN_CONSISTENCY_ISSUES + 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con unidades mixtas: $MIXED_UNITS"
log_info "Assets con muchas variaciones de color: $COLOR_VARIATIONS"

if [ "$DESIGN_CONSISTENCY_SCORE" -ge 85 ]; then
  log_info "‚úÖ Score de consistencia de dise√±o: $DESIGN_CONSISTENCY_SCORE/100"
else
  log_info "üí° Mejorar consistencia: usar unidades uniformes, limitar paleta de colores"
fi

# An√°lisis de optimizaci√≥n de red y cach√©
log_section "üåê An√°lisis de Optimizaci√≥n de Red y Cach√©"

NETWORK_OPTIMIZATION_SCORE=100
NETWORK_OPTIMIZATION_ISSUES=0
NO_CACHE_HINTS=0
LARGE_UNCOMPRESSED=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local file_size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo "0")
    
    # Verificar si hay hints de cach√© (no directamente en SVG, pero puede estar en meta)
    # Detectar archivos grandes sin compresi√≥n
    if [ "$file_size" -gt 50000 ] && ! grep -qiE 'compressed|gzip|br' "$svg_file" 2>/dev/null; then
      LARGE_UNCOMPRESSED=$((LARGE_UNCOMPRESSED + 1))
      NETWORK_OPTIMIZATION_SCORE=$((NETWORK_OPTIMIZATION_SCORE - 5))
      NETWORK_OPTIMIZATION_ISSUES=$((NETWORK_OPTIMIZATION_ISSUES + 1))
    fi
    
    # Verificar uso de sprites o inline (optimizaci√≥n de requests)
    if ! grep -qiE 'sprite|inline|data:image' "$svg_file" 2>/dev/null && [ "$file_size" -lt 1000 ]; then
      NO_CACHE_HINTS=$((NO_CACHE_HINTS + 1))
      NETWORK_OPTIMIZATION_SCORE=$((NETWORK_OPTIMIZATION_SCORE - 1))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets grandes sin compresi√≥n: $LARGE_UNCOMPRESSED"
log_info "Assets peque√±os sin optimizaci√≥n inline: $NO_CACHE_HINTS"

if [ "$NETWORK_OPTIMIZATION_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de optimizaci√≥n de red: $NETWORK_OPTIMIZATION_SCORE/100"
else
  log_info "üí° Optimizar red: comprimir archivos grandes, usar sprites/inline para peque√±os"
fi

# An√°lisis de compatibilidad m√≥vil avanzada
log_section "üì± An√°lisis de Compatibilidad M√≥vil Avanzada"

MOBILE_ADVANCED_SCORE=100
MOBILE_ADVANCED_ISSUES=0
SMALL_TOUCH_TARGETS=0
NO_MOBILE_OPTIMIZATION=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar touch targets (botones interactivos deben ser ‚â•44x44px)
    local buttons=$(grep -oE '<rect.*width="([0-9]+)".*height="([0-9]+)"|button.*width="([0-9]+)".*height="([0-9]+)"' "$svg_file" 2>/dev/null || echo "")
    if [ -n "$buttons" ]; then
      local button_width=$(echo "$buttons" | grep -oE 'width="([0-9]+)"' | head -1 | grep -oE '[0-9]+')
      local button_height=$(echo "$buttons" | grep -oE 'height="([0-9]+)"' | head -1 | grep -oE '[0-9]+')
      
      if [ -n "$button_width" ] && [ -n "$button_height" ]; then
        if [ "$button_width" -lt 44 ] || [ "$button_height" -lt 44 ]; then
          SMALL_TOUCH_TARGETS=$((SMALL_TOUCH_TARGETS + 1))
          MOBILE_ADVANCED_SCORE=$((MOBILE_ADVANCED_SCORE - 5))
          MOBILE_ADVANCED_ISSUES=$((MOBILE_ADVANCED_ISSUES + 1))
        fi
      fi
    fi
    
    # Verificar si tiene viewBox (esencial para m√≥vil)
    if ! grep -q 'viewBox=' "$svg_file" 2>/dev/null; then
      NO_MOBILE_OPTIMIZATION=$((NO_MOBILE_OPTIMIZATION + 1))
      MOBILE_ADVANCED_SCORE=$((MOBILE_ADVANCED_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con touch targets peque√±os: $SMALL_TOUCH_TARGETS"
log_info "Assets sin optimizaci√≥n m√≥vil: $NO_MOBILE_OPTIMIZATION"

if [ "$MOBILE_ADVANCED_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de compatibilidad m√≥vil avanzada: $MOBILE_ADVANCED_SCORE/100"
else
  log_info "üí° Mejorar m√≥vil: touch targets ‚â•44px, usar viewBox, considerar breakpoints"
fi

# An√°lisis de impacto en m√©tricas de negocio digitales
log_section "üìä An√°lisis de Impacto en M√©tricas de Negocio Digitales"

BUSINESS_DIGITAL_SCORE=0
CONVERSION_OPTIMIZATION=0
USER_ENGAGEMENT=0
BRAND_CONSISTENCY=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar elementos de optimizaci√≥n de conversi√≥n
    if grep -qiE 'cta|button|call.*action|inscrib|registr|compr|buy|order' "$svg_file" 2>/dev/null; then
      CONVERSION_OPTIMIZATION=$((CONVERSION_OPTIMIZATION + 1))
      BUSINESS_DIGITAL_SCORE=$((BUSINESS_DIGITAL_SCORE + 15))
    fi
    
    # Detectar elementos de engagement
    if grep -qiE 'social|share|like|comment|follow|subscribe' "$svg_file" 2>/dev/null; then
      USER_ENGAGEMENT=$((USER_ENGAGEMENT + 1))
      BUSINESS_DIGITAL_SCORE=$((BUSINESS_DIGITAL_SCORE + 10))
    fi
    
    # Verificar consistencia de branding
    if grep -qiE 'logo|brand|marca|trademark' "$svg_file" 2>/dev/null; then
      BRAND_CONSISTENCY=$((BRAND_CONSISTENCY + 1))
      BUSINESS_DIGITAL_SCORE=$((BUSINESS_DIGITAL_SCORE + 5))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$BUSINESS_DIGITAL_SCORE" -gt 100 ]; then
  BUSINESS_DIGITAL_SCORE=100
fi

log_info "Assets con optimizaci√≥n de conversi√≥n: $CONVERSION_OPTIMIZATION"
log_info "Assets con elementos de engagement: $USER_ENGAGEMENT"
log_info "Assets con branding consistente: $BRAND_CONSISTENCY"

if [ "$BUSINESS_DIGITAL_SCORE" -ge 50 ]; then
  log_info "‚úÖ Score de m√©tricas digitales: $BUSINESS_DIGITAL_SCORE/100"
else
  log_info "üí° Mejorar m√©tricas digitales: a√±adir CTAs, elementos sociales, branding consistente"
fi

# An√°lisis de preparaci√≥n para A/B testing
log_section "üß™ An√°lisis de Preparaci√≥n para A/B Testing"

AB_TESTING_SCORE=0
AB_READY_COUNT=0
TRACKING_EVENTS=0
VARIANT_READY=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local ready=0
    
    # Verificar si tiene tracking de eventos
    if grep -qiE 'trackEvent|analytics|gtag|data-track|data-test' "$svg_file" 2>/dev/null; then
      TRACKING_EVENTS=$((TRACKING_EVENTS + 1))
      ready=$((ready + 1))
    fi
    
    # Verificar si tiene identificadores para variantes
    if grep -qiE 'variant|version|test|ab' "$svg_file" 2>/dev/null || echo "$svg_file" | grep -qiE 'variant|version|test|ab'; then
      VARIANT_READY=$((VARIANT_READY + 1))
      ready=$((ready + 1))
    fi
    
    # Verificar si tiene elementos medibles (CTAs, botones)
    if grep -qiE 'cta|button|click|conversion' "$svg_file" 2>/dev/null; then
      ready=$((ready + 1))
    fi
    
    if [ "$ready" -ge 2 ]; then
      AB_READY_COUNT=$((AB_READY_COUNT + 1))
      AB_TESTING_SCORE=$((AB_TESTING_SCORE + 10))
    fi
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$AB_TESTING_SCORE" -gt 100 ]; then
  AB_TESTING_SCORE=100
fi

log_info "Assets listos para A/B testing: $AB_READY_COUNT/50"
log_info "Assets con tracking de eventos: $TRACKING_EVENTS"
log_info "Assets con variantes identificadas: $VARIANT_READY"

if [ "$AB_TESTING_SCORE" -ge 30 ]; then
  log_info "‚úÖ Score de preparaci√≥n A/B testing: $AB_TESTING_SCORE/100"
else
  log_info "üí° Preparar para A/B testing: a√±adir tracking, identificar variantes, elementos medibles"
fi

# Generaci√≥n de √≠ndice de calidad global mejorado
log_section "‚≠ê √çndice de Calidad Global Mejorado"

# Calcular √≠ndice compuesto mejorado
QUALITY_INDEX=$(((
  ${HEALTH_SCORE:-100} * 20 +
  ${ACCESSIBILITY_SCORE:-100} * 15 +
  ${PERFORMANCE_SCORE:-100} * 15 +
  ${SECURITY_ADV_SCORE:-100} * 15 +
  ${MAINTAINABILITY_SCORE:-100} * 10 +
  ${CWV_SCORE:-100} * 10 +
  ${WCAG_22_SCORE:-100} * 10 +
  ${PE_SCORE:-100} * 5
) / 100))

if [ "$QUALITY_INDEX" -gt 100 ]; then
  QUALITY_INDEX=100
fi

QUALITY_LEVEL=""
QUALITY_COLOR=""
if [ "$QUALITY_INDEX" -ge 90 ]; then
  QUALITY_LEVEL="‚≠ê EXCELENTE"
  QUALITY_COLOR="üü¢"
elif [ "$QUALITY_INDEX" -ge 75 ]; then
  QUALITY_LEVEL="‚≠ê MUY BUENO"
  QUALITY_COLOR="üü°"
elif [ "$QUALITY_INDEX" -ge 60 ]; then
  QUALITY_LEVEL="‚≠ê ACEPTABLE"
  QUALITY_COLOR="üü†"
else
  QUALITY_LEVEL="‚≠ê REQUIERE MEJORAS"
  QUALITY_COLOR="üî¥"
fi

log_info "$QUALITY_COLOR √çndice de Calidad Global: $QUALITY_INDEX/100 - $QUALITY_LEVEL"
log_info "   Componentes: Health(${HEALTH_SCORE:-100}) Accessibility(${ACCESSIBILITY_SCORE:-100}) Performance(${PERFORMANCE_SCORE:-100}) Security(${SECURITY_ADV_SCORE:-100})"

# An√°lisis de calidad de c√≥digo y est√°ndares
log_section "üîç An√°lisis de Calidad de C√≥digo y Est√°ndares"

CODE_QUALITY_SCORE=100
CODE_QUALITY_ISSUES=0
INCONSISTENT_STYLING=0
POOR_STRUCTURE=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar estructura y formato consistente
    local line_count=$(wc -l < "$svg_file" 2>/dev/null | xargs)
    local indentation_issues=$(grep -cE '^[^<]*[<>]' "$svg_file" 2>/dev/null || echo "0")
    
    # Detectar inconsistencias de estilo (mezcla de comillas simples/dobles)
    local single_quotes=$(grep -cE "='[^']*'" "$svg_file" 2>/dev/null || echo "0")
    local double_quotes=$(grep -cE '="[^"]*"' "$svg_file" 2>/dev/null || echo "0")
    
    if [ "$single_quotes" -gt 0 ] && [ "$double_quotes" -gt 0 ]; then
      INCONSISTENT_STYLING=$((INCONSISTENT_STYLING + 1))
      CODE_QUALITY_SCORE=$((CODE_QUALITY_SCORE - 2))
      CODE_QUALITY_ISSUES=$((CODE_QUALITY_ISSUES + 1))
    fi
    
    # Detectar estructura pobre (l√≠neas muy largas, falta de organizaci√≥n)
    local long_lines=$(awk 'length > 200' "$svg_file" 2>/dev/null | wc -l | xargs)
    if [ "$long_lines" -gt 10 ]; then
      POOR_STRUCTURE=$((POOR_STRUCTURE + 1))
      CODE_QUALITY_SCORE=$((CODE_QUALITY_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con estilo inconsistente: $INCONSISTENT_STYLING"
log_info "Assets con estructura pobre: $POOR_STRUCTURE"

if [ "$CODE_QUALITY_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de calidad de c√≥digo: $CODE_QUALITY_SCORE/100"
else
  log_info "üí° Mejorar calidad de c√≥digo: usar estilo consistente, mejorar estructura"
fi

# An√°lisis de cumplimiento legal y regulaciones
log_section "‚öñÔ∏è  An√°lisis de Cumplimiento Legal y Regulaciones"

LEGAL_COMPLIANCE_SCORE=100
LEGAL_COMPLIANCE_ISSUES=0
NO_ATTRIBUTION=0
COPYRIGHT_ISSUES=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar atribuci√≥n de contenido (licencias, cr√©ditos)
    if ! grep -qiE 'copyright|license|attribution|credit|¬©|¬Æ' "$svg_file" 2>/dev/null; then
      # Verificar si tiene elementos que podr√≠an requerir atribuci√≥n
      if grep -qiE 'font|icon|logo' "$svg_file" 2>/dev/null; then
        NO_ATTRIBUTION=$((NO_ATTRIBUTION + 1))
        LEGAL_COMPLIANCE_SCORE=$((LEGAL_COMPLIANCE_SCORE - 3))
        LEGAL_COMPLIANCE_ISSUES=$((LEGAL_COMPLIANCE_ISSUES + 1))
      fi
    fi
    
    # Detectar posibles problemas de copyright
    if grep -qiE 'trademark|¬Æ|copyright' "$svg_file" 2>/dev/null && ! grep -qiE 'license|permission|authorized' "$svg_file" 2>/dev/null; then
      COPYRIGHT_ISSUES=$((COPYRIGHT_ISSUES + 1))
      LEGAL_COMPLIANCE_SCORE=$((LEGAL_COMPLIANCE_SCORE - 5))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets sin atribuci√≥n: $NO_ATTRIBUTION"
log_info "Assets con posibles problemas de copyright: $COPYRIGHT_ISSUES"

if [ "$LEGAL_COMPLIANCE_SCORE" -ge 95 ]; then
  log_info "‚úÖ Score de cumplimiento legal: $LEGAL_COMPLIANCE_SCORE/100"
else
  log_info "‚ö†Ô∏è  Score de cumplimiento legal: $LEGAL_COMPLIANCE_SCORE/100 - Revisar licencias y atribuciones"
fi

# An√°lisis de impacto ambiental y sostenibilidad
log_section "üåç An√°lisis de Impacto Ambiental y Sostenibilidad"

ENVIRONMENTAL_SCORE=100
ENVIRONMENTAL_ISSUES=0
HIGH_ENERGY_CONSUMPTION=0
LARGE_CARBON_FOOTPRINT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local file_size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo "0")
    
    # Archivos grandes = m√°s transferencia = m√°s energ√≠a
    if [ "$file_size" -gt 200000 ]; then  # >200KB
      HIGH_ENERGY_CONSUMPTION=$((HIGH_ENERGY_CONSUMPTION + 1))
      ENVIRONMENTAL_SCORE=$((ENVIRONMENTAL_SCORE - 5))
      ENVIRONMENTAL_ISSUES=$((ENVIRONMENTAL_ISSUES + 1))
      LARGE_CARBON_FOOTPRINT=$((LARGE_CARBON_FOOTPRINT + 1))
    fi
    
    # Detectar animaciones complejas (consumen CPU = m√°s energ√≠a)
    local complex_anims=$(grep -cE '<animate.*dur="[0-9]+\.[0-9]+"|@keyframes|animation-duration' "$svg_file" 2>/dev/null || echo "0")
    if [ "$complex_anims" -gt 15 ]; then
      HIGH_ENERGY_CONSUMPTION=$((HIGH_ENERGY_CONSUMPTION + 1))
      ENVIRONMENTAL_SCORE=$((ENVIRONMENTAL_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con alto consumo de energ√≠a: $HIGH_ENERGY_CONSUMPTION"
log_info "Assets con huella de carbono alta: $LARGE_CARBON_FOOTPRINT"

if [ "$ENVIRONMENTAL_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de impacto ambiental: $ENVIRONMENTAL_SCORE/100"
else
  log_info "üí° Reducir impacto ambiental: optimizar tama√±o, simplificar animaciones"
fi

# An√°lisis de preparaci√≥n para escalamiento
log_section "üìà An√°lisis de Preparaci√≥n para Escalamiento"

SCALABILITY_PREP_SCORE=100
SCALABILITY_PREP_ISSUES=0
NO_LOAD_BALANCING=0
HARDCODED_CONFIGS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar configuraciones hardcodeadas que dificultan escalamiento
    local hardcoded_domains=$(grep -cE 'http://[a-z]+\.com|https://[a-z]+\.com|localhost:8080|127\.0\.0\.1' "$svg_file" 2>/dev/null || echo "0")
    if [ "$hardcoded_domains" -gt 2 ]; then
      HARDCODED_CONFIGS=$((HARDCODED_CONFIGS + 1))
      SCALABILITY_PREP_SCORE=$((SCALABILITY_PREP_SCORE - 5))
      SCALABILITY_PREP_ISSUES=$((SCALABILITY_PREP_ISSUES + 1))
    fi
    
    # Verificar si usa CDN o recursos distribuidos (preparado para load balancing)
    if ! grep -qiE 'cdn|cloudfront|cloudflare|s3|storage' "$svg_file" 2>/dev/null && grep -qiE 'http://|https://' "$svg_file" 2>/dev/null; then
      NO_LOAD_BALANCING=$((NO_LOAD_BALANCING + 1))
      SCALABILITY_PREP_SCORE=$((SCALABILITY_PREP_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con configuraciones hardcodeadas: $HARDCODED_CONFIGS"
log_info "Assets sin preparaci√≥n para load balancing: $NO_LOAD_BALANCING"

if [ "$SCALABILITY_PREP_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de preparaci√≥n para escalamiento: $SCALABILITY_PREP_SCORE/100"
else
  log_info "üí° Preparar para escalamiento: usar configs din√°micas, CDN, recursos distribuidos"
fi

# An√°lisis de resiliencia y recuperaci√≥n ante fallos
log_section "üõ°Ô∏è  An√°lisis de Resiliencia y Recuperaci√≥n"

RESILIENCE_SCORE=100
RESILIENCE_ISSUES=0
NO_FALLBACKS=0
SINGLE_POINT_FAILURE=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar fallbacks para recursos externos
    local external_resources=$(grep -cE 'http://|https://' "$svg_file" 2>/dev/null || echo "0")
    local fallbacks=$(grep -cE 'fallback|backup|alternative|onerror' "$svg_file" 2>/dev/null || echo "0")
    
    if [ "$external_resources" -gt 0 ] && [ "$fallbacks" -eq 0 ]; then
      NO_FALLBACKS=$((NO_FALLBACKS + 1))
      RESILIENCE_SCORE=$((RESILIENCE_SCORE - 5))
      RESILIENCE_ISSUES=$((RESILIENCE_ISSUES + 1))
      SINGLE_POINT_FAILURE=$((SINGLE_POINT_FAILURE + 1))
    fi
    
    # Verificar dependencias cr√≠ticas sin alternativas
    if grep -qiE 'googleapis|jquery|cdnjs' "$svg_file" 2>/dev/null && [ "$fallbacks" -eq 0 ]; then
      SINGLE_POINT_FAILURE=$((SINGLE_POINT_FAILURE + 1))
      RESILIENCE_SCORE=$((RESILIENCE_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets sin fallbacks: $NO_FALLBACKS"
log_info "Assets con puntos √∫nicos de fallo: $SINGLE_POINT_FAILURE"

if [ "$RESILIENCE_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de resiliencia: $RESILIENCE_SCORE/100"
else
  log_info "üí° Mejorar resiliencia: a√±adir fallbacks, evitar dependencias √∫nicas"
fi

# An√°lisis de preparaci√≥n para internacionalizaci√≥n avanzada
log_section "üåê An√°lisis de Internacionalizaci√≥n Avanzada"

I18N_ADVANCED_SCORE=100
I18N_ADVANCED_ISSUES=0
HARDCODED_LOCALE=0
NO_RTL_SUPPORT=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Detectar texto hardcodeado con localizaci√≥n impl√≠cita
    if grep -qiE '\bespa√±ol\b|\benglish\b|‚Ç¨|\$|USD|EUR' "$svg_file" 2>/dev/null && ! grep -qiE 'i18n|locale|lang|translate' "$svg_file" 2>/dev/null; then
      HARDCODED_LOCALE=$((HARDCODED_LOCALE + 1))
      I18N_ADVANCED_SCORE=$((I18N_ADVANCED_SCORE - 5))
      I18N_ADVANCED_ISSUES=$((I18N_ADVANCED_ISSUES + 1))
    fi
    
    # Verificar soporte RTL (Right-to-Left)
    if grep -qiE '<text|<tspan' "$svg_file" 2>/dev/null && ! grep -qiE 'dir=|rtl|ltr|textDirection' "$svg_file" 2>/dev/null; then
      NO_RTL_SUPPORT=$((NO_RTL_SUPPORT + 1))
      I18N_ADVANCED_SCORE=$((I18N_ADVANCED_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con localizaci√≥n hardcodeada: $HARDCODED_LOCALE"
log_info "Assets sin soporte RTL: $NO_RTL_SUPPORT"

if [ "$I18N_ADVANCED_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de internacionalizaci√≥n avanzada: $I18N_ADVANCED_SCORE/100"
else
  log_info "üí° Mejorar i18n: usar variables de localizaci√≥n, a√±adir soporte RTL"
fi

# An√°lisis de optimizaci√≥n para buscadores avanzado
log_section "üîé An√°lisis de Optimizaci√≥n para Buscadores Avanzado"

SEO_ADVANCED_SCORE=100
SEO_ADVANCED_ISSUES=0
MISSING_MICRODATA=0
NO_OPENGRAPH=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar microdata (schema.org)
    if ! grep -qiE 'itemscope|itemtype|itemprop|schema\.org' "$svg_file" 2>/dev/null; then
      MISSING_MICRODATA=$((MISSING_MICRODATA + 1))
      SEO_ADVANCED_SCORE=$((SEO_ADVANCED_SCORE - 5))
      SEO_ADVANCED_ISSUES=$((SEO_ADVANCED_ISSUES + 1))
    fi
    
    # Verificar Open Graph tags (para compartir en redes sociales)
    if grep -qiE '<title>|<desc>' "$svg_file" 2>/dev/null && ! grep -qiE 'og:|property="og' "$svg_file" 2>/dev/null; then
      NO_OPENGRAPH=$((NO_OPENGRAPH + 1))
      SEO_ADVANCED_SCORE=$((SEO_ADVANCED_SCORE - 3))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets sin microdata: $MISSING_MICRODATA"
log_info "Assets sin Open Graph: $NO_OPENGRAPH"

if [ "$SEO_ADVANCED_SCORE" -ge 90 ]; then
  log_info "‚úÖ Score de SEO avanzado: $SEO_ADVANCED_SCORE/100"
else
  log_info "üí° Mejorar SEO: a√±adir microdata schema.org, Open Graph tags"
fi

# Generar dashboard de m√©tricas consolidadas
log_section "üìä Generaci√≥n de Dashboard de M√©tricas Consolidadas"

DASHBOARD_METRICS_FILE="${REPORT%.txt}_metrics_dashboard.txt"
{
  echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
  echo "‚ïë          DASHBOARD DE M√âTRICAS CONSOLIDADAS                 ‚ïë"
  echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
  echo ""
  echo "üìÖ Fecha: $(date '+%Y-%m-%d %H:%M:%S')"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìä M√âTRICAS T√âCNICAS"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "  Health Score:           ${HEALTH_SCORE:-100}/100"
  echo "  Accessibility:         ${ACCESSIBILITY_SCORE:-100}/100"
  echo "  Performance:           ${PERFORMANCE_SCORE:-100}/100"
  echo "  Security:              ${SECURITY_ADV_SCORE:-100}/100"
  echo "  Mantenibilidad:        ${MAINTAINABILITY_SCORE:-100}/100"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üé® M√âTRICAS DE DISE√ëO"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "  Arquitectura:          ${ARCHITECTURE_SCORE:-100}/100"
  echo "  Consistencia dise√±o:   ${DESIGN_CONSISTENCY_SCORE:-100}/100"
  echo "  Calidad c√≥digo:        ${CODE_QUALITY_SCORE:-100}/100"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üöÄ M√âTRICAS DE NEGOCIO"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "  M√©tricas digitales:    ${BUSINESS_DIGITAL_SCORE:-0}/100"
  echo "  A/B Testing ready:    ${AB_TESTING_SCORE:-0}/100"
  echo "  Producci√≥n ready:     ${PRODUCTION_READY_SCORE:-0}/100"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üåç M√âTRICAS DE COMPLIANCE Y SOSTENIBILIDAD"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "  Cumplimiento legal:    ${LEGAL_COMPLIANCE_SCORE:-100}/100"
  echo "  Impacto ambiental:     ${ENVIRONMENTAL_SCORE:-100}/100"
  echo "  Resiliencia:           ${RESILIENCE_SCORE:-100}/100"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üåê M√âTRICAS DE ESCALAMIENTO Y GLOBALIZACI√ìN"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "  Escalamiento:          ${SCALABILITY_PREP_SCORE:-100}/100"
  echo "  Internacionalizaci√≥n:  ${I18N_ADVANCED_SCORE:-100}/100"
  echo "  SEO Avanzado:          ${SEO_ADVANCED_SCORE:-100}/100"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "$QUALITY_COLOR √çNDICE DE CALIDAD GLOBAL: $QUALITY_INDEX/100 - $QUALITY_LEVEL"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
} > "$DASHBOARD_METRICS_FILE" 2>/dev/null || true

log_info "‚úÖ Dashboard de m√©tricas generado: $DASHBOARD_METRICS_FILE"

# An√°lisis de anal√≠tica avanzada y tracking
log_section "üìà An√°lisis de Anal√≠tica Avanzada y Tracking"

ANALYTICS_ADVANCED_SCORE=0
ANALYTICS_ADVANCED_ISSUES=0
EVENT_TRACKING=0
CONVERSION_TRACKING=0
USER_JOURNEY_TRACKING=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local tracking_score=0
    
    # Detectar tracking de eventos
    if grep -qiE 'trackEvent|analytics\.track|gtag\(|dataLayer\.push' "$svg_file" 2>/dev/null; then
      EVENT_TRACKING=$((EVENT_TRACKING + 1))
      tracking_score=$((tracking_score + 20))
    fi
    
    # Detectar tracking de conversiones
    if grep -qiE 'conversion|purchase|checkout|signup|subscribe|register' "$svg_file" 2>/dev/null && grep -qiE 'track|analytics|gtag' "$svg_file" 2>/dev/null; then
      CONVERSION_TRACKING=$((CONVERSION_TRACKING + 1))
      tracking_score=$((tracking_score + 30))
    fi
    
    # Detectar tracking de user journey (clicks, scrolls, tiempo)
    if grep -qiE 'pageview|scroll|time|duration|engagement' "$svg_file" 2>/dev/null && grep -qiE 'track|analytics' "$svg_file" 2>/dev/null; then
      USER_JOURNEY_TRACKING=$((USER_JOURNEY_TRACKING + 1))
      tracking_score=$((tracking_score + 25))
    fi
    
    ANALYTICS_ADVANCED_SCORE=$((ANALYTICS_ADVANCED_SCORE + tracking_score))
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$ANALYTICS_ADVANCED_SCORE" -gt 100 ]; then
  ANALYTICS_ADVANCED_SCORE=100
fi

log_info "Assets con tracking de eventos: $EVENT_TRACKING"
log_info "Assets con tracking de conversiones: $CONVERSION_TRACKING"
log_info "Assets con tracking de user journey: $USER_JOURNEY_TRACKING"

if [ "$ANALYTICS_ADVANCED_SCORE" -ge 50 ]; then
  log_info "‚úÖ Score de anal√≠tica avanzada: $ANALYTICS_ADVANCED_SCORE/100"
else
  log_info "üí° Mejorar anal√≠tica: a√±adir tracking de eventos, conversiones y user journey"
fi

# An√°lisis de optimizaci√≥n de conversi√≥n avanzada
log_section "üí° An√°lisis de Optimizaci√≥n de Conversi√≥n Avanzada"

CONVERSION_OPTIMIZATION_SCORE=0
CONVERSION_OPTIMIZATION_ISSUES=0
CLEAR_CTAS=0
URGENCY_ELEMENTS=0
TRUST_INDICATORS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local conversion_score=0
    
    # Detectar CTAs claros y visibles
    if grep -qiE '(button|cta|call.*action).*inscrib|registr|compr|comenzar|empezar|probar' "$svg_file" 2>/dev/null; then
      CLEAR_CTAS=$((CLEAR_CTAS + 1))
      conversion_score=$((conversion_score + 25))
    fi
    
    # Detectar elementos de urgencia
    if grep -qiE '(limitado|√∫ltimo|solo.*hoy|oferta.*termina|agotado|stock.*limitado)' "$svg_file" 2>/dev/null; then
      URGENCY_ELEMENTS=$((URGENCY_ELEMENTS + 1))
      conversion_score=$((conversion_score + 20))
    fi
    
    # Detectar indicadores de confianza
    if grep -qiE '(garant√≠a|satisfacci√≥n|reembolso|seguro|certificado|verificado|recomendado)' "$svg_file" 2>/dev/null; then
      TRUST_INDICATORS=$((TRUST_INDICATORS + 1))
      conversion_score=$((conversion_score + 15))
    fi
    
    CONVERSION_OPTIMIZATION_SCORE=$((CONVERSION_OPTIMIZATION_SCORE + conversion_score))
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$CONVERSION_OPTIMIZATION_SCORE" -gt 100 ]; then
  CONVERSION_OPTIMIZATION_SCORE=100
fi

log_info "Assets con CTAs claros: $CLEAR_CTAS"
log_info "Assets con elementos de urgencia: $URGENCY_ELEMENTS"
log_info "Assets con indicadores de confianza: $TRUST_INDICATORS"

if [ "$CONVERSION_OPTIMIZATION_SCORE" -ge 40 ]; then
  log_info "‚úÖ Score de optimizaci√≥n de conversi√≥n: $CONVERSION_OPTIMIZATION_SCORE/100"
else
  log_info "üí° Mejorar conversi√≥n: a√±adir CTAs claros, elementos de urgencia, indicadores de confianza"
fi

# An√°lisis de usabilidad avanzada
log_section "üë• An√°lisis de Usabilidad Avanzada"

USABILITY_ADVANCED_SCORE=100
USABILITY_ADVANCED_ISSUES=0
POOR_READABILITY=0
MISSING_HELP_TEXT=0
COMPLEX_INTERACTIONS=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    # Verificar legibilidad (tama√±o de fuente)
    local small_text=$(grep -oE 'font-size="([0-9]+)px"' "$svg_file" 2>/dev/null | grep -oE '[0-9]+' | awk '$1 < 12' | wc -l | xargs)
    if [ "$small_text" -gt 3 ]; then
      POOR_READABILITY=$((POOR_READABILITY + 1))
      USABILITY_ADVANCED_SCORE=$((USABILITY_ADVANCED_SCORE - 5))
      USABILITY_ADVANCED_ISSUES=$((USABILITY_ADVANCED_ISSUES + 1))
    fi
    
    # Verificar ayuda contextual (tooltips, hints)
    local interactive_elements=$(grep -cE 'button|href=|onclick' "$svg_file" 2>/dev/null || echo "0")
    local help_elements=$(grep -cE 'title=|aria-label|tooltip|help|hint' "$svg_file" 2>/dev/null || echo "0")
    
    if [ "$interactive_elements" -gt 0 ] && [ "$help_elements" -lt "$interactive_elements" ]; then
      MISSING_HELP_TEXT=$((MISSING_HELP_TEXT + 1))
      USABILITY_ADVANCED_SCORE=$((USABILITY_ADVANCED_SCORE - 3))
    fi
    
    # Detectar interacciones complejas (m√∫ltiples pasos, formularios largos)
    local form_elements=$(grep -cE 'input|select|textarea|form' "$svg_file" 2>/dev/null || echo "0")
    if [ "$form_elements" -gt 5 ]; then
      COMPLEX_INTERACTIONS=$((COMPLEX_INTERACTIONS + 1))
      USABILITY_ADVANCED_SCORE=$((USABILITY_ADVANCED_SCORE - 4))
    fi
  fi
done < <(find "$ROOT_DIR" -name "*.svg" -type f -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null | head -30)

log_info "Assets con legibilidad pobre: $POOR_READABILITY"
log_info "Assets sin ayuda contextual: $MISSING_HELP_TEXT"
log_info "Assets con interacciones complejas: $COMPLEX_INTERACTIONS"

if [ "$USABILITY_ADVANCED_SCORE" -ge 85 ]; then
  log_info "‚úÖ Score de usabilidad avanzada: $USABILITY_ADVANCED_SCORE/100"
else
  log_info "üí° Mejorar usabilidad: aumentar tama√±o de fuente, a√±adir ayuda, simplificar interacciones"
fi

# An√°lisis de preparaci√≥n para analytics de negocio
log_section "üìä An√°lisis de Preparaci√≥n para Analytics de Negocio"

BUSINESS_ANALYTICS_SCORE=0
BUSINESS_ANALYTICS_ISSUES=0
REVENUE_TRACKING=0
CUSTOMER_JOURNEY=0
FUNNEL_TRACKING=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local analytics_score=0
    
    # Detectar tracking de ingresos
    if grep -qiE '(precio|precio|cost|revenue|ingresos|venta|purchase|checkout).*track|analytics' "$svg_file" 2>/dev/null; then
      REVENUE_TRACKING=$((REVENUE_TRACKING + 1))
      analytics_score=$((analytics_score + 30))
    fi
    
    # Detectar customer journey (p√°ginas vistas, navegaci√≥n)
    if grep -qiE '(pageview|navigation|journey|flow|path).*track|analytics' "$svg_file" 2>/dev/null; then
      CUSTOMER_JOURNEY=$((CUSTOMER_JOURNEY + 1))
      analytics_score=$((analytics_score + 25))
    fi
    
    # Detectar funnel tracking (etapas de conversi√≥n)
    if grep -qiE '(funnel|stage|step|stage).*track|analytics|conversion' "$svg_file" 2>/dev/null; then
      FUNNEL_TRACKING=$((FUNNEL_TRACKING + 1))
      analytics_score=$((analytics_score + 20))
    fi
    
    BUSINESS_ANALYTICS_SCORE=$((BUSINESS_ANALYTICS_SCORE + analytics_score))
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$BUSINESS_ANALYTICS_SCORE" -gt 100 ]; then
  BUSINESS_ANALYTICS_SCORE=100
fi

log_info "Assets con tracking de ingresos: $REVENUE_TRACKING"
log_info "Assets con customer journey: $CUSTOMER_JOURNEY"
log_info "Assets con funnel tracking: $FUNNEL_TRACKING"

if [ "$BUSINESS_ANALYTICS_SCORE" -ge 40 ]; then
  log_info "‚úÖ Score de analytics de negocio: $BUSINESS_ANALYTICS_SCORE/100"
else
  log_info "üí° Mejorar analytics de negocio: a√±adir tracking de ingresos, customer journey, funnels"
fi

# An√°lisis de preparaci√≥n para personalizaci√≥n
log_section "üéØ An√°lisis de Preparaci√≥n para Personalizaci√≥n"

PERSONALIZATION_SCORE=0
PERSONALIZATION_ISSUES=0
USER_PREFERENCES=0
DYNAMIC_CONTENT=0
SEGMENTATION=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local personalization_score=0
    
    # Detectar soporte para preferencias de usuario
    if grep -qiE '(user|preference|setting|config|customize).*data|localStorage|sessionStorage' "$svg_file" 2>/dev/null; then
      USER_PREFERENCES=$((USER_PREFERENCES + 1))
      personalization_score=$((personalization_score + 25))
    fi
    
    # Detectar contenido din√°mico
    if grep -qiE '(dynamic|template|variable|\$\{|{{|#{).*content|data-.*content' "$svg_file" 2>/dev/null; then
      DYNAMIC_CONTENT=$((DYNAMIC_CONTENT + 1))
      personalization_score=$((personalization_score + 30))
    fi
    
    # Detectar segmentaci√≥n
    if grep -qiE '(segment|audience|target|cohort|persona).*data|analytics' "$svg_file" 2>/dev/null; then
      SEGMENTATION=$((SEGMENTATION + 1))
      personalization_score=$((personalization_score + 20))
    fi
    
    PERSONALIZATION_SCORE=$((PERSONALIZATION_SCORE + personalization_score))
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$PERSONALIZATION_SCORE" -gt 100 ]; then
  PERSONALIZATION_SCORE=100
fi

log_info "Assets con preferencias de usuario: $USER_PREFERENCES"
log_info "Assets con contenido din√°mico: $DYNAMIC_CONTENT"
log_info "Assets con segmentaci√≥n: $SEGMENTATION"

if [ "$PERSONALIZATION_SCORE" -ge 30 ]; then
  log_info "‚úÖ Score de personalizaci√≥n: $PERSONALIZATION_SCORE/100"
else
  log_info "üí° Mejorar personalizaci√≥n: a√±adir preferencias, contenido din√°mico, segmentaci√≥n"
fi

# An√°lisis de preparaci√≥n para integraciones de marketing
log_section "üîó An√°lisis de Preparaci√≥n para Integraciones de Marketing"

MARKETING_INTEGRATION_SCORE=0
MARKETING_INTEGRATION_ISSUES=0
EMAIL_MARKETING=0
CRM_INTEGRATION=0
SOCIAL_MEDIA=0

while IFS= read -r svg_file; do
  if [ -f "$svg_file" ] && [ -s "$svg_file" ]; then
    local marketing_score=0
    
    # Detectar integraci√≥n con email marketing
    if grep -qiE '(mailchimp|sendgrid|mailgun|email.*api|newsletter|subscribe)' "$svg_file" 2>/dev/null; then
      EMAIL_MARKETING=$((EMAIL_MARKETING + 1))
      marketing_score=$((marketing_score + 30))
    fi
    
    # Detectar integraci√≥n con CRM
    if grep -qiE '(salesforce|hubspot|crm|contact.*api|customer.*api)' "$svg_file" 2>/dev/null; then
      CRM_INTEGRATION=$((CRM_INTEGRATION + 1))
      marketing_score=$((marketing_score + 25))
    fi
    
    # Detectar integraci√≥n con redes sociales
    if grep -qiE '(facebook|twitter|linkedin|instagram|share.*api|social.*api)' "$svg_file" 2>/dev/null; then
      SOCIAL_MEDIA=$((SOCIAL_MEDIA + 1))
      marketing_score=$((marketing_score + 20))
    fi
    
    MARKETING_INTEGRATION_SCORE=$((MARKETING_INTEGRATION_SCORE + marketing_score))
  fi
done < <(find "$ROOT_DIR/ads" -name "*.svg" -type f 2>/dev/null | head -50)

if [ "$MARKETING_INTEGRATION_SCORE" -gt 100 ]; then
  MARKETING_INTEGRATION_SCORE=100
fi

log_info "Assets con email marketing: $EMAIL_MARKETING"
log_info "Assets con CRM: $CRM_INTEGRATION"
log_info "Assets con redes sociales: $SOCIAL_MEDIA"

if [ "$MARKETING_INTEGRATION_SCORE" -ge 30 ]; then
  log_info "‚úÖ Score de integraciones de marketing: $MARKETING_INTEGRATION_SCORE/100"
else
  log_info "üí° Mejorar integraciones: a√±adir email marketing, CRM, redes sociales"
fi

# Generar resumen ejecutivo final consolidado
log_section "üìã Generaci√≥n de Resumen Ejecutivo Final"

EXECUTIVE_SUMMARY_FILE="${REPORT%.txt}_executive_summary.txt"
{
  echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
  echo "‚ïë          RESUMEN EJECUTIVO - AN√ÅLISIS DE ASSETS           ‚ïë"
  echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
  echo ""
  echo "üìÖ Fecha: $(date '+%Y-%m-%d %H:%M:%S')"
  echo "üìä Total Assets Analizados: ${TOTAL_SVGS:-0}"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "$QUALITY_COLOR ESTADO GENERAL: $QUALITY_LEVEL"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo ""
  echo "üìà √çndice de Calidad Global: $QUALITY_INDEX/100"
  echo ""
  echo "üéØ FORTALEZAS PRINCIPALES:"
  [ "${HEALTH_SCORE:-100}" -ge 85 ] && echo "  ‚úÖ Health Score: ${HEALTH_SCORE:-100}/100"
  [ "${ACCESSIBILITY_SCORE:-100}" -ge 80 ] && echo "  ‚úÖ Accesibilidad: ${ACCESSIBILITY_SCORE:-100}/100"
  [ "${PERFORMANCE_SCORE:-100}" -ge 85 ] && echo "  ‚úÖ Performance: ${PERFORMANCE_SCORE:-100}/100"
  [ "${SECURITY_ADV_SCORE:-100}" -ge 95 ] && echo "  ‚úÖ Seguridad: ${SECURITY_ADV_SCORE:-100}/100"
  [ "${BUSINESS_DIGITAL_SCORE:-0}" -ge 50 ] && echo "  ‚úÖ M√©tricas de Negocio: ${BUSINESS_DIGITAL_SCORE:-0}/100"
  echo ""
  echo "‚ö†Ô∏è  √ÅREAS DE MEJORA PRIORITARIAS:"
  [ "${HEALTH_SCORE:-100}" -lt 75 ] && echo "  üî¥ Health Score bajo: ${HEALTH_SCORE:-100}/100"
  [ "${ACCESSIBILITY_SCORE:-100}" -lt 70 ] && echo "  üî¥ Accesibilidad requiere atenci√≥n: ${ACCESSIBILITY_SCORE:-100}/100"
  [ "${PERFORMANCE_SCORE:-100}" -lt 75 ] && echo "  üî¥ Performance mejorable: ${PERFORMANCE_SCORE:-100}/100"
  [ "${SECURITY_ADV_ISSUES:-0}" -gt 0 ] && echo "  üî¥ ${SECURITY_ADV_ISSUES} issue(s) de seguridad detectado(s)"
  [ "${BROKEN_SVGS:-0}" -gt 5 ] && echo "  üî¥ ${BROKEN_SVGS} SVG(s) roto(s)"
  echo ""
  echo "üí° RECOMENDACIONES ESTRAT√âGICAS:"
  [ "${ANALYTICS_ADVANCED_SCORE:-0}" -lt 50 ] && echo "  ‚Ä¢ Implementar anal√≠tica avanzada y tracking de conversiones"
  [ "${CONVERSION_OPTIMIZATION_SCORE:-0}" -lt 40 ] && echo "  ‚Ä¢ Optimizar elementos de conversi√≥n (CTAs, urgencia, confianza)"
  [ "${AB_TESTING_SCORE:-0}" -lt 30 ] && echo "  ‚Ä¢ Preparar assets para A/B testing"
  [ "${PERSONALIZATION_SCORE:-0}" -lt 30 ] && echo "  ‚Ä¢ A√±adir capacidades de personalizaci√≥n"
  [ "${MARKETING_INTEGRATION_SCORE:-0}" -lt 30 ] && echo "  ‚Ä¢ Integrar con plataformas de marketing (email, CRM, social)"
  echo ""
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìÑ Reportes completos disponibles:"
  echo "   ‚Ä¢ Reporte detallado: $REPORT"
  echo "   ‚Ä¢ Dashboard de m√©tricas: $DASHBOARD_METRICS_FILE"
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
} > "$EXECUTIVE_SUMMARY_FILE" 2>/dev/null || true

log_info "‚úÖ Resumen ejecutivo generado: $EXECUTIVE_SUMMARY_FILE"

# Actualizar resumen final con todas las nuevas m√©tricas
echo "WCAG 2.2: ${WCAG_22_SCORE:-100}/100 | Core Web Vitals: ${CWV_SCORE:-100}/100 | Dark Mode: ${DARK_MODE_SCORE:-0}/100" >> "$REPORT"
echo "Progressive Enhancement: ${PE_SCORE:-100}/100 | Mantenibilidad: ${MAINTAINABILITY_SCORE:-100}/100" >> "$REPORT"
echo "Testing: ${TESTING_SCORE:-0}/100 (${COVERAGE_SCORE:-0}% cobertura) | Documentaci√≥n t√©cnica: ${DOC_TECH_SCORE:-100}/100" >> "$REPORT"
echo "Coherencia de mensajes: ${MESSAGE_CONSISTENCY_ISSUES:-0} issue(s) | Contenido obsoleto: ${OBSOLETE_CONTENT:-0} item(s)" >> "$REPORT"
echo "Arquitectura: ${ARCHITECTURE_SCORE:-100}/100 | Consistencia dise√±o: ${DESIGN_CONSISTENCY_SCORE:-100}/100 | Optimizaci√≥n red: ${NETWORK_OPTIMIZATION_SCORE:-100}/100" >> "$REPORT"
echo "M√≥vil avanzado: ${MOBILE_ADVANCED_SCORE:-100}/100 | M√©tricas digitales: ${BUSINESS_DIGITAL_SCORE:-0}/100 | A/B Testing: ${AB_TESTING_SCORE:-0}/100" >> "$REPORT"
echo "Calidad c√≥digo: ${CODE_QUALITY_SCORE:-100}/100 | Cumplimiento legal: ${LEGAL_COMPLIANCE_SCORE:-100}/100 | Impacto ambiental: ${ENVIRONMENTAL_SCORE:-100}/100" >> "$REPORT"
echo "Escalamiento: ${SCALABILITY_PREP_SCORE:-100}/100 | Resiliencia: ${RESILIENCE_SCORE:-100}/100 | i18n Avanzado: ${I18N_ADVANCED_SCORE:-100}/100" >> "$REPORT"
echo "SEO Avanzado: ${SEO_ADVANCED_SCORE:-100}/100 | Anal√≠tica avanzada: ${ANALYTICS_ADVANCED_SCORE:-0}/100 | Optimizaci√≥n conversi√≥n: ${CONVERSION_OPTIMIZATION_SCORE:-0}/100" >> "$REPORT"
echo "Usabilidad avanzada: ${USABILITY_ADVANCED_SCORE:-100}/100 | Analytics negocio: ${BUSINESS_ANALYTICS_SCORE:-0}/100 | Personalizaci√≥n: ${PERSONALIZATION_SCORE:-0}/100" >> "$REPORT"
echo "Integraciones marketing: ${MARKETING_INTEGRATION_SCORE:-0}/100" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"
echo "$QUALITY_COLOR √çNDICE DE CALIDAD GLOBAL: $QUALITY_INDEX/100 - $QUALITY_LEVEL" >> "$REPORT"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" >> "$REPORT"

exit "$EXIT_STATUS"
