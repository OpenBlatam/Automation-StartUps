#!/usr/bin/env bash
set -euo pipefail
# Analiza los assets y genera reporte con estad√≠sticas

ROOT_DIR="$(cd "$(dirname "$0")/.." && pwd)"
SRC_DIR="${SRC_DIR:-$ROOT_DIR/design/instagram}"
EXPORT_DIR="${EXPORT_DIR:-$ROOT_DIR/exports}"
REPORT="${REPORT:-$EXPORT_DIR/assets_report.txt}"
OUTPUT_FORMAT="${OUTPUT_FORMAT:-text}"

# Flags por CLI (opcionales):
#   --quiet / -q                 ‚Üí QUIET=true (no imprime todo en consola)
#   --summary-only / -s          ‚Üí SUMMARY_ONLY=true (imprime resumen)
#   --output-format / -o         ‚Üí OUTPUT_FORMAT=[text|all|html|csv|json]
#   --report / -r FILE           ‚Üí REPORT=FILE
#   --min-score / -m N           ‚Üí MIN_HEALTH_SCORE=N (para CI)
#   --palette-strict             ‚Üí PALETTE_STRICT=true (falla si hay colores fuera de tokens)
#   --fail-on-error              ‚Üí FAIL_ON_ERROR=true (exit 2 ante errores cr√≠ticos)
#   --fail-on-warn               ‚Üí FAIL_ON_WARN=true (exit 1 ante warnings)
#   --max-dom-nodes N            ‚Üí MAX_DOM_NODES=N
#   --max-filters N              ‚Üí MAX_FILTERS=N
#   --max-gradients N            ‚Üí MAX_GRADIENTS=N
#   --help / -h                  ‚Üí muestra ayuda

QUIET="${QUIET:-false}"
SUMMARY_ONLY="${SUMMARY_ONLY:-false}"
MIN_HEALTH_SCORE="${MIN_HEALTH_SCORE:-75}"
PALETTE_STRICT="${PALETTE_STRICT:-false}"
FAIL_ON_ERROR="${FAIL_ON_ERROR:-false}"
FAIL_ON_WARN="${FAIL_ON_WARN:-false}"
MAX_DOM_NODES="${MAX_DOM_NODES:-500}"
MAX_FILTERS="${MAX_FILTERS:-5}"
MAX_GRADIENTS="${MAX_GRADIENTS:-10}"
BASELINE_FILE="${BASELINE_FILE:-}"
PROFILE="${PROFILE:-}"
LOG_LEVEL="${LOG_LEVEL:-info}"
CONTINUE_ON_ERROR="${CONTINUE_ON_ERROR:-false}"
SHOW_PERFORMANCE="${SHOW_PERFORMANCE:-true}"
AUTO_REPAIR="${AUTO_REPAIR:-false}"
USE_CACHE="${USE_CACHE:-true}"
SHOW_PROGRESS="${SHOW_PROGRESS:-true}"
GENERATE_JUNIT="${GENERATE_JUNIT:-false}"
PARALLEL_ANALYSIS="${PARALLEL_ANALYSIS:-false}"
MAX_PARALLEL="${MAX_PARALLEL:-4}"
DETECT_DUPLICATES="${DETECT_DUPLICATES:-true}"
COMPARE_HISTORY="${COMPARE_HISTORY:-true}"
GENERATE_RECOMMENDATIONS="${GENERATE_RECOMMENDATIONS:-true}"

# Sistema de logging estructurado con niveles
log_level_num() {
  case "${1:-info}" in
    debug) echo 0 ;;
    info)  echo 1 ;;
    warn)  echo 2 ;;
    error) echo 3 ;;
    *)     echo 1 ;;
  esac
}

LOG_LEVEL_NUM=$(log_level_num "$LOG_LEVEL")

_log_debug() {
  if [ "$LOG_LEVEL_NUM" -le 0 ]; then
    echo "[DEBUG] $1" >&2
  fi
}

_log_info() {
  if [ "$LOG_LEVEL_NUM" -le 1 ]; then
    echo "[INFO] $1" >&2
  fi
}

_log_warn() {
  if [ "$LOG_LEVEL_NUM" -le 2 ]; then
    echo "[WARN] $1" >&2
  fi
}

_log_error() {
  if [ "$LOG_LEVEL_NUM" -le 3 ]; then
    echo "[ERROR] $1" >&2
  fi
}

# Funci√≥n para validar n√∫mero positivo
validate_positive_number() {
  local value="$1"
  local name="$2"
  if ! [[ "$value" =~ ^[0-9]+$ ]] || [ "$value" -le 0 ]; then
    _log_error "$name debe ser un n√∫mero positivo, se recibi√≥: '$value'"
    [ "$CONTINUE_ON_ERROR" = "false" ] && exit 2
    return 1
  fi
  return 0
}

# Funci√≥n para validar formato de salida
validate_output_format() {
  local fmt="$1"
  case "$fmt" in
    text|all|html|csv|json) return 0 ;;
    *) 
      _log_error "Formato de salida inv√°lido: '$fmt'. V√°lidos: text, all, html, csv, json"
      [ "$CONTINUE_ON_ERROR" = "false" ] && exit 2
      return 1 ;;
  esac
}

# Cargar perfil de configuraci√≥n
load_profile() {
  local profile_name="$1"
  local profile_file="$ROOT_DIR/tools/profiles/${profile_name}.json"
  
  if [ ! -f "$profile_file" ]; then
    _log_warn "Perfil '$profile_name' no encontrado en $profile_file"
    return 1
  fi
  
  if command -v jq >/dev/null 2>&1; then
    _log_info "Cargando perfil: $profile_name"
    export MIN_HEALTH_SCORE=$(jq -r '.min_health_score // 75' "$profile_file" 2>/dev/null || echo "$MIN_HEALTH_SCORE")
    export MAX_DOM_NODES=$(jq -r '.max_dom_nodes // 500' "$profile_file" 2>/dev/null || echo "$MAX_DOM_NODES")
    export MAX_FILTERS=$(jq -r '.max_filters // 5' "$profile_file" 2>/dev/null || echo "$MAX_FILTERS")
    export MAX_GRADIENTS=$(jq -r '.max_gradients // 10' "$profile_file" 2>/dev/null || echo "$MAX_GRADIENTS")
    export PALETTE_STRICT=$(jq -r '.palette_strict // false' "$profile_file" 2>/dev/null || echo "$PALETTE_STRICT")
    export FAIL_ON_ERROR=$(jq -r '.fail_on_error // false' "$profile_file" 2>/dev/null || echo "$FAIL_ON_ERROR")
    export FAIL_ON_WARN=$(jq -r '.fail_on_warn // false' "$profile_file" 2>/dev/null || echo "$FAIL_ON_WARN")
    _log_info "Perfil cargado exitosamente"
  else
    _log_warn "jq no disponible, no se puede cargar perfil JSON"
    return 1
  fi
}

# Validar paths y permisos antes de procesar
validate_paths() {
  local errors=0
  
  if [ ! -d "$SRC_DIR" ]; then
    _log_error "Directorio fuente no existe: $SRC_DIR"
    errors=$((errors + 1))
  elif [ ! -r "$SRC_DIR" ]; then
    _log_error "Sin permisos de lectura en: $SRC_DIR"
    errors=$((errors + 1))
  fi
  
  if [ ! -w "$(dirname "$REPORT")" ] 2>/dev/null; then
    _log_error "Sin permisos de escritura en: $(dirname "$REPORT")"
    errors=$((errors + 1))
  fi
  
  if [ ! -w "$EXPORT_DIR" ] 2>/dev/null; then
    _log_error "Sin permisos de escritura en: $EXPORT_DIR"
    errors=$((errors + 1))
  fi
  
  if [ "$errors" -gt 0 ]; then
    _log_error "Se encontraron $errors errores de validaci√≥n"
    [ "$CONTINUE_ON_ERROR" = "false" ] && exit 1
    return 1
  fi
  
  _log_debug "Validaci√≥n de paths exitosa"
  return 0
}

print_usage() {
  cat <<USAGE
Uso: $(basename "$0") [opciones]

Opciones:
  -q, --quiet                Ejecuta en modo silencioso (resumen en consola)
  -s, --summary-only         Muestra solo resumen (no imprime reporte completo)
  -o, --output-format FMT     Formato de salida: text|all|html|csv|json (default: text)
  -r, --report FILE          Ruta del reporte principal (default: exports/assets_report.txt)
  -m, --min-score N          Umbral m√≠nimo de Health Score para √©xito (default: 75)
      --palette-strict       Falla si hay colores fuera de la paleta (tokens.json)
      --fail-on-error        Exit 2 ante errores cr√≠ticos (seguridad/rotos/inv√°lidos)
      --fail-on-warn         Exit 1 ante advertencias
      --max-dom-nodes N      Umbral de nodos DOM para advertencia (default: 500)
      --max-filters N        Umbral de filtros por archivo (default: 5)
      --max-gradients N      Umbral de gradientes por archivo (default: 10)
      --config FILE           Archivo de configuraci√≥n JSON con umbrales (default: tools/analyze_assets.config.json)
      --diff                  Compara con reporte anterior y muestra diferencias
      --slack-webhook URL     Env√≠a alertas a Slack (webhook URL)
      --teams-webhook URL     Env√≠a alertas a Microsoft Teams (webhook URL)
      --cache-dir PATH        Directorio para cach√© incremental (default: .cache/analyze_assets)
      --no-cache              Deshabilita cach√© incremental
      --no-progress            Deshabilita barras de progreso
      --auto-repair            Auto-reparar problemas detectados (experimental)
      --junit FILE             Generar salida JUnit XML para CI (default: off)
      --parallel               Usar an√°lisis paralelo (acelera procesamiento)
      --max-parallel N         M√°ximo de procesos paralelos (default: 4)
      --no-duplicates          Saltar detecci√≥n de duplicados por contenido
      --no-history             Saltar comparaci√≥n con ejecuciones anteriores
      --no-recommendations     Saltar generaci√≥n de recomendaciones inteligentes
      --xml                    Exportar reporte en formato XML
      --yaml                   Exportar reporte en formato YAML
      --compliance             Validar compliance (WCAG, etc.)
      --business-metrics       Generar m√©tricas de negocio
      --git-analysis           An√°lisis de cambios con Git
      --detect-patterns        Detectar patrones de dise√±o
      --changelog              Generar changelog autom√°tico
      --bi-export              Exportar CSV para PowerBI/Tableau
      --validate-metadata      Validaci√≥n completa de metadatos
      --generate-docs          Generar documentaci√≥n autom√°tica
      --validate-versioning    Validar versionado sem√°ntico
      --plugins                Ejecutar plugins personalizados
      --analyze-usage          An√°lisis de uso de assets
      --detect-obsolete        Detectar assets obsoletos por fecha
      --validate-branding      Validar consistencia de branding
      --alerts                 Generar alertas autom√°ticas
      --detect-duplicates      Detectar duplicados por contenido
      --analyze-complexity     An√°lisis de complejidad visual
      --generate-thumbnails    Generar thumbnails autom√°ticos
      --accessibility-adv      An√°lisis de accesibilidad avanzado
      --validate-wcag           Validaci√≥n de compliance WCAG 2.1
      --analyze-markers         An√°lisis de uso de markers y patterns
      --detect-scaling          Detecci√≥n de problemas de scaling
      --validate-css-vars       Validaci√≥n de CSS custom properties
      --analyze-foreign         An√°lisis de uso de foreignObject
      --detect-vulnerabilities  Detecci√≥n de vulnerabilidades conocidas (XXE, XSS)
      --advanced-performance    An√°lisis avanzado de performance
      --detect-orphans          Detectar assets hu√©rfanos (sin referencias)
      --markdown                Generar reporte en formato Markdown
      --analyze-dependencies  An√°lisis de dependencias entre assets
      --generate-badges        Generar badges para CI/CD (shields.io)
      --visual-similarity      An√°lisis de similitud visual entre assets
      --ascii-chart            Generar gr√°fico ASCII de m√©tricas
      --export-executive       Exportar resumen ejecutivo (JSON/YAML)
      --validate-naming        Validaci√≥n estricta de naming conventions
      --change-impact          An√°lisis de impacto de cambios (Git)
      --enhanced-summary       Generar resumen mejorado con m√©tricas y pr√≥ximos pasos (default: true)
      --no-enhanced-summary    Deshabilitar resumen mejorado
      --notifications          Enviar notificaciones a Slack/Teams al completar
      --no-notifications       Deshabilitar notificaciones (default)
  -h, --help                 Muestra esta ayuda

Ejemplos:
  # An√°lisis completo enterprise
  $0 --profile strict --security-scan --compliance --business-metrics --xml
  
  # CI/CD pipeline completo
  $0 --profile ci --fail-on-error --xml --dashboard --slack-webhook "https://..."
  
  # An√°lisis de calidad avanzado
  $0 --performance-adv --optimization-suggest --analyze-deps --yaml
  
  # An√°lisis r√°pido para desarrollo
  $0 --validate-naming --detect-orphans --quiet --output-format json
USAGE
}

while [[ ${1:-} =~ ^- ]]; do
  case "$1" in
    -q|--quiet) 
      QUIET=true; shift ;;
    -s|--summary-only) 
      SUMMARY_ONLY=true; shift ;;
    -o|--output-format)
      if [ -z "${2:-}" ]; then
        _log_error "--output-format requiere un valor"
        print_usage; exit 2
      fi
      validate_output_format "$2"
      OUTPUT_FORMAT="$2"; shift 2 ;;
    -r|--report)
      if [ -z "${2:-}" ]; then
        _log_error "--report requiere una ruta"
        print_usage; exit 2
      fi
      REPORT="$2"; shift 2 ;;
    -m|--min-score)
      if [ -z "${2:-}" ]; then
        _log_error "--min-score requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--min-score"
      MIN_HEALTH_SCORE="$2"; shift 2 ;;
    --palette-strict)
      PALETTE_STRICT=true; shift ;;
    --fail-on-error)
      FAIL_ON_ERROR=true; shift ;;
    --fail-on-warn)
      FAIL_ON_WARN=true; shift ;;
    --max-dom-nodes)
      if [ -z "${2:-}" ]; then
        _log_error "--max-dom-nodes requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-dom-nodes"
      MAX_DOM_NODES="$2"; shift 2 ;;
    --max-filters)
      if [ -z "${2:-}" ]; then
        _log_error "--max-filters requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-filters"
      MAX_FILTERS="$2"; shift 2 ;;
    --max-gradients)
      if [ -z "${2:-}" ]; then
        _log_error "--max-gradients requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-gradients"
      MAX_GRADIENTS="$2"; shift 2 ;;
    --baseline)
      if [ -z "${2:-}" ]; then
        _log_error "--baseline requiere una ruta de archivo"
        print_usage; exit 2
      fi
      if [ ! -f "$2" ]; then
        _log_warn "Archivo baseline no encontrado: $2"
      fi
      BASELINE_FILE="$2"; shift 2 ;;
    --export-dir)
      if [ -z "${2:-}" ]; then
        echo "‚ùå Error: --export-dir requiere una ruta" >&2
        print_usage; exit 2
      fi
      EXPORT_DIR="$2"
      # Actualizar REPORT si est√° en el directorio de exports por defecto
      if [[ "$REPORT" == "$ROOT_DIR/exports"* ]]; then
        REPORT="$EXPORT_DIR/assets_report.txt"
      fi
      shift 2 ;;
    --src)
      if [ -z "${2:-}" ]; then
        _log_error "--src requiere una ruta"
        print_usage; exit 2
      fi
      SRC_DIR="$2"; shift 2 ;;
    --profile)
      if [ -z "${2:-}" ]; then
        _log_error "--profile requiere un nombre de perfil"
        print_usage; exit 2
      fi
      PROFILE="$2"
      load_profile "$PROFILE" || _log_warn "Continuando con configuraci√≥n por defecto"
      shift 2 ;;
    --log-level)
      if [ -z "${2:-}" ]; then
        _log_error "--log-level requiere un nivel: debug|info|warn|error"
        print_usage; exit 2
      fi
      case "$2" in
        debug|info|warn|error) LOG_LEVEL="$2"; LOG_LEVEL_NUM=$(log_level_num "$LOG_LEVEL") ;;
        *) 
          _log_error "Nivel de log inv√°lido: $2. V√°lidos: debug|info|warn|error"
          print_usage; exit 2 ;;
      esac
      shift 2 ;;
    --continue-on-error)
      CONTINUE_ON_ERROR=true; shift ;;
    --show-performance)
      SHOW_PERFORMANCE=true; shift ;;
    --no-performance)
      SHOW_PERFORMANCE=false; shift ;;
    --cache-dir)
      if [ -z "${2:-}" ]; then
        _log_error "--cache-dir requiere una ruta"
        print_usage; exit 2
      fi
      CACHE_DIR="$2"
      USE_CACHE=true
      shift 2 ;;
    --no-cache)
      USE_CACHE=false; shift ;;
    --parallel)
      PARALLEL_ANALYSIS=true; shift ;;
    --max-parallel)
      if [ -z "${2:-}" ]; then
        _log_error "--max-parallel requiere un n√∫mero"
        print_usage; exit 2
      fi
      validate_positive_number "$2" "--max-parallel"
      MAX_PARALLEL="$2"; shift 2 ;;
    --no-duplicates)
      DETECT_DUPLICATES=false; shift ;;
    --no-history)
      COMPARE_HISTORY=false; shift ;;
    --no-recommendations)
      GENERATE_RECOMMENDATIONS=false; shift ;;
    --slack-webhook)
      if [ -z "${2:-}" ]; then
        _log_error "--slack-webhook requiere una URL"
        print_usage; exit 2
      fi
      SLACK_WEBHOOK="$2"; shift 2 ;;
    --teams-webhook)
      if [ -z "${2:-}" ]; then
        _log_error "--teams-webhook requiere una URL"
        print_usage; exit 2
      fi
      TEAMS_WEBHOOK="$2"; shift 2 ;;
    --notify-on-error)
      NOTIFY_ON_ERROR=true; shift ;;
    --notify-on-warn)
      NOTIFY_ON_WARN=true; shift ;;
    --detect-orphans)
      DETECT_ORPHANS=true; shift ;;
    --analyze-trends)
      ANALYZE_TRENDS=true; shift ;;
    --validate-naming)
      VALIDATE_NAMING=true; shift ;;
    --dashboard)
      GENERATE_DASHBOARD=true; shift ;;
    --markdown)
      EXPORT_MARKDOWN=true; shift ;;
    --analyze-deps)
      ANALYZE_DEPS=true; shift ;;
    --security-scan)
      SECURITY_SCAN=true; shift ;;
    --performance-adv)
      PERFORMANCE_ADV=true; shift ;;
    --optimization-suggest)
      OPTIMIZATION_SUGGEST=true; shift ;;
    --xml)
      EXPORT_XML=true; shift ;;
    --yaml)
      EXPORT_YAML=true; shift ;;
    --compliance)
      VALIDATE_COMPLIANCE=true; shift ;;
    --business-metrics)
      GENERATE_BUSINESS_METRICS=true; shift ;;
    --git-analysis)
      GIT_ANALYSIS=true; shift ;;
    --detect-patterns)
      DETECT_PATTERNS=true; shift ;;
    --changelog)
      GENERATE_CHANGELOG=true; shift ;;
    --bi-export)
      BI_EXPORT=true; shift ;;
    --validate-metadata)
      VALIDATE_METADATA=true; shift ;;
    --generate-docs)
      GENERATE_DOCS=true; shift ;;
    --validate-versioning)
      VALIDATE_VERSIONING=true; shift ;;
    --plugins)
      RUN_PLUGINS=true; shift ;;
    --analyze-usage)
      ANALYZE_USAGE=true; shift ;;
    --detect-obsolete)
      DETECT_OBSOLETE=true; shift ;;
    --validate-branding)
      VALIDATE_BRANDING=true; shift ;;
    --alerts)
      GENERATE_ALERTS=true; shift ;;
    --detect-duplicates)
      DETECT_DUPLICATES=true; shift ;;
    --analyze-complexity)
      ANALYZE_COMPLEXITY=true; shift ;;
    --generate-thumbnails)
      GENERATE_THUMBNAILS=true; shift ;;
    --accessibility-adv)
      ACCESSIBILITY_ADV=true; shift ;;
    --validate-wcag)
      VALIDATE_WCAG=true; shift ;;
    --analyze-markers)
      ANALYZE_MARKERS=true; shift ;;
    --detect-scaling)
      DETECT_SCALING=true; shift ;;
    --validate-css-vars)
      VALIDATE_CSS_VARS=true; shift ;;
    --analyze-foreign)
      ANALYZE_FOREIGN=true; shift ;;
    --detect-vulnerabilities)
      DETECT_VULNERABILITIES=true; shift ;;
    --advanced-performance)
      ADVANCED_PERFORMANCE=true; shift ;;
    --detect-orphans)
      DETECT_ORPHANS=true; shift ;;
    --markdown)
      GENERATE_MARKDOWN=true; shift ;;
    --analyze-dependencies)
      ANALYZE_DEPENDENCIES=true; shift ;;
    --generate-badges)
      GENERATE_BADGES=true; shift ;;
    --visual-similarity)
      VISUAL_SIMILARITY=true; shift ;;
    --ascii-chart)
      ASCII_CHART=true; shift ;;
    --export-executive)
      EXPORT_EXECUTIVE=true; shift ;;
    --validate-naming)
      VALIDATE_NAMING=true; shift ;;
    --change-impact)
      ANALYZE_CHANGE_IMPACT=true; shift ;;
    --ml-patterns)
      ANALYZE_ML_PATTERNS=true; shift ;;
    --benchmarking)
      ADVANCED_BENCHMARKING=true; shift ;;
    --business-roi)
      BUSINESS_ROI=true; shift ;;
    --roadmap)
      GENERATE_ROADMAP=true; shift ;;
    --external-api)
      EXTERNAL_API_ENABLED=true; shift ;;

    --enhanced-summary)
      GENERATE_ENHANCED_SUMMARY=true; shift ;;
    --no-enhanced-summary)
      GENERATE_ENHANCED_SUMMARY=false; shift ;;
    --notifications)
      SEND_NOTIFICATIONS=true; shift ;;
    --no-notifications)
      SEND_NOTIFICATIONS=false; shift ;;
    -h|--help)
      print_usage; exit 0 ;;
    --) shift; break ;;
    *) 
      _log_error "Opci√≥n desconocida: $1"
      print_usage; exit 2 ;;
  esac
done

# Validar paths despu√©s de procesar argumentos
validate_paths

# Asegurar que EXPORT_DIR y directorio del reporte existen
mkdir -p "$EXPORT_DIR" "$(dirname "$REPORT")"

# Tiempo de inicio
START_TIME=$(date +%s)
SECTION_TIMES=()

# Sistema de cach√© inteligente
USE_CACHE="${USE_CACHE:-true}"
CACHE_DIR="${CACHE_DIR:-$ROOT_DIR/.cache/asset_analysis}"
PARALLEL_ANALYSIS="${PARALLEL_ANALYSIS:-false}"
MAX_PARALLEL="${MAX_PARALLEL:-4}"
DETECT_DUPLICATES="${DETECT_DUPLICATES:-true}"
COMPARE_HISTORY="${COMPARE_HISTORY:-true}"
GENERATE_RECOMMENDATIONS="${GENERATE_RECOMMENDATIONS:-true}"

# Funciones de cach√©
get_file_hash() {
  local file="$1"
  if command -v md5 >/dev/null 2>&1; then
    md5 -q "$file" 2>/dev/null || echo ""
  elif command -v md5sum >/dev/null 2>&1; then
    md5sum "$file" 2>/dev/null | cut -d' ' -f1 || echo ""
  elif command -v shasum >/dev/null 2>&1; then
    shasum -a 256 "$file" 2>/dev/null | cut -d' ' -f1 || echo ""
  else
    echo ""
  fi
}

get_cache_key() {
  local file="$1"
  local hash=$(get_file_hash "$file")
  if [ -n "$hash" ]; then
    echo "${file//\//_}_$hash"
  else
    echo "${file//\//_}_$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo 0)"
  fi
}

is_cached() {
  local file="$1"
  local cache_key=$(get_cache_key "$file")
  local cache_file="$CACHE_DIR/$cache_key"
  
  if [ "$USE_CACHE" != "true" ] || [ ! -f "$cache_file" ]; then
    return 1
  fi
  
  # Verificar que el archivo no ha cambiado desde el cach√©
  local cached_time=$(stat -f%m "$cache_file" 2>/dev/null || stat -c%Y "$cache_file" 2>/dev/null || echo 0)
  local file_time=$(stat -f%m "$file" 2>/dev/null || stat -c%Y "$file" 2>/dev/null || echo 0)
  
  if [ "$file_time" -le "$cached_time" ]; then
    return 0
  fi
  
  return 1
}

save_to_cache() {
  local file="$1"
  local data="$2"
  local cache_key=$(get_cache_key "$file")
  local cache_file="$CACHE_DIR/$cache_key"
  
  if [ "$USE_CACHE" = "true" ]; then
    echo "$data" > "$cache_file" 2>/dev/null || true
  fi
}

get_from_cache() {
  local file="$1"
  local cache_key=$(get_cache_key "$file")
  local cache_file="$CACHE_DIR/$cache_key"
  
  if [ -f "$cache_file" ]; then
    cat "$cache_file" 2>/dev/null || echo ""
  else
    echo ""
  fi
}

# Inicializar cach√© si est√° habilitado
if [ "$USE_CACHE" = "true" ]; then
  mkdir -p "$CACHE_DIR"
  _log_debug "Cach√© habilitado: $CACHE_DIR"
fi

# Variables para notificaciones
SLACK_WEBHOOK="${SLACK_WEBHOOK:-}"
TEAMS_WEBHOOK="${TEAMS_WEBHOOK:-}"
NOTIFY_ON_ERROR="${NOTIFY_ON_ERROR:-false}"
NOTIFY_ON_WARN="${NOTIFY_ON_WARN:-false}"

# Funciones de notificaci√≥n
send_slack_notification() {
  local message="$1"
  local webhook="${SLACK_WEBHOOK}"
  
  if [ -z "$webhook" ]; then
    return 1
  fi
  
  local color="good"
  if echo "$message" | grep -q "‚ö†Ô∏è\|‚ùå\|ERROR"; then
    color="danger"
  elif echo "$message" | grep -q "‚ö†Ô∏è\|WARN"; then
    color="warning"
  fi
  
  local payload=$(cat <<EOF
{
  "text": "Asset Analysis Report",
  "attachments": [{
    "color": "$color",
    "text": "$message",
    "footer": "Asset Analyzer",
    "ts": $(date +%s)
  }]
}
EOF
)
  
  curl -s -X POST -H 'Content-type: application/json' \
    --data "$payload" "$webhook" >/dev/null 2>&1 || return 1
}

send_teams_notification() {
  local message="$1"
  local webhook="${TEAMS_WEBHOOK}"
  
  if [ -z "$webhook" ]; then
    return 1
  fi
  
  local theme_color="28a745"
  if echo "$message" | grep -q "‚ö†Ô∏è\|‚ùå\|ERROR"; then
    theme_color="dc3545"
  elif echo "$message" | grep -q "‚ö†Ô∏è\|WARN"; then
    theme_color="ffc107"
  fi
  
  local payload=$(cat <<EOF
{
  "@type": "MessageCard",
  "@context": "https://schema.org/extensions",
  "summary": "Asset Analysis Report",
  "themeColor": "$theme_color",
  "sections": [{
    "activityTitle": "Asset Analysis Report",
    "text": "$message",
    "markdown": true
  }]
}
EOF
)
  
  curl -s -X POST -H 'Content-type: application/json' \
    --data "$payload" "$webhook" >/dev/null 2>&1 || return 1
}

# Detecci√≥n de archivos hu√©rfanos (no referenciados)
detect_orphan_files() {
  local orphans_tmp=$(mktemp)
  local orphan_count=0
  
  _log_debug "Analizando archivos hu√©rfanos..."
  
  # Buscar SVGs que no est√°n referenciados en CSV, HTML u otros archivos
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local filename=$(basename "$svg_file")
    local relative_path="${svg_file#$ROOT_DIR/}"
    
    # Verificar referencias en CSV
    local in_csv=false
    if [ -f "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" ]; then
      if grep -q "$filename\|$relative_path" "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" 2>/dev/null; then
        in_csv=true
      fi
    fi
    
    # Verificar referencias en otros archivos
    local referenced=false
    if find "$ROOT_DIR" -name "*.svg" -o -name "*.html" -o -name "*.md" -o -name "*.js" -o -name "*.json" 2>/dev/null | \
       xargs grep -l "$filename" 2>/dev/null | grep -v "^$svg_file$" | head -1 | grep -q .; then
      referenced=true
    fi
    
    if [ "$in_csv" = false ] && [ "$referenced" = false ]; then
      echo "$svg_file" >> "$orphans_tmp"
      orphan_count=$((orphan_count + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if [ "$orphan_count" -gt 0 ]; then
    log_info "Archivos hu√©rfanos encontrados: $orphan_count"
    head -10 "$orphans_tmp" | while read -r orphan; do
      log_info "  ‚Ä¢ $orphan"
    done
    [ "$orphan_count" -gt 10 ] && log_info "  ... y $((orphan_count - 10)) m√°s"
    
    # Exportar lista completa
    ORPHANS_JSON="$EXPORT_DIR/orphan_files.json"
    if command -v jq >/dev/null 2>&1; then
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"orphan_count\": $orphan_count,"
        echo "  \"files\": ["
        FIRST=true
        while read -r f; do
          [ "$FIRST" = false ] && echo ","
          echo "    \"$f\""
          FIRST=false
        done < "$orphans_tmp"
        echo "  ]"
        echo "}"
      } > "$ORPHANS_JSON" 2>/dev/null && log_info "üìä Lista JSON: $ORPHANS_JSON"
    fi
    
    rm -f "$orphans_tmp"
    return 0
  else
    rm -f "$orphans_tmp"
    return 1
  fi
}

# An√°lisis de tendencias temporales (si hay historial)
analyze_trends() {
  if [ "$COMPARE_HISTORY" != "true" ]; then
    return 0
  fi
  
  local history_dir="$EXPORT_DIR/history"
  mkdir -p "$history_dir"
  
  # Guardar m√©tricas actuales para comparaci√≥n futura
  local metrics_file="$history_dir/metrics_$(date +%Y%m%d).json"
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"date\": \"$(date +%Y-%m-%d)\","
      echo "  \"total_svgs\": $TOTAL_SVGS,"
      echo "  \"health_score\": $HEALTH_SCORE,"
      echo "  \"empty_svgs\": ${EMPTY_SVGS:-0},"
      echo "  \"broken_svgs\": ${BROKEN_SVGS:-0},"
      echo "  \"security_issues\": ${SECURITY_ISSUES:-0},"
      echo "  \"coverage_percent\": ${COVERAGE_PERCENT:-0}"
      echo "}"
    } > "$metrics_file" 2>/dev/null || true
    
    # Analizar tendencias si hay archivos previos
    local prev_files=$(find "$history_dir" -name "metrics_*.json" -type f | sort | tail -7)
    if [ -n "$prev_files" ] && [ "$(echo "$prev_files" | wc -l | xargs)" -ge 2 ]; then
      _log_debug "Analizando tendencias de $(echo "$prev_files" | wc -l | xargs) puntos de datos"
    fi
  fi
}

# Validaci√≥n de naming conventions
validate_naming_conventions() {
  local violations=0
  local violations_tmp=$(mktemp)
  
  _log_debug "Validando convenciones de nombres..."
  
  # Patrones esperados: lowercase, underscores, n√∫meros
  local valid_pattern='^[a-z0-9_]+(-[a-z0-9_]+)*\.svg$'
  
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    local basename=$(basename "$svg_file")
    
    # Verificar patrones comunes de violaci√≥n
    local issues=()
    
    # Espacios en nombres
    if echo "$basename" | grep -q ' '; then
      issues+=("contiene espacios")
    fi
    
    # May√∫sculas
    if echo "$basename" | grep -q '[A-Z]'; then
      issues+=("contiene may√∫sculas")
    fi
    
    # Caracteres especiales no permitidos
    if echo "$basename" | grep -qE '[^a-z0-9_\-\.]'; then
      issues+=("contiene caracteres especiales")
    fi
    
    # Nombres muy largos (>100 chars)
    if [ "${#basename}" -gt 100 ]; then
      issues+=("nombre muy largo (${#basename} chars)")
    fi
    
    # Nombres muy cortos (<3 chars sin extensi√≥n)
    local name_no_ext="${basename%.svg}"
    if [ "${#name_no_ext}" -lt 3 ]; then
      issues+=("nombre muy corto")
    fi
    
    if [ ${#issues[@]} -gt 0 ]; then
      echo "$svg_file|${issues[*]}" >> "$violations_tmp"
      violations=$((violations + 1))
    fi
  done
  
  local violation_count=$(wc -l < "$violations_tmp" | xargs)
  
  if [ "$violation_count" -gt 0 ]; then
    return 0
  else
    rm -f "$violations_tmp"
    return 1
  fi
}

# Generar dashboard HTML interactivo mejorado
generate_interactive_dashboard() {
  local dashboard_file="$EXPORT_DIR/dashboard.html"
  
  cat > "$dashboard_file" <<'DASHBOARD_EOF'
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>üìä Asset Analysis Dashboard</title>
  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      padding: 20px;
      min-height: 100vh;
    }
    .container { max-width: 1400px; margin: 0 auto; }
    .header {
      background: white; padding: 30px; border-radius: 15px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.2); margin-bottom: 30px;
    }
    .stats-grid {
      display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 20px; margin-bottom: 30px;
    }
    .stat-card {
      background: white; padding: 25px; border-radius: 15px;
      box-shadow: 0 5px 15px rgba(0,0,0,0.1); transition: transform 0.3s;
    }
    .stat-card:hover { transform: translateY(-5px); }
    .stat-card h3 {
      color: #666; font-size: 0.9em; text-transform: uppercase;
      letter-spacing: 1px; margin-bottom: 10px;
    }
    .stat-card .value {
      color: #333; font-size: 2.5em; font-weight: bold;
    }
    .chart-container {
      background: white; padding: 25px; border-radius: 15px;
      box-shadow: 0 5px 15px rgba(0,0,0,0.1); margin-bottom: 30px;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>üìä Asset Analysis Dashboard</h1>
      <p>Generated: DASHBOARD_TIMESTAMP</p>
    </div>
    <div class="stats-grid">
      <div class="stat-card">
        <h3>Total Assets</h3>
        <div class="value">DASHBOARD_TOTAL_SVGS</div>
      </div>
      <div class="stat-card">
        <h3>Health Score</h3>
        <div class="value">DASHBOARD_HEALTH_SCORE</div>
      </div>
      <div class="stat-card">
        <h3>Coverage</h3>
        <div class="value">DASHBOARD_COVERAGE%</div>
      </div>
      <div class="stat-card">
        <h3>Issues</h3>
        <div class="value">DASHBOARD_ISSUES</div>
      </div>
    </div>
    <div class="chart-container">
      <canvas id="healthChart"></canvas>
    </div>
  </div>
  <script>
    const ctx = document.getElementById('healthChart').getContext('2d');
    new Chart(ctx, {
      type: 'bar',
      data: {
        labels: ['Health Score', 'Coverage', 'Performance'],
        datasets: [{
          label: 'Metrics',
          data: [DASHBOARD_HEALTH_SCORE, DASHBOARD_COVERAGE, 85],
          backgroundColor: ['#28a745', '#17a2b8', '#ffc107']
        }]
      },
      options: {
        responsive: true,
        scales: { y: { beginAtZero: true, max: 100 } }
      }
    });
  </script>
</body>
</html>
DASHBOARD_EOF
  
  # Reemplazar placeholders
  sed -i.bak \
    -e "s|DASHBOARD_TIMESTAMP|$(date '+%Y-%m-%d %H:%M:%S')|g" \
    -e "s|DASHBOARD_TOTAL_SVGS|${TOTAL_SVGS:-0}|g" \
    -e "s|DASHBOARD_HEALTH_SCORE|${HEALTH_SCORE:-0}|g" \
    -e "s|DASHBOARD_COVERAGE|${COVERAGE_PERCENT:-0}|g" \
    -e "s|DASHBOARD_ISSUES|$(( ${EMPTY_SVGS:-0} + ${BROKEN_SVGS:-0} + ${SECURITY_ISSUES:-0} ))|g" \
    "$dashboard_file" 2>/dev/null || true
  
  rm -f "${dashboard_file}.bak" 2>/dev/null || true
  
  if [ -f "$dashboard_file" ]; then
    echo "$dashboard_file"
    return 0
  fi
  return 1
}

# Exportar a Markdown
export_to_markdown() {
  local md_file="${REPORT%.txt}.md"
  
  {
    echo "# üìä Asset Analysis Report"
    echo ""
    echo "**Generated:** $(date '+%Y-%m-%d %H:%M:%S')"
    echo ""
    echo "## Summary"
    echo ""
    echo "| Metric | Value |"
    echo "|--------|-------|"
    echo "| Total SVGs | ${TOTAL_SVGS:-0} |"
    echo "| Health Score | ${HEALTH_SCORE:-0}/100 |"
    echo "| Empty SVGs | ${EMPTY_SVGS:-0} |"
    echo "| Broken SVGs | ${BROKEN_SVGS:-0} |"
    echo "| Security Issues | ${SECURITY_ISSUES:-0} |"
    echo "| Coverage | ${COVERAGE_PERCENT:-0}% |"
    echo ""
    echo "## Full Report"
    echo ""
    echo "\`\`\`"
    cat "$REPORT"
    echo "\`\`\`"
  } > "$md_file" 2>/dev/null || return 1
  
  if [ -f "$md_file" ]; then
    echo "$md_file"
    return 0
  fi
  return 1
}

# An√°lisis de dependencias entre archivos
analyze_dependencies() {
  local deps_file="$EXPORT_DIR/dependencies.json"
  local deps_count=0
  
  _log_debug "Analizando dependencias entre archivos..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"dependencies\": ["
      
      FIRST=true
      find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
        [ ! -f "$svg_file" ] && continue
        
        # Buscar referencias a otros archivos
        local references=$(grep -oE 'href=["'\'']([^"'\'']+)["'\'']|xlink:href=["'\'']([^"'\'']+)["'\'']|url\(([^)]+)\)' "$svg_file" 2>/dev/null || true)
        
        if [ -n "$references" ]; then
          if [ "$FIRST" = false ]; then
            echo ","
          fi
          
          echo "    {"
          echo "      \"file\": \"${svg_file#$ROOT_DIR/}\","
          echo "      \"references\": ["
          
          FIRST_REF=true
          echo "$references" | grep -oE 'href=["'\'']([^"'\'']+)["'\'']|xlink:href=["'\'']([^"'\'']+)["'\'']|url\(([^)]+)\)' | while read -r ref; do
            local ref_path=$(echo "$ref" | sed -E 's/.*["'\'']([^"'\'']+)["'\''].*/\1/' | sed -E 's/url\(([^)]+)\)/\1/')
            
            if [ -n "$ref_path" ]; then
              if [ "$FIRST_REF" = false ]; then
                echo ","
              fi
              echo "        \"$ref_path\""
              FIRST_REF=false
              deps_count=$((deps_count + 1))
            fi
          done
          
          echo "      ]"
          echo "    }"
          FIRST=false
        fi
      done
      
      echo "  ],"
      echo "  \"total_dependencies\": $deps_count"
      echo "}"
    } > "$deps_file" 2>/dev/null || true
    
    if [ -f "$deps_file" ]; then
      echo "$deps_file"
      return 0
    fi
  fi
  
  return 1
}

# Detecci√≥n avanzada de vulnerabilidades
detect_vulnerabilities() {
  local vuln_count=0
  local vuln_tmp=$(mktemp)
  
  _log_debug "Detectando vulnerabilidades de seguridad..."
  
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local issues=()
    
    # Script tags (XSS potencial)
    if grep -qiE '<script[^>]*>' "$svg_file" 2>/dev/null; then
      issues+=("Contiene tags <script> (riesgo XSS)")
    fi
    
    # Event handlers inline
    if grep -qiE 'on\w+\s*=' "$svg_file" 2>/dev/null; then
      issues+=("Event handlers inline (riesgo XSS)")
    fi
    
    # Links a dominios externos no confiables
    if grep -qiE 'href=["'\'']http://[^"'\'']+["'\'']' "$svg_file" 2>/dev/null; then
      issues+=("Enlaces HTTP no seguros")
    fi
    
    # Data URIs sospechosos
    if grep -qiE 'data:.*base64.*eval|data:.*javascript' "$svg_file" 2>/dev/null; then
      issues+=("Data URIs potencialmente peligrosos")
    fi
    
    # Inclusi√≥n de archivos externos sin validar
    if grep -qiE '<image[^>]*href=["'\'']http' "$svg_file" 2>/dev/null; then
      issues+=("Im√°genes desde URLs externas")
    fi
    
    if [ ${#issues[@]} -gt 0 ]; then
      echo "$svg_file|${issues[*]}" >> "$vuln_tmp"
      vuln_count=$((vuln_count + 1))
    fi
  done
  
  local total_vulns=$(wc -l < "$vuln_tmp" | xargs)
  
  if [ "$total_vulns" -gt 0 ]; then
    log_info "‚ö†Ô∏è  Vulnerabilidades detectadas: $total_vulns archivos"
    head -5 "$vuln_tmp" | while IFS='|' read -r file issues; do
      log_info "  ‚Ä¢ $(basename "$file"): $issues"
    done
    
    # Exportar a JSON
    if command -v jq >/dev/null 2>&1; then
      VULN_JSON="$EXPORT_DIR/vulnerabilities.json"
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"vulnerability_count\": $total_vulns,"
        echo "  \"vulnerabilities\": ["
        FIRST=true
        while IFS='|' read -r file issues; do
          [ "$FIRST" = false ] && echo ","
          echo "    {"
          echo "      \"file\": \"$file\","
          echo "      \"issues\": [$(echo "$issues" | sed 's/ /", "/g' | sed 's/^/"/' | sed 's/$/"/')]"
          echo "    }"
          FIRST=false
        done < "$vuln_tmp"
        echo "  ]"
        echo "}"
      } > "$VULN_JSON" 2>/dev/null && log_info "üìä Vulnerabilidades JSON: $VULN_JSON"
    fi
    
    rm -f "$vuln_tmp"
    return 0
  else
    rm -f "$vuln_tmp"
    return 1
  fi
}

# An√°lisis de performance avanzado
analyze_performance_advanced() {
  local perf_tmp=$(mktemp)
  local slow_files=0
  
  _log_debug "An√°lisis avanzado de performance..."
  
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_size=$(stat -f%z "$svg_file" 2>/dev/null || stat -c%s "$svg_file" 2>/dev/null || echo 0)
    local node_count=$(grep -oE '<[^/>]+>' "$svg_file" 2>/dev/null | wc -l | xargs)
    local filter_count=$(grep -c '<filter>' "$svg_file" 2>/dev/null || echo 0)
    local gradient_count=$(grep -cE '<linearGradient|<radialGradient>' "$svg_file" 2>/dev/null || echo 0)
    
    # Calcular score de performance (0-100, mayor es mejor)
    local perf_score=100
    
    # Penalizar por tama√±o
    if [ "$file_size" -gt 500000 ]; then
      perf_score=$((perf_score - 20))
    elif [ "$file_size" -gt 200000 ]; then
      perf_score=$((perf_score - 10))
    fi
    
    # Penalizar por complejidad
    if [ "$node_count" -gt "$MAX_DOM_NODES" ]; then
      perf_score=$((perf_score - 15))
    fi
    
    if [ "$filter_count" -gt "$MAX_FILTERS" ]; then
      perf_score=$((perf_score - 10))
    fi
    
    if [ "$gradient_count" -gt "$MAX_GRADIENTS" ]; then
      perf_score=$((perf_score - 5))
    fi
    
    if [ "$perf_score" -lt 70 ]; then
      echo "$svg_file|$file_size|$node_count|$perf_score" >> "$perf_tmp"
      slow_files=$((slow_files + 1))
    fi
  done
  
  local total_slow=$(wc -l < "$perf_tmp" | xargs)
  
  if [ "$total_slow" -gt 0 ]; then
    return 0
  else
    rm -f "$perf_tmp"
    return 1
  fi
}

# Generar sugerencias de optimizaci√≥n autom√°tica
generate_optimization_suggestions() {
  local suggestions_file="$EXPORT_DIR/optimization_suggestions.json"
  
  _log_debug "Generando sugerencias de optimizaci√≥n..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"suggestions\": ["
      
      FIRST=true
      
      # Sugerencia 1: Archivos grandes
      if [ "${LARGE_COUNT:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"size_optimization\","
        echo "      \"priority\": \"high\","
        echo "      \"title\": \"Optimizar archivos grandes\","
        echo "      \"description\": \"${LARGE_COUNT:-0} archivos superan 500KB. Considera usar SVGO para optimizar.\","
        echo "      \"action\": \"Ejecutar: svgo --folder . --recursive\""
        echo "    }"
        FIRST=false
      fi
      
      # Sugerencia 2: Duplicados
      if [ "${DUPLICATE_GROUPS:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"deduplication\","
        echo "      \"priority\": \"medium\","
        echo "      \"title\": \"Eliminar archivos duplicados\","
        echo "      \"description\": \"${DUPLICATE_GROUPS:-0} grupos de duplicados detectados. Puedes eliminar redundancias.\","
        echo "      \"action\": \"Revisar exports/duplicates.json\""
        echo "    }"
        FIRST=false
      fi
      
      # Sugerencia 3: Accesibilidad
      if [ "${NO_ACCESSIBILITY:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"accessibility\","
        echo "      \"priority\": \"high\","
        echo "      \"title\": \"Mejorar accesibilidad\","
        echo "      \"description\": \"${NO_ACCESSIBILITY:-0} archivos sin atributos de accesibilidad. A√±ade aria-label y <title>.\","
        echo "      \"action\": \"A√±adir aria-label y <title> a todos los SVGs\""
        echo "    }"
        FIRST=false
      fi
      
      echo "  ]"
      echo "}"
    } > "$suggestions_file" 2>/dev/null || true
    
    if [ -f "$suggestions_file" ]; then
      echo "$suggestions_file"
      return 0
    fi
  fi
  
  return 1
}

# Exportar a XML para herramientas de CI/CD
export_to_xml() {
  local xml_file="${REPORT%.txt}.xml"
  
  {
    echo "<?xml version=\"1.0\" encoding=\"UTF-8\"?>"
    echo "<asset-analysis>"
    echo "  <timestamp>$(date -u +"%Y-%m-%dT%H:%M:%SZ")</timestamp>"
    echo "  <summary>"
    echo "    <total-svgs>${TOTAL_SVGS:-0}</total-svgs>"
    echo "    <health-score>${HEALTH_SCORE:-0}</health-score>"
    echo "    <empty-svgs>${EMPTY_SVGS:-0}</empty-svgs>"
    echo "    <broken-svgs>${BROKEN_SVGS:-0}</broken-svgs>"
    echo "    <security-issues>${SECURITY_ISSUES:-0}</security-issues>"
    echo "    <coverage-percent>${COVERAGE_PERCENT:-0}</coverage-percent>"
    echo "  </summary>"
    echo "  <issues>"
    [ "${EMPTY_SVGS:-0}" -gt 0 ] && echo "    <empty-svgs count=\"${EMPTY_SVGS:-0}\" severity=\"warning\"/>"
    [ "${BROKEN_SVGS:-0}" -gt 0 ] && echo "    <broken-svgs count=\"${BROKEN_SVGS:-0}\" severity=\"error\"/>"
    [ "${SECURITY_ISSUES:-0}" -gt 0 ] && echo "    <security-issues count=\"${SECURITY_ISSUES:-0}\" severity=\"critical\"/>"
    echo "  </issues>"
    echo "</asset-analysis>"
  } > "$xml_file" 2>/dev/null || return 1
  
  if [ -f "$xml_file" ]; then
    echo "$xml_file"
    return 0
  fi
  return 1
}

# Exportar a YAML
export_to_yaml() {
  local yaml_file="${REPORT%.txt}.yaml"
  
  {
    echo "---"
    echo "generated_at: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
    echo "summary:"
    echo "  total_svgs: ${TOTAL_SVGS:-0}"
    echo "  health_score: ${HEALTH_SCORE:-0}"
    echo "  empty_svgs: ${EMPTY_SVGS:-0}"
    echo "  broken_svgs: ${BROKEN_SVGS:-0}"
    echo "  security_issues: ${SECURITY_ISSUES:-0}"
    echo "  coverage_percent: ${COVERAGE_PERCENT:-0}"
    echo "issues:"
    echo "  empty_svgs: ${EMPTY_SVGS:-0}"
    echo "  broken_svgs: ${BROKEN_SVGS:-0}"
    echo "  security_issues: ${SECURITY_ISSUES:-0}"
    echo "  missing_accessibility: ${NO_ACCESSIBILITY:-0}"
  } > "$yaml_file" 2>/dev/null || return 1
  
  if [ -f "$yaml_file" ]; then
    echo "$yaml_file"
    return 0
  fi
  return 1
}

# Validaci√≥n de compliance (WCAG, etc.)
validate_compliance() {
  local compliance_file="$EXPORT_DIR/compliance_report.json"
  local wcag_score=0
  local wcag_issues=0
  
  _log_debug "Validando compliance con est√°ndares..."
  
  # Verificar WCAG 2.1 AA b√°sico
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    # Verificar contraste (simplificado - verificar si tiene texto)
    if grep -q '<text' "$svg_file" 2>/dev/null; then
      # Verificar si tiene aria-label o title para texto
      if ! grep -qiE 'aria-label|<title>|<desc>' "$svg_file" 2>/dev/null; then
        wcag_issues=$((wcag_issues + 1))
      fi
    fi
    
    # Verificar si tiene roles ARIA apropiados
    if ! grep -qiE 'role=|aria-' "$svg_file" 2>/dev/null; then
      wcag_issues=$((wcag_issues + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | head -100)
  
  # Calcular score (100 - (issues * 2))
  wcag_score=$((100 - (wcag_issues * 2)))
  [ "$wcag_score" -lt 0 ] && wcag_score=0
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"compliance\": {"
      echo "    \"wcag_2_1_aa\": {"
      echo "      \"score\": $wcag_score,"
      echo "      \"issues\": $wcag_issues,"
      echo "      \"status\": \"$([ "$wcag_score" -ge 80 ] && echo "compliant" || echo "needs_improvement")\""
      echo "    }"
      echo "  }"
      echo "}"
    } > "$compliance_file" 2>/dev/null || true
    
    if [ -f "$compliance_file" ]; then
      echo "$compliance_file"
      return 0
    fi
  fi
  
  return 1
}

# Generar m√©tricas de negocio
generate_business_metrics() {
  local business_file="$EXPORT_DIR/business_metrics.json"
  
  _log_debug "Generando m√©tricas de negocio..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"business_metrics\": {"
      echo "    \"asset_health\": ${HEALTH_SCORE:-0},"
      echo "    \"coverage_completeness\": ${COVERAGE_PERCENT:-0},"
      echo "    \"maintenance_score\": ${MAINT_SCORE:-100},"
      echo "    \"security_score\": $((100 - (${SECURITY_ISSUES:-0} * 10))),"
      echo "    \"accessibility_score\": $([ "${NO_ACCESSIBILITY:-0}" -eq 0 ] && echo "100" || echo "$((100 - ${NO_ACCESSIBILITY:-0} * 5))"),"
      echo "    \"quality_index\": $(awk "BEGIN {printf \"%.1f\", (${HEALTH_SCORE:-0} + ${COVERAGE_PERCENT:-0} + ${MAINT_SCORE:-100}) / 3}")"
      echo "  },"
      echo "  \"recommendations\": {"
      echo "    \"priority\": \"$([ "$HEALTH_SCORE" -lt 70 ] && echo "high" || echo "medium")\","
      echo "    \"estimated_impact\": \"$([ "$HEALTH_SCORE" -lt 60 ] && echo "critical" || [ "$HEALTH_SCORE" -lt 80 ] && echo "high" || echo "low")\""
      echo "  }"
      echo "}"
    } > "$business_file" 2>/dev/null || true
    
    if [ -f "$business_file" ]; then
      echo "$business_file"
      return 0
    fi
  fi
  
  return 1
}

# An√°lisis de impacto de cambios (Git integration)
analyze_changes_impact() {
  local changes_file="$EXPORT_DIR/changes_impact.json"
  local changed_files=0
  local modified_count=0
  local added_count=0
  local deleted_count=0
  
  _log_debug "Analizando impacto de cambios con Git..."
  
  if command -v git >/dev/null 2>&1 && [ -d "$ROOT_DIR/.git" ]; then
    # Archivos modificados en el √∫ltimo commit
    local git_changed=$(git diff --name-only HEAD~1 HEAD 2>/dev/null | grep '\.svg$' || true)
    modified_count=$(echo "$git_changed" | wc -l | xargs)
    
    # Archivos agregados
    local git_added=$(git diff --name-only --diff-filter=A HEAD~1 HEAD 2>/dev/null | grep '\.svg$' || true)
    added_count=$(echo "$git_added" | wc -l | xargs)
    
    # Archivos eliminados
    local git_deleted=$(git diff --name-only --diff-filter=D HEAD~1 HEAD 2>/dev/null | grep '\.svg$' || true)
    deleted_count=$(echo "$git_deleted" | wc -l | xargs)
    
    changed_files=$((modified_count + added_count + deleted_count))
    
    if command -v jq >/dev/null 2>&1; then
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"git_info\": {"
        echo "    \"branch\": \"$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "unknown")\","
        echo "    \"commit\": \"$(git rev-parse --short HEAD 2>/dev/null || echo "unknown")\","
        echo "    \"last_commit_date\": \"$(git log -1 --format=%ci 2>/dev/null || echo "unknown")\""
        echo "  },"
        echo "  \"changes\": {"
        echo "    \"total_changed\": $changed_files,"
        echo "    \"modified\": $modified_count,"
        echo "    \"added\": $added_count,"
        echo "    \"deleted\": $deleted_count"
        echo "  },"
        echo "  \"impact\": {"
        echo "    \"level\": \"$([ "$changed_files" -gt 50 ] && echo "high" || [ "$changed_files" -gt 10 ] && echo "medium" || echo "low")\","
        echo "    \"requires_review\": $([ "$changed_files" -gt 20 ] && echo "true" || echo "false")"
        echo "  }"
        echo "}"
      } > "$changes_file" 2>/dev/null || true
      
      if [ -f "$changes_file" ]; then
        echo "$changes_file"
        return 0
      fi
    fi
  else
    _log_debug "Git no disponible o no es un repositorio Git"
  fi
  
  return 1
}

# Detectar patrones de dise√±o
detect_design_patterns() {
  local patterns_file="$EXPORT_DIR/design_patterns.json"
  local pattern_count=0
  
  _log_debug "Detectando patrones de dise√±o..."
  
  declare -A PATTERNS=(
    ["before_after"]="before.*after|antes.*despu"
    ["testimonial"]="testimonial|testimonio|review"
    ["benefits"]="benefit|beneficio|ventaja"
    ["social_proof"]="social.*proof|prueba.*social|rating|estrellas"
    ["urgency"]="urgent|urgente|limited|limitado"
    ["cta"]="call.*to.*action|click|mas.*info|compra.*ahora"
  )
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"patterns\": {"
      
      FIRST=true
      for pattern_name in "${!PATTERNS[@]}"; do
        pattern_regex="${PATTERNS[$pattern_name]}"
        count=$(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | xargs grep -liE "$pattern_regex" 2>/dev/null | wc -l | xargs)
        
        [ "$FIRST" = false ] && echo ","
        echo "    \"$pattern_name\": {"
        echo "      \"count\": $count,"
        echo "      \"percentage\": $(awk "BEGIN {printf \"%.1f\", ($count / ($TOTAL_SVGS + 1)) * 100}" 2>/dev/null || echo "0")"
        echo "    }"
        FIRST=false
        pattern_count=$((pattern_count + count))
      done
      
      echo "  },"
      echo "  \"total_patterns_detected\": $pattern_count"
      echo "}"
    } > "$patterns_file" 2>/dev/null || true
    
    if [ -f "$patterns_file" ]; then
      echo "$patterns_file"
      return 0
    fi
  fi
  
  return 1
}

# Generar changelog autom√°tico
generate_changelog() {
  local changelog_file="$EXPORT_DIR/CHANGELOG.md"
  
  _log_debug "Generando changelog autom√°tico..."
  
  {
    echo "# Changelog - Asset Analysis"
    echo ""
    echo "## $(date '+%Y-%m-%d')"
    echo ""
    echo "### M√©tricas"
    echo "- Total SVGs: ${TOTAL_SVGS:-0}"
    echo "- Health Score: ${HEALTH_SCORE:-0}/100"
    echo "- Coverage: ${COVERAGE_PERCENT:-0}%"
    echo ""
    echo "### Cambios detectados"
    [ "${EMPTY_SVGS:-0}" -gt 0 ] && echo "- ‚ö†Ô∏è ${EMPTY_SVGS:-0} archivos vac√≠os detectados"
    [ "${BROKEN_SVGS:-0}" -gt 0 ] && echo "- ‚ùå ${BROKEN_SVGS:-0} archivos rotos"
    [ "${SECURITY_ISSUES:-0}" -gt 0 ] && echo "- üîí ${SECURITY_ISSUES:-0} problemas de seguridad"
    [ "${DUPLICATE_GROUPS:-0}" -gt 0 ] && echo "- üîÑ ${DUPLICATE_GROUPS:-0} grupos de duplicados"
    echo ""
    echo "### Mejoras recomendadas"
    [ "${LARGE_COUNT:-0}" -gt 0 ] && echo "- üíæ Optimizar ${LARGE_COUNT:-0} archivos grandes"
    [ "${NO_ACCESSIBILITY:-0}" -gt 0 ] && echo "- ‚ôø Mejorar accesibilidad en ${NO_ACCESSIBILITY:-0} archivos"
    echo ""
    echo "---"
    echo "*Generado autom√°ticamente por analyze_assets.sh*"
  } > "$changelog_file" 2>/dev/null || return 1
  
  if [ -f "$changelog_file" ]; then
    echo "$changelog_file"
    return 0
  fi
  return 1
}

# Exportar para PowerBI/Tableau (CSV estructurado)
export_for_bi() {
  local bi_file="$EXPORT_DIR/assets_bi_export.csv"
  
  _log_debug "Generando exportaci√≥n para herramientas de BI..."
  
  {
    echo "Date,Asset_Count,Health_Score,Coverage_Percent,Empty_Files,Broken_Files,Security_Issues,Accessibility_Score,Performance_Score,Quality_Index"
    echo "$(date +%Y-%m-%d),${TOTAL_SVGS:-0},${HEALTH_SCORE:-0},${COVERAGE_PERCENT:-0},${EMPTY_SVGS:-0},${BROKEN_SVGS:-0},${SECURITY_ISSUES:-0},$([ "${NO_ACCESSIBILITY:-0}" -eq 0 ] && echo "100" || echo "$((100 - ${NO_ACCESSIBILITY:-0} * 5))"),85,$(awk "BEGIN {printf \"%.1f\", (${HEALTH_SCORE:-0} + ${COVERAGE_PERCENT:-0} + ${MAINT_SCORE:-100}) / 3}")"
  } > "$bi_file" 2>/dev/null || return 1
  
  if [ -f "$bi_file" ]; then
    echo "$bi_file"
    return 0
  fi
  return 1
}

# Validaci√≥n completa de metadatos
validate_metadata_complete() {
  local metadata_file="$EXPORT_DIR/metadata_validation.json"
  local missing_metadata=0
  local incomplete_metadata=0
  
  _log_debug "Validando metadatos completos..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local has_title=false
    local has_desc=false
    local has_metadata=false
    local has_dublin_core=false
    
    # Verificar elementos de metadata
    grep -qiE '<title[^>]*>' "$svg_file" 2>/dev/null && has_title=true
    grep -qiE '<desc[^>]*>|<description' "$svg_file" 2>/dev/null && has_desc=true
    grep -qiE '<metadata' "$svg_file" 2>/dev/null && has_metadata=true
    grep -qiE 'dc:title|dc:creator|dublin.*core' "$svg_file" 2>/dev/null && has_dublin_core=true
    
    if [ "$has_title" = false ] && [ "$has_desc" = false ]; then
      missing_metadata=$((missing_metadata + 1))
    elif [ "$has_title" = false ] || [ "$has_desc" = false ]; then
      incomplete_metadata=$((incomplete_metadata + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | head -100)
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"validation\": {"
      echo "    \"files_without_metadata\": $missing_metadata,"
      echo "    \"files_incomplete_metadata\": $incomplete_metadata,"
      echo "    \"coverage_percent\": $(awk "BEGIN {printf \"%.1f\", ((100 - $missing_metadata - $incomplete_metadata) / 100) * 100}" 2>/dev/null || echo "0")"
      echo "  },"
      echo "  \"recommendations\": ["
      [ "$missing_metadata" -gt 0 ] && echo "    \"Agregar <title> y <desc> a $missing_metadata archivos\","
      [ "$incomplete_metadata" -gt 0 ] && echo "    \"Completar metadatos en $incomplete_metadata archivos\""
      echo "  ]"
      echo "}"
    } > "$metadata_file" 2>/dev/null || true
    
    if [ -f "$metadata_file" ]; then
      echo "$metadata_file"
      return 0
    fi
  fi
  
  return 1
}

# Generar documentaci√≥n autom√°tica completa
generate_auto_documentation() {
  local doc_file="$EXPORT_DIR/ASSETS_DOCUMENTATION.md"
  
  _log_debug "Generando documentaci√≥n autom√°tica..."
  
  {
    echo "# üìö Documentaci√≥n de Assets - Generada Autom√°ticamente"
    echo ""
    echo "**Generado:** $(date '+%Y-%m-%d %H:%M:%S')"
    echo ""
    echo "## üìä Resumen Ejecutivo"
    echo ""
    echo "| M√©trica | Valor |"
    echo "|---------|-------|"
    echo "| Total de Assets | ${TOTAL_SVGS:-0} |"
    echo "| Health Score | ${HEALTH_SCORE:-0}/100 |"
    echo "| Cobertura | ${COVERAGE_PERCENT:-0}% |"
    echo "| Estado General | $HEALTH_STATUS |"
    echo ""
    echo "## üéØ Estructura de Directorios"
    echo ""
    echo "\`\`\`"
    find "$SRC_DIR" -type d -maxdepth 2 2>/dev/null | head -20 | sed "s|$ROOT_DIR/||"
    echo "\`\`\`"
    echo ""
    echo "## üìã Formatos Soportados"
    echo ""
    echo "- **Instagram Feed:** 1080x1080"
    echo "- **Instagram Ads:** 1080x1350"
    echo "- **Instagram Stories:** 1080x1920"
    echo "- **LinkedIn:** 1200x627 (horizontal), 1080x1080 (square), 1080x1920 (vertical)"
    echo ""
    echo "## üîç Validaciones Realizadas"
    echo ""
    echo "- ‚úÖ Estructura SVG"
    echo "- ‚úÖ Integridad de archivos"
    echo "- ‚úÖ Accesibilidad (WCAG)"
    echo "- ‚úÖ Seguridad"
    echo "- ‚úÖ Performance"
    echo "- ‚úÖ Compliance"
    echo ""
    echo "## üìà M√©tricas de Calidad"
    echo ""
    echo "- **Mantenibilidad:** ${MAINT_SCORE:-100}/100"
    echo "- **Seguridad:** $((100 - (${SECURITY_ISSUES:-0} * 10)))"
    echo "- **Accesibilidad:** $([ "${NO_ACCESSIBILITY:-0}" -eq 0 ] && echo "100" || echo "$((100 - ${NO_ACCESSIBILITY:-0} * 5))")"
    echo ""
    echo "## üõ†Ô∏è Herramientas Recomendadas"
    echo ""
    echo "- SVGO para optimizaci√≥n"
    echo "- Lighthouse para performance"
    echo "- WAVE para accesibilidad"
    echo ""
    echo "---"
    echo "*Documentaci√≥n generada autom√°ticamente. Actualiza con: \`./tools/analyze_assets.sh --generate-docs\`*"
  } > "$doc_file" 2>/dev/null || return 1
  
  if [ -f "$doc_file" ]; then
    echo "$doc_file"
    return 0
  fi
  return 1
}

# Validar versionado sem√°ntico en nombres
validate_semantic_versioning() {
  local versioning_file="$EXPORT_DIR/versioning_analysis.json"
  local versioned_files=0
  local invalid_versions=0
  
  _log_debug "Validando versionado sem√°ntico..."
  
  # Patr√≥n de versionado sem√°ntico: v1.0.0, 1.0.0, v2.1.3, etc.
  local semver_pattern='v?[0-9]+\.[0-9]+(\.[0-9]+)?(-[a-zA-Z0-9]+)?'
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local basename=$(basename "$svg_file" .svg)
    
    # Buscar versiones en el nombre
    if echo "$basename" | grep -qE "$semver_pattern"; then
      versioned_files=$((versioned_files + 1))
      
      # Verificar que la versi√≥n es v√°lida (no duplicada, no inconsistente)
      local version=$(echo "$basename" | grep -oE "$semver_pattern" | head -1)
      if [ -z "$version" ]; then
        invalid_versions=$((invalid_versions + 1))
      fi
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"versioning\": {"
      echo "    \"files_with_versions\": $versioned_files,"
      echo "    \"invalid_versions\": $invalid_versions,"
      echo "    \"versioning_rate\": $(awk "BEGIN {printf \"%.1f\", ($versioned_files / ($TOTAL_SVGS + 1)) * 100}" 2>/dev/null || echo "0")"
      echo "  }"
      echo "}"
    } > "$versioning_file" 2>/dev/null || true
    
    if [ -f "$versioning_file" ]; then
      echo "$versioning_file"
      return 0
    fi
  fi
  
  return 1
}

# Sistema de plugins (ejecutar scripts externos)
run_plugins() {
  local plugins_dir="$ROOT_DIR/tools/plugins"
  local plugins_executed=0
  local plugins_failed=0
  
  _log_debug "Ejecutando plugins..."
  
  if [ ! -d "$plugins_dir" ]; then
    _log_debug "Directorio de plugins no existe: $plugins_dir"
    return 1
  fi
  
  # Exportar variables para plugins
  export ASSET_ANALYSIS_REPORT="$REPORT"
  export ASSET_ANALYSIS_TOTAL_SVGS="$TOTAL_SVGS"
  export ASSET_ANALYSIS_HEALTH_SCORE="$HEALTH_SCORE"
  export ASSET_ANALYSIS_EXPORT_DIR="$EXPORT_DIR"
  export ASSET_ANALYSIS_ROOT_DIR="$ROOT_DIR"
  export ASSET_ANALYSIS_SRC_DIR="$SRC_DIR"
  
  # Buscar scripts ejecutables en plugins/ (excluir ejemplo)
  find "$plugins_dir" -type f -perm +111 ! -name "example_*" 2>/dev/null | while read -r plugin; do
    [ ! -f "$plugin" ] && continue
    
    local plugin_name=$(basename "$plugin")
    _log_debug "Ejecutando plugin: $plugin_name"
    
    # Ejecutar plugin con timeout de 30 segundos
    if timeout 30 "$plugin" >> "$EXPORT_DIR/plugins.log" 2>&1; then
      plugins_executed=$((plugins_executed + 1))
      log_info "  ‚úÖ Plugin ejecutado: $plugin_name"
    else
      plugins_failed=$((plugins_failed + 1))
      _log_warn "Plugin fall√≥: $plugin_name"
    fi
  done
  
  if [ "$plugins_executed" -gt 0 ]; then
    log_info "Total plugins ejecutados: $plugins_executed"
    [ "$plugins_failed" -gt 0 ] && log_info "Plugins con errores: $plugins_failed"
    return 0
  fi
  
  return 1
}

# An√°lisis de uso de assets (archivos m√°s referenciados)
analyze_asset_usage() {
  local usage_file="$EXPORT_DIR/asset_usage_analysis.json"
  local usage_tmp=$(mktemp)
  
  _log_debug "Analizando uso de assets..."
  
  # Contar referencias a cada archivo SVG
  find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null | while read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local filename=$(basename "$svg_file")
    local reference_count=0
    
    # Buscar referencias en CSV
    if [ -f "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" ]; then
      local csv_refs=$(grep -c "$filename" "$ROOT_DIR/CSV_MASTER_CREATIVES.csv" 2>/dev/null || echo "0")
      reference_count=$((reference_count + csv_refs))
    fi
    
    # Buscar referencias en otros archivos
    local file_refs=$(find "$ROOT_DIR" -name "*.svg" -o -name "*.html" -o -name "*.md" -o -name "*.js" 2>/dev/null | \
      xargs grep -l "$filename" 2>/dev/null | wc -l | xargs)
    reference_count=$((reference_count + file_refs))
    
    if [ "$reference_count" -gt 0 ]; then
      echo "$filename|$reference_count|${svg_file#$ROOT_DIR/}" >> "$usage_tmp"
    fi
  done
  
  local total_referenced=$(wc -l < "$usage_tmp" | xargs)
  
  if [ "$total_referenced" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"usage_stats\": {"
      echo "    \"total_referenced\": $total_referenced,"
      echo "    \"unreferenced\": $((TOTAL_SVGS - total_referenced))"
      echo "  },"
      echo "  \"most_used\": ["
      
      FIRST=true
      sort -t'|' -k2 -nr "$usage_tmp" | head -10 | while IFS='|' read -r filename count path; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$filename\","
        echo "      \"references\": $count,"
        echo "      \"path\": \"$path\""
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$usage_file" 2>/dev/null || true
    
    rm -f "$usage_tmp"
    
    if [ -f "$usage_file" ]; then
      echo "$usage_file"
      return 0
    fi
  fi
  
  rm -f "$usage_tmp" 2>/dev/null || true
  return 1
}

# Detectar assets obsoletos por fecha
detect_obsolete_assets() {
  local obsolete_file="$EXPORT_DIR/obsolete_assets.json"
  local obsolete_days="${OBSOLETE_DAYS:-365}"
  local obsolete_count=0
  local obsolete_tmp=$(mktemp)
  local current_time=$(date +%s)
  
  _log_debug "Detectando assets obsoletos (m√°s de $obsolete_days d√≠as sin modificar)..."
  
  while IFS= read -r svg_file; do
    [ ! -f "$svg_file" ] && continue
    
    local file_time=$(stat -f%m "$svg_file" 2>/dev/null || stat -c%Y "$svg_file" 2>/dev/null || echo 0)
    local days_old=$(( (current_time - file_time) / 86400 ))
    
    if [ "$days_old" -gt "$obsolete_days" ]; then
      echo "${svg_file#$ROOT_DIR/}|$days_old" >> "$obsolete_tmp"
      obsolete_count=$((obsolete_count + 1))
    fi
  done < <(find "$SRC_DIR" -name "*.svg" -type f 2>/dev/null)
  
  if [ "$obsolete_count" -gt 0 ] && command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"threshold_days\": $obsolete_days,"
      echo "  \"obsolete_count\": $obsolete_count,"
      echo "  \"obsolete_assets\": ["
      
      FIRST=true
      sort -t'|' -k2 -nr "$obsolete_tmp" | head -20 | while IFS='|' read -r file days; do
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"file\": \"$file\","
        echo "      \"days_old\": $days"
        echo "    }"
        FIRST=false
      done
      
      echo "  ]"
      echo "}"
    } > "$obsolete_file" 2>/dev/null || true
    
    rm -f "$obsolete_tmp"
    
    if [ -f "$obsolete_file" ]; then
      echo "$obsolete_file"
      return 0
    fi
  fi
  
  rm -f "$obsolete_tmp" 2>/dev/null || true
  return 1
}

# Validar branding consistente
validate_branding() {
  local branding_file="$EXPORT_DIR/branding_validation.json"
  local branding_issues=0
  
  _log_debug "Validando consistencia de branding..."
  
  # Buscar colores de marca en tokens.json
  if [ -f "$ROOT_DIR/tokens.json" ]; then
    local brand_colors=$(grep -oE '"[a-zA-Z0-9_]+":\s*"#[0-9a-fA-F]{3,6}"' "$ROOT_DIR/tokens.json" 2>/dev/null | \
      grep -iE 'brand|primary|secondary|accent' | wc -l | xargs)
    
    # Verificar uso consistente de colores de marca
    local inconsistent_usage=0
    
    if command -v jq >/dev/null 2>&1; then
      {
        echo "{"
        echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
        echo "  \"branding\": {"
        echo "    \"brand_colors_defined\": $brand_colors,"
        echo "    \"consistency_score\": $([ "$OUT_OF_PALETTE" -gt 0 ] && echo "$((100 - OUT_OF_PALETTE * 2))" || echo "100"),"
        echo "    \"issues\": ${OUT_OF_PALETTE:-0}"
        echo "  }"
        echo "}"
      } > "$branding_file" 2>/dev/null || true
      
      if [ -f "$branding_file" ]; then
        echo "$branding_file"
        return 0
      fi
    fi
  fi
  
  return 1
}

# Generar alertas autom√°ticas
generate_alerts() {
  local alerts_file="$EXPORT_DIR/alerts.json"
  local alert_count=0
  
  _log_debug "Generando alertas autom√°ticas..."
  
  if command -v jq >/dev/null 2>&1; then
    {
      echo "{"
      echo "  \"generated_at\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\","
      echo "  \"alerts\": ["
      
      FIRST=true
      
      # Alerta: Health score bajo
      if [ "$HEALTH_SCORE" -lt "${MIN_HEALTH_SCORE:-75}" ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"health_score\","
        echo "      \"severity\": \"$([ "$HEALTH_SCORE" -lt 50 ] && echo "critical" || echo "warning")\","
        echo "      \"message\": \"Health score bajo: $HEALTH_SCORE/100\","
        echo "      \"value\": $HEALTH_SCORE,"
        echo "      \"threshold\": ${MIN_HEALTH_SCORE:-75}"
        echo "    }"
        FIRST=false
        alert_count=$((alert_count + 1))
      fi
      
      # Alerta: Problemas de seguridad
      if [ "${SECURITY_ISSUES:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"security\","
        echo "      \"severity\": \"critical\","
        echo "      \"message\": \"${SECURITY_ISSUES:-0} problemas de seguridad detectados\","
        echo "      \"count\": ${SECURITY_ISSUES:-0}"
        echo "    }"
        FIRST=false
        alert_count=$((alert_count + 1))
      fi
      
      # Alerta: Archivos rotos
      if [ "${BROKEN_SVGS:-0}" -gt 0 ]; then
        [ "$FIRST" = false ] && echo ","
        echo "    {"
        echo "      \"type\": \"broken_files\","
        echo "      \"severity\": \"error\","
        echo "      \"message\": \"${BROKEN_SVGS:-0} archivos SVG rotos\","
        echo "      \"count\": ${BROKEN_SVGS:-0}"
        echo "    }"
        FIRST=false
        alert_count=$((alert_count + 1))
      fi
      
      echo "  ],"
      echo "  \"total_alerts\": $alert_count"
      echo "}"
    } > "$alerts_file" 2>/dev/null || true
    
    if [ -f "$alerts_file" ]; then
      echo "$alerts_file"
      return 0
    fi
  fi
  
  return 1
}

# Detectar duplicado