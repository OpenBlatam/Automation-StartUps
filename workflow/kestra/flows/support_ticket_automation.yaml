id: support_ticket_automation
namespace: workflows

labels:
  app: support
  process: ticket-automation
  category: automation

description: |
  ü§ñ Sistema Completo de Automatizaci√≥n de Soporte al Cliente / Tickets
  
  Este workflow procesa tickets de soporte con:
  1. ‚úÖ Chatbot para FAQs - Responde autom√°ticamente consultas frecuentes
  2. ‚úÖ Priorizaci√≥n Autom√°tica - Calcula prioridad basada en contenido, cliente y urgencia
  3. ‚úÖ Enrutamiento Inteligente - Dirige tickets a departamentos/agentes apropiados
  4. ‚úÖ Integraci√≥n con CRM - Sincroniza con HubSpot si est√° disponible
  5. ‚úÖ Persistencia Completa - Guarda en BD con historial y m√©tricas
  
  FLUJO:
  - Recibe ticket v√≠a webhook (email, chat, web, API, etc.)
  - Intenta resolver con chatbot (FAQs + LLM)
  - Si no resuelve, calcula prioridad autom√°tica
  - Enruta a departamento/agente apropiado
  - Persiste en BD y notifica seg√∫n configuraci√≥n
  
  CARACTER√çSTICAS:
  - Detecci√≥n de intenciones (billing, technical, sales, etc.)
  - Matching de FAQs con b√∫squeda sem√°ntica
  - Respuestas contextuales con OpenAI GPT
  - Score de prioridad 0-100 con m√∫ltiples factores
  - Enrutamiento basado en reglas configurables
  - Balanceo de carga entre agentes
  - Notificaciones a Slack/Teams opcionales
  - M√©tricas y tracking completo

inputs:
  # Base de datos
  - name: jdbc_url
    type: STRING
    required: false
    description: URL JDBC para conexi√≥n a PostgreSQL
  - name: jdbc_user
    type: STRING
    required: false
    description: Usuario de base de datos
  - name: jdbc_password
    type: STRING
    required: false
    description: Contrase√±a de base de datos
  - name: enable_db_persistence
    type: BOOLEAN
    required: false
    default: true
    description: Habilitar persistencia en BD
  
  # Chatbot
  - name: openai_api_key
    type: STRING
    required: false
    description: API key de OpenAI para respuestas con LLM
  - name: openai_model
    type: STRING
    required: false
    default: "gpt-4o-mini"
    description: Modelo de OpenAI a usar
  - name: enable_chatbot
    type: BOOLEAN
    required: false
    default: true
    description: Habilitar chatbot para FAQs
  - name: chatbot_confidence_threshold
    type: FLOAT
    required: false
    default: 0.7
    description: Umbral de confianza para considerar respuesta v√°lida (0.0-1.0)
  
  # Priorizaci√≥n
  - name: enable_auto_priority
    type: BOOLEAN
    required: false
    default: true
    description: Habilitar priorizaci√≥n autom√°tica
  - name: vip_customers
    type: STRING
    required: false
    description: JSON array con emails de clientes VIP
  - name: enterprise_customers
    type: STRING
    required: false
    description: JSON array con emails de clientes Enterprise
  
  # Enrutamiento
  - name: enable_auto_routing
    type: BOOLEAN
    required: false
    default: true
    description: Habilitar enrutamiento autom√°tico
  - name: enable_auto_assign
    type: BOOLEAN
    required: false
    default: false
    description: Habilitar asignaci√≥n autom√°tica a agentes
  
  # HubSpot Integration
  - name: hubspot_token
    type: STRING
    required: false
    description: Token de API de HubSpot para sincronizaci√≥n
  - name: enable_hubspot_sync
    type: BOOLEAN
    required: false
    default: false
    description: Habilitar sincronizaci√≥n con HubSpot
  
  # Notificaciones
  - name: slack_webhook_url
    type: STRING
    required: false
    description: Webhook URL de Slack para notificaciones
  - name: teams_webhook_url
    type: STRING
    required: false
    description: Webhook URL de Microsoft Teams para notificaciones
  - name: enable_notifications
    type: BOOLEAN
    required: false
    default: true
    description: Habilitar notificaciones

triggers:
  - id: ticket_webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: support-ticket
    description: Webhook para recibir tickets de soporte

tasks:
  # ========================================================================
  # FASE 1: Validaci√≥n y Normalizaci√≥n
  # ========================================================================
  - id: validate_input
    type: io.kestra.core.tasks.scripts.Python
    description: Valida y normaliza los datos del ticket recibido
    script: |
      import json
      import re
      from datetime import datetime
      import uuid
      
      # Obtener payload del webhook
      payload = {{ trigger.body | json }}
      
      # Validar campos requeridos
      if not payload.get("description"):
          raise ValueError("El campo 'description' es requerido")
      
      if not payload.get("customer_email"):
          raise ValueError("El campo 'customer_email' es requerido")
      
      # Validar email
      email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
      if not re.match(email_pattern, payload["customer_email"]):
          raise ValueError(f"Email inv√°lido: {payload['customer_email']}")
      
      # Generar ticket_id si no existe
      ticket_id = payload.get("ticket_id") or str(uuid.uuid4())
      
      # Normalizar datos
      normalized = {
          "ticket_id": ticket_id,
          "source": payload.get("source", "web"),
          "subject": (payload.get("subject") or "").strip(),
          "description": payload["description"].strip(),
          "customer_email": payload["customer_email"].lower().strip(),
          "customer_name": (payload.get("customer_name") or "").strip(),
          "customer_id": payload.get("customer_id"),
          "category": payload.get("category"),
          "tags": payload.get("tags", []),
          "metadata": payload.get("metadata", {})
      }
      
      # Guardar para siguientes tareas
      {{ outputs.validate_input.normalized = normalized | json }}
  
  # ========================================================================
  # FASE 2: Chatbot - Intentar Resolver con FAQs
  # ========================================================================
  - id: chatbot_processing
    type: io.kestra.core.tasks.scripts.Python
    description: Procesa el ticket con chatbot (FAQs + LLM)
    inputFiles:
      support_chatbot.py: |
        {{ read('workflow/kestra/flows/lib/support_chatbot.py') }}
    runner: DOCKER
    docker:
      image: python:3.11-slim
    env:
      OPENAI_API_KEY: "{{ inputs.openai_api_key }}"
      DB_HOST: "{{ vars.db_host }}"
      DB_NAME: "{{ vars.db_name }}"
      DB_USER: "{{ vars.db_user }}"
      DB_PASSWORD: "{{ vars.db_password }}"
    script: |
      import sys
      import json
      import os
      import psycopg2
      from support_chatbot import SupportChatbot
      
      # Cargar datos normalizados
      normalized = json.loads('''{{ outputs.validate_input.normalized }}''')
      
      # Conectar a BD si est√° habilitado
      db_conn = None
      if {{ inputs.enable_db_persistence | lower }} == "true":
          try:
              db_conn = psycopg2.connect(
                  host=os.getenv("DB_HOST"),
                  database=os.getenv("DB_NAME"),
                  user=os.getenv("DB_USER"),
                  password=os.getenv("DB_PASSWORD")
              )
          except Exception as e:
              print(f"Warning: No se pudo conectar a BD: {e}")
      
      # Inicializar chatbot
      chatbot = SupportChatbot(
          db_connection=db_conn,
          openai_api_key=os.getenv("OPENAI_API_KEY") if {{ inputs.enable_chatbot | lower }} == "true" else None,
          openai_model="{{ inputs.openai_model }}",
          confidence_threshold={{ inputs.chatbot_confidence_threshold }},
          enable_llm={{ inputs.enable_chatbot | lower }} == "true"
      )
      
      # Procesar mensaje
      user_message = f"{normalized['subject']} {normalized['description']}"
      response = chatbot.process_message(
          user_message=user_message,
          ticket_id=normalized["ticket_id"]
      )
      
      # Cerrar conexi√≥n
      if db_conn:
          db_conn.close()
      
      # Guardar resultado
      result = {
          "chatbot_attempted": True,
          "chatbot_resolved": response.resolved,
          "chatbot_response": response.response_text,
          "faq_matched": response.faq_matched,
          "faq_article_id": response.faq_article_id,
          "intent_detected": response.intent_detected,
          "confidence": response.confidence,
          "escalation_reason": response.escalation_reason,
          "metadata": response.metadata or {}
      }
      
      print(json.dumps(result))
      {{ outputs.chatbot_processing.result = result | json }}
  
  # ========================================================================
  # FASE 3: Priorizaci√≥n Autom√°tica
  # ========================================================================
  - id: priority_calculation
    type: io.kestra.core.tasks.scripts.Python
    description: Calcula prioridad autom√°tica del ticket
    inputFiles:
      support_priority.py: |
        {{ read('workflow/kestra/flows/lib/support_priority.py') }}
    runner: DOCKER
    docker:
      image: python:3.11-slim
    env:
      DB_HOST: "{{ vars.db_host }}"
      DB_NAME: "{{ vars.db_name }}"
      DB_USER: "{{ vars.db_user }}"
      DB_PASSWORD: "{{ vars.db_password }}"
    script: |
      import sys
      import json
      import os
      import psycopg2
      from support_priority import SupportPriorityCalculator
      
      # Cargar datos
      normalized = json.loads('''{{ outputs.validate_input.normalized }}''')
      chatbot_result = json.loads('''{{ outputs.chatbot_processing.result }}''')
      
      # Si el chatbot resolvi√≥, prioridad baja
      if chatbot_result.get("chatbot_resolved"):
          priority_result = {
              "priority": "low",
              "priority_score": 20.0,
              "reasoning": "Resuelto por chatbot autom√°ticamente",
              "factors": {}
          }
          print(json.dumps(priority_result))
          {{ outputs.priority_calculation.result = priority_result | json }}
          sys.exit(0)
      
      # Conectar a BD
      db_conn = None
      if {{ inputs.enable_db_persistence | lower }} == "true":
          try:
              db_conn = psycopg2.connect(
                  host=os.getenv("DB_HOST"),
                  database=os.getenv("DB_NAME"),
                  user=os.getenv("DB_USER"),
                  password=os.getenv("DB_PASSWORD")
              )
          except Exception as e:
              print(f"Warning: No se pudo conectar a BD: {e}")
      
      # Cargar VIPs y Enterprise
      vip_customers = []
      enterprise_customers = []
      try:
          if {{ inputs.vip_customers }}:
              vip_customers = json.loads({{ inputs.vip_customers }})
      except:
          pass
      try:
          if {{ inputs.enterprise_customers }}:
              enterprise_customers = json.loads({{ inputs.enterprise_customers }})
      except:
          pass
      
      # Calcular prioridad
      calculator = SupportPriorityCalculator(
          db_connection=db_conn,
          vip_customers=vip_customers,
          enterprise_customers=enterprise_customers
      )
      
      priority_score = calculator.calculate_priority(
          subject=normalized["subject"],
          description=normalized["description"],
          customer_email=normalized["customer_email"],
          customer_id=normalized.get("customer_id"),
          source=normalized["source"],
          category=normalized.get("category") or chatbot_result.get("intent_detected")
      )
      
      # Cerrar conexi√≥n
      if db_conn:
          db_conn.close()
      
      # Guardar resultado
      result = {
          "priority": priority_score.priority,
          "priority_score": priority_score.score,
          "reasoning": priority_score.reasoning,
          "factors": priority_score.factors
      }
      
      print(json.dumps(result))
      {{ outputs.priority_calculation.result = result | json }}
  
  # ========================================================================
  # FASE 3.5: Categorizaci√≥n Autom√°tica (si no existe)
  # ========================================================================
  - id: auto_categorization
    type: io.kestra.core.tasks.scripts.Python
    description: Categoriza autom√°ticamente el ticket si no tiene categor√≠a
    inputFiles:
      support_auto_categorization.py: |
        {{ read('workflow/kestra/flows/lib/support_auto_categorization.py') }}
    runner: DOCKER
    docker:
      image: python:3.11-slim
    env:
      DB_HOST: "{{ vars.db_host }}"
      DB_NAME: "{{ vars.db_name }}"
      DB_USER: "{{ vars.db_user }}"
      DB_PASSWORD: "{{ vars.db_password }}"
    script: |
      import sys
      import json
      import os
      import psycopg2
      from support_auto_categorization import SupportAutoCategorizer
      
      # Cargar datos
      normalized = json.loads('''{{ outputs.validate_input.normalized }}''')
      
      # Si ya tiene categor√≠a, usar esa
      if normalized.get("category") and normalized["category"] != "general":
          result = {
              "category": normalized["category"],
              "subcategory": normalized.get("subcategory"),
              "confidence": 1.0,
              "reasoning": "Categor√≠a ya existente",
              "keywords_matched": []
          }
          print(json.dumps(result))
          {{ outputs.auto_categorization.result = result | json }}
          sys.exit(0)
      
      # Conectar a BD
      db_conn = None
      if {{ inputs.enable_db_persistence | lower }} == "true":
          try:
              db_conn = psycopg2.connect(
                  host=os.getenv("DB_HOST"),
                  database=os.getenv("DB_NAME"),
                  user=os.getenv("DB_USER"),
                  password=os.getenv("DB_PASSWORD")
              )
          except Exception as e:
              print(f"Warning: No se pudo conectar a BD: {e}")
      
      # Categorizar
      categorizer = SupportAutoCategorizer(db_connection=db_conn)
      
      category_result = categorizer.categorize(
          subject=normalized.get("subject"),
          description=normalized["description"],
          existing_category=normalized.get("category"),
          customer_email=normalized["customer_email"]
      )
      
      # Actualizar categor√≠a en normalized
      normalized["category"] = category_result.category
      normalized["subcategory"] = category_result.subcategory
      
      # Cerrar conexi√≥n
      if db_conn:
          db_conn.close()
      
      # Guardar resultado
      result = {
          "category": category_result.category,
          "subcategory": category_result.subcategory,
          "confidence": category_result.confidence,
          "reasoning": category_result.reasoning,
          "keywords_matched": category_result.keywords_matched
      }
      
      print(json.dumps(result))
      {{ outputs.auto_categorization.result = result | json }}
  
  # ========================================================================
  # FASE 4: Enrutamiento Inteligente (Mejorado con Expertise)
  # ========================================================================
  - id: intelligent_routing
    type: io.kestra.core.tasks.scripts.Python
    description: Enruta ticket a departamento/agente apropiado usando expertise
    inputFiles:
      support_routing.py: |
        {{ read('workflow/kestra/flows/lib/support_routing.py') }}
      support_expertise_routing.py: |
        {{ read('workflow/kestra/flows/lib/support_expertise_routing.py') }}
    runner: DOCKER
    docker:
      image: python:3.11-slim
    env:
      DB_HOST: "{{ vars.db_host }}"
      DB_NAME: "{{ vars.db_name }}"
      DB_USER: "{{ vars.db_user }}"
      DB_PASSWORD: "{{ vars.db_password }}"
    script: |
      import sys
      import json
      import os
      import psycopg2
      from support_routing import SupportRouter
      
      # Cargar datos
      normalized = json.loads('''{{ outputs.validate_input.normalized }}''')
      priority_result = json.loads('''{{ outputs.priority_calculation.result }}''')
      chatbot_result = json.loads('''{{ outputs.chatbot_processing.result }}''')
      
      # Obtener categor√≠a (de categorizaci√≥n autom√°tica o existente)
      try:
          cat_result = json.loads('''{{ outputs.auto_categorization.result }}''')
          category = cat_result.get("category") or normalized.get("category")
          subcategory = cat_result.get("subcategory")
      except:
          category = normalized.get("category")
          subcategory = None
      
      # Si el chatbot resolvi√≥, no enrutar
      if chatbot_result.get("chatbot_resolved"):
          routing_result = {
              "department": None,
              "agent_id": None,
              "agent_name": None,
              "reason": "Resuelto por chatbot - no requiere enrutamiento",
              "auto_assign": False
          }
          print(json.dumps(routing_result))
          {{ outputs.intelligent_routing.result = routing_result | json }}
          sys.exit(0)
      
      # Conectar a BD
      db_conn = None
      if {{ inputs.enable_db_persistence | lower }} == "true":
          try:
              db_conn = psycopg2.connect(
                  host=os.getenv("DB_HOST"),
                  database=os.getenv("DB_NAME"),
                  user=os.getenv("DB_USER"),
                  password=os.getenv("DB_PASSWORD")
              )
          except Exception as e:
              print(f"Warning: No se pudo conectar a BD: {e}")
      
      # Enrutar usando routing b√°sico primero
      router = SupportRouter(db_connection=db_conn)
      
      routing = router.route_ticket(
          category=category or chatbot_result.get("intent_detected"),
          priority=priority_result["priority"],
          tags=normalized.get("tags", []),
          subject=normalized["subject"],
          description=normalized["description"],
          customer_email=normalized["customer_email"],
          customer_id=normalized.get("customer_id")
      )
      
      # Si est√° habilitado, usar expertise routing para asignaci√≥n
      if {{ inputs.enable_auto_assign | lower }} == "true" and routing.department:
          try:
              from support_expertise_routing import SupportExpertiseRouter
              expertise_router = SupportExpertiseRouter(db_connection=db_conn)
              
              # Intentar asignar por expertise
              match = expertise_router.find_best_agent(
                  category=category or "general",
                  subcategory=subcategory,
                  department=routing.department,
                  priority=priority_result["priority"]
              )
              
              if match:
                  routing.agent_id = match.agent_id
                  routing.agent_name = match.agent_name
                  routing.reason = f"{routing.reason} | Asignado por expertise: {match.reasoning}"
                  routing.auto_assign = True
          except Exception as e:
              print(f"Warning: Error en expertise routing: {e}")
              # Fallback a routing b√°sico
              agent = router.find_available_agent(
                  department=routing.department,
                  specialties=None
              )
              if agent:
                  routing.agent_id = agent["agent_id"]
                  routing.agent_name = agent["agent_name"]
                  routing.auto_assign = True
      
      # Cerrar conexi√≥n
      if db_conn:
          db_conn.close()
      
      # Guardar resultado
      result = {
          "department": routing.department,
          "agent_id": routing.agent_id,
          "agent_name": routing.agent_name,
          "reason": routing.reason,
          "auto_assign": routing.auto_assign
      }
      
      print(json.dumps(result))
      {{ outputs.intelligent_routing.result = result | json }}
  
  # ========================================================================
  # FASE 5: Persistencia en Base de Datos
  # ========================================================================
  - id: persist_to_database
    type: io.kestra.plugin.jdbc.postgresql.Query
    description: Guarda ticket en base de datos
    url: "{{ inputs.jdbc_url }}"
    username: "{{ inputs.jdbc_user }}"
    password: "{{ inputs.jdbc_password }}"
    fetchOne: true
    sql: |
      INSERT INTO support_tickets (
          ticket_id,
          source,
          subject,
          description,
          customer_email,
          customer_name,
          customer_id,
          category,
          subcategory,
          tags,
          priority,
          priority_score,
          urgency_factors,
          assigned_department,
          assigned_agent_id,
          assigned_agent_name,
          routing_reason,
          status,
          chatbot_attempted,
          chatbot_resolved,
          chatbot_response,
          faq_matched,
          faq_article_id,
          metadata
      ) VALUES (
          '{{ outputs.validate_input.normalized.ticket_id }}',
          '{{ outputs.validate_input.normalized.source }}',
          {{ outputs.validate_input.normalized.subject | sql }},
          {{ outputs.validate_input.normalized.description | sql }},
          '{{ outputs.validate_input.normalized.customer_email }}',
          {{ outputs.validate_input.normalized.customer_name | sql }},
          {{ outputs.validate_input.normalized.customer_id | sql }},
          COALESCE({{ outputs.auto_categorization.result.category | sql }}, {{ outputs.validate_input.normalized.category | sql }}),
          COALESCE({{ outputs.auto_categorization.result.subcategory | sql }}, NULL),
          ARRAY[{{ outputs.validate_input.normalized.tags | join(',') | sql }}],
          '{{ outputs.priority_calculation.result.priority }}',
          {{ outputs.priority_calculation.result.priority_score }},
          '{{ outputs.priority_calculation.result.factors | json }}'::jsonb,
          {{ outputs.intelligent_routing.result.department | sql }},
          {{ outputs.intelligent_routing.result.agent_id | sql }},
          {{ outputs.intelligent_routing.result.agent_name | sql }},
          {{ outputs.intelligent_routing.result.reason | sql }},
          CASE 
              WHEN {{ outputs.chatbot_processing.result.chatbot_resolved | lower }} = 'true' THEN 'chatbot_handled'
              WHEN {{ outputs.intelligent_routing.result.agent_id }} IS NOT NULL THEN 'assigned'
              ELSE 'open'
          END,
          {{ outputs.chatbot_processing.result.chatbot_attempted }},
          {{ outputs.chatbot_processing.result.chatbot_resolved }},
          {{ outputs.chatbot_processing.result.chatbot_response | sql }},
          {{ outputs.chatbot_processing.result.faq_matched }},
          {{ outputs.chatbot_processing.result.faq_article_id | sql }},
          '{{ outputs.validate_input.normalized.metadata | json }}'::jsonb
      )
      RETURNING id, ticket_id, status;
    disabled: "{{ not inputs.enable_db_persistence }}"
  
  # ========================================================================
  # FASE 6: Guardar Interacci√≥n con Chatbot (si aplica)
  # ========================================================================
  - id: save_chatbot_interaction
    type: io.kestra.plugin.jdbc.postgresql.Query
    description: Guarda interacci√≥n con chatbot en historial
    url: "{{ inputs.jdbc_url }}"
    username: "{{ inputs.jdbc_user }}"
    password: "{{ inputs.jdbc_password }}"
    sql: |
      INSERT INTO support_chatbot_interactions (
          ticket_id,
          interaction_number,
          user_message,
          chatbot_response,
          intent_detected,
          confidence_score,
          faq_matched,
          faq_article_id,
          resolved_by_chatbot,
          escalation_reason,
          metadata
      ) VALUES (
          '{{ outputs.validate_input.normalized.ticket_id }}',
          1,
          {{ outputs.validate_input.normalized.description | sql }},
          {{ outputs.chatbot_processing.result.chatbot_response | sql }},
          {{ outputs.chatbot_processing.result.intent_detected | sql }},
          {{ outputs.chatbot_processing.result.confidence }},
          {{ outputs.chatbot_processing.result.faq_matched }},
          {{ outputs.chatbot_processing.result.faq_article_id | sql }},
          {{ outputs.chatbot_processing.result.chatbot_resolved }},
          {{ outputs.chatbot_processing.result.escalation_reason | sql }},
          '{{ outputs.chatbot_processing.result.metadata | json }}'::jsonb
      );
    disabled: "{{ not inputs.enable_db_persistence or not outputs.chatbot_processing.result.chatbot_attempted }}"
  
  # ========================================================================
  # FASE 7: Escalaci√≥n de Urgentes (si aplica)
  # ========================================================================
  - id: check_and_escalate_urgent
    type: io.kestra.core.tasks.scripts.Python
    description: Escala autom√°ticamente tickets urgentes/cr√≠ticos
    inputFiles:
      support_urgent_escalation.py: |
        {{ read('workflow/kestra/flows/lib/support_urgent_escalation.py') }}
    runner: DOCKER
    docker:
      image: python:3.11-slim
    env:
      DB_HOST: "{{ vars.db_host }}"
      DB_NAME: "{{ vars.db_name }}"
      DB_USER: "{{ vars.db_user }}"
      DB_PASSWORD: "{{ vars.db_password }}"
    script: |
      import sys
      import json
      import os
      import psycopg2
      from support_urgent_escalation import SupportUrgentEscalation
      
      # Cargar datos
      priority_result = json.loads('''{{ outputs.priority_calculation.result }}''')
      ticket_id = '''{{ outputs.validate_input.normalized.ticket_id }}'''
      
      # Solo escalar si es urgente o cr√≠tico
      if priority_result["priority"] not in ["urgent", "critical"]:
          result = {
              "escalated": False,
              "reason": "No requiere escalaci√≥n - prioridad no es urgente/cr√≠tica"
          }
          print(json.dumps(result))
          {{ outputs.check_and_escalate_urgent.result = result | json }}
          sys.exit(0)
      
      # Conectar a BD
      db_conn = None
      if {{ inputs.enable_db_persistence | lower }} == "true":
          try:
              db_conn = psycopg2.connect(
                  host=os.getenv("DB_HOST"),
                  database=os.getenv("DB_NAME"),
                  user=os.getenv("DB_USER"),
                  password=os.getenv("DB_PASSWORD")
              )
          except Exception as e:
              print(f"Warning: No se pudo conectar a BD: {e}")
              result = {"escalated": False, "reason": f"Error de conexi√≥n: {e}"}
              print(json.dumps(result))
              {{ outputs.check_and_escalate_urgent.result = result | json }}
              sys.exit(0)
      
      # Escalar
      escalation = SupportUrgentEscalation(db_connection=db_conn)
      escalation_result = escalation.escalate_ticket(
          ticket_id=ticket_id,
          reason="auto_urgent_on_creation"
      )
      
      # Cerrar conexi√≥n
      if db_conn:
          db_conn.close()
      
      # Guardar resultado
      result = {
          "escalated": escalation_result.escalated,
          "actions": [a.action_type for a in escalation_result.actions],
          "new_priority": escalation_result.new_priority,
          "new_agent_id": escalation_result.new_agent_id,
          "supervisor_notified": escalation_result.supervisor_notified,
          "reason": escalation_result.reason
      }
      
      print(json.dumps(result))
      {{ outputs.check_and_escalate_urgent.result = result | json }}
    disabled: "{{ outputs.priority_calculation.result.priority not in ['urgent', 'critical'] }}"
  
  # ========================================================================
  # FASE 8: Notificaci√≥n de Status Inicial
  # ========================================================================
  - id: send_initial_status_notification
    type: io.kestra.core.tasks.scripts.Python
    description: Env√≠a notificaci√≥n inicial al cliente sobre el ticket creado
    inputFiles:
      support_status_notifications.py: |
        {{ read('workflow/kestra/flows/lib/support_status_notifications.py') }}
      support_notifications_multi.py: |
        {{ read('workflow/kestra/flows/lib/support_notifications_multi.py') }}
    runner: DOCKER
    docker:
      image: python:3.11-slim
    env:
      DB_HOST: "{{ vars.db_host }}"
      DB_NAME: "{{ vars.db_name }}"
      DB_USER: "{{ vars.db_user }}"
      DB_PASSWORD: "{{ vars.db_password }}"
      EMAIL_API_URL: "{{ vars.email_api_url }}"
    script: |
      import sys
      import json
      import os
      import psycopg2
      from support_status_notifications import SupportStatusNotifier
      from support_notifications_multi import (
          SupportNotificationManager,
          NotificationChannel,
          NotificationConfig
      )
      
      ticket_id = '''{{ outputs.validate_input.normalized.ticket_id }}'''
      initial_status = '''{{ outputs.persist_to_database.result.status }}'''
      
      # Configurar notificaciones
      notification_configs = [
          NotificationConfig(
              channel=NotificationChannel.EMAIL,
              enabled=True,
              priority=1,
              config={"api_url": os.getenv("EMAIL_API_URL")}
          )
      ]
      
      notification_manager = SupportNotificationManager(notification_configs)
      
      # Conectar a BD
      db_conn = None
      if {{ inputs.enable_db_persistence | lower }} == "true":
          try:
              db_conn = psycopg2.connect(
                  host=os.getenv("DB_HOST"),
                  database=os.getenv("DB_NAME"),
                  user=os.getenv("DB_USER"),
                  password=os.getenv("DB_PASSWORD")
              )
          except Exception as e:
              print(f"Warning: No se pudo conectar a BD: {e}")
              result = {"sent": False, "reason": f"Error de conexi√≥n: {e}"}
              print(json.dumps(result))
              {{ outputs.send_initial_status_notification.result = result | json }}
              sys.exit(0)
      
      # Enviar notificaci√≥n
      notifier = SupportStatusNotifier(
          db_connection=db_conn,
          notification_manager=notification_manager
      )
      
      sent = notifier.send_status_notification(
          ticket_id=ticket_id,
          new_status=initial_status,
          old_status=None
      )
      
      # Cerrar conexi√≥n
      if db_conn:
          db_conn.close()
      
      result = {"sent": sent, "status": initial_status}
      print(json.dumps(result))
      {{ outputs.send_initial_status_notification.result = result | json }}
    disabled: "{{ not inputs.enable_notifications }}"
  
  # ========================================================================
  # FASE 9: Sincronizaci√≥n con HubSpot (opcional)
  # ========================================================================
  - id: sync_to_hubspot
    type: io.kestra.core.tasks.flows.Http
    description: Sincroniza ticket con HubSpot
    uri: "https://api.hubapi.com/crm/v3/objects/tickets"
    method: POST
    headers:
      Authorization: "Bearer {{ inputs.hubspot_token }}"
      Content-Type: "application/json"
    body: |
      {
        "properties": {
          "subject": "{{ outputs.validate_input.normalized.subject }}",
          "content": "{{ outputs.validate_input.normalized.description }}",
          "hs_pipeline": "support",
          "hs_pipeline_stage": "{{ outputs.priority_calculation.result.priority }}",
          "hs_ticket_priority": "{{ outputs.priority_calculation.result.priority }}"
        },
        "associations": [
          {
            "to": {
              "id": "{{ outputs.validate_input.normalized.customer_id }}"
            },
            "type": "ticket_to_contact"
          }
        ]
      }
    disabled: "{{ not inputs.enable_hubspot_sync or not inputs.hubspot_token }}"
  
  # ========================================================================
  # FASE 8: Notificaciones
  # ========================================================================
  - id: notify_slack
    type: io.kestra.core.tasks.flows.Http
    description: Notifica a Slack sobre nuevo ticket
    uri: "{{ inputs.slack_webhook_url }}"
    method: POST
    headers:
      Content-Type: "application/json"
    body: |
      {
        "text": "üé´ Nuevo Ticket de Soporte",
        "blocks": [
          {
            "type": "section",
            "text": {
              "type": "mrkdwn",
              "text": "*Ticket ID:* {{ outputs.validate_input.normalized.ticket_id }}\n*Cliente:* {{ outputs.validate_input.normalized.customer_email }}\n*Prioridad:* {{ outputs.priority_calculation.result.priority }}\n*Departamento:* {{ outputs.intelligent_routing.result.department }}\n*Estado:* {{ outputs.chatbot_processing.result.chatbot_resolved ? 'Resuelto por Chatbot' : 'Pendiente' }}"
            }
          }
        ]
      }
    disabled: "{{ not inputs.enable_notifications or not inputs.slack_webhook_url }}"
  
  # ========================================================================
  # FASE 9: Resumen Final
  # ========================================================================
  - id: final_summary
    type: io.kestra.core.tasks.scripts.Python
    description: Genera resumen final del procesamiento
    script: |
      import json
      
      summary = {
          "ticket_id": "{{ outputs.validate_input.normalized.ticket_id }}",
          "status": "{{ outputs.chatbot_processing.result.chatbot_resolved ? 'chatbot_handled' : 'open' }}",
          "chatbot": {
              "attempted": {{ outputs.chatbot_processing.result.chatbot_attempted }},
              "resolved": {{ outputs.chatbot_processing.result.chatbot_resolved }},
              "confidence": {{ outputs.chatbot_processing.result.confidence }}
          },
          "priority": {
              "level": "{{ outputs.priority_calculation.result.priority }}",
              "score": {{ outputs.priority_calculation.result.priority_score }}
          },
          "routing": {
              "department": "{{ outputs.intelligent_routing.result.department }}",
              "agent_assigned": {{ outputs.intelligent_routing.result.agent_id is not none }},
              "agent_name": "{{ outputs.intelligent_routing.result.agent_name }}"
          },
          "persisted": {{ outputs.persist_to_database is not none }}
      }
      
      print(json.dumps(summary, indent=2))
      {{ outputs.final_summary.summary = summary | json }}





