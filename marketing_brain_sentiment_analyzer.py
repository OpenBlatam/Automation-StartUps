#!/usr/bin/env python3
"""
üòä MARKETING BRAIN SENTIMENT ANALYZER
Sistema Avanzado de An√°lisis de Sentimientos y Emociones
Incluye an√°lisis multimodal, detecci√≥n de emociones, an√°lisis de voz y procesamiento de im√°genes
"""

import json
import asyncio
import uuid
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
import logging
from dataclasses import dataclass, asdict
from pathlib import Path
import sys
from enum import Enum
import sqlite3
import redis
import requests
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import threading
import queue
import time
import hashlib
import hmac
import base64
import cv2
import librosa
import soundfile as sf
import whisper
import transformers
from transformers import pipeline, AutoTokenizer, AutoModel
import torch
import torchvision
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from textblob import TextBlob
import spacy
import vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VaderAnalyzer
import flair
from flair.models import TextClassifier
from flair.data import Sentence
import openai
import anthropic
import google.generativeai as genai
import yaml
import pickle
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import mediapipe as mp
import face_recognition
import dlib
import opencv as cv
import speech_recognition as sr
import pyttsx3
import pyaudio
import wave
import moviepy.editor as mp4
import yt_dlp
import tweepy
import praw
import facebook
import linkedin
import instagram
import tiktok
import youtube
import telegram
import discord
import slack
import whatsapp
import signal
import os
from concurrent.futures import ThreadPoolExecutor
import psutil
import GPUtil
import requests
import aiohttp
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.live import Live
from rich.layout import Layout
from rich.text import Text
from rich.align import Align
from rich import box

# Agregar el directorio actual al path
sys.path.append(str(Path(__file__).parent))

logger = logging.getLogger(__name__)
console = Console()

class SentimentType(Enum):
    """Tipos de sentimientos"""
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    MIXED = "mixed"

class EmotionType(Enum):
    """Tipos de emociones"""
    JOY = "joy"
    SADNESS = "sadness"
    ANGER = "anger"
    FEAR = "fear"
    SURPRISE = "surprise"
    DISGUST = "disgust"
    TRUST = "trust"
    ANTICIPATION = "anticipation"

class ContentType(Enum):
    """Tipos de contenido"""
    TEXT = "text"
    IMAGE = "image"
    AUDIO = "audio"
    VIDEO = "video"
    SOCIAL_MEDIA = "social_media"
    REVIEW = "review"
    COMMENT = "comment"
    POST = "post"

class Platform(Enum):
    """Plataformas sociales"""
    TWITTER = "twitter"
    FACEBOOK = "facebook"
    INSTAGRAM = "instagram"
    LINKEDIN = "linkedin"
    YOUTUBE = "youtube"
    TIKTOK = "tiktok"
    REDDIT = "reddit"
    DISCORD = "discord"

@dataclass
class SentimentAnalysis:
    """An√°lisis de sentimientos"""
    analysis_id: str
    content_type: ContentType
    platform: Optional[Platform]
    text_content: Optional[str]
    image_path: Optional[str]
    audio_path: Optional[str]
    video_path: Optional[str]
    sentiment_scores: Dict[str, float]
    emotions: Dict[str, float]
    confidence: float
    language: str
    timestamp: str
    metadata: Dict[str, Any]

@dataclass
class EmotionDetection:
    """Detecci√≥n de emociones"""
    emotion_id: str
    emotion_type: EmotionType
    intensity: float
    confidence: float
    facial_landmarks: Optional[List[Tuple[int, int]]]
    voice_features: Optional[Dict[str, float]]
    text_indicators: Optional[List[str]]
    timestamp: str

@dataclass
class SentimentTrend:
    """Tendencia de sentimientos"""
    trend_id: str
    platform: Platform
    topic: str
    time_period: str
    sentiment_timeline: List[Dict[str, Any]]
    emotion_timeline: List[Dict[str, Any]]
    volume_timeline: List[Dict[str, Any]]
    influencers: List[str]
    viral_content: List[str]
    created_at: str

class MarketingBrainSentimentAnalyzer:
    """
    Sistema Avanzado de An√°lisis de Sentimientos y Emociones
    Incluye an√°lisis multimodal, detecci√≥n de emociones, an√°lisis de voz y procesamiento de im√°genes
    """
    
    def __init__(self):
        self.sentiment_analyses = {}
        self.emotion_detections = {}
        self.sentiment_trends = {}
        self.analysis_queue = queue.Queue()
        self.trend_queue = queue.Queue()
        
        # Configuraci√≥n
        self.config = self._load_config()
        
        # Bases de datos
        self.db_connection = None
        self.redis_client = None
        
        # Modelos de IA
        self.sentiment_models = {}
        self.emotion_models = {}
        self.multimodal_models = {}
        
        # APIs externas
        self.api_clients = {}
        
        # Threads
        self.analysis_processor_thread = None
        self.trend_processor_thread = None
        
        # Estado del sistema
        self.is_running = False
        
        # M√©tricas
        self.sentiment_metrics = {
            'total_analyses': 0,
            'text_analyses': 0,
            'image_analyses': 0,
            'audio_analyses': 0,
            'video_analyses': 0,
            'social_media_analyses': 0,
            'emotion_detections': 0,
            'trend_analyses': 0,
            'average_confidence': 0.0,
            'processing_time': 0.0,
            'accuracy_score': 0.0,
            'multimodal_analyses': 0
        }
        
        logger.info("üòä Marketing Brain Sentiment Analyzer initialized successfully")
    
    def _load_config(self) -> Dict[str, Any]:
        """Cargar configuraci√≥n del analizador de sentimientos"""
        return {
            'sentiment': {
                'max_text_length': 10000,
                'max_audio_duration': 300,  # 5 minutos
                'max_video_duration': 600,  # 10 minutos
                'confidence_threshold': 0.7,
                'batch_size': 32,
                'processing_timeout': 30,
                'cache_results': True,
                'real_time_analysis': True
            },
            'models': {
                'text_sentiment': {
                    'primary': 'roberta-base-sentiment',
                    'fallback': 'vader',
                    'multilingual': 'xlm-roberta-base',
                    'emotion': 'j-hartmann/emotion-english-distilroberta-base'
                },
                'image_emotion': {
                    'primary': 'microsoft/emotion-recognition',
                    'fallback': 'opencv_haar',
                    'face_detection': 'mediapipe'
                },
                'audio_emotion': {
                    'primary': 'wav2vec2-emotion',
                    'fallback': 'librosa_features',
                    'speech_recognition': 'whisper'
                },
                'multimodal': {
                    'primary': 'clip-sentiment',
                    'fallback': 'ensemble'
                }
            },
            'apis': {
                'openai': {
                    'enabled': True,
                    'model': 'gpt-4',
                    'max_tokens': 1000
                },
                'anthropic': {
                    'enabled': True,
                    'model': 'claude-3-sonnet',
                    'max_tokens': 1000
                },
                'google': {
                    'enabled': True,
                    'model': 'gemini-pro',
                    'max_tokens': 1000
                }
            },
            'social_media': {
                'twitter': {
                    'enabled': True,
                    'rate_limit': 300,
                    'real_time': True
                },
                'facebook': {
                    'enabled': True,
                    'rate_limit': 200,
                    'real_time': True
                },
                'instagram': {
                    'enabled': True,
                    'rate_limit': 200,
                    'real_time': True
                },
                'youtube': {
                    'enabled': True,
                    'rate_limit': 100,
                    'real_time': False
                },
                'tiktok': {
                    'enabled': True,
                    'rate_limit': 100,
                    'real_time': True
                }
            },
            'emotions': {
                'ekman_basic': ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust'],
                'plutchik_extended': ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'trust', 'anticipation'],
                'custom_business': ['satisfaction', 'frustration', 'excitement', 'concern', 'trust', 'skepticism']
            },
            'languages': {
                'supported': ['en', 'es', 'fr', 'de', 'it', 'pt', 'ru', 'zh', 'ja', 'ko', 'ar'],
                'default': 'en',
                'auto_detect': True
            }
        }
    
    async def initialize_sentiment_system(self):
        """Inicializar sistema de an√°lisis de sentimientos"""
        logger.info("üöÄ Initializing Marketing Brain Sentiment Analyzer...")
        
        try:
            # Inicializar bases de datos
            await self._initialize_databases()
            
            # Crear directorios necesarios
            await self._create_directories()
            
            # Inicializar modelos de IA
            await self._initialize_ai_models()
            
            # Inicializar APIs externas
            await self._initialize_api_clients()
            
            # Cargar an√°lisis existentes
            await self._load_existing_analyses()
            
            # Crear an√°lisis de demostraci√≥n
            await self._create_demo_analyses()
            
            # Iniciar threads de procesamiento
            self._start_processing_threads()
            
            logger.info("‚úÖ Sentiment Analyzer system initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing sentiment system: {e}")
            raise
    
    async def _initialize_databases(self):
        """Inicializar bases de datos"""
        try:
            # SQLite para metadatos
            self.db_connection = sqlite3.connect('sentiment_analysis.db', check_same_thread=False)
            
            # Redis para cache y colas
            self.redis_client = redis.Redis(host='localhost', port=6379, db=12, decode_responses=True)
            
            # Crear tablas
            await self._create_sentiment_tables()
            
        except Exception as e:
            logger.error(f"Error initializing databases: {e}")
            raise
    
    async def _create_sentiment_tables(self):
        """Crear tablas de base de datos"""
        try:
            cursor = self.db_connection.cursor()
            
            # Tabla de an√°lisis de sentimientos
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS sentiment_analyses (
                    analysis_id TEXT PRIMARY KEY,
                    content_type TEXT NOT NULL,
                    platform TEXT,
                    text_content TEXT,
                    image_path TEXT,
                    audio_path TEXT,
                    video_path TEXT,
                    sentiment_scores TEXT NOT NULL,
                    emotions TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    language TEXT NOT NULL,
                    timestamp TEXT NOT NULL,
                    metadata TEXT NOT NULL
                )
            ''')
            
            # Tabla de detecci√≥n de emociones
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS emotion_detections (
                    emotion_id TEXT PRIMARY KEY,
                    emotion_type TEXT NOT NULL,
                    intensity REAL NOT NULL,
                    confidence REAL NOT NULL,
                    facial_landmarks TEXT,
                    voice_features TEXT,
                    text_indicators TEXT,
                    timestamp TEXT NOT NULL
                )
            ''')
            
            # Tabla de tendencias de sentimientos
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS sentiment_trends (
                    trend_id TEXT PRIMARY KEY,
                    platform TEXT NOT NULL,
                    topic TEXT NOT NULL,
                    time_period TEXT NOT NULL,
                    sentiment_timeline TEXT NOT NULL,
                    emotion_timeline TEXT NOT NULL,
                    volume_timeline TEXT NOT NULL,
                    influencers TEXT NOT NULL,
                    viral_content TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            ''')
            
            self.db_connection.commit()
            logger.info("Sentiment Analyzer database tables created successfully")
            
        except Exception as e:
            logger.error(f"Error creating sentiment tables: {e}")
            raise
    
    async def _create_directories(self):
        """Crear directorios necesarios"""
        try:
            directories = [
                'sentiment_data',
                'emotion_data',
                'trend_data',
                'model_cache',
                'temp_files',
                'social_media_data',
                'multimodal_data',
                'sentiment_logs',
                'emotion_models',
                'sentiment_reports'
            ]
            
            for directory in directories:
                Path(directory).mkdir(parents=True, exist_ok=True)
            
            logger.info("Sentiment Analyzer directories created successfully")
            
        except Exception as e:
            logger.error(f"Error creating directories: {e}")
            raise
    
    async def _initialize_ai_models(self):
        """Inicializar modelos de IA"""
        try:
            # Modelo de sentimientos de texto
            self.sentiment_models['text_sentiment'] = pipeline(
                "sentiment-analysis",
                model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                return_all_scores=True
            )
            
            # Modelo de emociones
            self.emotion_models['emotion_classifier'] = pipeline(
                "text-classification",
                model="j-hartmann/emotion-english-distilroberta-base",
                return_all_scores=True
            )
            
            # Modelo VADER para an√°lisis r√°pido
            self.sentiment_models['vader'] = VaderAnalyzer()
            
            # Modelo Flair para an√°lisis avanzado
            self.sentiment_models['flair'] = TextClassifier.load('en-sentiment')
            
            # Modelo de reconocimiento facial
            self.emotion_models['face_detection'] = mp.solutions.face_detection
            self.emotion_models['face_mesh'] = mp.solutions.face_mesh
            
            # Modelo de an√°lisis de audio
            self.emotion_models['audio_emotion'] = pipeline(
                "audio-classification",
                model="superb/hubert-large-superb-er"
            )
            
            # Modelo Whisper para transcripci√≥n
            self.sentiment_models['whisper'] = whisper.load_model("base")
            
            logger.info(f"Initialized {len(self.sentiment_models)} sentiment models")
            logger.info(f"Initialized {len(self.emotion_models)} emotion models")
            
        except Exception as e:
            logger.error(f"Error initializing AI models: {e}")
            raise
    
    async def _initialize_api_clients(self):
        """Inicializar clientes de API"""
        try:
            # OpenAI
            if self.config['apis']['openai']['enabled']:
                openai.api_key = os.getenv('OPENAI_API_KEY')
                self.api_clients['openai'] = openai
            
            # Anthropic
            if self.config['apis']['anthropic']['enabled']:
                self.api_clients['anthropic'] = anthropic.Anthropic(
                    api_key=os.getenv('ANTHROPIC_API_KEY')
                )
            
            # Google
            if self.config['apis']['google']['enabled']:
                genai.configure(api_key=os.getenv('GOOGLE_AI_KEY'))
                self.api_clients['google'] = genai
            
            logger.info(f"Initialized {len(self.api_clients)} API clients")
            
        except Exception as e:
            logger.error(f"Error initializing API clients: {e}")
            raise
    
    async def _load_existing_analyses(self):
        """Cargar an√°lisis existentes"""
        try:
            cursor = self.db_connection.cursor()
            cursor.execute('SELECT * FROM sentiment_analyses')
            rows = cursor.fetchall()
            
            for row in rows:
                analysis = SentimentAnalysis(
                    analysis_id=row[0],
                    content_type=ContentType(row[1]),
                    platform=Platform(row[2]) if row[2] else None,
                    text_content=row[3],
                    image_path=row[4],
                    audio_path=row[5],
                    video_path=row[6],
                    sentiment_scores=json.loads(row[7]),
                    emotions=json.loads(row[8]),
                    confidence=row[9],
                    language=row[10],
                    timestamp=row[11],
                    metadata=json.loads(row[12])
                )
                self.sentiment_analyses[analysis.analysis_id] = analysis
            
            logger.info(f"Loaded {len(self.sentiment_analyses)} sentiment analyses")
            
        except Exception as e:
            logger.error(f"Error loading existing analyses: {e}")
            raise
    
    async def _create_demo_analyses(self):
        """Crear an√°lisis de demostraci√≥n"""
        try:
            # An√°lisis de texto positivo
            positive_text_analysis = SentimentAnalysis(
                analysis_id=str(uuid.uuid4()),
                content_type=ContentType.TEXT,
                platform=Platform.TWITTER,
                text_content="I absolutely love this new product! It's amazing and exceeded all my expectations. Highly recommend!",
                image_path=None,
                audio_path=None,
                video_path=None,
                sentiment_scores={
                    'positive': 0.95,
                    'negative': 0.02,
                    'neutral': 0.03
                },
                emotions={
                    'joy': 0.90,
                    'trust': 0.85,
                    'anticipation': 0.70,
                    'surprise': 0.60
                },
                confidence=0.92,
                language='en',
                timestamp=datetime.now().isoformat(),
                metadata={
                    'model_used': 'roberta-base-sentiment',
                    'processing_time': 0.15,
                    'word_count': 20
                }
            )
            
            self.sentiment_analyses[positive_text_analysis.analysis_id] = positive_text_analysis
            
            # An√°lisis de texto negativo
            negative_text_analysis = SentimentAnalysis(
                analysis_id=str(uuid.uuid4()),
                content_type=ContentType.TEXT,
                platform=Platform.FACEBOOK,
                text_content="This service is terrible. I've been waiting for hours and nobody is helping me. Very disappointed.",
                image_path=None,
                audio_path=None,
                video_path=None,
                sentiment_scores={
                    'positive': 0.05,
                    'negative': 0.88,
                    'neutral': 0.07
                },
                emotions={
                    'anger': 0.85,
                    'sadness': 0.70,
                    'disgust': 0.60,
                    'fear': 0.30
                },
                confidence=0.89,
                language='en',
                timestamp=datetime.now().isoformat(),
                metadata={
                    'model_used': 'roberta-base-sentiment',
                    'processing_time': 0.12,
                    'word_count': 18
                }
            )
            
            self.sentiment_analyses[negative_text_analysis.analysis_id] = negative_text_analysis
            
            # An√°lisis de imagen (simulado)
            image_analysis = SentimentAnalysis(
                analysis_id=str(uuid.uuid4()),
                content_type=ContentType.IMAGE,
                platform=Platform.INSTAGRAM,
                text_content=None,
                image_path="demo_images/happy_customer.jpg",
                audio_path=None,
                video_path=None,
                sentiment_scores={
                    'positive': 0.82,
                    'negative': 0.05,
                    'neutral': 0.13
                },
                emotions={
                    'joy': 0.88,
                    'trust': 0.75,
                    'surprise': 0.45
                },
                confidence=0.85,
                language='en',
                timestamp=datetime.now().isoformat(),
                metadata={
                    'model_used': 'microsoft/emotion-recognition',
                    'processing_time': 0.25,
                    'face_count': 1,
                    'dominant_emotion': 'joy'
                }
            )
            
            self.sentiment_analyses[image_analysis.analysis_id] = image_analysis
            
            logger.info("Demo sentiment analyses created successfully")
            
        except Exception as e:
            logger.error(f"Error creating demo analyses: {e}")
            raise
    
    def _start_processing_threads(self):
        """Iniciar threads de procesamiento"""
        self.is_running = True
        
        self.analysis_processor_thread = threading.Thread(target=self._analysis_processor_loop, daemon=True)
        self.analysis_processor_thread.start()
        
        self.trend_processor_thread = threading.Thread(target=self._trend_processor_loop, daemon=True)
        self.trend_processor_thread.start()
        
        logger.info("Sentiment Analyzer processing threads started")
    
    def _analysis_processor_loop(self):
        """Loop del procesador de an√°lisis"""
        while self.is_running:
            try:
                if not self.analysis_queue.empty():
                    analysis = self.analysis_queue.get_nowait()
                    asyncio.run(self._process_sentiment_analysis(analysis))
                    self.analysis_queue.task_done()
                
                time.sleep(0.1)
                
            except queue.Empty:
                time.sleep(0.1)
            except Exception as e:
                logger.error(f"Error in analysis processor loop: {e}")
                time.sleep(1)
    
    def _trend_processor_loop(self):
        """Loop del procesador de tendencias"""
        while self.is_running:
            try:
                if not self.trend_queue.empty():
                    trend = self.trend_queue.get_nowait()
                    asyncio.run(self._process_sentiment_trend(trend))
                    self.trend_queue.task_done()
                
                time.sleep(1)
                
            except queue.Empty:
                time.sleep(1)
            except Exception as e:
                logger.error(f"Error in trend processor loop: {e}")
                time.sleep(5)
    
    async def analyze_sentiment(self, content: str, content_type: ContentType, 
                              platform: Optional[Platform] = None, 
                              image_path: Optional[str] = None,
                              audio_path: Optional[str] = None,
                              video_path: Optional[str] = None) -> str:
        """Analizar sentimientos"""
        try:
            # Crear an√°lisis
            analysis = SentimentAnalysis(
                analysis_id=str(uuid.uuid4()),
                content_type=content_type,
                platform=platform,
                text_content=content,
                image_path=image_path,
                audio_path=audio_path,
                video_path=video_path,
                sentiment_scores={},
                emotions={},
                confidence=0.0,
                language='en',
                timestamp=datetime.now().isoformat(),
                metadata={}
            )
            
            # Agregar an√°lisis
            self.sentiment_analyses[analysis.analysis_id] = analysis
            
            # Guardar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                INSERT INTO sentiment_analyses (analysis_id, content_type, platform, text_content,
                                              image_path, audio_path, video_path, sentiment_scores,
                                              emotions, confidence, language, timestamp, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                analysis.analysis_id,
                analysis.content_type.value,
                analysis.platform.value if analysis.platform else None,
                analysis.text_content,
                analysis.image_path,
                analysis.audio_path,
                analysis.video_path,
                json.dumps(analysis.sentiment_scores),
                json.dumps(analysis.emotions),
                analysis.confidence,
                analysis.language,
                analysis.timestamp,
                json.dumps(analysis.metadata)
            ))
            self.db_connection.commit()
            
            # Agregar a cola de procesamiento
            self.analysis_queue.put(analysis)
            
            # Actualizar m√©tricas
            self.sentiment_metrics['total_analyses'] += 1
            if content_type == ContentType.TEXT:
                self.sentiment_metrics['text_analyses'] += 1
            elif content_type == ContentType.IMAGE:
                self.sentiment_metrics['image_analyses'] += 1
            elif content_type == ContentType.AUDIO:
                self.sentiment_metrics['audio_analyses'] += 1
            elif content_type == ContentType.VIDEO:
                self.sentiment_metrics['video_analyses'] += 1
            elif content_type == ContentType.SOCIAL_MEDIA:
                self.sentiment_metrics['social_media_analyses'] += 1
            
            logger.info(f"Sentiment analysis created: {analysis.analysis_id}")
            return analysis.analysis_id
            
        except Exception as e:
            logger.error(f"Error analyzing sentiment: {e}")
            return None
    
    async def _process_sentiment_analysis(self, analysis: SentimentAnalysis):
        """Procesar an√°lisis de sentimientos"""
        try:
            logger.info(f"Processing sentiment analysis: {analysis.analysis_id}")
            
            start_time = time.time()
            
            # Procesar seg√∫n el tipo de contenido
            if analysis.content_type == ContentType.TEXT:
                await self._analyze_text_sentiment(analysis)
            elif analysis.content_type == ContentType.IMAGE:
                await self._analyze_image_sentiment(analysis)
            elif analysis.content_type == ContentType.AUDIO:
                await self._analyze_audio_sentiment(analysis)
            elif analysis.content_type == ContentType.VIDEO:
                await self._analyze_video_sentiment(analysis)
            elif analysis.content_type == ContentType.SOCIAL_MEDIA:
                await self._analyze_social_media_sentiment(analysis)
            
            # Calcular tiempo de procesamiento
            processing_time = time.time() - start_time
            analysis.metadata['processing_time'] = processing_time
            
            # Actualizar m√©tricas
            self.sentiment_metrics['processing_time'] += processing_time
            if analysis.confidence > 0:
                self.sentiment_metrics['average_confidence'] = (
                    (self.sentiment_metrics['average_confidence'] * (self.sentiment_metrics['total_analyses'] - 1) + 
                     analysis.confidence) / self.sentiment_metrics['total_analyses']
                )
            
            # Actualizar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                UPDATE sentiment_analyses SET sentiment_scores = ?, emotions = ?, confidence = ?, metadata = ?
                WHERE analysis_id = ?
            ''', (
                json.dumps(analysis.sentiment_scores),
                json.dumps(analysis.emotions),
                analysis.confidence,
                json.dumps(analysis.metadata),
                analysis.analysis_id
            ))
            self.db_connection.commit()
            
            logger.info(f"Sentiment analysis processed: {analysis.analysis_id}")
            
        except Exception as e:
            logger.error(f"Error processing sentiment analysis: {e}")
    
    async def _analyze_text_sentiment(self, analysis: SentimentAnalysis):
        """Analizar sentimientos de texto"""
        try:
            if not analysis.text_content:
                return
            
            # An√°lisis con modelo principal
            sentiment_result = self.sentiment_models['text_sentiment'](analysis.text_content)
            
            # Procesar resultados
            for result in sentiment_result[0]:
                label = result['label'].lower()
                score = result['score']
                
                if 'positive' in label:
                    analysis.sentiment_scores['positive'] = score
                elif 'negative' in label:
                    analysis.sentiment_scores['negative'] = score
                elif 'neutral' in label:
                    analysis.sentiment_scores['neutral'] = score
            
            # An√°lisis de emociones
            emotion_result = self.emotion_models['emotion_classifier'](analysis.text_content)
            
            for result in emotion_result[0]:
                emotion = result['label'].lower()
                score = result['score']
                analysis.emotions[emotion] = score
            
            # Calcular confianza
            max_sentiment_score = max(analysis.sentiment_scores.values())
            max_emotion_score = max(analysis.emotions.values()) if analysis.emotions else 0
            analysis.confidence = (max_sentiment_score + max_emotion_score) / 2
            
            # Detectar idioma
            analysis.language = await self._detect_language(analysis.text_content)
            
        except Exception as e:
            logger.error(f"Error analyzing text sentiment: {e}")
    
    async def _analyze_image_sentiment(self, analysis: SentimentAnalysis):
        """Analizar sentimientos de imagen"""
        try:
            if not analysis.image_path or not Path(analysis.image_path).exists():
                return
            
            # Cargar imagen
            image = cv2.imread(analysis.image_path)
            if image is None:
                return
            
            # Detectar caras
            face_detection = self.emotion_models['face_detection']
            with face_detection.FaceDetection() as face_detector:
                results = face_detector.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
                
                if results.detections:
                    # Simular an√°lisis de emociones faciales
                    analysis.emotions = {
                        'joy': np.random.uniform(0.6, 0.9),
                        'trust': np.random.uniform(0.5, 0.8),
                        'surprise': np.random.uniform(0.3, 0.7)
                    }
                    
                    analysis.sentiment_scores = {
                        'positive': np.random.uniform(0.7, 0.95),
                        'negative': np.random.uniform(0.05, 0.2),
                        'neutral': np.random.uniform(0.1, 0.3)
                    }
                    
                    analysis.confidence = np.random.uniform(0.8, 0.95)
                    analysis.metadata['face_count'] = len(results.detections)
                    analysis.metadata['dominant_emotion'] = max(analysis.emotions, key=analysis.emotions.get)
            
        except Exception as e:
            logger.error(f"Error analyzing image sentiment: {e}")
    
    async def _analyze_audio_sentiment(self, analysis: SentimentAnalysis):
        """Analizar sentimientos de audio"""
        try:
            if not analysis.audio_path or not Path(analysis.audio_path).exists():
                return
            
            # Transcribir audio
            transcription = self.sentiment_models['whisper'].transcribe(analysis.audio_path)
            analysis.text_content = transcription["text"]
            
            # Analizar sentimientos del texto transcrito
            await self._analyze_text_sentiment(analysis)
            
            # An√°lisis de caracter√≠sticas de voz
            audio, sr = librosa.load(analysis.audio_path)
            
            # Extraer caracter√≠sticas de audio
            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
            spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)
            zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)
            
            # Simular an√°lisis de emociones basado en caracter√≠sticas de voz
            analysis.emotions.update({
                'joy': np.random.uniform(0.4, 0.8),
                'sadness': np.random.uniform(0.2, 0.6),
                'anger': np.random.uniform(0.1, 0.5)
            })
            
            analysis.metadata['audio_features'] = {
                'duration': len(audio) / sr,
                'sample_rate': sr,
                'mfcc_mean': float(np.mean(mfccs)),
                'spectral_centroid_mean': float(np.mean(spectral_centroids)),
                'zero_crossing_rate_mean': float(np.mean(zero_crossing_rate))
            }
            
        except Exception as e:
            logger.error(f"Error analyzing audio sentiment: {e}")
    
    async def _analyze_video_sentiment(self, analysis: SentimentAnalysis):
        """Analizar sentimientos de video"""
        try:
            if not analysis.video_path or not Path(analysis.video_path).exists():
                return
            
            # Extraer audio del video
            video = mp4.VideoFileClip(analysis.video_path)
            audio_path = f"temp_files/audio_{analysis.analysis_id}.wav"
            video.audio.write_audiofile(audio_path)
            
            # Analizar audio
            analysis.audio_path = audio_path
            await self._analyze_audio_sentiment(analysis)
            
            # Analizar frames del video
            frame_count = int(video.fps * min(video.duration, 10))  # Analizar primeros 10 segundos
            emotions_per_frame = []
            
            for i in range(0, frame_count, int(video.fps)):  # 1 frame por segundo
                frame = video.get_frame(i / video.fps)
                frame_path = f"temp_files/frame_{analysis.analysis_id}_{i}.jpg"
                cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
                
                # Analizar frame
                temp_analysis = SentimentAnalysis(
                    analysis_id=f"temp_{i}",
                    content_type=ContentType.IMAGE,
                    platform=None,
                    text_content=None,
                    image_path=frame_path,
                    audio_path=None,
                    video_path=None,
                    sentiment_scores={},
                    emotions={},
                    confidence=0.0,
                    language='en',
                    timestamp=datetime.now().isoformat(),
                    metadata={}
                )
                
                await self._analyze_image_sentiment(temp_analysis)
                emotions_per_frame.append(temp_analysis.emotions)
            
            # Promediar emociones de todos los frames
            if emotions_per_frame:
                all_emotions = set()
                for frame_emotions in emotions_per_frame:
                    all_emotions.update(frame_emotions.keys())
                
                for emotion in all_emotions:
                    scores = [frame_emotions.get(emotion, 0) for frame_emotions in emotions_per_frame]
                    analysis.emotions[emotion] = np.mean(scores)
            
            analysis.metadata['video_features'] = {
                'duration': video.duration,
                'fps': video.fps,
                'frames_analyzed': len(emotions_per_frame),
                'resolution': f"{video.w}x{video.h}"
            }
            
            # Limpiar archivos temporales
            video.close()
            if Path(audio_path).exists():
                Path(audio_path).unlink()
            for i in range(0, frame_count, int(video.fps)):
                frame_path = f"temp_files/frame_{analysis.analysis_id}_{i}.jpg"
                if Path(frame_path).exists():
                    Path(frame_path).unlink()
            
        except Exception as e:
            logger.error(f"Error analyzing video sentiment: {e}")
    
    async def _analyze_social_media_sentiment(self, analysis: SentimentAnalysis):
        """Analizar sentimientos de redes sociales"""
        try:
            # Combinar an√°lisis de texto, imagen y audio si est√°n disponibles
            if analysis.text_content:
                await self._analyze_text_sentiment(analysis)
            
            if analysis.image_path:
                await self._analyze_image_sentiment(analysis)
            
            if analysis.audio_path:
                await self._analyze_audio_sentiment(analysis)
            
            # An√°lisis espec√≠fico de plataforma
            if analysis.platform:
                platform_analysis = await self._analyze_platform_specific_sentiment(analysis)
                analysis.metadata.update(platform_analysis)
            
            # Marcar como an√°lisis multimodal si tiene m√∫ltiples tipos de contenido
            content_types = sum([
                1 for x in [analysis.text_content, analysis.image_path, analysis.audio_path, analysis.video_path] if x
            ])
            
            if content_types > 1:
                self.sentiment_metrics['multimodal_analyses'] += 1
                analysis.metadata['multimodal'] = True
            
        except Exception as e:
            logger.error(f"Error analyzing social media sentiment: {e}")
    
    async def _analyze_platform_specific_sentiment(self, analysis: SentimentAnalysis) -> Dict[str, Any]:
        """Analizar sentimientos espec√≠ficos de plataforma"""
        try:
            platform_analysis = {}
            
            if analysis.platform == Platform.TWITTER:
                # An√°lisis espec√≠fico de Twitter
                platform_analysis['hashtags'] = [word for word in analysis.text_content.split() if word.startswith('#')]
                platform_analysis['mentions'] = [word for word in analysis.text_content.split() if word.startswith('@')]
                platform_analysis['character_count'] = len(analysis.text_content)
                
            elif analysis.platform == Platform.FACEBOOK:
                # An√°lisis espec√≠fico de Facebook
                platform_analysis['engagement_indicators'] = ['like', 'love', 'wow', 'haha', 'sad', 'angry']
                
            elif analysis.platform == Platform.INSTAGRAM:
                # An√°lisis espec√≠fico de Instagram
                platform_analysis['hashtag_count'] = len([word for word in analysis.text_content.split() if word.startswith('#')])
                platform_analysis['emoji_count'] = len([char for char in analysis.text_content if ord(char) > 127])
                
            return platform_analysis
            
        except Exception as e:
            logger.error(f"Error in platform-specific analysis: {e}")
            return {}
    
    async def _detect_language(self, text: str) -> str:
        """Detectar idioma del texto"""
        try:
            # Simular detecci√≥n de idioma
            # En implementaci√≥n real, usar langdetect o similar
            if any(char in text for char in '√±√°√©√≠√≥√∫√º'):
                return 'es'
            elif any(char in text for char in '√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ø√ß'):
                return 'fr'
            elif any(char in text for char in '√§√∂√º√ü'):
                return 'de'
            else:
                return 'en'
        except Exception as e:
            logger.error(f"Error detecting language: {e}")
            return 'en'
    
    async def create_sentiment_trend(self, platform: Platform, topic: str, 
                                   time_period: str = "7d") -> str:
        """Crear an√°lisis de tendencias de sentimientos"""
        try:
            # Crear tendencia
            trend = SentimentTrend(
                trend_id=str(uuid.uuid4()),
                platform=platform,
                topic=topic,
                time_period=time_period,
                sentiment_timeline=[],
                emotion_timeline=[],
                volume_timeline=[],
                influencers=[],
                viral_content=[],
                created_at=datetime.now().isoformat()
            )
            
            # Agregar tendencia
            self.sentiment_trends[trend.trend_id] = trend
            
            # Guardar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                INSERT INTO sentiment_trends (trend_id, platform, topic, time_period,
                                            sentiment_timeline, emotion_timeline,
                                            volume_timeline, influencers, viral_content, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                trend.trend_id,
                trend.platform.value,
                trend.topic,
                trend.time_period,
                json.dumps(trend.sentiment_timeline),
                json.dumps(trend.emotion_timeline),
                json.dumps(trend.volume_timeline),
                json.dumps(trend.influencers),
                json.dumps(trend.viral_content),
                trend.created_at
            ))
            self.db_connection.commit()
            
            # Agregar a cola de procesamiento
            self.trend_queue.put(trend)
            
            # Actualizar m√©tricas
            self.sentiment_metrics['trend_analyses'] += 1
            
            logger.info(f"Sentiment trend created: {trend.trend_id}")
            return trend.trend_id
            
        except Exception as e:
            logger.error(f"Error creating sentiment trend: {e}")
            return None
    
    async def _process_sentiment_trend(self, trend: SentimentTrend):
        """Procesar tendencia de sentimientos"""
        try:
            logger.info(f"Processing sentiment trend: {trend.trend_id}")
            
            # Simular recolecci√≥n de datos de la plataforma
            await self._collect_platform_data(trend)
            
            # Analizar sentimientos en el tiempo
            await self._analyze_temporal_sentiment(trend)
            
            # Identificar influencers
            await self._identify_influencers(trend)
            
            # Identificar contenido viral
            await self._identify_viral_content(trend)
            
            # Actualizar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                UPDATE sentiment_trends SET sentiment_timeline = ?, emotion_timeline = ?,
                                          volume_timeline = ?, influencers = ?, viral_content = ?
                WHERE trend_id = ?
            ''', (
                json.dumps(trend.sentiment_timeline),
                json.dumps(trend.emotion_timeline),
                json.dumps(trend.volume_timeline),
                json.dumps(trend.influencers),
                json.dumps(trend.viral_content),
                trend.trend_id
            ))
            self.db_connection.commit()
            
            logger.info(f"Sentiment trend processed: {trend.trend_id}")
            
        except Exception as e:
            logger.error(f"Error processing sentiment trend: {e}")
    
    async def _collect_platform_data(self, trend: SentimentTrend):
        """Recolectar datos de la plataforma"""
        try:
            # Simular recolecci√≥n de datos
            # En implementaci√≥n real, usar APIs de redes sociales
            
            if trend.platform == Platform.TWITTER:
                # Simular datos de Twitter
                trend.volume_timeline = [
                    {'timestamp': '2024-01-01T00:00:00Z', 'volume': 100},
                    {'timestamp': '2024-01-01T06:00:00Z', 'volume': 150},
                    {'timestamp': '2024-01-01T12:00:00Z', 'volume': 200},
                    {'timestamp': '2024-01-01T18:00:00Z', 'volume': 180}
                ]
            
            elif trend.platform == Platform.FACEBOOK:
                # Simular datos de Facebook
                trend.volume_timeline = [
                    {'timestamp': '2024-01-01T00:00:00Z', 'volume': 80},
                    {'timestamp': '2024-01-01T06:00:00Z', 'volume': 120},
                    {'timestamp': '2024-01-01T12:00:00Z', 'volume': 160},
                    {'timestamp': '2024-01-01T18:00:00Z', 'volume': 140}
                ]
            
        except Exception as e:
            logger.error(f"Error collecting platform data: {e}")
    
    async def _analyze_temporal_sentiment(self, trend: SentimentTrend):
        """Analizar sentimientos temporales"""
        try:
            # Simular an√°lisis temporal
            trend.sentiment_timeline = [
                {
                    'timestamp': '2024-01-01T00:00:00Z',
                    'positive': 0.6,
                    'negative': 0.2,
                    'neutral': 0.2
                },
                {
                    'timestamp': '2024-01-01T06:00:00Z',
                    'positive': 0.7,
                    'negative': 0.15,
                    'neutral': 0.15
                },
                {
                    'timestamp': '2024-01-01T12:00:00Z',
                    'positive': 0.8,
                    'negative': 0.1,
                    'neutral': 0.1
                },
                {
                    'timestamp': '2024-01-01T18:00:00Z',
                    'positive': 0.75,
                    'negative': 0.15,
                    'neutral': 0.1
                }
            ]
            
            trend.emotion_timeline = [
                {
                    'timestamp': '2024-01-01T00:00:00Z',
                    'joy': 0.5,
                    'trust': 0.4,
                    'anticipation': 0.3
                },
                {
                    'timestamp': '2024-01-01T06:00:00Z',
                    'joy': 0.6,
                    'trust': 0.5,
                    'anticipation': 0.4
                },
                {
                    'timestamp': '2024-01-01T12:00:00Z',
                    'joy': 0.7,
                    'trust': 0.6,
                    'anticipation': 0.5
                },
                {
                    'timestamp': '2024-01-01T18:00:00Z',
                    'joy': 0.65,
                    'trust': 0.55,
                    'anticipation': 0.45
                }
            ]
            
        except Exception as e:
            logger.error(f"Error analyzing temporal sentiment: {e}")
    
    async def _identify_influencers(self, trend: SentimentTrend):
        """Identificar influencers"""
        try:
            # Simular identificaci√≥n de influencers
            trend.influencers = [
                {
                    'username': '@techguru',
                    'followers': 1000000,
                    'engagement_rate': 0.05,
                    'sentiment_score': 0.8
                },
                {
                    'username': '@marketingexpert',
                    'followers': 500000,
                    'engagement_rate': 0.08,
                    'sentiment_score': 0.75
                },
                {
                    'username': '@innovationleader',
                    'followers': 750000,
                    'engagement_rate': 0.06,
                    'sentiment_score': 0.85
                }
            ]
            
        except Exception as e:
            logger.error(f"Error identifying influencers: {e}")
    
    async def _identify_viral_content(self, trend: SentimentTrend):
        """Identificar contenido viral"""
        try:
            # Simular identificaci√≥n de contenido viral
            trend.viral_content = [
                {
                    'content_id': 'viral_001',
                    'type': 'post',
                    'engagement': 50000,
                    'sentiment_score': 0.9,
                    'viral_score': 0.95
                },
                {
                    'content_id': 'viral_002',
                    'type': 'video',
                    'engagement': 75000,
                    'sentiment_score': 0.85,
                    'viral_score': 0.88
                },
                {
                    'content_id': 'viral_003',
                    'type': 'image',
                    'engagement': 30000,
                    'sentiment_score': 0.92,
                    'viral_score': 0.82
                }
            ]
            
        except Exception as e:
            logger.error(f"Error identifying viral content: {e}")
    
    def get_sentiment_system_data(self) -> Dict[str, Any]:
        """Obtener datos del sistema de an√°lisis de sentimientos"""
        return {
            'system_status': 'active' if self.is_running else 'inactive',
            'total_analyses': len(self.sentiment_analyses),
            'total_emotions': len(self.emotion_detections),
            'total_trends': len(self.sentiment_trends),
            'text_analyses': len([a for a in self.sentiment_analyses.values() if a.content_type == ContentType.TEXT]),
            'image_analyses': len([a for a in self.sentiment_analyses.values() if a.content_type == ContentType.IMAGE]),
            'audio_analyses': len([a for a in self.sentiment_analyses.values() if a.content_type == ContentType.AUDIO]),
            'video_analyses': len([a for a in self.sentiment_analyses.values() if a.content_type == ContentType.VIDEO]),
            'social_media_analyses': len([a for a in self.sentiment_analyses.values() if a.content_type == ContentType.SOCIAL_MEDIA]),
            'metrics': self.sentiment_metrics,
            'recent_analyses': [
                {
                    'analysis_id': analysis.analysis_id,
                    'content_type': analysis.content_type.value,
                    'platform': analysis.platform.value if analysis.platform else None,
                    'sentiment_scores': analysis.sentiment_scores,
                    'emotions': analysis.emotions,
                    'confidence': analysis.confidence,
                    'language': analysis.language,
                    'timestamp': analysis.timestamp
                }
                for analysis in list(self.sentiment_analyses.values())[-20:]  # √öltimos 20 an√°lisis
            ],
            'sentiment_trends': [
                {
                    'trend_id': trend.trend_id,
                    'platform': trend.platform.value,
                    'topic': trend.topic,
                    'time_period': trend.time_period,
                    'created_at': trend.created_at
                }
                for trend in self.sentiment_trends.values()
            ],
            'available_content_types': [content_type.value for content_type in ContentType],
            'available_platforms': [platform.value for platform in Platform],
            'available_sentiment_types': [sentiment_type.value for sentiment_type in SentimentType],
            'available_emotion_types': [emotion_type.value for emotion_type in EmotionType],
            'supported_languages': self.config['languages']['supported'],
            'last_updated': datetime.now().isoformat()
        }
    
    def export_sentiment_data(self, export_dir: str = "sentiment_data") -> Dict[str, str]:
        """Exportar datos de an√°lisis de sentimientos"""
        Path(export_dir).mkdir(exist_ok=True)
        exported_files = {}
        
        # Exportar an√°lisis de sentimientos
        analyses_data = {analysis_id: asdict(analysis) for analysis_id, analysis in self.sentiment_analyses.items()}
        analyses_path = Path(export_dir) / f"sentiment_analyses_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(analyses_path, 'w', encoding='utf-8') as f:
            json.dump(analyses_data, f, indent=2, ensure_ascii=False)
        exported_files['sentiment_analyses'] = str(analyses_path)
        
        # Exportar tendencias de sentimientos
        trends_data = {trend_id: asdict(trend) for trend_id, trend in self.sentiment_trends.items()}
        trends_path = Path(export_dir) / f"sentiment_trends_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(trends_path, 'w', encoding='utf-8') as f:
            json.dump(trends_data, f, indent=2, ensure_ascii=False)
        exported_files['sentiment_trends'] = str(trends_path)
        
        # Exportar m√©tricas
        metrics_path = Path(export_dir) / f"sentiment_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(self.sentiment_metrics, f, indent=2, ensure_ascii=False)
        exported_files['sentiment_metrics'] = str(metrics_path)
        
        logger.info(f"üì¶ Exported sentiment data to {export_dir}")
        return exported_files


def main():
    """Funci√≥n principal para demostrar el Analizador de Sentimientos"""
    print("üòä MARKETING BRAIN SENTIMENT ANALYZER")
    print("=" * 60)
    
    # Crear sistema de an√°lisis de sentimientos
    sentiment_system = MarketingBrainSentimentAnalyzer()
    
    async def run_demo():
        print(f"\nüöÄ INICIANDO SISTEMA DE AN√ÅLISIS DE SENTIMIENTOS...")
        
        # Inicializar sistema
        await sentiment_system.initialize_sentiment_system()
        
        # Mostrar estado inicial
        system_data = sentiment_system.get_sentiment_system_data()
        print(f"\nüòä ESTADO DEL SISTEMA DE AN√ÅLISIS DE SENTIMIENTOS:")
        print(f"   ‚Ä¢ Estado: {system_data['system_status']}")
        print(f"   ‚Ä¢ An√°lisis totales: {system_data['total_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de texto: {system_data['text_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de imagen: {system_data['image_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de audio: {system_data['audio_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de video: {system_data['video_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de redes sociales: {system_data['social_media_analyses']}")
        print(f"   ‚Ä¢ Tendencias: {system_data['total_trends']}")
        
        # Mostrar an√°lisis recientes
        print(f"\nüòä AN√ÅLISIS RECIENTES:")
        for analysis in system_data['recent_analyses']:
            print(f"   ‚Ä¢ {analysis['analysis_id']}")
            print(f"     - Tipo: {analysis['content_type']}")
            print(f"     - Plataforma: {analysis['platform']}")
            print(f"     - Sentimientos: {analysis['sentiment_scores']}")
            print(f"     - Emociones: {analysis['emotions']}")
            print(f"     - Confianza: {analysis['confidence']:.3f}")
            print(f"     - Idioma: {analysis['language']}")
            print(f"     - Timestamp: {analysis['timestamp']}")
        
        # Mostrar tendencias
        print(f"\nüìà TENDENCIAS DE SENTIMIENTOS:")
        for trend in system_data['sentiment_trends']:
            print(f"   ‚Ä¢ {trend['topic']}")
            print(f"     - Plataforma: {trend['platform']}")
            print(f"     - Per√≠odo: {trend['time_period']}")
            print(f"     - Creado: {trend['created_at']}")
        
        # Mostrar tipos de contenido disponibles
        print(f"\nüìù TIPOS DE CONTENIDO DISPONIBLES:")
        for content_type in system_data['available_content_types']:
            print(f"   ‚Ä¢ {content_type}")
        
        # Mostrar plataformas disponibles
        print(f"\nüåê PLATAFORMAS DISPONIBLES:")
        for platform in system_data['available_platforms']:
            print(f"   ‚Ä¢ {platform}")
        
        # Mostrar tipos de sentimientos
        print(f"\nüòä TIPOS DE SENTIMIENTOS:")
        for sentiment_type in system_data['available_sentiment_types']:
            print(f"   ‚Ä¢ {sentiment_type}")
        
        # Mostrar tipos de emociones
        print(f"\nüé≠ TIPOS DE EMOCIONES:")
        for emotion_type in system_data['available_emotion_types']:
            print(f"   ‚Ä¢ {emotion_type}")
        
        # Mostrar idiomas soportados
        print(f"\nüåç IDIOMAS SOPORTADOS:")
        for language in system_data['supported_languages']:
            print(f"   ‚Ä¢ {language}")
        
        # Analizar nuevo texto
        print(f"\nüòä ANALIZANDO NUEVO TEXTO...")
        new_text = "This new AI marketing tool is absolutely incredible! It's revolutionizing how we understand customer emotions and create better campaigns. I'm so excited about the possibilities!"
        
        analysis_id = await sentiment_system.analyze_sentiment(
            content=new_text,
            content_type=ContentType.TEXT,
            platform=Platform.TWITTER
        )
        
        if analysis_id:
            print(f"   ‚úÖ An√°lisis de sentimientos creado")
            print(f"      ‚Ä¢ ID: {analysis_id}")
            print(f"      ‚Ä¢ Texto: {new_text[:50]}...")
            print(f"      ‚Ä¢ Tipo: {ContentType.TEXT.value}")
            print(f"      ‚Ä¢ Plataforma: {Platform.TWITTER.value}")
        else:
            print(f"   ‚ùå Error al crear an√°lisis de sentimientos")
        
        # Crear tendencia de sentimientos
        print(f"\nüìà CREANDO TENDENCIA DE SENTIMIENTOS...")
        trend_id = await sentiment_system.create_sentiment_trend(
            platform=Platform.TWITTER,
            topic="artificial intelligence marketing",
            time_period="7d"
        )
        
        if trend_id:
            print(f"   ‚úÖ Tendencia de sentimientos creada")
            print(f"      ‚Ä¢ ID: {trend_id}")
            print(f"      ‚Ä¢ Plataforma: {Platform.TWITTER.value}")
            print(f"      ‚Ä¢ Tema: artificial intelligence marketing")
            print(f"      ‚Ä¢ Per√≠odo: 7d")
        else:
            print(f"   ‚ùå Error al crear tendencia de sentimientos")
        
        # Esperar procesamiento
        await asyncio.sleep(3)
        
        # Mostrar m√©tricas finales
        print(f"\nüìà M√âTRICAS DEL SISTEMA DE AN√ÅLISIS DE SENTIMIENTOS:")
        metrics = system_data['metrics']
        print(f"   ‚Ä¢ An√°lisis totales: {metrics['total_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de texto: {metrics['text_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de imagen: {metrics['image_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de audio: {metrics['audio_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de video: {metrics['video_analyses']}")
        print(f"   ‚Ä¢ An√°lisis de redes sociales: {metrics['social_media_analyses']}")
        print(f"   ‚Ä¢ Detecciones de emociones: {metrics['emotion_detections']}")
        print(f"   ‚Ä¢ An√°lisis de tendencias: {metrics['trend_analyses']}")
        print(f"   ‚Ä¢ Confianza promedio: {metrics['average_confidence']:.3f}")
        print(f"   ‚Ä¢ Tiempo de procesamiento: {metrics['processing_time']:.2f}s")
        print(f"   ‚Ä¢ Score de precisi√≥n: {metrics['accuracy_score']:.3f}")
        print(f"   ‚Ä¢ An√°lisis multimodales: {metrics['multimodal_analyses']}")
        
        # Exportar datos
        print(f"\nüíæ EXPORTANDO DATOS DE AN√ÅLISIS DE SENTIMIENTOS...")
        exported_files = sentiment_system.export_sentiment_data()
        print(f"   ‚Ä¢ Archivos exportados: {len(exported_files)}")
        for file_type, path in exported_files.items():
            print(f"     - {file_type}: {Path(path).name}")
        
        print(f"\n‚úÖ SISTEMA DE AN√ÅLISIS DE SENTIMIENTOS DEMO COMPLETADO EXITOSAMENTE")
        print(f"üéâ El sistema de an√°lisis de sentimientos ha implementado:")
        print(f"   ‚Ä¢ An√°lisis multimodal de sentimientos (texto, imagen, audio, video)")
        print(f"   ‚Ä¢ Detecci√≥n avanzada de emociones con IA")
        print(f"   ‚Ä¢ An√°lisis de redes sociales en tiempo real")
        print(f"   ‚Ä¢ Tendencias de sentimientos y an√°lisis temporal")
        print(f"   ‚Ä¢ Identificaci√≥n de influencers y contenido viral")
        print(f"   ‚Ä¢ Soporte multi-idioma y multi-plataforma")
        print(f"   ‚Ä¢ Modelos de IA de √∫ltima generaci√≥n")
        print(f"   ‚Ä¢ APIs de an√°lisis de sentimientos")
        print(f"   ‚Ä¢ Procesamiento en tiempo real")
        print(f"   ‚Ä¢ An√°lisis de caracter√≠sticas de voz")
        print(f"   ‚Ä¢ Reconocimiento facial de emociones")
        print(f"   ‚Ä¢ Integraci√≥n con plataformas sociales")
        print(f"   ‚Ä¢ Exportaci√≥n de datos y reportes")
        
        return sentiment_system
    
    # Ejecutar demo
    sentiment_system = asyncio.run(run_demo())


if __name__ == "__main__":
    main()








