#!/usr/bin/env python3
"""
üîÆ MARKETING BRAIN PREDICTIVE ANALYTICS
Sistema Avanzado de An√°lisis Predictivo
Incluye modelos de ML, forecasting, segmentaci√≥n, churn prediction y an√°lisis de tendencias
"""

import json
import asyncio
import uuid
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
import logging
from dataclasses import dataclass, asdict
from pathlib import Path
import sys
from enum import Enum
import sqlite3
import redis
import requests
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import threading
import queue
import time
import hashlib
import hmac
import base64
import tensorflow as tf
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import sklearn
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso
from sklearn.svm import SVC, SVR
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA, FactorAnalysis, FastICA
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb
import lightgbm as lgb
import catboost as cb
from catboost import CatBoostClassifier, CatBoostRegressor
import prophet
from prophet import Prophet
import statsmodels.api as sm
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
import scipy.stats as stats
import scipy.cluster.hierarchy as sch
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import joblib
import yaml
import pickle
import psutil
import GPUtil
import requests
import aiohttp
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.live import Live
from rich.layout import Layout
from rich.text import Text
from rich.align import Align
from rich import box

# Agregar el directorio actual al path
sys.path.append(str(Path(__file__).parent))

logger = logging.getLogger(__name__)
console = Console()

class ModelType(Enum):
    """Tipos de modelos"""
    CLASSIFICATION = "classification"
    REGRESSION = "regression"
    CLUSTERING = "clustering"
    TIME_SERIES = "time_series"
    DEEP_LEARNING = "deep_learning"
    ENSEMBLE = "ensemble"

class PredictionType(Enum):
    """Tipos de predicci√≥n"""
    CHURN_PREDICTION = "churn_prediction"
    CUSTOMER_LIFETIME_VALUE = "customer_lifetime_value"
    SALES_FORECASTING = "sales_forecasting"
    DEMAND_FORECASTING = "demand_forecasting"
    PRICE_OPTIMIZATION = "price_optimization"
    CUSTOMER_SEGMENTATION = "customer_segmentation"
    MARKET_TREND_ANALYSIS = "market_trend_analysis"
    CAMPAIGN_PERFORMANCE = "campaign_performance"

class ModelStatus(Enum):
    """Estados de modelos"""
    TRAINING = "training"
    TRAINED = "trained"
    DEPLOYED = "deployed"
    RETRAINING = "retraining"
    FAILED = "failed"

@dataclass
class PredictiveModel:
    """Modelo predictivo"""
    model_id: str
    name: str
    description: str
    model_type: ModelType
    prediction_type: PredictionType
    algorithm: str
    parameters: Dict[str, Any]
    training_data: Dict[str, Any]
    performance_metrics: Dict[str, float]
    status: ModelStatus
    created_at: str
    updated_at: str
    last_trained: Optional[str]
    version: str

@dataclass
class Prediction:
    """Predicci√≥n"""
    prediction_id: str
    model_id: str
    input_data: Dict[str, Any]
    prediction_result: Dict[str, Any]
    confidence_score: float
    prediction_timestamp: str
    metadata: Dict[str, Any]

@dataclass
class ModelPerformance:
    """Rendimiento del modelo"""
    model_id: str
    metric_name: str
    metric_value: float
    evaluation_timestamp: str
    dataset_type: str  # train, validation, test
    metadata: Dict[str, Any]

class MarketingBrainPredictiveAnalytics:
    """
    Sistema Avanzado de An√°lisis Predictivo
    Incluye modelos de ML, forecasting, segmentaci√≥n, churn prediction y an√°lisis de tendencias
    """
    
    def __init__(self):
        self.predictive_models = {}
        self.predictions = {}
        self.model_performances = {}
        self.training_queue = queue.Queue()
        self.prediction_queue = queue.Queue()
        
        # Configuraci√≥n
        self.config = self._load_config()
        
        # Bases de datos
        self.db_connection = None
        self.redis_client = None
        
        # Modelos de ML
        self.ml_models = {}
        
        # Datasets
        self.datasets = {}
        
        # Threads
        self.training_processor_thread = None
        self.prediction_processor_thread = None
        
        # Estado del sistema
        self.is_running = False
        
        # M√©tricas
        self.analytics_metrics = {
            'total_models': 0,
            'active_models': 0,
            'total_predictions': 0,
            'successful_predictions': 0,
            'failed_predictions': 0,
            'average_accuracy': 0.0,
            'average_precision': 0.0,
            'average_recall': 0.0,
            'average_f1_score': 0.0,
            'average_rmse': 0.0,
            'average_mae': 0.0,
            'average_r2_score': 0.0,
            'model_retraining_frequency': 0.0,
            'prediction_latency': 0.0
        }
        
        logger.info("üîÆ Marketing Brain Predictive Analytics initialized successfully")
    
    def _load_config(self) -> Dict[str, Any]:
        """Cargar configuraci√≥n del sistema de an√°lisis predictivo"""
        return {
            'models': {
                'max_models_per_type': 10,
                'auto_retraining_enabled': True,
                'retraining_frequency': 7,  # d√≠as
                'performance_threshold': 0.8,
                'cross_validation_folds': 5,
                'test_size': 0.2,
                'random_state': 42
            },
            'algorithms': {
                'classification': {
                    'random_forest': {
                        'n_estimators': 100,
                        'max_depth': 10,
                        'random_state': 42
                    },
                    'gradient_boosting': {
                        'n_estimators': 100,
                        'learning_rate': 0.1,
                        'max_depth': 6
                    },
                    'xgboost': {
                        'n_estimators': 100,
                        'learning_rate': 0.1,
                        'max_depth': 6
                    },
                    'lightgbm': {
                        'n_estimators': 100,
                        'learning_rate': 0.1,
                        'max_depth': 6
                    },
                    'catboost': {
                        'iterations': 100,
                        'learning_rate': 0.1,
                        'depth': 6
                    },
                    'logistic_regression': {
                        'random_state': 42,
                        'max_iter': 1000
                    },
                    'svm': {
                        'kernel': 'rbf',
                        'random_state': 42
                    }
                },
                'regression': {
                    'random_forest': {
                        'n_estimators': 100,
                        'max_depth': 10,
                        'random_state': 42
                    },
                    'gradient_boosting': {
                        'n_estimators': 100,
                        'learning_rate': 0.1,
                        'max_depth': 6
                    },
                    'linear_regression': {
                        'fit_intercept': True
                    },
                    'ridge': {
                        'alpha': 1.0
                    },
                    'lasso': {
                        'alpha': 1.0
                    },
                    'svr': {
                        'kernel': 'rbf'
                    }
                },
                'clustering': {
                    'kmeans': {
                        'n_clusters': 5,
                        'random_state': 42
                    },
                    'dbscan': {
                        'eps': 0.5,
                        'min_samples': 5
                    },
                    'agglomerative': {
                        'n_clusters': 5
                    }
                },
                'time_series': {
                    'prophet': {
                        'yearly_seasonality': True,
                        'weekly_seasonality': True,
                        'daily_seasonality': False
                    },
                    'arima': {
                        'order': (1, 1, 1)
                    }
                },
                'deep_learning': {
                    'neural_network': {
                        'hidden_layers': [64, 32, 16],
                        'activation': 'relu',
                        'dropout': 0.2,
                        'epochs': 100,
                        'batch_size': 32
                    }
                }
            },
            'data_processing': {
                'missing_value_strategy': 'median',
                'outlier_detection': True,
                'feature_scaling': True,
                'feature_selection': True,
                'dimensionality_reduction': True
            },
            'evaluation': {
                'metrics': {
                    'classification': ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc'],
                    'regression': ['rmse', 'mae', 'r2_score'],
                    'clustering': ['silhouette_score', 'calinski_harabasz_score'],
                    'time_series': ['mape', 'smape', 'rmse']
                },
                'cross_validation': True,
                'holdout_validation': True
            },
            'deployment': {
                'model_serving': True,
                'batch_prediction': True,
                'real_time_prediction': True,
                'model_versioning': True,
                'a_b_testing': True
            }
        }
    
    async def initialize_predictive_analytics_system(self):
        """Inicializar sistema de an√°lisis predictivo"""
        logger.info("üöÄ Initializing Marketing Brain Predictive Analytics...")
        
        try:
            # Inicializar bases de datos
            await self._initialize_databases()
            
            # Crear directorios necesarios
            await self._create_directories()
            
            # Inicializar modelos de ML
            await self._initialize_ml_models()
            
            # Cargar modelos existentes
            await self._load_existing_models()
            
            # Crear modelos de demostraci√≥n
            await self._create_demo_models()
            
            # Iniciar threads de procesamiento
            self._start_processing_threads()
            
            logger.info("‚úÖ Predictive Analytics system initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing predictive analytics system: {e}")
            raise
    
    async def _initialize_databases(self):
        """Inicializar bases de datos"""
        try:
            # SQLite para metadatos
            self.db_connection = sqlite3.connect('predictive_analytics.db', check_same_thread=False)
            
            # Redis para cache y colas
            self.redis_client = redis.Redis(host='localhost', port=6379, db=15, decode_responses=True)
            
            # Crear tablas
            await self._create_analytics_tables()
            
        except Exception as e:
            logger.error(f"Error initializing databases: {e}")
            raise
    
    async def _create_analytics_tables(self):
        """Crear tablas de base de datos"""
        try:
            cursor = self.db_connection.cursor()
            
            # Tabla de modelos predictivos
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS predictive_models (
                    model_id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    description TEXT NOT NULL,
                    model_type TEXT NOT NULL,
                    prediction_type TEXT NOT NULL,
                    algorithm TEXT NOT NULL,
                    parameters TEXT NOT NULL,
                    training_data TEXT NOT NULL,
                    performance_metrics TEXT NOT NULL,
                    status TEXT NOT NULL,
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL,
                    last_trained TEXT,
                    version TEXT NOT NULL
                )
            ''')
            
            # Tabla de predicciones
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS predictions (
                    prediction_id TEXT PRIMARY KEY,
                    model_id TEXT NOT NULL,
                    input_data TEXT NOT NULL,
                    prediction_result TEXT NOT NULL,
                    confidence_score REAL NOT NULL,
                    prediction_timestamp TEXT NOT NULL,
                    metadata TEXT NOT NULL,
                    FOREIGN KEY (model_id) REFERENCES predictive_models (model_id)
                )
            ''')
            
            # Tabla de rendimiento de modelos
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS model_performances (
                    performance_id TEXT PRIMARY KEY,
                    model_id TEXT NOT NULL,
                    metric_name TEXT NOT NULL,
                    metric_value REAL NOT NULL,
                    evaluation_timestamp TEXT NOT NULL,
                    dataset_type TEXT NOT NULL,
                    metadata TEXT NOT NULL,
                    FOREIGN KEY (model_id) REFERENCES predictive_models (model_id)
                )
            ''')
            
            self.db_connection.commit()
            logger.info("Predictive Analytics database tables created successfully")
            
        except Exception as e:
            logger.error(f"Error creating analytics tables: {e}")
            raise
    
    async def _create_directories(self):
        """Crear directorios necesarios"""
        try:
            directories = [
                'predictive_models',
                'model_data',
                'training_data',
                'prediction_data',
                'model_performance',
                'analytics_reports',
                'model_artifacts',
                'feature_engineering',
                'model_deployment',
                'analytics_logs'
            ]
            
            for directory in directories:
                Path(directory).mkdir(parents=True, exist_ok=True)
            
            logger.info("Predictive Analytics directories created successfully")
            
        except Exception as e:
            logger.error(f"Error creating directories: {e}")
            raise
    
    async def _initialize_ml_models(self):
        """Inicializar modelos de ML"""
        try:
            # Modelos de clasificaci√≥n
            self.ml_models['classification'] = {
                'random_forest': RandomForestClassifier(**self.config['algorithms']['classification']['random_forest']),
                'gradient_boosting': GradientBoostingClassifier(**self.config['algorithms']['classification']['gradient_boosting']),
                'xgboost': xgb.XGBClassifier(**self.config['algorithms']['classification']['xgboost']),
                'lightgbm': lgb.LGBMClassifier(**self.config['algorithms']['classification']['lightgbm']),
                'catboost': CatBoostClassifier(**self.config['algorithms']['classification']['catboost']),
                'logistic_regression': LogisticRegression(**self.config['algorithms']['classification']['logistic_regression']),
                'svm': SVC(**self.config['algorithms']['classification']['svm'])
            }
            
            # Modelos de regresi√≥n
            self.ml_models['regression'] = {
                'random_forest': RandomForestRegressor(**self.config['algorithms']['regression']['random_forest']),
                'gradient_boosting': GradientBoostingRegressor(**self.config['algorithms']['regression']['gradient_boosting']),
                'linear_regression': LinearRegression(**self.config['algorithms']['regression']['linear_regression']),
                'ridge': Ridge(**self.config['algorithms']['regression']['ridge']),
                'lasso': Lasso(**self.config['algorithms']['regression']['lasso']),
                'svr': SVR(**self.config['algorithms']['regression']['svr'])
            }
            
            # Modelos de clustering
            self.ml_models['clustering'] = {
                'kmeans': KMeans(**self.config['algorithms']['clustering']['kmeans']),
                'dbscan': DBSCAN(**self.config['algorithms']['clustering']['dbscan']),
                'agglomerative': AgglomerativeClustering(**self.config['algorithms']['clustering']['agglomerative'])
            }
            
            # Modelos de series temporales
            self.ml_models['time_series'] = {
                'prophet': Prophet(**self.config['algorithms']['time_series']['prophet']),
                'arima': None  # Se inicializa din√°micamente
            }
            
            # Modelos de deep learning
            self.ml_models['deep_learning'] = {
                'neural_network': None  # Se inicializa din√°micamente
            }
            
            logger.info(f"Initialized ML models: {list(self.ml_models.keys())}")
            
        except Exception as e:
            logger.error(f"Error initializing ML models: {e}")
            raise
    
    async def _load_existing_models(self):
        """Cargar modelos existentes"""
        try:
            cursor = self.db_connection.cursor()
            cursor.execute('SELECT * FROM predictive_models')
            rows = cursor.fetchall()
            
            for row in rows:
                model = PredictiveModel(
                    model_id=row[0],
                    name=row[1],
                    description=row[2],
                    model_type=ModelType(row[3]),
                    prediction_type=PredictionType(row[4]),
                    algorithm=row[5],
                    parameters=json.loads(row[6]),
                    training_data=json.loads(row[7]),
                    performance_metrics=json.loads(row[8]),
                    status=ModelStatus(row[9]),
                    created_at=row[10],
                    updated_at=row[11],
                    last_trained=row[12],
                    version=row[13]
                )
                self.predictive_models[model.model_id] = model
            
            logger.info(f"Loaded {len(self.predictive_models)} predictive models")
            
        except Exception as e:
            logger.error(f"Error loading existing models: {e}")
            raise
    
    async def _create_demo_models(self):
        """Crear modelos de demostraci√≥n"""
        try:
            # Modelo de predicci√≥n de churn
            churn_model = PredictiveModel(
                model_id=str(uuid.uuid4()),
                name="Customer Churn Prediction Model",
                description="Predicts customer churn probability using behavioral and demographic features",
                model_type=ModelType.CLASSIFICATION,
                prediction_type=PredictionType.CHURN_PREDICTION,
                algorithm="random_forest",
                parameters={
                    'n_estimators': 100,
                    'max_depth': 10,
                    'random_state': 42
                },
                training_data={
                    'features': ['age', 'tenure', 'monthly_charges', 'total_charges', 'contract_type', 'payment_method'],
                    'target': 'churn',
                    'sample_size': 10000,
                    'train_size': 0.8
                },
                performance_metrics={
                    'accuracy': 0.85,
                    'precision': 0.82,
                    'recall': 0.78,
                    'f1_score': 0.80,
                    'roc_auc': 0.88
                },
                status=ModelStatus.TRAINED,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                last_trained=datetime.now().isoformat(),
                version="1.0.0"
            )
            
            self.predictive_models[churn_model.model_id] = churn_model
            
            # Modelo de valor de vida del cliente
            clv_model = PredictiveModel(
                model_id=str(uuid.uuid4()),
                name="Customer Lifetime Value Model",
                description="Predicts customer lifetime value using RFM analysis and behavioral patterns",
                model_type=ModelType.REGRESSION,
                prediction_type=PredictionType.CUSTOMER_LIFETIME_VALUE,
                algorithm="gradient_boosting",
                parameters={
                    'n_estimators': 100,
                    'learning_rate': 0.1,
                    'max_depth': 6
                },
                training_data={
                    'features': ['recency', 'frequency', 'monetary', 'age', 'gender', 'location'],
                    'target': 'lifetime_value',
                    'sample_size': 15000,
                    'train_size': 0.8
                },
                performance_metrics={
                    'rmse': 1250.50,
                    'mae': 980.25,
                    'r2_score': 0.75
                },
                status=ModelStatus.TRAINED,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                last_trained=datetime.now().isoformat(),
                version="1.0.0"
            )
            
            self.predictive_models[clv_model.model_id] = clv_model
            
            # Modelo de pron√≥stico de ventas
            sales_forecast_model = PredictiveModel(
                model_id=str(uuid.uuid4()),
                name="Sales Forecasting Model",
                description="Forecasts sales using time series analysis and external factors",
                model_type=ModelType.TIME_SERIES,
                prediction_type=PredictionType.SALES_FORECASTING,
                algorithm="prophet",
                parameters={
                    'yearly_seasonality': True,
                    'weekly_seasonality': True,
                    'daily_seasonality': False
                },
                training_data={
                    'features': ['date', 'sales', 'holidays', 'promotions', 'competitor_activity'],
                    'target': 'sales',
                    'sample_size': 365,
                    'train_size': 0.8
                },
                performance_metrics={
                    'mape': 0.12,
                    'smape': 0.15,
                    'rmse': 2500.75
                },
                status=ModelStatus.TRAINED,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                last_trained=datetime.now().isoformat(),
                version="1.0.0"
            )
            
            self.predictive_models[sales_forecast_model.model_id] = sales_forecast_model
            
            # Modelo de segmentaci√≥n de clientes
            segmentation_model = PredictiveModel(
                model_id=str(uuid.uuid4()),
                name="Customer Segmentation Model",
                description="Segments customers using RFM analysis and behavioral clustering",
                model_type=ModelType.CLUSTERING,
                prediction_type=PredictionType.CUSTOMER_SEGMENTATION,
                algorithm="kmeans",
                parameters={
                    'n_clusters': 5,
                    'random_state': 42
                },
                training_data={
                    'features': ['recency', 'frequency', 'monetary', 'age', 'gender', 'location'],
                    'target': 'segment',
                    'sample_size': 20000,
                    'train_size': 1.0
                },
                performance_metrics={
                    'silhouette_score': 0.65,
                    'calinski_harabasz_score': 1250.50
                },
                status=ModelStatus.TRAINED,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                last_trained=datetime.now().isoformat(),
                version="1.0.0"
            )
            
            self.predictive_models[segmentation_model.model_id] = segmentation_model
            
            logger.info("Demo predictive models created successfully")
            
        except Exception as e:
            logger.error(f"Error creating demo models: {e}")
            raise
    
    def _start_processing_threads(self):
        """Iniciar threads de procesamiento"""
        self.is_running = True
        
        self.training_processor_thread = threading.Thread(target=self._training_processor_loop, daemon=True)
        self.training_processor_thread.start()
        
        self.prediction_processor_thread = threading.Thread(target=self._prediction_processor_loop, daemon=True)
        self.prediction_processor_thread.start()
        
        logger.info("Predictive Analytics processing threads started")
    
    def _training_processor_loop(self):
        """Loop del procesador de entrenamiento"""
        while self.is_running:
            try:
                if not self.training_queue.empty():
                    training_task = self.training_queue.get_nowait()
                    asyncio.run(self._process_model_training(training_task))
                    self.training_queue.task_done()
                
                time.sleep(1)
                
            except queue.Empty:
                time.sleep(1)
            except Exception as e:
                logger.error(f"Error in training processor loop: {e}")
                time.sleep(5)
    
    def _prediction_processor_loop(self):
        """Loop del procesador de predicciones"""
        while self.is_running:
            try:
                if not self.prediction_queue.empty():
                    prediction_task = self.prediction_queue.get_nowait()
                    asyncio.run(self._process_prediction(prediction_task))
                    self.prediction_queue.task_done()
                
                time.sleep(0.1)
                
            except queue.Empty:
                time.sleep(0.1)
            except Exception as e:
                logger.error(f"Error in prediction processor loop: {e}")
                time.sleep(1)
    
    async def create_predictive_model(self, model: PredictiveModel) -> str:
        """Crear modelo predictivo"""
        try:
            # Validar modelo
            if not await self._validate_predictive_model(model):
                return None
            
            # Agregar modelo
            self.predictive_models[model.model_id] = model
            
            # Guardar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                INSERT INTO predictive_models (model_id, name, description, model_type, prediction_type,
                                             algorithm, parameters, training_data, performance_metrics,
                                             status, created_at, updated_at, last_trained, version)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                model.model_id,
                model.name,
                model.description,
                model.model_type.value,
                model.prediction_type.value,
                model.algorithm,
                json.dumps(model.parameters),
                json.dumps(model.training_data),
                json.dumps(model.performance_metrics),
                model.status.value,
                model.created_at,
                model.updated_at,
                model.last_trained,
                model.version
            ))
            self.db_connection.commit()
            
            # Agregar a cola de entrenamiento si es necesario
            if model.status == ModelStatus.TRAINING:
                self.training_queue.put(model)
            
            # Actualizar m√©tricas
            self.analytics_metrics['total_models'] += 1
            if model.status == ModelStatus.TRAINED:
                self.analytics_metrics['active_models'] += 1
            
            logger.info(f"Predictive model created: {model.name}")
            return model.model_id
            
        except Exception as e:
            logger.error(f"Error creating predictive model: {e}")
            return None
    
    async def _validate_predictive_model(self, model: PredictiveModel) -> bool:
        """Validar modelo predictivo"""
        try:
            # Validar campos requeridos
            if not model.name or not model.description:
                logger.error("Model name and description are required")
                return False
            
            # Validar tipo de modelo
            if model.model_type not in ModelType:
                logger.error(f"Invalid model type: {model.model_type}")
                return False
            
            # Validar tipo de predicci√≥n
            if model.prediction_type not in PredictionType:
                logger.error(f"Invalid prediction type: {model.prediction_type}")
                return False
            
            # Validar algoritmo
            if model.algorithm not in self.ml_models.get(model.model_type.value, {}):
                logger.error(f"Invalid algorithm for model type: {model.algorithm}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Error validating predictive model: {e}")
            return False
    
    async def _process_model_training(self, model: PredictiveModel):
        """Procesar entrenamiento de modelo"""
        try:
            logger.info(f"Processing model training: {model.model_id}")
            
            # Simular entrenamiento
            await asyncio.sleep(5)
            
            # Actualizar estado del modelo
            model.status = ModelStatus.TRAINED
            model.last_trained = datetime.now().isoformat()
            model.updated_at = datetime.now().isoformat()
            
            # Simular m√©tricas de rendimiento
            if model.model_type == ModelType.CLASSIFICATION:
                model.performance_metrics = {
                    'accuracy': np.random.uniform(0.8, 0.95),
                    'precision': np.random.uniform(0.75, 0.90),
                    'recall': np.random.uniform(0.70, 0.85),
                    'f1_score': np.random.uniform(0.72, 0.88),
                    'roc_auc': np.random.uniform(0.80, 0.95)
                }
            elif model.model_type == ModelType.REGRESSION:
                model.performance_metrics = {
                    'rmse': np.random.uniform(100, 1000),
                    'mae': np.random.uniform(80, 800),
                    'r2_score': np.random.uniform(0.70, 0.90)
                }
            elif model.model_type == ModelType.CLUSTERING:
                model.performance_metrics = {
                    'silhouette_score': np.random.uniform(0.5, 0.8),
                    'calinski_harabasz_score': np.random.uniform(500, 2000)
                }
            elif model.model_type == ModelType.TIME_SERIES:
                model.performance_metrics = {
                    'mape': np.random.uniform(0.05, 0.20),
                    'smape': np.random.uniform(0.08, 0.25),
                    'rmse': np.random.uniform(1000, 5000)
                }
            
            # Actualizar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                UPDATE predictive_models SET status = ?, last_trained = ?, updated_at = ?, performance_metrics = ?
                WHERE model_id = ?
            ''', (
                model.status.value,
                model.last_trained,
                model.updated_at,
                json.dumps(model.performance_metrics),
                model.model_id
            ))
            self.db_connection.commit()
            
            # Actualizar m√©tricas
            self.analytics_metrics['active_models'] += 1
            
            logger.info(f"Model training completed: {model.model_id}")
            
        except Exception as e:
            logger.error(f"Error processing model training: {e}")
            model.status = ModelStatus.FAILED
            model.updated_at = datetime.now().isoformat()
    
    async def make_prediction(self, model_id: str, input_data: Dict[str, Any]) -> str:
        """Hacer predicci√≥n"""
        try:
            # Verificar que el modelo existe
            if model_id not in self.predictive_models:
                logger.error(f"Model {model_id} not found")
                return None
            
            model = self.predictive_models[model_id]
            
            # Verificar que el modelo est√° entrenado
            if model.status != ModelStatus.TRAINED:
                logger.error(f"Model {model_id} is not trained")
                return None
            
            # Crear predicci√≥n
            prediction = Prediction(
                prediction_id=str(uuid.uuid4()),
                model_id=model_id,
                input_data=input_data,
                prediction_result={},
                confidence_score=0.0,
                prediction_timestamp=datetime.now().isoformat(),
                metadata={
                    'model_name': model.name,
                    'model_type': model.model_type.value,
                    'prediction_type': model.prediction_type.value,
                    'algorithm': model.algorithm
                }
            )
            
            # Agregar predicci√≥n
            self.predictions[prediction.prediction_id] = prediction
            
            # Guardar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                INSERT INTO predictions (prediction_id, model_id, input_data, prediction_result,
                                       confidence_score, prediction_timestamp, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                prediction.prediction_id,
                prediction.model_id,
                json.dumps(prediction.input_data),
                json.dumps(prediction.prediction_result),
                prediction.confidence_score,
                prediction.prediction_timestamp,
                json.dumps(prediction.metadata)
            ))
            self.db_connection.commit()
            
            # Agregar a cola de procesamiento
            self.prediction_queue.put(prediction)
            
            # Actualizar m√©tricas
            self.analytics_metrics['total_predictions'] += 1
            
            logger.info(f"Prediction created: {prediction.prediction_id}")
            return prediction.prediction_id
            
        except Exception as e:
            logger.error(f"Error making prediction: {e}")
            return None
    
    async def _process_prediction(self, prediction: Prediction):
        """Procesar predicci√≥n"""
        try:
            logger.info(f"Processing prediction: {prediction.prediction_id}")
            
            model = self.predictive_models[prediction.model_id]
            
            # Simular predicci√≥n seg√∫n el tipo de modelo
            if model.model_type == ModelType.CLASSIFICATION:
                prediction.prediction_result = {
                    'predicted_class': np.random.choice(['class_0', 'class_1']),
                    'class_probabilities': {
                        'class_0': np.random.uniform(0.3, 0.7),
                        'class_1': np.random.uniform(0.3, 0.7)
                    }
                }
                prediction.confidence_score = np.random.uniform(0.7, 0.95)
                
            elif model.model_type == ModelType.REGRESSION:
                prediction.prediction_result = {
                    'predicted_value': np.random.uniform(1000, 10000),
                    'confidence_interval': {
                        'lower': np.random.uniform(800, 1200),
                        'upper': np.random.uniform(8000, 12000)
                    }
                }
                prediction.confidence_score = np.random.uniform(0.8, 0.95)
                
            elif model.model_type == ModelType.CLUSTERING:
                prediction.prediction_result = {
                    'predicted_cluster': np.random.randint(0, 5),
                    'cluster_probabilities': {
                        f'cluster_{i}': np.random.uniform(0.1, 0.4) for i in range(5)
                    }
                }
                prediction.confidence_score = np.random.uniform(0.6, 0.9)
                
            elif model.model_type == ModelType.TIME_SERIES:
                prediction.prediction_result = {
                    'forecast_values': [np.random.uniform(1000, 5000) for _ in range(30)],
                    'forecast_dates': [(datetime.now() + timedelta(days=i)).isoformat() for i in range(30)]
                }
                prediction.confidence_score = np.random.uniform(0.7, 0.9)
            
            # Actualizar en base de datos
            cursor = self.db_connection.cursor()
            cursor.execute('''
                UPDATE predictions SET prediction_result = ?, confidence_score = ?
                WHERE prediction_id = ?
            ''', (
                json.dumps(prediction.prediction_result),
                prediction.confidence_score,
                prediction.prediction_id
            ))
            self.db_connection.commit()
            
            # Actualizar m√©tricas
            self.analytics_metrics['successful_predictions'] += 1
            
            logger.info(f"Prediction processed: {prediction.prediction_id}")
            
        except Exception as e:
            logger.error(f"Error processing prediction: {e}")
            self.analytics_metrics['failed_predictions'] += 1
    
    def get_predictive_analytics_data(self) -> Dict[str, Any]:
        """Obtener datos del sistema de an√°lisis predictivo"""
        return {
            'system_status': 'active' if self.is_running else 'inactive',
            'total_models': len(self.predictive_models),
            'active_models': len([m for m in self.predictive_models.values() if m.status == ModelStatus.TRAINED]),
            'total_predictions': len(self.predictions),
            'successful_predictions': len([p for p in self.predictions.values() if p.confidence_score > 0]),
            'failed_predictions': len([p for p in self.predictions.values() if p.confidence_score == 0]),
            'metrics': self.analytics_metrics,
            'models': [
                {
                    'model_id': model.model_id,
                    'name': model.name,
                    'description': model.description,
                    'model_type': model.model_type.value,
                    'prediction_type': model.prediction_type.value,
                    'algorithm': model.algorithm,
                    'performance_metrics': model.performance_metrics,
                    'status': model.status.value,
                    'created_at': model.created_at,
                    'last_trained': model.last_trained,
                    'version': model.version
                }
                for model in self.predictive_models.values()
            ],
            'recent_predictions': [
                {
                    'prediction_id': prediction.prediction_id,
                    'model_id': prediction.model_id,
                    'prediction_result': prediction.prediction_result,
                    'confidence_score': prediction.confidence_score,
                    'prediction_timestamp': prediction.prediction_timestamp,
                    'metadata': prediction.metadata
                }
                for prediction in list(self.predictions.values())[-20:]  # √öltimas 20 predicciones
            ],
            'available_model_types': [model_type.value for model_type in ModelType],
            'available_prediction_types': [prediction_type.value for prediction_type in PredictionType],
            'available_algorithms': {
                model_type: list(algorithms.keys()) for model_type, algorithms in self.ml_models.items()
            },
            'available_model_statuses': [status.value for status in ModelStatus],
            'last_updated': datetime.now().isoformat()
        }
    
    def export_predictive_analytics_data(self, export_dir: str = "predictive_analytics_data") -> Dict[str, str]:
        """Exportar datos de an√°lisis predictivo"""
        Path(export_dir).mkdir(exist_ok=True)
        exported_files = {}
        
        # Exportar modelos predictivos
        models_data = {model_id: asdict(model) for model_id, model in self.predictive_models.items()}
        models_path = Path(export_dir) / f"predictive_models_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(models_path, 'w', encoding='utf-8') as f:
            json.dump(models_data, f, indent=2, ensure_ascii=False)
        exported_files['predictive_models'] = str(models_path)
        
        # Exportar predicciones
        predictions_data = {pred_id: asdict(prediction) for pred_id, prediction in self.predictions.items()}
        predictions_path = Path(export_dir) / f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(predictions_path, 'w', encoding='utf-8') as f:
            json.dump(predictions_data, f, indent=2, ensure_ascii=False)
        exported_files['predictions'] = str(predictions_path)
        
        # Exportar m√©tricas
        metrics_path = Path(export_dir) / f"analytics_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(self.analytics_metrics, f, indent=2, ensure_ascii=False)
        exported_files['analytics_metrics'] = str(metrics_path)
        
        logger.info(f"üì¶ Exported predictive analytics data to {export_dir}")
        return exported_files


def main():
    """Funci√≥n principal para demostrar el An√°lisis Predictivo"""
    print("üîÆ MARKETING BRAIN PREDICTIVE ANALYTICS")
    print("=" * 60)
    
    # Crear sistema de an√°lisis predictivo
    analytics_system = MarketingBrainPredictiveAnalytics()
    
    async def run_demo():
        print(f"\nüöÄ INICIANDO SISTEMA DE AN√ÅLISIS PREDICTIVO...")
        
        # Inicializar sistema
        await analytics_system.initialize_predictive_analytics_system()
        
        # Mostrar estado inicial
        system_data = analytics_system.get_predictive_analytics_data()
        print(f"\nüîÆ ESTADO DEL SISTEMA DE AN√ÅLISIS PREDICTIVO:")
        print(f"   ‚Ä¢ Estado: {system_data['system_status']}")
        print(f"   ‚Ä¢ Modelos totales: {system_data['total_models']}")
        print(f"   ‚Ä¢ Modelos activos: {system_data['active_models']}")
        print(f"   ‚Ä¢ Predicciones totales: {system_data['total_predictions']}")
        print(f"   ‚Ä¢ Predicciones exitosas: {system_data['successful_predictions']}")
        print(f"   ‚Ä¢ Predicciones fallidas: {system_data['failed_predictions']}")
        
        # Mostrar modelos
        print(f"\nüîÆ MODELOS PREDICTIVOS:")
        for model in system_data['models']:
            print(f"   ‚Ä¢ {model['name']}")
            print(f"     - ID: {model['model_id']}")
            print(f"     - Descripci√≥n: {model['description']}")
            print(f"     - Tipo: {model['model_type']}")
            print(f"     - Predicci√≥n: {model['prediction_type']}")
            print(f"     - Algoritmo: {model['algorithm']}")
            print(f"     - Estado: {model['status']}")
            print(f"     - M√©tricas: {model['performance_metrics']}")
            print(f"     - √öltimo entrenamiento: {model['last_trained']}")
            print(f"     - Versi√≥n: {model['version']}")
        
        # Mostrar predicciones recientes
        print(f"\nüîÆ PREDICCIONES RECIENTES:")
        for prediction in system_data['recent_predictions']:
            print(f"   ‚Ä¢ {prediction['prediction_id']}")
            print(f"     - Modelo: {prediction['model_id']}")
            print(f"     - Resultado: {prediction['prediction_result']}")
            print(f"     - Confianza: {prediction['confidence_score']:.3f}")
            print(f"     - Timestamp: {prediction['prediction_timestamp']}")
        
        # Mostrar tipos de modelo disponibles
        print(f"\nüîÆ TIPOS DE MODELO DISPONIBLES:")
        for model_type in system_data['available_model_types']:
            print(f"   ‚Ä¢ {model_type}")
        
        # Mostrar tipos de predicci√≥n disponibles
        print(f"\nüîÆ TIPOS DE PREDICCI√ìN DISPONIBLES:")
        for prediction_type in system_data['available_prediction_types']:
            print(f"   ‚Ä¢ {prediction_type}")
        
        # Mostrar algoritmos disponibles
        print(f"\nüîÆ ALGORITMOS DISPONIBLES:")
        for model_type, algorithms in system_data['available_algorithms'].items():
            print(f"   ‚Ä¢ {model_type}:")
            for algorithm in algorithms:
                print(f"     - {algorithm}")
        
        # Mostrar estados de modelo disponibles
        print(f"\nüîÆ ESTADOS DE MODELO DISPONIBLES:")
        for status in system_data['available_model_statuses']:
            print(f"   ‚Ä¢ {status}")
        
        # Crear nuevo modelo predictivo
        print(f"\nüîÆ CREANDO NUEVO MODELO PREDICTIVO...")
        new_model = PredictiveModel(
            model_id=str(uuid.uuid4()),
            name="Price Optimization Model",
            description="Optimizes product pricing using demand elasticity and competitor analysis",
            model_type=ModelType.REGRESSION,
            prediction_type=PredictionType.PRICE_OPTIMIZATION,
            algorithm="xgboost",
            parameters={
                'n_estimators': 100,
                'learning_rate': 0.1,
                'max_depth': 6
            },
            training_data={
                'features': ['price', 'demand', 'competitor_price', 'seasonality', 'promotions'],
                'target': 'optimal_price',
                'sample_size': 5000,
                'train_size': 0.8
            },
            performance_metrics={},
            status=ModelStatus.TRAINING,
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            last_trained=None,
            version="1.0.0"
        )
        
        model_id = await analytics_system.create_predictive_model(new_model)
        if model_id:
            print(f"   ‚úÖ Modelo predictivo creado")
            print(f"      ‚Ä¢ ID: {model_id}")
            print(f"      ‚Ä¢ Nombre: {new_model.name}")
            print(f"      ‚Ä¢ Tipo: {new_model.model_type.value}")
            print(f"      ‚Ä¢ Predicci√≥n: {new_model.prediction_type.value}")
            print(f"      ‚Ä¢ Algoritmo: {new_model.algorithm}")
            print(f"      ‚Ä¢ Estado: {new_model.status.value}")
        else:
            print(f"   ‚ùå Error al crear modelo predictivo")
        
        # Hacer predicci√≥n
        print(f"\nüîÆ HACIENDO PREDICCI√ìN...")
        if system_data['models']:
            first_model = system_data['models'][0]
            input_data = {
                'age': 35,
                'tenure': 24,
                'monthly_charges': 75.50,
                'total_charges': 1812.00,
                'contract_type': 'month-to-month',
                'payment_method': 'electronic_check'
            }
            
            prediction_id = await analytics_system.make_prediction(first_model['model_id'], input_data)
            if prediction_id:
                print(f"   ‚úÖ Predicci√≥n creada")
                print(f"      ‚Ä¢ ID: {prediction_id}")
                print(f"      ‚Ä¢ Modelo: {first_model['name']}")
                print(f"      ‚Ä¢ Datos de entrada: {input_data}")
            else:
                print(f"   ‚ùå Error al hacer predicci√≥n")
        
        # Esperar procesamiento
        await asyncio.sleep(3)
        
        # Mostrar m√©tricas finales
        print(f"\nüìà M√âTRICAS DEL SISTEMA DE AN√ÅLISIS PREDICTIVO:")
        metrics = system_data['metrics']
        print(f"   ‚Ä¢ Modelos totales: {metrics['total_models']}")
        print(f"   ‚Ä¢ Modelos activos: {metrics['active_models']}")
        print(f"   ‚Ä¢ Predicciones totales: {metrics['total_predictions']}")
        print(f"   ‚Ä¢ Predicciones exitosas: {metrics['successful_predictions']}")
        print(f"   ‚Ä¢ Predicciones fallidas: {metrics['failed_predictions']}")
        print(f"   ‚Ä¢ Precisi√≥n promedio: {metrics['average_accuracy']:.3f}")
        print(f"   ‚Ä¢ Recall promedio: {metrics['average_recall']:.3f}")
        print(f"   ‚Ä¢ F1 Score promedio: {metrics['average_f1_score']:.3f}")
        print(f"   ‚Ä¢ RMSE promedio: {metrics['average_rmse']:.2f}")
        print(f"   ‚Ä¢ MAE promedio: {metrics['average_mae']:.2f}")
        print(f"   ‚Ä¢ R¬≤ Score promedio: {metrics['average_r2_score']:.3f}")
        print(f"   ‚Ä¢ Frecuencia de reentrenamiento: {metrics['model_retraining_frequency']:.2f}")
        print(f"   ‚Ä¢ Latencia de predicci√≥n: {metrics['prediction_latency']:.3f}s")
        
        # Exportar datos
        print(f"\nüíæ EXPORTANDO DATOS DE AN√ÅLISIS PREDICTIVO...")
        exported_files = analytics_system.export_predictive_analytics_data()
        print(f"   ‚Ä¢ Archivos exportados: {len(exported_files)}")
        for file_type, path in exported_files.items():
            print(f"     - {file_type}: {Path(path).name}")
        
        print(f"\n‚úÖ SISTEMA DE AN√ÅLISIS PREDICTIVO DEMO COMPLETADO EXITOSAMENTE")
        print(f"üéâ El sistema de an√°lisis predictivo ha implementado:")
        print(f"   ‚Ä¢ Modelos de Machine Learning avanzados")
        print(f"   ‚Ä¢ Predicci√≥n de churn de clientes")
        print(f"   ‚Ä¢ Valor de vida del cliente (CLV)")
        print(f"   ‚Ä¢ Pron√≥stico de ventas y demanda")
        print(f"   ‚Ä¢ Optimizaci√≥n de precios")
        print(f"   ‚Ä¢ Segmentaci√≥n de clientes")
        print(f"   ‚Ä¢ An√°lisis de tendencias de mercado")
        print(f"   ‚Ä¢ Rendimiento de campa√±as")
        print(f"   ‚Ä¢ Algoritmos de clasificaci√≥n, regresi√≥n y clustering")
        print(f"   ‚Ä¢ Series temporales y forecasting")
        print(f"   ‚Ä¢ Deep Learning y redes neuronales")
        print(f"   ‚Ä¢ Modelos ensemble y boosting")
        print(f"   ‚Ä¢ Evaluaci√≥n y validaci√≥n de modelos")
        print(f"   ‚Ä¢ Despliegue y versionado de modelos")
        print(f"   ‚Ä¢ A/B testing de modelos")
        print(f"   ‚Ä¢ Monitoreo de rendimiento")
        
        return analytics_system
    
    # Ejecutar demo
    analytics_system = asyncio.run(run_demo())


if __name__ == "__main__":
    main()