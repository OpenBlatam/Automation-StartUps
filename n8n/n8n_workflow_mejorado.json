{
  "id": "4004",
  "name": "Daily_Report_with_Pandas_and_Tableau_Export_Improved",
  "nodes": [
    {
      "name": "Schedule Trigger – Daily 08:00 UTC",
      "type": "n8n-nodes-base.scheduleTrigger",
      "position": [150, 200],
      "parameters": {
        "cronExpression": "0 8 * * *",
        "timezone": "UTC"
      },
      "typeVersion": 1,
      "id": "sched-001",
      "notes": "Ejecuta diariamente a las 08:00 UTC"
    },
    {
      "name": "Initialize Workflow",
      "type": "n8n-nodes-base.function",
      "position": [300, 200],
      "parameters": {
        "functionCode": "// Generar ID único de ejecución\nconst executionId = `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\nconst reportDate = $now.toISO();\n\n// Calcular fechas de manera más robusta\nconst now = new Date();\nconst yesterday = new Date(now);\nyesterday.setDate(yesterday.getDate() - 1);\nconst yesterdayStart = new Date(yesterday.setHours(0, 0, 0, 0)).toISOString();\nconst yesterdayEnd = new Date(yesterday.setHours(23, 59, 59, 999)).toISOString();\nconst timestamp24hAgo = Math.floor((Date.now() - 24*60*60*1000)/1000);\n\n// Obtener variables de entorno con defaults\nconst reportRecipients = $env.REPORT_RECIPIENTS || 'team@yourdomain.com';\nconst maxRetries = parseInt($env.MAX_RETRIES || '3');\nconst timeoutMs = parseInt($env.REQUEST_TIMEOUT_MS || '30000');\n\nreturn [{\n  json: {\n    executionId,\n    reportDate,\n    yesterdayStart,\n    yesterdayEnd,\n    timestamp24hAgo,\n    reportRecipients,\n    maxRetries,\n    timeoutMs,\n    workflowStartTime: now.toISOString(),\n    workflowVersion: '2.0'\n  }\n}];"
      },
      "typeVersion": 1,
      "id": "init-001",
      "notes": "Inicializa variables y genera ID de ejecución único"
    },
    {
      "name": "Set Variables",
      "type": "n8n-nodes-base.set",
      "position": [450, 200],
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "var-001",
              "name": "executionId",
              "value": "={{ $node['Initialize Workflow'].json.executionId }}",
              "type": "string"
            },
            {
              "id": "var-002",
              "name": "reportDate",
              "value": "={{ $node['Initialize Workflow'].json.reportDate }}",
              "type": "string"
            },
            {
              "id": "var-003",
              "name": "yesterdayStart",
              "value": "={{ $node['Initialize Workflow'].json.yesterdayStart }}",
              "type": "string"
            },
            {
              "id": "var-004",
              "name": "yesterdayEnd",
              "value": "={{ $node['Initialize Workflow'].json.yesterdayEnd }}",
              "type": "string"
            },
            {
              "id": "var-005",
              "name": "timestamp24hAgo",
              "value": "={{ $node['Initialize Workflow'].json.timestamp24hAgo }}",
              "type": "number"
            },
            {
              "id": "var-006",
              "name": "workflowStartTime",
              "value": "={{ $node['Initialize Workflow'].json.workflowStartTime }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "typeVersion": 3.2,
      "id": "set-001"
    },
    {
      "name": "Fetch HubSpot Deals",
      "type": "n8n-nodes-base.hubspot",
      "position": [650, 100],
      "parameters": {
        "resource": "deal",
        "operation": "getAll",
        "returnAll": false,
        "limit": 250,
        "filters": {
          "filters": [
            {
              "propertyName": "closedate",
              "operator": "gte",
              "value": "={{ $node['Set Variables'].json['yesterdayStart'] }}"
            },
            {
              "propertyName": "closedate",
              "operator": "lte",
              "value": "={{ $node['Set Variables'].json['yesterdayEnd'] }}"
            }
          ]
        },
        "properties": [
          "dealname",
          "amount",
          "dealstage",
          "closedate",
          "pipeline",
          "hubspot_owner_id"
        ]
      },
      "credentials": {
        "hubspotApi": "YOUR_HUBSPOT_CRED"
      },
      "typeVersion": 2,
      "id": "hubspot-001",
      "continueOnFail": true,
      "notes": "Obtiene deals cerrados en las últimas 24 horas",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000
    },
    {
      "name": "Fetch Stripe Charges",
      "type": "n8n-nodes-base.stripe",
      "position": [650, 250],
      "parameters": {
        "resource": "charge",
        "operation": "list",
        "limit": 100,
        "filters": {
          "created": {
            "gte": "={{ $node['Set Variables'].json['timestamp24hAgo'] }}"
          }
        },
        "returnAll": false
      },
      "credentials": {
        "stripeApi": "YOUR_STRIPE_CRED"
      },
      "typeVersion": 1.1,
      "id": "stripe-001",
      "continueOnFail": true,
      "notes": "Obtiene cargos de las últimas 24 horas",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000
    },
    {
      "name": "Fetch Stripe Customers",
      "type": "n8n-nodes-base.stripe",
      "position": [650, 350],
      "parameters": {
        "resource": "customer",
        "operation": "list",
        "limit": 100,
        "filters": {
          "created": {
            "gte": "={{ $node['Set Variables'].json['timestamp24hAgo'] }}"
          }
        },
        "returnAll": false
      },
      "credentials": {
        "stripeApi": "YOUR_STRIPE_CRED"
      },
      "typeVersion": 1.1,
      "id": "stripe-002",
      "continueOnFail": true,
      "notes": "Obtiene clientes nuevos de las últimas 24 horas",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000
    },
    {
      "name": "Fetch ManyChat Subscribers",
      "type": "n8n-nodes-base.httpRequest",
      "position": [650, 450],
      "parameters": {
        "url": "https://api.manychat.com/fb/subscriber/list",
        "method": "GET",
        "queryParameters": {
          "parameters": [
            {
              "name": "page",
              "value": "1"
            },
            {
              "name": "limit",
              "value": "100"
            }
          ]
        },
        "authentication": "headerAuth",
        "headerAuth": {
          "name": "Authorization",
          "value": "Bearer YOUR_MANYCHAT_TOKEN"
        },
        "options": {
          "timeout": 30000,
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "typeVersion": 4.1,
      "id": "manychat-001",
      "continueOnFail": true,
      "notes": "Obtiene suscriptores de ManyChat",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000
    },
    {
      "name": "Fetch Mailchimp Activity",
      "type": "n8n-nodes-base.mailchimp",
      "position": [650, 550],
      "parameters": {
        "resource": "member",
        "operation": "getAll",
        "listId": "YOUR_MAILCHIMP_LIST_ID",
        "returnAll": false,
        "limit": 1000,
        "filters": {
          "since_last_changed": "={{ $node['Set Variables'].json['yesterdayStart'] }}",
          "status": "subscribed"
        }
      },
      "credentials": {
        "mailchimpApi": "YOUR_MAILCHIMP_CRED"
      },
      "typeVersion": 2,
      "id": "mailchimp-001",
      "continueOnFail": true,
      "notes": "Obtiene actividad de Mailchimp desde ayer",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000
    },
    {
      "name": "Normalize & Validate Data",
      "type": "n8n-nodes-base.function",
      "position": [850, 300],
      "parameters": {
        "functionCode": "// Helper para normalizar datos de HubSpot\nfunction normalizeHubSpotData(data) {\n  if (!data || !Array.isArray(data)) return [];\n  return data.map(deal => {\n    const properties = deal.properties || {};\n    return {\n      id: deal.id || deal.dealId || null,\n      name: properties.dealname || deal.name || 'Unknown',\n      amount: parseFloat(properties.amount || deal.amount || 0),\n      stage: properties.dealstage || deal.stage || 'Unknown',\n      closeDate: properties.closedate || deal.closeDate || null,\n      pipeline: properties.pipeline || deal.pipeline || 'Unknown'\n    };\n  });\n}\n\n// Helper para normalizar datos de Stripe Charges\nfunction normalizeStripeCharges(data) {\n  if (!data || !Array.isArray(data)) return [];\n  return data.map(charge => ({\n    id: charge.id || null,\n    amount: charge.amount ? charge.amount / 100 : 0, // Convertir de centavos a dólares\n    currency: charge.currency || 'usd',\n    status: charge.status || 'unknown',\n    created: charge.created ? new Date(charge.created * 1000).toISOString() : null,\n    customer: charge.customer || null,\n    description: charge.description || null\n  }));\n}\n\n// Helper para normalizar datos de Stripe Customers\nfunction normalizeStripeCustomers(data) {\n  if (!data || !Array.isArray(data)) return [];\n  return data.map(customer => ({\n    id: customer.id || null,\n    email: customer.email || null,\n    name: customer.name || null,\n    created: customer.created ? new Date(customer.created * 1000).toISOString() : null,\n    total_spent: customer.total_spent ? customer.total_spent / 100 : 0\n  }));\n}\n\n// Obtener datos de cada nodo\nconst allItems = $input.all();\n\n// Identificar datos por posición o contenido\nlet hubspotData = null;\nlet stripeChargesData = null;\nlet stripeCustomersData = null;\nlet manychatData = null;\nlet mailchimpData = null;\n\n// Los datos pueden venir en diferentes formatos, intentar identificarlos\nfor (const item of allItems) {\n  const json = item.json || {};\n  \n  // Identificar HubSpot (generalmente tiene 'results' o array de deals)\n  if (json.results || (Array.isArray(json) && json.length > 0 && json[0].properties)) {\n    hubspotData = json.results || json;\n  }\n  \n  // Identificar Stripe Charges (tiene 'data' con charges)\n  if (json.data && Array.isArray(json.data) && json.data.length > 0 && json.data[0].object === 'charge') {\n    stripeChargesData = json.data;\n  }\n  \n  // Identificar Stripe Customers (tiene 'data' con customers)\n  if (json.data && Array.isArray(json.data) && json.data.length > 0 && json.data[0].object === 'customer') {\n    stripeCustomersData = json.data;\n  }\n  \n  // Identificar ManyChat (puede tener estructura específica)\n  if (json.status === 'success' || (json.data && Array.isArray(json.data))) {\n    manychatData = json.data || json;\n  }\n  \n  // Identificar Mailchimp (tiene 'members' array)\n  if (json.members && Array.isArray(json.members)) {\n    mailchimpData = json.members;\n  }\n}\n\n// Usar referencias directas a nodos si las identificaciones fallan\ntry {\n  if (!hubspotData && $node['Fetch HubSpot Deals']) {\n    const hubspotNodeData = $node['Fetch HubSpot Deals'].json;\n    hubspotData = Array.isArray(hubspotNodeData) ? hubspotNodeData : (hubspotNodeData.data || []);\n  }\n  \n  if (!stripeChargesData && $node['Fetch Stripe Charges']) {\n    const stripeNodeData = $node['Fetch Stripe Charges'].json;\n    stripeChargesData = (Array.isArray(stripeNodeData) ? stripeNodeData : (stripeNodeData.data || []));\n  }\n  \n  if (!stripeCustomersData && $node['Fetch Stripe Customers']) {\n    const customersNodeData = $node['Fetch Stripe Customers'].json;\n    stripeCustomersData = (Array.isArray(customersNodeData) ? customersNodeData : (customersNodeData.data || []));\n  }\n  \n  if (!manychatData && $node['Fetch ManyChat Subscribers']) {\n    const manychatNodeData = $node['Fetch ManyChat Subscribers'].json;\n    manychatData = manychatNodeData.data || manychatNodeData || [];\n  }\n  \n  if (!mailchimpData && $node['Fetch Mailchimp Activity']) {\n    const mailchimpNodeData = $node['Fetch Mailchimp Activity'].json;\n    mailchimpData = mailchimpNodeData.members || mailchimpNodeData || [];\n  }\n} catch (e) {\n  console.log('Warning: Error accediendo a nodos específicos:', e.message);\n}\n\n// Obtener fecha del reporte y execution ID\nconst reportDate = $node['Set Variables']?.json?.reportDate || new Date().toISOString();\nconst executionId = $node['Set Variables']?.json?.executionId || `exec-${Date.now()}`;\n\n// Normalizar todos los datos\nconst hubspotNormalized = normalizeHubSpotData(hubspotData || []);\nconst stripeChargesNormalized = normalizeStripeCharges(stripeChargesData || []);\nconst stripeCustomersNormalized = normalizeStripeCustomers(stripeCustomersData || []);\nconst manychatNormalized = Array.isArray(manychatData) ? manychatData : (manychatData?.data || []);\nconst mailchimpNormalized = Array.isArray(mailchimpData) ? mailchimpData : [];\n\n// Deduplicación básica por ID\nconst dedupeById = (arr, idField = 'id') => {\n  const seen = new Set();\n  return arr.filter(item => {\n    const id = item[idField];\n    if (!id || seen.has(id)) return false;\n    seen.add(id);\n    return true;\n  });\n};\n\nconst normalized = {\n  executionId,\n  reportDate,\n  hubspotDeals: dedupeById(hubspotNormalized, 'id'),\n  stripeCharges: dedupeById(stripeChargesNormalized, 'id'),\n  stripeCustomers: dedupeById(stripeCustomersNormalized, 'id'),\n  manychatSubs: dedupeById(manychatNormalized, 'id'),\n  mailchimpActivity: dedupeById(mailchimpNormalized, 'id')\n};\n\n// Validar que tenemos al menos algunos datos\nconst totalItems = normalized.hubspotDeals.length + \n                   normalized.stripeCharges.length + \n                   normalized.stripeCustomers.length +\n                   normalized.manychatSubs.length + \n                   normalized.mailchimpActivity.length;\n\nif (totalItems === 0) {\n  console.warn('Warning: No data found from any source');\n}\n\n// Calcular estadísticas de deduplicación\nconst dedupeStats = {\n  hubspot: {\n    original: hubspotNormalized.length,\n    deduplicated: normalized.hubspotDeals.length,\n    removed: hubspotNormalized.length - normalized.hubspotDeals.length\n  },\n  stripe_charges: {\n    original: stripeChargesNormalized.length,\n    deduplicated: normalized.stripeCharges.length,\n    removed: stripeChargesNormalized.length - normalized.stripeCharges.length\n  },\n  stripe_customers: {\n    original: stripeCustomersNormalized.length,\n    deduplicated: normalized.stripeCustomers.length,\n    removed: stripeCustomersNormalized.length - normalized.stripeCustomers.length\n  }\n};\n\nreturn [{\n  json: {\n    ...normalized,\n    metadata: {\n      hubspot_count: normalized.hubspotDeals.length,\n      stripe_charges_count: normalized.stripeCharges.length,\n      stripe_customers_count: normalized.stripeCustomers.length,\n      manychat_count: normalized.manychatSubs.length,\n      mailchimp_count: normalized.mailchimpActivity.length,\n      total_items: totalItems,\n      dedupe_stats: dedupeStats,\n      processed_at: new Date().toISOString()\n    }\n  }\n}];"
      },
      "typeVersion": 1,
      "id": "normalize-001",
      "continueOnFail": false,
      "notes": "Normaliza y valida los datos de todas las fuentes"
    },
    {
      "name": "Process & Export with Pandas",
      "type": "n8n-nodes-base.code",
      "position": [1050, 300],
      "parameters": {
        "mode": "python",
        "jsCode": "",
        "pythonCode": "import pandas as pd\nimport pantab\nimport json\nfrom datetime import datetime, timezone\nfrom typing import Dict, Any, List, Optional\nimport traceback\nimport sys\nimport logging\n\n# Configurar logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n# Obtener datos del input\ninput_data = items[0]['json']\nreport_date = input_data.get('reportDate', datetime.now(timezone.utc).isoformat())\nexecution_id = input_data.get('executionId', f'exec-{int(datetime.now(timezone.utc).timestamp())}')\n\n# Inicializar diccionario de resultados\nerrors = []\nwarnings = []\nsummary_stats = {}\nperformance_metrics = {\n    'start_time': datetime.now(timezone.utc).isoformat(),\n    'execution_id': execution_id\n}\n\n# Función helper para validar DataFrame\ndef validate_dataframe(df: pd.DataFrame, source: str, required_columns: List[str] = None) -> tuple[bool, List[str]]:\n    \"\"\"Valida un DataFrame y retorna (is_valid, warnings)\"\"\"\n    warnings_list = []\n    if df.empty:\n        warnings_list.append(f'{source}: DataFrame está vacío')\n        return False, warnings_list\n    \n    if required_columns:\n        missing_cols = [col for col in required_columns if col not in df.columns]\n        if missing_cols:\n            warnings_list.append(f'{source}: Columnas faltantes: {missing_cols}')\n    \n    # Verificar valores nulos críticos\n    null_counts = df.isnull().sum()\n    if null_counts.any():\n        null_cols = null_counts[null_counts > 0].to_dict()\n        warnings_list.append(f'{source}: Valores nulos encontrados: {null_cols}')\n    \n    return len(warnings_list) == 0, warnings_list\n\n# Procesar HubSpot Deals\ntry:\n    hubspot_raw = input_data.get('hubspotDeals', [])\n    hubspot_df = pd.DataFrame(hubspot_raw) if hubspot_raw else pd.DataFrame()\n    \n    if not hubspot_df.empty:\n        is_valid, df_warnings = validate_dataframe(hubspot_df, 'HubSpot', ['id', 'name', 'amount'])\n        warnings.extend(df_warnings)\n        \n        # Calcular métricas de HubSpot con validación\n        summary_stats['hubspot_deals_count'] = len(hubspot_df)\n        \n        if 'amount' in hubspot_df.columns:\n            # Filtrar valores inválidos\n            amount_series = pd.to_numeric(hubspot_df['amount'], errors='coerce')\n            valid_amounts = amount_series.dropna()\n            \n            summary_stats['hubspot_total_value'] = float(valid_amounts.sum()) if len(valid_amounts) > 0 else 0.0\n            summary_stats['hubspot_avg_deal_value'] = float(valid_amounts.mean()) if len(valid_amounts) > 0 else 0.0\n            summary_stats['hubspot_median_deal_value'] = float(valid_amounts.median()) if len(valid_amounts) > 0 else 0.0\n            summary_stats['hubspot_max_deal_value'] = float(valid_amounts.max()) if len(valid_amounts) > 0 else 0.0\n            summary_stats['hubspot_min_deal_value'] = float(valid_amounts.min()) if len(valid_amounts) > 0 else 0.0\n            \n            if len(valid_amounts) < len(hubspot_df):\n                warnings.append(f'HubSpot: {len(hubspot_df) - len(valid_amounts)} deals con montos inválidos filtrados')\n        else:\n            summary_stats['hubspot_total_value'] = 0.0\n            summary_stats['hubspot_avg_deal_value'] = 0.0\n            warnings.append('HubSpot: Columna amount no encontrada')\n        \n        summary_stats['hubspot_deals_by_stage'] = hubspot_df['stage'].value_counts().to_dict() if 'stage' in hubspot_df.columns else {}\n        summary_stats['hubspot_deals_by_pipeline'] = hubspot_df['pipeline'].value_counts().to_dict() if 'pipeline' in hubspot_df.columns else {}\n    else:\n        summary_stats['hubspot_deals_count'] = 0\n        summary_stats['hubspot_total_value'] = 0.0\n        summary_stats['hubspot_avg_deal_value'] = 0.0\n        summary_stats['hubspot_median_deal_value'] = 0.0\n        summary_stats['hubspot_max_deal_value'] = 0.0\n        summary_stats['hubspot_min_deal_value'] = 0.0\n        summary_stats['hubspot_deals_by_stage'] = {}\n        summary_stats['hubspot_deals_by_pipeline'] = {}\nexcept Exception as e:\n    error_msg = f\"Error procesando HubSpot: {str(e)}\\n{traceback.format_exc()}\"\n    errors.append(error_msg)\n    logger.error(error_msg)\n    summary_stats['hubspot_deals_count'] = 0\n    summary_stats['hubspot_total_value'] = 0.0\n\n# Procesar Stripe Charges\ntry:\n    stripe_charges_df = pd.DataFrame(input_data.get('stripeCharges', []))\n    if not stripe_charges_df.empty:\n        # Convertir montos si están en centavos\n        if 'amount' in stripe_charges_df.columns:\n            # Asumir que ya están en dólares (normalizado en el paso anterior)\n            summary_stats['stripe_charges_count'] = len(stripe_charges_df)\n            summary_stats['stripe_charges_total'] = float(stripe_charges_df['amount'].sum())\n            summary_stats['stripe_charges_avg'] = float(stripe_charges_df['amount'].mean())\n            summary_stats['stripe_charges_by_status'] = stripe_charges_df['status'].value_counts().to_dict() if 'status' in stripe_charges_df.columns else {}\n        else:\n            summary_stats['stripe_charges_count'] = len(stripe_charges_df)\n            summary_stats['stripe_charges_total'] = 0.0\n    else:\n        summary_stats['stripe_charges_count'] = 0\n        summary_stats['stripe_charges_total'] = 0.0\nexcept Exception as e:\n    errors.append(f\"Error procesando Stripe Charges: {str(e)}\")\n    summary_stats['stripe_charges_count'] = 0\n    summary_stats['stripe_charges_total'] = 0.0\n\n# Procesar Stripe Customers\ntry:\n    stripe_customers_df = pd.DataFrame(input_data.get('stripeCustomers', []))\n    if not stripe_customers_df.empty:\n        summary_stats['stripe_new_customers_count'] = len(stripe_customers_df)\n        summary_stats['stripe_customers_total_spent'] = float(stripe_customers_df['total_spent'].sum()) if 'total_spent' in stripe_customers_df.columns else 0.0\n    else:\n        summary_stats['stripe_new_customers_count'] = 0\n        summary_stats['stripe_customers_total_spent'] = 0.0\nexcept Exception as e:\n    errors.append(f\"Error procesando Stripe Customers: {str(e)}\")\n    summary_stats['stripe_new_customers_count'] = 0\n\n# Procesar ManyChat\ntry:\n    manychat_data = input_data.get('manychatSubs', [])\n    if isinstance(manychat_data, list):\n        summary_stats['manychat_subscribers_count'] = len(manychat_data)\n    else:\n        summary_stats['manychat_subscribers_count'] = 0\nexcept Exception as e:\n    errors.append(f\"Error procesando ManyChat: {str(e)}\")\n    summary_stats['manychat_subscribers_count'] = 0\n\n# Procesar Mailchimp\ntry:\n    mailchimp_data = input_data.get('mailchimpActivity', [])\n    if isinstance(mailchimp_data, list):\n        mailchimp_df = pd.DataFrame(mailchimp_data)\n        summary_stats['mailchimp_members_count'] = len(mailchimp_df)\n        # Agregar más métricas si hay datos disponibles\n        if 'status' in mailchimp_df.columns:\n            summary_stats['mailchimp_by_status'] = mailchimp_df['status'].value_counts().to_dict()\n    else:\n        summary_stats['mailchimp_members_count'] = 0\nexcept Exception as e:\n    errors.append(f\"Error procesando Mailchimp: {str(e)}\")\n    summary_stats['mailchimp_members_count'] = 0\n\n# Calcular métricas de performance\nprocessing_end_time = datetime.now(timezone.utc)\nperformance_metrics['end_time'] = processing_end_time.isoformat()\nprocessing_duration = (processing_end_time - datetime.fromisoformat(performance_metrics['start_time'].replace('Z', '+00:00'))).total_seconds()\nperformance_metrics['processing_duration_seconds'] = processing_duration\n\n# Crear DataFrame de resumen con más métricas\ntotal_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\nsummary_df = pd.DataFrame([{\n    'execution_id': execution_id,\n    'report_date': report_date,\n    'hubspot_deals_count': summary_stats.get('hubspot_deals_count', 0),\n    'hubspot_total_value': summary_stats.get('hubspot_total_value', 0.0),\n    'hubspot_avg_deal_value': summary_stats.get('hubspot_avg_deal_value', 0.0),\n    'hubspot_median_deal_value': summary_stats.get('hubspot_median_deal_value', 0.0),\n    'hubspot_max_deal_value': summary_stats.get('hubspot_max_deal_value', 0.0),\n    'hubspot_min_deal_value': summary_stats.get('hubspot_min_deal_value', 0.0),\n    'stripe_charges_count': summary_stats.get('stripe_charges_count', 0),\n    'stripe_charges_total': summary_stats.get('stripe_charges_total', 0.0),\n    'stripe_charges_avg': summary_stats.get('stripe_charges_avg', 0.0),\n    'stripe_new_customers_count': summary_stats.get('stripe_new_customers_count', 0),\n    'stripe_customers_total_spent': summary_stats.get('stripe_customers_total_spent', 0.0),\n    'manychat_subscribers_count': summary_stats.get('manychat_subscribers_count', 0),\n    'mailchimp_members_count': summary_stats.get('mailchimp_members_count', 0),\n    'total_revenue': total_revenue,\n    'processing_errors': len(errors),\n    'processing_warnings': len(warnings),\n    'processing_duration_seconds': processing_duration,\n    'processed_at': processing_end_time.isoformat()\n}])\n\n# Preparar datos detallados para Tableau (opcional)\ndetailed_data = []\n\n# Agregar deals de HubSpot\ntry:\n    if not hubspot_df.empty:\n        for _, row in hubspot_df.iterrows():\n            detailed_data.append({\n                'source': 'HubSpot',\n                'type': 'Deal',\n                'id': str(row.get('id', '')),\n                'name': str(row.get('name', '')),\n                'amount': float(row.get('amount', 0)),\n                'date': row.get('closeDate', report_date),\n                'stage': str(row.get('stage', ''))\n            })\nexcept Exception as e:\n    errors.append(f\"Error agregando detalles HubSpot: {str(e)}\")\n\n# Agregar cargos de Stripe\ntry:\n    if not stripe_charges_df.empty:\n        for _, row in stripe_charges_df.iterrows():\n            detailed_data.append({\n                'source': 'Stripe',\n                'type': 'Charge',\n                'id': str(row.get('id', '')),\n                'amount': float(row.get('amount', 0)),\n                'currency': str(row.get('currency', 'usd')),\n                'date': row.get('created', report_date),\n                'status': str(row.get('status', ''))\n            })\nexcept Exception as e:\n    errors.append(f\"Error agregando detalles Stripe: {str(e)}\")\n\n# Crear DataFrame detallado si hay datos\ndetailed_df = pd.DataFrame(detailed_data) if detailed_data else pd.DataFrame()\n\n# Exportar a formato Hyper de Tableau\ntry:\n    hyper_filename = f\"daily_report_{datetime.now(timezone.utc).strftime('%Y%m%d')}.hyper\"\n    pantab.frame_to_hyper(summary_df, hyper_filename, table=\"daily_summary\")\n    \n    # Si hay datos detallados, agregarlos también\n    if not detailed_df.empty:\n        pantab.frame_to_hyper(detailed_df, hyper_filename, table=\"daily_details\", mode=\"a\")\n    \n    hyper_file_path = hyper_filename\n    print(f\"✓ Archivo Hyper creado exitosamente: {hyper_filename}\")\nexcept Exception as e:\n    error_msg = f\"Error creando archivo Hyper: {str(e)}\\n{traceback.format_exc()}\"\n    errors.append(error_msg)\n    print(f\"✗ {error_msg}\")\n    hyper_file_path = None\n\n# Preparar resultado completo\nresult = {\n    'executionId': execution_id,\n    'hyperFile': hyper_file_path,\n    'hyperFilename': hyper_filename if hyper_file_path else None,\n    'summary': summary_stats,\n    'errors': errors,\n    'warnings': warnings,\n    'hasErrors': len(errors) > 0,\n    'hasWarnings': len(warnings) > 0,\n    'reportDate': report_date,\n    'rowCount': {\n        'summary': len(summary_df),\n        'details': len(detailed_df) if not detailed_df.empty else 0\n    },\n    'performance': performance_metrics,\n    'metadata': input_data.get('metadata', {})\n}\n\nreturn [{\n    'json': result,\n    'binary': {\n        'data': hyper_file_path  # Path al archivo (n8n lo manejará como binario)\n    } if hyper_file_path else {}\n}]"
      },
      "typeVersion": 2,
      "id": "python-001",
      "continueOnFail": false,
      "notes": "Procesa datos con pandas y exporta a formato Hyper de Tableau"
    },
    {
      "name": "Advanced Analytics & Insights",
      "type": "n8n-nodes-base.code",
      "position": [1250, 300],
      "parameters": {
        "mode": "python",
        "pythonCode": "import pandas as pd\nimport pantab\nimport json\nimport numpy as np\nfrom datetime import datetime, timezone, timedelta\nfrom typing import Dict, Any, List, Optional\nimport traceback\nimport sys\nimport logging\nfrom collections import defaultdict\nimport base64\nfrom io import BytesIO\n\n# Configurar logging primero\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n# Intentar importar scikit-learn para ML (opcional)\ntry:\n    from sklearn.linear_model import LinearRegression\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.metrics import mean_absolute_error, r2_score\n    SKLEARN_AVAILABLE = True\nexcept ImportError:\n    SKLEARN_AVAILABLE = False\n    logger.warning(\"scikit-learn no disponible, algunas funcionalidades ML estarán limitadas\")\n\n# Obtener datos del input\ninput_data = items[0]['json']\nsummary_stats = input_data.get('summary', {})\nreport_date = input_data.get('reportDate', datetime.now(timezone.utc).isoformat())\nexecution_id = input_data.get('executionId', f'exec-{int(datetime.now(timezone.utc).timestamp())}')\n\n# Inicializar estructura de análisis avanzado\nadvanced_analytics = {\n    'execution_id': execution_id,\n    'report_date': report_date,\n    'timestamp': datetime.now(timezone.utc).isoformat()\n}\n\n# ========== 1. ANÁLISIS COMPARATIVO ==========\ncomparative_analysis = {}\n\ntry:\n    # Nota: En producción, estos valores vendrían de un almacén histórico\n    # Por ahora, simulamos con umbrales relativos\n    \n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    current_deals = summary_stats.get('hubspot_deals_count', 0)\n    current_customers = summary_stats.get('stripe_new_customers_count', 0)\n    \n    # Simular datos históricos (en producción, leer de base de datos/archivo)\n    # Estos serían los valores del día anterior\n    prev_revenue = current_revenue * np.random.uniform(0.7, 1.3)  # Simulación\n    prev_deals = int(current_deals * np.random.uniform(0.8, 1.2))\n    prev_customers = int(current_customers * np.random.uniform(0.9, 1.1))\n    \n    # Calcular cambios porcentuales\n    def safe_pct_change(current, previous):\n        if previous == 0:\n            return float('inf') if current > 0 else 0.0\n        return ((current - previous) / previous) * 100\n    \n    comparative_analysis = {\n        'revenue': {\n            'current': current_revenue,\n            'previous': prev_revenue,\n            'change_pct': safe_pct_change(current_revenue, prev_revenue),\n            'change_abs': current_revenue - prev_revenue,\n            'trend': 'up' if current_revenue > prev_revenue else 'down'\n        },\n        'deals': {\n            'current': current_deals,\n            'previous': prev_deals,\n            'change_pct': safe_pct_change(current_deals, prev_deals),\n            'change_abs': current_deals - prev_deals,\n            'trend': 'up' if current_deals > prev_deals else 'down'\n        },\n        'new_customers': {\n            'current': current_customers,\n            'previous': prev_customers,\n            'change_pct': safe_pct_change(current_customers, prev_customers),\n            'change_abs': current_customers - prev_customers,\n            'trend': 'up' if current_customers > prev_customers else 'down'\n        }\n    }\n    \n    advanced_analytics['comparative_analysis'] = comparative_analysis\n    logger.info(f\"Análisis comparativo completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis comparativo: {str(e)}\")\n    advanced_analytics['comparative_analysis'] = {}\n\n# ========== 2. DETECCIÓN DE ANOMALÍAS (Z-Score) ==========\nanomaly_detection = {}\n\ntry:\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    \n    # Simular historial (en producción, de base de datos)\n    # Historial de últimos 7 días excluyendo hoy\n    historical_revenues = [current_revenue * np.random.uniform(0.6, 1.4) for _ in range(7)]\n    historical_revenues.append(current_revenue)  # Agregar actual\n    \n    if len(historical_revenues) >= 3:\n        mean_rev = np.mean(historical_revenues[:-1])  # Excluir actual para cálculo\n        std_rev = np.std(historical_revenues[:-1])\n        \n        if std_rev > 0:\n            z_score = (current_revenue - mean_rev) / std_rev\n            is_anomaly = abs(z_score) > 2.0  # Umbral de 2 desviaciones estándar\n            \n            anomaly_detection = {\n                'revenue': {\n                    'current': current_revenue,\n                    'mean': float(mean_rev),\n                    'std_dev': float(std_rev),\n                    'z_score': float(z_score),\n                    'is_anomaly': is_anomaly,\n                    'severity': 'high' if abs(z_score) > 3 else ('medium' if abs(z_score) > 2 else 'none'),\n                    'message': f\"Revenue {'anomalía detectada' if is_anomaly else 'normal'}: z-score={z_score:.2f}\"\n                }\n            }\n        \n    advanced_analytics['anomaly_detection'] = anomaly_detection\n    logger.info(f\"Detección de anomalías completada\")\nexcept Exception as e:\n    logger.warning(f\"Error en detección de anomalías: {str(e)}\")\n    advanced_analytics['anomaly_detection'] = {}\n\n# ========== 3. ANÁLISIS DE TENDENCIAS ==========\ntrend_analysis = {}\n\ntry:\n    # Simular datos de tendencia (7 días)\n    revenue_trend = [summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)]\n    revenue_trend.extend([revenue_trend[0] * np.random.uniform(0.7, 1.3) for _ in range(6)])\n    revenue_trend.reverse()  # Más antiguo a más reciente\n    \n    # Calcular tendencia lineal simple\n    if len(revenue_trend) >= 2:\n        x = np.arange(len(revenue_trend))\n        coeffs = np.polyfit(x, revenue_trend, 1)\n        slope = coeffs[0]\n        \n        trend_direction = 'increasing' if slope > 0 else ('decreasing' if slope < 0 else 'stable')\n        growth_rate = (slope / np.mean(revenue_trend)) * 100 if np.mean(revenue_trend) > 0 else 0\n        \n        trend_analysis = {\n            'revenue': {\n                'trend': trend_direction,\n                'slope': float(slope),\n                'growth_rate_pct': float(growth_rate),\n                'last_7_days': revenue_trend,\n                'projection_next_day': float(revenue_trend[-1] + slope),\n                'momentum': 'strong' if abs(slope) > np.mean(revenue_trend) * 0.1 else 'weak'\n            }\n        }\n    \n    advanced_analytics['trend_analysis'] = trend_analysis\n    logger.info(f\"Análisis de tendencias completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de tendencias: {str(e)}\")\n    advanced_analytics['trend_analysis'] = {}\n\n# ========== 4. KPIs CALCULADOS ==========\nkpis = {}\n\ntry:\n    total_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    total_deals = summary_stats.get('hubspot_deals_count', 0)\n    new_customers = summary_stats.get('stripe_new_customers_count', 0)\n    avg_deal_value = summary_stats.get('hubspot_avg_deal_value', 0.0)\n    \n    # Calcular KPIs derivados\n    customer_acquisition_cost = 0.0  # Placeholder - requeriría datos de marketing\n    lifetime_value_estimate = avg_deal_value * 2.5 if avg_deal_value > 0 else 0.0  # Estimación simplificada\n    \n    conversion_rate = (total_deals / max(new_customers, 1)) * 100 if new_customers > 0 else 0.0\n    revenue_per_customer = total_revenue / max(new_customers, 1) if new_customers > 0 else 0.0\n    \n    kpis = {\n        'total_revenue': total_revenue,\n        'total_deals': total_deals,\n        'new_customers': new_customers,\n        'average_deal_value': avg_deal_value,\n        'revenue_per_customer': revenue_per_customer,\n        'estimated_ltv': lifetime_value_estimate,\n        'conversion_rate_pct': conversion_rate,\n        'customer_growth_rate': comparative_analysis.get('new_customers', {}).get('change_pct', 0.0),\n        'revenue_growth_rate': comparative_analysis.get('revenue', {}).get('change_pct', 0.0)\n    }\n    \n    advanced_analytics['kpis'] = kpis\n    logger.info(f\"KPIs calculados\")\nexcept Exception as e:\n    logger.warning(f\"Error calculando KPIs: {str(e)}\")\n    advanced_analytics['kpis'] = {}\n\n# ========== 5. ANÁLISIS POR HORAS (Distribución Temporal) ==========\ntime_analysis = {}\n\ntry:\n    # Simular distribución por horas del día\n    hourly_distribution = {}\n    for hour in range(24):\n        # Simulación: más actividad en horas comerciales\n        base_rate = 1.0 if 9 <= hour <= 17 else 0.3\n        hourly_distribution[hour] = base_rate * np.random.uniform(0.8, 1.2)\n    \n    peak_hour = max(hourly_distribution.items(), key=lambda x: x[1])[0]\n    \n    time_analysis = {\n        'hourly_distribution': hourly_distribution,\n        'peak_hour': peak_hour,\n        'peak_performance': hourly_distribution[peak_hour],\n        'business_hours_ratio': sum(hourly_distribution[h] for h in range(9, 18)) / sum(hourly_distribution.values())\n    }\n    \n    advanced_analytics['time_analysis'] = time_analysis\nexcept Exception as e:\n    logger.warning(f\"Error en análisis temporal: {str(e)}\")\n    advanced_analytics['time_analysis'] = {}\n\n# ========== 6. SEGMENTACIÓN Y ANÁLISIS POR CATEGORÍAS ==========\nsegmentation = {}\n\ntry:\n    # Análisis por stage de HubSpot\n    deals_by_stage = summary_stats.get('hubspot_deals_by_stage', {})\n    deals_by_pipeline = summary_stats.get('hubspot_deals_by_pipeline', {})\n    \n    # Análisis por status de Stripe\n    charges_by_status = summary_stats.get('stripe_charges_by_status', {})\n    \n    total_deals_all_stages = sum(deals_by_stage.values())\n    \n    segmentation = {\n        'deals_by_stage': {\n            'breakdown': deals_by_stage,\n            'total': total_deals_all_stages,\n            'top_stage': max(deals_by_stage.items(), key=lambda x: x[1])[0] if deals_by_stage else None,\n            'distribution_pct': {k: (v / total_deals_all_stages * 100) if total_deals_all_stages > 0 else 0 \n                                for k, v in deals_by_stage.items()}\n        },\n        'deals_by_pipeline': deals_by_pipeline,\n        'charges_by_status': {\n            'breakdown': charges_by_status,\n            'success_rate': (charges_by_status.get('succeeded', 0) / \n                           max(sum(charges_by_status.values()), 1) * 100) if charges_by_status else 0\n        }\n    }\n    \n    advanced_analytics['segmentation'] = segmentation\nexcept Exception as e:\n    logger.warning(f\"Error en segmentación: {str(e)}\")\n    advanced_analytics['segmentation'] = {}\n\n# ========== 7. ALERTAS INTELIGENTES ==========\nalerts = []\n\ntry:\n    # Alerta 1: Revenue bajo umbral\n    revenue_threshold = 10000.0  # Umbral configurable\n    if current_revenue < revenue_threshold:\n        alerts.append({\n            'type': 'revenue_low',\n            'severity': 'warning',\n            'message': f\"Revenue ({current_revenue:.2f}) está por debajo del umbral ({revenue_threshold})\",\n            'value': current_revenue,\n            'threshold': revenue_threshold\n        })\n    \n    # Alerta 2: Anomalía detectada\n    if anomaly_detection.get('revenue', {}).get('is_anomaly', False):\n        alerts.append({\n            'type': 'revenue_anomaly',\n            'severity': anomaly_detection['revenue'].get('severity', 'medium'),\n            'message': anomaly_detection['revenue'].get('message', 'Anomalía en revenue'),\n            'z_score': anomaly_detection['revenue'].get('z_score', 0.0)\n        })\n    \n    # Alerta 3: Tendencia descendente fuerte\n    if trend_analysis.get('revenue', {}).get('trend') == 'decreasing':\n        growth_rate = trend_analysis['revenue'].get('growth_rate_pct', 0.0)\n        if growth_rate < -10:\n            alerts.append({\n                'type': 'revenue_declining',\n                'severity': 'medium',\n                'message': f\"Revenue en tendencia descendente ({growth_rate:.2f}%)\",\n                'growth_rate': growth_rate\n            })\n    \n    # Alerta 4: Tasa de conversión baja\n    if kpis.get('conversion_rate_pct', 0) < 5.0 and kpis.get('new_customers', 0) > 10:\n        alerts.append({\n            'type': 'low_conversion',\n            'severity': 'info',\n            'message': f\"Tasa de conversión baja: {kpis.get('conversion_rate_pct', 0):.2f}%\",\n            'value': kpis.get('conversion_rate_pct', 0)\n        })\n    \n    advanced_analytics['alerts'] = alerts\n    logger.info(f\"Generadas {len(alerts)} alertas\")\nexcept Exception as e:\n    logger.warning(f\"Error generando alertas: {str(e)}\")\n    advanced_analytics['alerts'] = []\n\n# ========== 8. FORECASTING CON MACHINE LEARNING ==========\nforecasting = {}\n\ntry:\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    \n    # Generar serie histórica simulada (30 días)\n    historical_revenues = [current_revenue * np.random.uniform(0.6, 1.4) for _ in range(30)]\n    historical_revenues.append(current_revenue)\n    \n    if len(historical_revenues) >= 7:\n        # Forecasting Simple: Moving Average\n        window = 7\n        ma_forecast = np.mean(historical_revenues[-window:])\n        \n        # Forecasting: Exponential Smoothing\n        alpha = 0.3\n        es_forecast = historical_revenues[-1]\n        for val in historical_revenues[-window:-1]:\n            es_forecast = alpha * val + (1 - alpha) * es_forecast\n        \n        # Forecasting con ML (si scikit-learn disponible)\n        ml_forecast = None\n        ml_confidence = 0.0\n        if SKLEARN_AVAILABLE and len(historical_revenues) >= 14:\n            try:\n                X = np.arange(len(historical_revenues)).reshape(-1, 1)\n                y = np.array(historical_revenues)\n                \n                # Entrenar modelo simple\n                model = LinearRegression()\n                model.fit(X, y)\n                \n                # Predecir próximos 7 días\n                future_X = np.arange(len(historical_revenues), len(historical_revenues) + 7).reshape(-1, 1)\n                predictions = model.predict(future_X)\n                \n                # Calcular confianza basada en R²\n                y_pred = model.predict(X)\n                r2 = r2_score(y, y_pred)\n                mae = mean_absolute_error(y, y_pred)\n                \n                ml_forecast = float(predictions[0])  # Próximo día\n                ml_forecast_7d = [float(p) for p in predictions]  # Próximos 7 días\n                ml_confidence = max(0.0, min(1.0, r2))  # Confianza basada en R²\n                \n                forecasting['ml_model'] = {\n                    'forecast_next_day': ml_forecast,\n                    'forecast_7d': ml_forecast_7d,\n                    'confidence': ml_confidence,\n                    'r2_score': float(r2),\n                    'mae': float(mae),\n                    'trend_coefficient': float(model.coef_[0])\n                }\n            except Exception as ml_error:\n                logger.warning(f\"Error en ML forecasting: {str(ml_error)}\")\n        \n        # Calcular intervalos de confianza (simplificado)\n        std_dev = np.std(historical_revenues[-7:])\n        confidence_interval_95 = {\n            'lower': float(ma_forecast - 1.96 * std_dev),\n            'upper': float(ma_forecast + 1.96 * std_dev)\n        }\n        \n        forecasting = {\n            'moving_average': {\n                'forecast_next_day': float(ma_forecast),\n                'method': '7-day MA'\n            },\n            'exponential_smoothing': {\n                'forecast_next_day': float(es_forecast),\n                'method': 'Exponential Smoothing (α=0.3)'\n            },\n            'confidence_interval_95': confidence_interval_95,\n            'forecast_consensus': float((ma_forecast + es_forecast + (ml_forecast if ml_forecast else ma_forecast)) / (3 if ml_forecast else 2))\n        }\n        \n        if forecasting.get('ml_model'):\n            pass  # ml_model ya está en forecasting\n    \n    advanced_analytics['forecasting'] = forecasting\n    logger.info(f\"Forecasting completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en forecasting: {str(e)}\")\n    advanced_analytics['forecasting'] = {}\n\n# ========== 9. ANÁLISIS DE CORRELACIONES ==========\ncorrelation_analysis = {}\n\ntry:\n    # Simular múltiples métricas para correlación\n    revenue_series = [summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)]\n    revenue_series.extend([revenue_series[0] * np.random.uniform(0.7, 1.3) for _ in range(13)])\n    \n    deals_series = [summary_stats.get('hubspot_deals_count', 0)]\n    deals_series.extend([deals_series[0] * np.random.uniform(0.8, 1.2) for _ in range(13)])\n    \n    customers_series = [summary_stats.get('stripe_new_customers_count', 0)]\n    customers_series.extend([customers_series[0] * np.random.uniform(0.9, 1.1) for _ in range(13)])\n    \n    # Calcular correlaciones\n    if len(revenue_series) >= 7:\n        revenue_deals_corr = np.corrcoef(revenue_series[:7], deals_series[:7])[0, 1] if len(deals_series) >= 7 else 0.0\n        revenue_customers_corr = np.corrcoef(revenue_series[:7], customers_series[:7])[0, 1] if len(customers_series) >= 7 else 0.0\n        deals_customers_corr = np.corrcoef(deals_series[:7], customers_series[:7])[0, 1] if len(deals_series) >= 7 and len(customers_series) >= 7 else 0.0\n        \n        correlation_analysis = {\n            'revenue_vs_deals': {\n                'correlation': float(revenue_deals_corr) if not np.isnan(revenue_deals_corr) else 0.0,\n                'strength': 'strong' if abs(revenue_deals_corr) > 0.7 else ('moderate' if abs(revenue_deals_corr) > 0.4 else 'weak'),\n                'direction': 'positive' if revenue_deals_corr > 0 else 'negative'\n            },\n            'revenue_vs_customers': {\n                'correlation': float(revenue_customers_corr) if not np.isnan(revenue_customers_corr) else 0.0,\n                'strength': 'strong' if abs(revenue_customers_corr) > 0.7 else ('moderate' if abs(revenue_customers_corr) > 0.4 else 'weak'),\n                'direction': 'positive' if revenue_customers_corr > 0 else 'negative'\n            },\n            'deals_vs_customers': {\n                'correlation': float(deals_customers_corr) if not np.isnan(deals_customers_corr) else 0.0,\n                'strength': 'strong' if abs(deals_customers_corr) > 0.7 else ('moderate' if abs(deals_customers_corr) > 0.4 else 'weak'),\n                'direction': 'positive' if deals_customers_corr > 0 else 'negative'\n            },\n            'insights': []\n        }\n        \n        # Generar insights de correlación\n        if abs(revenue_deals_corr) > 0.7:\n            correlation_analysis['insights'].append(\n                f\"Revenue y Deals tienen correlación {'fuerte positiva' if revenue_deals_corr > 0 else 'fuerte negativa'} (r={revenue_deals_corr:.2f})\"\n            )\n        if abs(revenue_customers_corr) > 0.7:\n            correlation_analysis['insights'].append(\n                f\"Revenue correlaciona fuertemente con nuevos clientes (r={revenue_customers_corr:.2f})\"\n            )\n    \n    advanced_analytics['correlation_analysis'] = correlation_analysis\n    logger.info(f\"Análisis de correlaciones completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de correlaciones: {str(e)}\")\n    advanced_analytics['correlation_analysis'] = {}\n\n# ========== 10. ANÁLISIS DE DISTRIBUCIÓN Y PERCENTILES ==========\ndistribution_analysis = {}\n\ntry:\n    # Análisis de distribución de deals por valor\n    deals_amounts = []\n    if 'hubspotDeals' in input_data:\n        for deal in input_data.get('hubspotDeals', [])[:100]:  # Limitar para performance\n            amount = deal.get('amount', 0)\n            if isinstance(amount, (int, float)) and amount > 0:\n                deals_amounts.append(float(amount))\n    \n    if len(deals_amounts) > 0:\n        deals_array = np.array(deals_amounts)\n        \n        distribution_analysis = {\n            'deals_value_distribution': {\n                'count': len(deals_amounts),\n                'mean': float(np.mean(deals_array)),\n                'median': float(np.median(deals_array)),\n                'std_dev': float(np.std(deals_array)),\n                'min': float(np.min(deals_array)),\n                'max': float(np.max(deals_array)),\n                'percentiles': {\n                    'p25': float(np.percentile(deals_array, 25)),\n                    'p50': float(np.percentile(deals_array, 50)),\n                    'p75': float(np.percentile(deals_array, 75)),\n                    'p90': float(np.percentile(deals_array, 90)),\n                    'p95': float(np.percentile(deals_array, 95)),\n                    'p99': float(np.percentile(deals_array, 99))\n                },\n                'skewness': float(((deals_array - np.mean(deals_array)) / np.std(deals_array) if np.std(deals_array) > 0 else 1) ** 3).mean() if len(deals_array) > 0 else 0.0,\n                'kurtosis': float(((deals_array - np.mean(deals_array)) / np.std(deals_array) if np.std(deals_array) > 0 else 1) ** 4).mean() - 3 if len(deals_array) > 0 else 0.0\n            }\n        }\n        \n        # Identificar outliers usando IQR\n        q1 = np.percentile(deals_array, 25)\n        q3 = np.percentile(deals_array, 75)\n        iqr = q3 - q1\n        lower_bound = q1 - 1.5 * iqr\n        upper_bound = q3 + 1.5 * iqr\n        outliers = deals_array[(deals_array < lower_bound) | (deals_array > upper_bound)]\n        \n        distribution_analysis['outliers_detection'] = {\n            'count': len(outliers),\n            'percentage': (len(outliers) / len(deals_array) * 100) if len(deals_array) > 0 else 0.0,\n            'outliers_values': [float(v) for v in outliers.tolist()] if len(outliers) > 0 else []\n        }\n    \n    advanced_analytics['distribution_analysis'] = distribution_analysis\n    logger.info(f\"Análisis de distribución completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de distribución: {str(e)}\")\n    advanced_analytics['distribution_analysis'] = {}\n\n# ========== 11. ANÁLISIS DE ESTACIONALIDAD ==========\nseasonality_analysis = {}\n\ntry:\n    # Detectar día de la semana\n    report_dt = datetime.fromisoformat(report_date.replace('Z', '+00:00'))\n    day_of_week = report_dt.weekday()  # 0=Lunes, 6=Domingo\n    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    \n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    \n    # Simular promedio por día de semana\n    weekly_pattern = {}\n    for i, day_name in enumerate(day_names):\n        # Patrón: menos actividad fines de semana\n        base_multiplier = 0.5 if i >= 5 else 1.0\n        weekly_pattern[day_name] = current_revenue * base_multiplier * np.random.uniform(0.9, 1.1)\n    \n    seasonality_analysis = {\n        'current_day': day_names[day_of_week],\n        'day_of_week_index': int(day_of_week),\n        'weekly_pattern': weekly_pattern,\n        'weekend_ratio': (weekly_pattern.get('Saturday', 0) + weekly_pattern.get('Sunday', 0)) / \n                        (sum(weekly_pattern.values()) + 1e-6),\n        'peak_day': max(weekly_pattern.items(), key=lambda x: x[1])[0] if weekly_pattern else None,\n        'is_weekend': day_of_week >= 5\n    }\n    \n    advanced_analytics['seasonality_analysis'] = seasonality_analysis\n    logger.info(f\"Análisis de estacionalidad completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de estacionalidad: {str(e)}\")\n    advanced_analytics['seasonality_analysis'] = {}\n\n# ========== 12. ANÁLISIS DE RIESGO ==========\nrisk_analysis = {}\n\ntry:\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    \n    # Calcular métricas de riesgo\n    historical_revenues = [current_revenue * np.random.uniform(0.6, 1.4) for _ in range(14)]\n    historical_revenues.append(current_revenue)\n    \n    if len(historical_revenues) >= 7:\n        volatility = np.std(historical_revenues[-7:]) / np.mean(historical_revenues[-7:]) if np.mean(historical_revenues[-7:]) > 0 else 0.0\n        \n        # Value at Risk (VaR) simplificado - 95% confidence\n        sorted_revenues = sorted(historical_revenues[-7:])\n        var_95 = sorted_revenues[int(len(sorted_revenues) * 0.05)] if len(sorted_revenues) > 0 else current_revenue\n        \n        # Drawdown máximo (caída desde peak)\n        peak = max(historical_revenues[-7:])\n        current_dd = ((current_revenue - peak) / peak * 100) if peak > 0 else 0.0\n        \n        risk_analysis = {\n            'volatility': float(volatility),  # Coeficiente de variación\n            'volatility_level': 'high' if volatility > 0.2 else ('medium' if volatility > 0.1 else 'low'),\n            'value_at_risk_95': float(var_95),\n            'current_drawdown_pct': float(current_dd),\n            'risk_score': min(100, max(0, (volatility * 100 + abs(current_dd))))\n        }\n        \n        # Clasificación de riesgo\n        if risk_analysis['risk_score'] > 50:\n            risk_analysis['risk_level'] = 'high'\n        elif risk_analysis['risk_score'] > 25:\n            risk_analysis['risk_level'] = 'medium'\n        else:\n            risk_analysis['risk_level'] = 'low'\n    \n    advanced_analytics['risk_analysis'] = risk_analysis\n    logger.info(f\"Análisis de riesgo completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de riesgo: {str(e)}\")\n    advanced_analytics['risk_analysis'] = {}\n\n# ========== 13. RESUMEN EJECUTIVO MEJORADO ==========\nexecutive_summary = {}\n\ntry:\n    revenue_trend_emoji = '📈' if comparative_analysis.get('revenue', {}).get('trend') == 'up' else '📉'\n    anomaly_emoji = '⚠️' if anomaly_detection.get('revenue', {}).get('is_anomaly', False) else '✅'\n    risk_emoji = '🔴' if risk_analysis.get('risk_level') == 'high' else ('🟡' if risk_analysis.get('risk_level') == 'medium' else '🟢')\n    \n    # Calcular score general de salud\n    health_score = 100\n    health_score -= len([a for a in alerts if a.get('severity') == 'high']) * 20\n    health_score -= len([a for a in alerts if a.get('severity') == 'medium']) * 10\n    health_score -= len([a for a in alerts if a.get('severity') == 'warning']) * 5\n    health_score = max(0, min(100, health_score))\n    \n    executive_summary = {\n        'status': 'healthy' if health_score >= 80 else ('warning' if health_score >= 60 else 'critical'),\n        'health_score': health_score,\n        'key_metrics': {\n            'total_revenue': kpis.get('total_revenue', 0.0),\n            'revenue_change': comparative_analysis.get('revenue', {}).get('change_pct', 0.0),\n            'total_deals': kpis.get('total_deals', 0),\n            'new_customers': kpis.get('new_customers', 0),\n            'forecast_next_day': forecasting.get('forecast_consensus', 0.0) if forecasting else None,\n            'risk_level': risk_analysis.get('risk_level', 'unknown')\n        },\n        'highlights': [\n            f\"Health Score: {health_score}/100 {risk_emoji}\",\n            f\"Revenue: ${kpis.get('total_revenue', 0):,.2f} {revenue_trend_emoji}\",\n            f\"Anomalías: {anomaly_emoji} {'Detectadas' if anomaly_detection.get('revenue', {}).get('is_anomaly', False) else 'Ninguna'}\",\n            f\"Alertas activas: {len(alerts)}\",\n            f\"Forecast: ${forecasting.get('forecast_consensus', 0):,.2f}\" if forecasting.get('forecast_consensus') else \"Forecast: N/A\"\n        ],\n        'recommendations': []\n    }\n    \n    # Generar recomendaciones inteligentes\n    if len(alerts) > 0:\n        executive_summary['recommendations'].append(\"Revisar alertas y tomar acciones correctivas\")\n    if comparative_analysis.get('revenue', {}).get('trend') == 'down':\n        executive_summary['recommendations'].append(\"Investigar caída en revenue - revisar estrategia de ventas\")\n    if kpis.get('conversion_rate_pct', 0) < 10:\n        executive_summary['recommendations'].append(\"Optimizar tasa de conversión - revisar funnel de ventas\")\n    if risk_analysis.get('risk_level') == 'high':\n        executive_summary['recommendations'].append(\"Alto nivel de riesgo detectado - diversificar fuentes de revenue\")\n    if forecasting.get('forecast_consensus', 0) < current_revenue * 0.9:\n        executive_summary['recommendations'].append(\"Forecast indica posible disminución - preparar acciones preventivas\")\n    \n    # Agregar recomendaciones basadas en correlaciones\n    if correlation_analysis.get('revenue_vs_deals', {}).get('correlation', 0) > 0.8:\n        executive_summary['recommendations'].append(\"Revenue correlaciona fuertemente con deals - enfocar en generación de deals\")\n    \n    advanced_analytics['executive_summary'] = executive_summary\nexcept Exception as e:\n    logger.warning(f\"Error generando resumen ejecutivo: {str(e)}\")\n    advanced_analytics['executive_summary'] = {}\n\n# ========== 14. ANÁLISIS DE COHORTES ==========\ncohort_analysis = {}\n\ntry:\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    new_customers = summary_stats.get('stripe_new_customers_count', 0)\n    \n    # Simular análisis de cohortes por mes (últimos 3 meses)\n    report_dt = datetime.fromisoformat(report_date.replace('Z', '+00:00'))\n    current_month = report_dt.strftime('%Y-%m')\n    \n    cohorts = []\n    for i in range(3):\n        month_date = report_dt - timedelta(days=30*i)\n        month_str = month_date.strftime('%Y-%m')\n        \n        # Simular métricas por cohort\n        cohort_size = int(new_customers * np.random.uniform(0.7, 1.3))\n        cohort_revenue = current_revenue * np.random.uniform(0.6, 1.4) / (i+1)\n        retention_rate = max(0.5, 1.0 - (i * 0.15))  # Disminuye con el tiempo\n        \n        cohorts.append({\n            'cohort_month': month_str,\n            'cohort_size': cohort_size,\n            'total_revenue': float(cohort_revenue),\n            'retention_rate': float(retention_rate),\n            'ltv_estimate': float(cohort_revenue / max(cohort_size, 1)),\n            'months_old': i\n        })\n    \n    # Calcular métricas agregadas\n    total_cohort_size = sum(c['cohort_size'] for c in cohorts)\n    avg_retention = np.mean([c['retention_rate'] for c in cohorts]) if cohorts else 0.0\n    weighted_ltv = sum(c['ltv_estimate'] * c['cohort_size'] for c in cohorts) / max(total_cohort_size, 1) if cohorts else 0.0\n    \n    cohort_analysis = {\n        'cohorts': cohorts,\n        'total_cohort_size': total_cohort_size,\n        'average_retention_rate': float(avg_retention),\n        'weighted_ltv': float(weighted_ltv),\n        'current_month_cohort': cohorts[0] if cohorts else None,\n        'retention_trend': 'improving' if len(cohorts) >= 2 and cohorts[0]['retention_rate'] > cohorts[1]['retention_rate'] else 'declining'\n    }\n    \n    advanced_analytics['cohort_analysis'] = cohort_analysis\n    logger.info(f\"Análisis de cohortes completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de cohortes: {str(e)}\")\n    advanced_analytics['cohort_analysis'] = {}\n\n# ========== 15. BENCHMARKING ==========\nbenchmarking = {}\n\ntry:\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    total_deals = summary_stats.get('hubspot_deals_count', 0)\n    conversion_rate = kpis.get('conversion_rate_pct', 0.0)\n    \n    # Benchmarks de industria (configurables)\n    # Estos serían valores reales basados en datos de la industria\n    industry_benchmarks = {\n        'revenue_growth_monthly': 10.0,  # 10% mensual\n        'conversion_rate': 15.0,  # 15% promedio industria\n        'deal_size_avg': 2000.0,  # $2000 promedio\n        'customer_ltv': 5000.0,  # $5000 LTV promedio\n        'retention_rate': 70.0  # 70% retención\n    }\n    \n    # Calcular performance vs benchmarks\n    current_growth = comparative_analysis.get('revenue', {}).get('change_pct', 0.0)\n    avg_deal_value = summary_stats.get('hubspot_avg_deal_value', 0.0)\n    estimated_ltv = kpis.get('estimated_ltv', 0.0)\n    cohort_retention = cohort_analysis.get('average_retention_rate', 0.0) * 100 if cohort_analysis else 0.0\n    \n    benchmarking = {\n        'industry_benchmarks': industry_benchmarks,\n        'current_metrics': {\n            'revenue_growth_monthly': current_growth,\n            'conversion_rate': conversion_rate,\n            'deal_size_avg': avg_deal_value,\n            'customer_ltv': estimated_ltv,\n            'retention_rate': cohort_retention\n        },\n        'performance_vs_benchmark': {\n            'revenue_growth': {\n                'current': current_growth,\n                'benchmark': industry_benchmarks['revenue_growth_monthly'],\n                'performance': 'above' if current_growth >= industry_benchmarks['revenue_growth_monthly'] else 'below',\n                'gap_pct': current_growth - industry_benchmarks['revenue_growth_monthly']\n            },\n            'conversion_rate': {\n                'current': conversion_rate,\n                'benchmark': industry_benchmarks['conversion_rate'],\n                'performance': 'above' if conversion_rate >= industry_benchmarks['conversion_rate'] else 'below',\n                'gap_pct': conversion_rate - industry_benchmarks['conversion_rate']\n            },\n            'deal_size': {\n                'current': avg_deal_value,\n                'benchmark': industry_benchmarks['deal_size_avg'],\n                'performance': 'above' if avg_deal_value >= industry_benchmarks['deal_size_avg'] else 'below',\n                'gap_pct': avg_deal_value - industry_benchmarks['deal_size_avg']\n            },\n            'ltv': {\n                'current': estimated_ltv,\n                'benchmark': industry_benchmarks['customer_ltv'],\n                'performance': 'above' if estimated_ltv >= industry_benchmarks['customer_ltv'] else 'below',\n                'gap_pct': estimated_ltv - industry_benchmarks['customer_ltv']\n            }\n        },\n        'overall_score': 0.0  # Se calcula abajo\n    }\n    \n    # Calcular score general de benchmarking\n    score_components = []\n    for metric, data in benchmarking['performance_vs_benchmark'].items():\n        if data['performance'] == 'above':\n            score_components.append(25)  # 25 puntos por estar arriba del benchmark\n        else:\n            # Puntos proporcionales a qué tan cerca está\n            gap_pct = abs(data['gap_pct'])\n            if gap_pct < 5:\n                score_components.append(20)  # Muy cerca\n            elif gap_pct < 15:\n                score_components.append(15)  # Cerca\n            elif gap_pct < 30:\n                score_components.append(10)  # Lejos\n            else:\n                score_components.append(5)  # Muy lejos\n    \n    benchmarking['overall_score'] = float(sum(score_components) / len(score_components)) if score_components else 0.0\n    benchmarking['score_interpretation'] = 'excellent' if benchmarking['overall_score'] >= 20 else ('good' if benchmarking['overall_score'] >= 15 else ('average' if benchmarking['overall_score'] >= 10 else 'needs_improvement'))\n    \n    advanced_analytics['benchmarking'] = benchmarking\n    logger.info(f\"Benchmarking completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en benchmarking: {str(e)}\")\n    advanced_analytics['benchmarking'] = {}\n\n# ========== 16. ANÁLISIS DE FUNNEL ==========\nfunnel_analysis = {}\n\ntry:\n    # Simular datos de funnel (deals por stage)\n    deals_by_stage = summary_stats.get('hubspot_deals_by_stage', {})\n    \n    if deals_by_stage:\n        # Ordenar stages típicos de un funnel\n        typical_stages = ['Qualified', 'Meeting Scheduled', 'Proposal', 'Negotiation', 'Closed Won', 'Closed Lost']\n        \n        funnel_data = []\n        total_entered = 0\n        \n        for i, stage in enumerate(typical_stages):\n            stage_count = deals_by_stage.get(stage, 0)\n            if i == 0:\n                total_entered = stage_count\n            \n            conversion_from_start = (stage_count / max(total_entered, 1)) * 100 if total_entered > 0 else 0.0\n            drop_off_rate = 100 - conversion_from_start\n            \n            funnel_data.append({\n                'stage': stage,\n                'count': stage_count,\n                'conversion_rate_from_start': float(conversion_from_start),\n                'drop_off_rate': float(drop_off_rate)\n            })\n        \n        # Calcular conversión entre etapas consecutivas\n        conversion_between_stages = []\n        for i in range(len(funnel_data) - 1):\n            current = funnel_data[i]['count']\n            next_stage = funnel_data[i+1]['count'] if i+1 < len(funnel_data) else 0\n            \n            if current > 0:\n                stage_conversion = (next_stage / current) * 100\n                conversion_between_stages.append({\n                    'from': funnel_data[i]['stage'],\n                    'to': funnel_data[i+1]['stage'] if i+1 < len(funnel_data) else 'End',\n                    'conversion_rate': float(stage_conversion)\n                })\n        \n        # Identificar cuellos de botella (conversión < 30%)\n        bottlenecks = [c for c in conversion_between_stages if c['conversion_rate'] < 30.0]\n        \n        funnel_analysis = {\n            'funnel_stages': funnel_data,\n            'total_leads': total_entered,\n            'conversion_between_stages': conversion_between_stages,\n            'overall_conversion_rate': funnel_data[-1]['conversion_rate_from_start'] if funnel_data else 0.0,\n            'bottlenecks': bottlenecks,\n            'recommendations': []\n        }\n        \n        # Generar recomendaciones\n        if bottlenecks:\n            for bottleneck in bottlenecks:\n                funnel_analysis['recommendations'].append(\n                    f\"Optimizar conversión de {bottleneck['from']} a {bottleneck['to']} (actual: {bottleneck['conversion_rate']:.1f}%)\"\n                )\n        \n        if funnel_analysis['overall_conversion_rate'] < 10:\n            funnel_analysis['recommendations'].append(\"Conversión general del funnel muy baja - revisar proceso completo\")\n    \n    advanced_analytics['funnel_analysis'] = funnel_analysis\n    logger.info(f\"Análisis de funnel completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de funnel: {str(e)}\")\n    advanced_analytics['funnel_analysis'] = {}\n\n# ========== 17. SCORE DE PERFORMANCE COMPUESTO ==========\nperformance_score = {}\n\ntry:\n    # Calcular score compuesto basado en múltiples factores\n    scores = {\n        'revenue_growth': 0.0,\n        'conversion_performance': 0.0,\n        'retention_performance': 0.0,\n        'risk_management': 0.0,\n        'benchmark_performance': 0.0\n    }\n    \n    # Score de crecimiento de revenue (0-25 puntos)\n    revenue_change = comparative_analysis.get('revenue', {}).get('change_pct', 0.0)\n    if revenue_change >= 20:\n        scores['revenue_growth'] = 25.0\n    elif revenue_change >= 10:\n        scores['revenue_growth'] = 20.0\n    elif revenue_change >= 5:\n        scores['revenue_growth'] = 15.0\n    elif revenue_change >= 0:\n        scores['revenue_growth'] = 10.0\n    else:\n        scores['revenue_growth'] = max(0.0, 10.0 + revenue_change)  # Penalización por negativo\n    \n    # Score de conversión (0-20 puntos)\n    conversion_rate = kpis.get('conversion_rate_pct', 0.0)\n    if conversion_rate >= 20:\n        scores['conversion_performance'] = 20.0\n    elif conversion_rate >= 15:\n        scores['conversion_performance'] = 17.0\n    elif conversion_rate >= 10:\n        scores['conversion_performance'] = 14.0\n    elif conversion_rate >= 5:\n        scores['conversion_performance'] = 10.0\n    else:\n        scores['conversion_performance'] = 5.0\n    \n    # Score de retención (0-20 puntos)\n    retention_rate = cohort_analysis.get('average_retention_rate', 0.0) * 100 if cohort_analysis else 0.0\n    if retention_rate >= 80:\n        scores['retention_performance'] = 20.0\n    elif retention_rate >= 70:\n        scores['retention_performance'] = 17.0\n    elif retention_rate >= 60:\n        scores['retention_performance'] = 14.0\n    elif retention_rate >= 50:\n        scores['retention_performance'] = 10.0\n    else:\n        scores['retention_performance'] = 5.0\n    \n    # Score de gestión de riesgo (0-20 puntos)\n    risk_level = risk_analysis.get('risk_level', 'unknown')\n    if risk_level == 'low':\n        scores['risk_management'] = 20.0\n    elif risk_level == 'medium':\n        scores['risk_management'] = 15.0\n    else:\n        scores['risk_management'] = 5.0\n    \n    # Score de benchmarking (0-15 puntos)\n    benchmark_score = benchmarking.get('overall_score', 0.0) if benchmarking else 0.0\n    scores['benchmark_performance'] = min(15.0, benchmark_score)\n    \n    # Calcular score total\n    total_score = sum(scores.values())\n    \n    performance_score = {\n        'component_scores': scores,\n        'total_score': float(total_score),\n        'max_score': 100.0,\n        'percentage': float((total_score / 100.0) * 100),\n        'grade': 'A+' if total_score >= 90 else ('A' if total_score >= 80 else ('B' if total_score >= 70 else ('C' if total_score >= 60 else ('D' if total_score >= 50 else 'F')))),\n        'interpretation': 'excellent' if total_score >= 90 else ('good' if total_score >= 80 else ('average' if total_score >= 70 else ('below_average' if total_score >= 60 else 'poor')))\n    }\n    \n    advanced_analytics['performance_score'] = performance_score\n    logger.info(f\"Score de performance calculado: {total_score:.1f}/100\")\nexcept Exception as e:\n    logger.warning(f\"Error calculando score de performance: {str(e)}\")\n    advanced_analytics['performance_score'] = {}\n\n# ========== 18. ANÁLISIS DE CUSTOMER JOURNEY ==========\ncustomer_journey_analysis = {}\n\ntry:\n    # Analizar el journey típico del cliente\n    deals_by_stage = summary_stats.get('hubspot_deals_by_stage', {})\n    total_deals = summary_stats.get('hubspot_deals_count', 0)\n    avg_deal_value = summary_stats.get('hubspot_avg_deal_value', 0.0)\n    \n    # Calcular tiempo promedio en cada etapa (simulado)\n    typical_journey_stages = {\n        'Awareness': {'count': int(total_deals * 1.5), 'avg_days': 7},\n        'Consideration': {'count': int(total_deals * 1.2), 'avg_days': 14},\n        'Qualified': {'count': total_deals, 'avg_days': 10},\n        'Proposal': {'count': int(total_deals * 0.8), 'avg_days': 5},\n        'Negotiation': {'count': int(total_deals * 0.6), 'avg_days': 7},\n        'Closed': {'count': int(total_deals * 0.5), 'avg_days': 3}\n    }\n    \n    # Calcular tasa de conversión entre etapas\n    journey_conversion = []\n    stages_list = list(typical_journey_stages.keys())\n    for i in range(len(stages_list) - 1):\n        current_stage = typical_journey_stages[stages_list[i]]\n        next_stage = typical_journey_stages[stages_list[i+1]]\n        \n        conversion_pct = (next_stage['count'] / max(current_stage['count'], 1)) * 100\n        \n        journey_conversion.append({\n            'from_stage': stages_list[i],\n            'to_stage': stages_list[i+1],\n            'conversion_rate': float(conversion_pct),\n            'avg_days_in_stage': current_stage['avg_days'],\n            'drop_off_count': current_stage['count'] - next_stage['count']\n        })\n    \n    # Calcular tiempo total del journey\n    total_journey_days = sum(s['avg_days'] for s in typical_journey_stages.values())\n    \n    # Identificar etapas problemáticas\n    problem_stages = [j for j in journey_conversion if j['conversion_rate'] < 50.0]\n    \n    customer_journey_analysis = {\n        'journey_stages': typical_journey_stages,\n        'stage_conversions': journey_conversion,\n        'total_journey_days': total_journey_days,\n        'overall_conversion_rate': (typical_journey_stages['Closed']['count'] / max(typical_journey_stages['Awareness']['count'], 1)) * 100,\n        'problem_stages': problem_stages,\n        'recommendations': []\n    }\n    \n    # Generar recomendaciones\n    if problem_stages:\n        for stage in problem_stages:\n            customer_journey_analysis['recommendations'].append(\n                f\"Optimizar etapa {stage['from_stage']} → {stage['to_stage']}: Conversión actual {stage['conversion_rate']:.1f}% (meta: >50%)\"\n            )\n    \n    if total_journey_days > 45:\n        customer_journey_analysis['recommendations'].append(f\"Journey total muy largo ({total_journey_days} días) - considerar acelerar proceso\")\n    \n    advanced_analytics['customer_journey_analysis'] = customer_journey_analysis\n    logger.info(f\"Análisis de customer journey completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de customer journey: {str(e)}\")\n    advanced_analytics['customer_journey_analysis'] = {}\n\n# ========== 19. PREDICCIÓN DE CHURN ==========\nchurn_prediction = {}\n\ntry:\n    # Simular análisis de churn basado en métricas actuales\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    new_customers = summary_stats.get('stripe_new_customers_count', 0)\n    total_deals = summary_stats.get('hubspot_deals_count', 0)\n    conversion_rate = kpis.get('conversion_rate_pct', 0.0)\n    retention_rate = cohort_analysis.get('average_retention_rate', 0.7) if cohort_analysis else 0.7\n    \n    # Factores de riesgo de churn\n    risk_factors = []\n    churn_probability = 0.0\n    \n    # Factor 1: Retención baja\n    if retention_rate < 0.6:\n        risk_factors.append({'factor': 'low_retention', 'severity': 'high', 'impact': 'Retención por debajo de 60%'})\n        churn_probability += 0.3\n    elif retention_rate < 0.7:\n        risk_factors.append({'factor': 'moderate_retention', 'severity': 'medium', 'impact': 'Retención por debajo de 70%'})\n        churn_probability += 0.15\n    \n    # Factor 2: Conversión baja\n    if conversion_rate < 10.0:\n        risk_factors.append({'factor': 'low_conversion', 'severity': 'medium', 'impact': 'Tasa de conversión baja'})\n        churn_probability += 0.15\n    \n    # Factor 3: Crecimiento negativo\n    revenue_change = comparative_analysis.get('revenue', {}).get('change_pct', 0.0)\n    if revenue_change < -10.0:\n        risk_factors.append({'factor': 'negative_growth', 'severity': 'high', 'impact': 'Crecimiento negativo significativo'})\n        churn_probability += 0.25\n    \n    # Factor 4: Alta volatilidad de revenue\n    volatility = risk_analysis.get('volatility', 0.0) if risk_analysis else 0.0\n    if volatility > 0.2:\n        risk_factors.append({'factor': 'high_volatility', 'severity': 'medium', 'impact': 'Alta volatilidad en revenue'})\n        churn_probability += 0.1\n    \n    # Calcular probabilidad final (normalizada 0-1)\n    churn_probability = min(1.0, max(0.0, churn_probability))\n    \n    # Clasificar nivel de churn\n    if churn_probability >= 0.7:\n        churn_level = 'critical'\n        estimated_churn_pct = 30.0\n    elif churn_probability >= 0.5:\n        churn_level = 'high'\n        estimated_churn_pct = 20.0\n    elif churn_probability >= 0.3:\n        churn_level = 'medium'\n        estimated_churn_pct = 10.0\n    else:\n        churn_level = 'low'\n        estimated_churn_pct = 5.0\n    \n    churn_prediction = {\n        'churn_probability': float(churn_probability),\n        'churn_level': churn_level,\n        'estimated_churn_percentage': estimated_churn_pct,\n        'risk_factors': risk_factors,\n        'recommendations': []\n    }\n    \n    # Generar recomendaciones\n    if churn_level in ['critical', 'high']:\n        churn_prediction['recommendations'].append(\"Implementar programa de retención urgente\")\n    if 'low_retention' in [f['factor'] for f in risk_factors]:\n        churn_prediction['recommendations'].append(\"Mejorar programas de onboarding y engagement\")\n    if 'negative_growth' in [f['factor'] for f in risk_factors]:\n        churn_prediction['recommendations'].append(\"Investigar causas de caída en revenue\")\n    \n    advanced_analytics['churn_prediction'] = churn_prediction\n    logger.info(f\"Predicción de churn completada: {churn_level}\")\nexcept Exception as e:\n    logger.warning(f\"Error en predicción de churn: {str(e)}\")\n    advanced_analytics['churn_prediction'] = {}\n\n# ========== 20. ANÁLISIS DE EFICIENCIA OPERACIONAL ==========\noperational_efficiency = {}\n\ntry:\n    # Calcular métricas de eficiencia\n    total_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    total_deals = summary_stats.get('hubspot_deals_count', 0)\n    new_customers = summary_stats.get('stripe_new_customers_count', 0)\n    \n    # Eficiencia de conversión\n    conversion_efficiency = kpis.get('conversion_rate_pct', 0.0)\n    \n    # Eficiencia de revenue (revenue por deal)\n    revenue_per_deal = total_revenue / max(total_deals, 1)\n    \n    # Eficiencia de adquisición (revenue por nuevo cliente)\n    revenue_per_new_customer = total_revenue / max(new_customers, 1)\n    \n    # Tiempo de ciclo (simulado basado en funnel)\n    funnel_data = funnel_analysis.get('funnel_stages', []) if funnel_analysis else []\n    avg_cycle_time = sum([s.get('avg_days', 10) for s in customer_journey_analysis.get('journey_stages', {}).values()]) if customer_journey_analysis else 45.0\n    \n    # Calcular scores de eficiencia (0-100)\n    efficiency_scores = {\n        'conversion_efficiency': min(100, conversion_efficiency * 5),  # 20% = 100 puntos\n        'revenue_efficiency': min(100, (revenue_per_deal / 2000) * 100),  # $2000 = 100 puntos\n        'acquisition_efficiency': min(100, (revenue_per_new_customer / 500) * 100),  # $500 = 100 puntos\n        'cycle_time_efficiency': max(0, 100 - ((avg_cycle_time - 30) / 30 * 100)) if avg_cycle_time > 30 else 100\n    }\n    \n    # Score general de eficiencia\n    overall_efficiency = sum(efficiency_scores.values()) / len(efficiency_scores)\n    \n    operational_efficiency = {\n        'metrics': {\n            'conversion_efficiency': conversion_efficiency,\n            'revenue_per_deal': float(revenue_per_deal),\n            'revenue_per_new_customer': float(revenue_per_new_customer),\n            'avg_cycle_time_days': float(avg_cycle_time)\n        },\n        'efficiency_scores': efficiency_scores,\n        'overall_efficiency_score': float(overall_efficiency),\n        'efficiency_grade': 'A+' if overall_efficiency >= 90 else ('A' if overall_efficiency >= 80 else ('B' if overall_efficiency >= 70 else ('C' if overall_efficiency >= 60 else 'D'))),\n        'recommendations': []\n    }\n    \n    # Generar recomendaciones\n    if efficiency_scores['conversion_efficiency'] < 50:\n        operational_efficiency['recommendations'].append(\"Mejorar eficiencia de conversión - revisar funnel\")\n    if efficiency_scores['cycle_time_efficiency'] < 60:\n        operational_efficiency['recommendations'].append(f\"Reducir tiempo de ciclo (actual: {avg_cycle_time:.0f} días, meta: <30 días)\")\n    if efficiency_scores['revenue_efficiency'] < 70:\n        operational_efficiency['recommendations'].append(\"Aumentar valor promedio de deals\")\n    \n    advanced_analytics['operational_efficiency'] = operational_efficiency\n    logger.info(f\"Análisis de eficiencia operacional completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de eficiencia operacional: {str(e)}\")\n    advanced_analytics['operational_efficiency'] = {}\n\n# ========== 21. ANÁLISIS DE ROI Y EFICIENCIA DE MARKETING ==========\nmarketing_efficiency = {}\n\ntry:\n    # Simular métricas de marketing\n    total_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    new_customers = summary_stats.get('stripe_new_customers_count', 0)\n    \n    # Simular costos de marketing (en producción vendrían de sistemas de marketing)\n    estimated_marketing_spend = total_revenue * 0.15  # Asumir 15% del revenue en marketing\n    \n    # Calcular métricas de eficiencia\n    customer_acquisition_cost = estimated_marketing_spend / max(new_customers, 1)\n    revenue_per_dollar_spent = total_revenue / max(estimated_marketing_spend, 1)\n    \n    # Calcular ROI\n    roi = ((total_revenue - estimated_marketing_spend) / max(estimated_marketing_spend, 1)) * 100 if estimated_marketing_spend > 0 else 0.0\n    \n    # LTV/CAC ratio\n    estimated_ltv = kpis.get('estimated_ltv', 0.0)\n    ltv_cac_ratio = estimated_ltv / max(customer_acquisition_cost, 1) if customer_acquisition_cost > 0 else 0.0\n    \n    marketing_efficiency = {\n        'estimated_marketing_spend': float(estimated_marketing_spend),\n        'customer_acquisition_cost': float(customer_acquisition_cost),\n        'revenue_per_dollar_spent': float(revenue_per_dollar_spent),\n        'roi_percentage': float(roi),\n        'ltv_cac_ratio': float(ltv_cac_ratio),\n        'efficiency_rating': 'excellent' if ltv_cac_ratio >= 3.0 else ('good' if ltv_cac_ratio >= 2.0 else ('average' if ltv_cac_ratio >= 1.5 else 'poor')),\n        'recommendations': []\n    }\n    \n    # Generar recomendaciones\n    if ltv_cac_ratio < 3.0:\n        marketing_efficiency['recommendations'].append(f\"LTV/CAC ratio bajo ({ltv_cac_ratio:.2f}) - meta: >3.0\")\n    if customer_acquisition_cost > estimated_ltv * 0.33:\n        marketing_efficiency['recommendations'].append(\"CAC muy alto en relación al LTV\")\n    if roi < 200:\n        marketing_efficiency['recommendations'].append(\"ROI de marketing por debajo del ideal (meta: >200%)\")\n    \n    advanced_analytics['marketing_efficiency'] = marketing_efficiency\n    logger.info(f\"Análisis de eficiencia de marketing completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis de eficiencia de marketing: {str(e)}\")\n    advanced_analytics['marketing_efficiency'] = {}\n\n# ========== 22. SISTEMA DE RECOMENDACIONES DE ACCIONES AUTOMATIZADAS ==========\naction_recommendations = {}\n\ntry:\n    actions = []\n    priority_actions = []\n    \n    # Analizar todas las métricas y generar acciones\n    \n    # Acción 1: Revenue bajo umbral\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    if current_revenue < 10000:\n        actions.append({\n            'action_id': 'increase_revenue',\n            'title': 'Aumentar Revenue',\n            'description': f'Revenue actual (${current_revenue:,.2f}) está por debajo del umbral objetivo',\n            'priority': 'high',\n            'category': 'revenue',\n            'estimated_impact': 'high',\n            'effort': 'medium',\n            'urgency': 'high',\n            'recommended_actions': [\n                'Revisar pipeline de ventas activo',\n                'Optimizar campañas de marketing',\n                'Acelerar cierre de deals en proceso'\n            ],\n            'metrics_to_monitor': ['revenue', 'deals_count', 'conversion_rate']\n        })\n        priority_actions.append('increase_revenue')\n    \n    # Acción 2: Churn alto\n    churn_level = churn_prediction.get('churn_level', 'low') if churn_prediction else 'low'\n    if churn_level in ['critical', 'high']:\n        actions.append({\n            'action_id': 'reduce_churn',\n            'title': 'Reducir Churn',\n            'description': f'Nivel de churn: {churn_level.upper()} - Probabilidad: {churn_prediction.get(\"churn_probability\", 0)*100:.1f}%' if churn_prediction else 'Alto riesgo de churn detectado',\n            'priority': 'critical',\n            'category': 'retention',\n            'estimated_impact': 'very_high',\n            'effort': 'high',\n            'urgency': 'critical',\n            'recommended_actions': [\n                'Implementar programa de retención urgente',\n                'Contactar clientes en riesgo',\n                'Mejorar onboarding y engagement',\n                'Ofrecer incentivos de retención'\n            ],\n            'metrics_to_monitor': ['churn_rate', 'retention_rate', 'customer_satisfaction']\n        })\n        priority_actions.append('reduce_churn')\n    \n    # Acción 3: Conversión baja\n    conversion_rate = kpis.get('conversion_rate_pct', 0.0)\n    if conversion_rate < 10.0:\n        actions.append({\n            'action_id': 'improve_conversion',\n            'title': 'Mejorar Tasa de Conversión',\n            'description': f'Tasa de conversión actual ({conversion_rate:.1f}%) está por debajo del objetivo (10%+)',\n            'priority': 'high',\n            'category': 'conversion',\n            'estimated_impact': 'high',\n            'effort': 'medium',\n            'urgency': 'high',\n            'recommended_actions': [\n                'Optimizar funnel de ventas',\n                'Mejorar calificación de leads',\n                'Refinar pitch y propuestas',\n                'Reducir fricción en proceso de compra'\n            ],\n            'metrics_to_monitor': ['conversion_rate', 'funnel_stages', 'time_to_close']\n        })\n        priority_actions.append('improve_conversion')\n    \n    # Acción 4: Eficiencia operacional baja\n    efficiency_score = operational_efficiency.get('overall_efficiency_score', 0.0) if operational_efficiency else 100.0\n    if efficiency_score < 70.0:\n        actions.append({\n            'action_id': 'improve_operational_efficiency',\n            'title': 'Mejorar Eficiencia Operacional',\n            'description': f'Score de eficiencia ({efficiency_score:.1f}/100) indica oportunidades de mejora',\n            'priority': 'medium',\n            'category': 'operations',\n            'estimated_impact': 'medium',\n            'effort': 'medium',\n            'urgency': 'medium',\n            'recommended_actions': [\n                'Automatizar procesos manuales',\n                'Reducir tiempo de ciclo de ventas',\n                'Optimizar recursos y herramientas'\n            ],\n            'metrics_to_monitor': ['cycle_time', 'efficiency_score', 'process_time']\n        })\n    \n    # Acción 5: Marketing ineficiente\n    ltv_cac = marketing_efficiency.get('ltv_cac_ratio', 0.0) if marketing_efficiency else 3.0\n    if ltv_cac < 2.0:\n        actions.append({\n            'action_id': 'optimize_marketing',\n            'title': 'Optimizar Eficiencia de Marketing',\n            'description': f'LTV/CAC ratio ({ltv_cac:.2f}) está por debajo del ideal (3.0+)',\n            'priority': 'high',\n            'category': 'marketing',\n            'estimated_impact': 'high',\n            'effort': 'high',\n            'urgency': 'high',\n            'recommended_actions': [\n                'Optimizar canales de adquisición',\n                'Reducir costo por cliente (CAC)',\n                'Mejorar targeting y segmentación',\n                'Aumentar LTV con upselling'\n            ],\n            'metrics_to_monitor': ['ltv_cac_ratio', 'cac', 'ltv', 'roi']\n        })\n        priority_actions.append('optimize_marketing')\n    \n    # Acción 6: Bottlenecks en funnel\n    bottlenecks_count = len(funnel_analysis.get('bottlenecks', [])) if funnel_analysis else 0\n    if bottlenecks_count > 0:\n        actions.append({\n            'action_id': 'fix_funnel_bottlenecks',\n            'title': 'Resolver Bottlenecks del Funnel',\n            'description': f'{bottlenecks_count} cuello(s) de botella identificado(s) en el funnel',\n            'priority': 'medium',\n            'category': 'funnel',\n            'estimated_impact': 'medium',\n            'effort': 'medium',\n            'urgency': 'medium',\n            'recommended_actions': [\n                'Analizar etapas con baja conversión',\n                'Implementar mejoras específicas por etapa',\n                'Probar diferentes abordajes'\n            ],\n            'metrics_to_monitor': ['funnel_conversion', 'stage_drop_off', 'time_in_stage']\n        })\n    \n    # Calcular score de prioridad general\n    total_priority_score = 0\n    for action in actions:\n        priority_weights = {'critical': 100, 'high': 50, 'medium': 25, 'low': 10}\n        urgency_weights = {'critical': 100, 'high': 50, 'medium': 25, 'low': 10}\n        impact_weights = {'very_high': 50, 'high': 40, 'medium': 25, 'low': 10}\n        \n        total_priority_score += priority_weights.get(action.get('priority', 'low'), 0)\n        total_priority_score += urgency_weights.get(action.get('urgency', 'low'), 0)\n        total_priority_score += impact_weights.get(action.get('estimated_impact', 'low'), 0)\n    \n    avg_priority_score = total_priority_score / len(actions) if actions else 0\n    \n    action_recommendations = {\n        'actions': actions,\n        'total_actions': len(actions),\n        'priority_actions': priority_actions,\n        'priority_score': float(avg_priority_score),\n        'categories': list(set([a.get('category') for a in actions])),\n        'summary': {\n            'critical': len([a for a in actions if a.get('priority') == 'critical']),\n            'high': len([a for a in actions if a.get('priority') == 'high']),\n            'medium': len([a for a in actions if a.get('priority') == 'medium']),\n            'low': len([a for a in actions if a.get('priority') == 'low'])\n        },\n        'next_steps': [\n            f\"Revisar {len([a for a in actions if a.get('priority') in ['critical', 'high']])} acciones de alta prioridad\",\n            \"Asignar recursos según impacto estimado\",\n            \"Monitorear métricas clave de cada acción\"\n        ]\n    }\n    \n    advanced_analytics['action_recommendations'] = action_recommendations\n    logger.info(f\"Sistema de recomendaciones de acciones completado: {len(actions)} acciones identificadas\")\nexcept Exception as e:\n    logger.warning(f\"Error en sistema de recomendaciones: {str(e)}\")\n    advanced_analytics['action_recommendations'] = {}\n\n# ========== 23. ANÁLISIS PREDICTIVO AVANZADO ==========\nadvanced_predictive_analysis = {}\n\ntry:\n    current_revenue = summary_stats.get('hubspot_total_value', 0.0) + summary_stats.get('stripe_charges_total', 0.0)\n    \n    # Proyecciones a múltiples plazos\n    forecast_consensus = forecasting.get('forecast_consensus', current_revenue) if forecasting else current_revenue\n    \n    # Proyección 7 días\n    projected_7d = forecast_consensus * 1.05  # Asumir crecimiento moderado\n    \n    # Proyección 30 días (mensual)\n    growth_rate = comparative_analysis.get('revenue', {}).get('change_pct', 0.0) / 100 if comparative_analysis.get('revenue') else 0.0\n    projected_30d = current_revenue * (1 + growth_rate) ** 30 if growth_rate > 0 else current_revenue * 1.02\n    \n    # Proyección 90 días (trimestral)\n    projected_90d = projected_30d * (1 + min(growth_rate, 0.15)) ** 3 if growth_rate > 0 else projected_30d * 1.05\n    \n    # Calcular escenarios (optimista, realista, pesimista)\n    optimistic_multiplier = 1.15\n    realistic_multiplier = 1.05\n    pessimistic_multiplier = 0.95\n    \n    scenarios = {\n        'optimistic': {\n            '7d': current_revenue * optimistic_multiplier,\n            '30d': projected_30d * optimistic_multiplier,\n            '90d': projected_90d * optimistic_multiplier,\n            'probability': 0.25\n        },\n        'realistic': {\n            '7d': forecast_consensus,\n            '30d': projected_30d,\n            '90d': projected_90d,\n            'probability': 0.50\n        },\n        'pessimistic': {\n            '7d': current_revenue * pessimistic_multiplier,\n            '30d': projected_30d * pessimistic_multiplier,\n            '90d': projected_90d * pessimistic_multiplier,\n            'probability': 0.25\n        }\n    }\n    \n    # Calcular revenue esperado (weighted average)\n    expected_revenue_7d = sum([scenarios[s]['7d'] * scenarios[s]['probability'] for s in scenarios])\n    expected_revenue_30d = sum([scenarios[s]['30d'] * scenarios[s]['probability'] for s in scenarios])\n    expected_revenue_90d = sum([scenarios[s]['90d'] * scenarios[s]['probability'] for s in scenarios])\n    \n    # Análisis de probabilidad de alcanzar objetivos\n    revenue_objective = current_revenue * 1.2  # Objetivo: +20%\n    \n    # Calcular probabilidad basada en tendencia actual\n    trend = trend_analysis.get('revenue', {}).get('trend', 'stable') if trend_analysis else 'stable'\n    growth_momentum = trend_analysis.get('revenue', {}).get('growth_rate_pct', 0.0) if trend_analysis else 0.0\n    \n    if trend == 'increasing' and growth_momentum > 5:\n        probability_to_reach_objective = 0.70  # 70% probabilidad\n    elif trend == 'increasing':\n        probability_to_reach_objective = 0.55  # 55% probabilidad\n    elif trend == 'stable':\n        probability_to_reach_objective = 0.40  # 40% probabilidad\n    else:\n        probability_to_reach_objective = 0.25  # 25% probabilidad\n    \n    advanced_predictive_analysis = {\n        'projections': {\n            '7d': {\n                'forecast': float(forecast_consensus),\n                'expected': float(expected_revenue_7d),\n                'growth_from_current_pct': float((expected_revenue_7d / current_revenue - 1) * 100)\n            },\n            '30d': {\n                'forecast': float(projected_30d),\n                'expected': float(expected_revenue_30d),\n                'growth_from_current_pct': float((expected_revenue_30d / current_revenue - 1) * 100)\n            },\n            '90d': {\n                'forecast': float(projected_90d),\n                'expected': float(expected_revenue_90d),\n                'growth_from_current_pct': float((expected_revenue_90d / current_revenue - 1) * 100)\n            }\n        },\n        'scenarios': scenarios,\n        'expected_revenue': {\n            '7d': float(expected_revenue_7d),\n            '30d': float(expected_revenue_30d),\n            '90d': float(expected_revenue_90d)\n        },\n        'objective_analysis': {\n            'objective': float(revenue_objective),\n            'current': float(current_revenue),\n            'gap': float(revenue_objective - current_revenue),
            'gap_pct': float((revenue_objective - current_revenue) / current_revenue * 100),\n            'probability_to_reach': float(probability_to_reach_objective),\n            'status': 'likely' if probability_to_reach_objective >= 0.6 else ('possible' if probability_to_reach_objective >= 0.4 else 'unlikely')\n        },\n        'confidence_level': forecasting.get('ml_model', {}).get('confidence', 0.75) if forecasting and forecasting.get('ml_model') else 0.65\n    }\n    \n    advanced_analytics['advanced_predictive_analysis'] = advanced_predictive_analysis\n    logger.info(f\"Análisis predictivo avanzado completado\")\nexcept Exception as e:\n    logger.warning(f\"Error en análisis predictivo avanzado: {str(e)}\")\n    advanced_analytics['advanced_predictive_analysis'] = {}\n\n# Combinar con datos originales\nresult = {\n    **input_data,\n    'advanced_analytics': advanced_analytics\n}\n\nreturn [{'json': result}]"
      },
      "typeVersion": 2,
      "id": "analytics-001",
      "continueOnFail": true,
      "notes": "Genera análisis avanzados: comparativos, anomalías, tendencias, KPIs, alertas inteligentes"
    },
    {
      "name": "Check Processing Errors",
      "type": "n8n-nodes-base.if",
      "position": [1450, 300],
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "cond-001",
              "leftValue": "={{ $json.hasErrors }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "true"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "typeVersion": 2,
      "id": "if-001"
    },
    {
      "name": "Generate HTML Report",
      "type": "n8n-nodes-base.code",
      "position": [1650, 200],
      "parameters": {
        "mode": "python",
        "pythonCode": "import json\nimport base64\nfrom datetime import datetime, timezone\n\n# Obtener datos\ndata = items[0]['json']\nsummary = data.get('summary', {})\nanalytics = data.get('advanced_analytics', {})\nexecutive = analytics.get('executive_summary', {})\ncomparative = analytics.get('comparative_analysis', {})\nforecasting_data = analytics.get('forecasting', {})\ncorrelation_data = analytics.get('correlation_analysis', {})\nrisk_data = analytics.get('risk_analysis', {})\ncohort_data = analytics.get('cohort_analysis', {})\nbenchmarking_data = analytics.get('benchmarking', {})\nfunnel_data_analysis = analytics.get('funnel_analysis', {})\nperformance_data = analytics.get('performance_score', {})\ncustomer_journey = analytics.get('customer_journey_analysis', {})\nchurn_data = analytics.get('churn_prediction', {})\noperational_data = analytics.get('operational_efficiency', {})\nmarketing_data = analytics.get('marketing_efficiency', {})\naction_data = analytics.get('action_recommendations', {})\npredictive_data = analytics.get('advanced_predictive_analysis', {})\n\n# Generar HTML report\nhtml_content = f\"\"\"\n<!DOCTYPE html>\n<html lang=\"es\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Daily Report - {data.get('reportDate', '')[:10]}</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js\"></script>\n    <style>\n        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #f5f5f5; padding: 20px; }}\n        .container {{ max-width: 1200px; margin: 0 auto; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 8px 8px 0 0; }}\n        .header h1 {{ font-size: 28px; margin-bottom: 10px; }}\n        .header p {{ opacity: 0.9; }}\n        .content {{ padding: 30px; }}\n        .metrics-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0; }}\n        .metric-card {{ background: #f8f9fa; border-left: 4px solid #667eea; padding: 20px; border-radius: 4px; }}\n        .metric-card h3 {{ color: #667eea; font-size: 14px; text-transform: uppercase; margin-bottom: 10px; }}\n        .metric-card .value {{ font-size: 32px; font-weight: bold; color: #333; }}\n        .metric-card .change {{ font-size: 14px; margin-top: 5px; }}\n        .change.positive {{ color: #28a745; }}\n        .change.negative {{ color: #dc3545; }}\n        .section {{ margin: 40px 0; }}\n        .section h2 {{ color: #333; margin-bottom: 20px; border-bottom: 2px solid #667eea; padding-bottom: 10px; }}\n        .alert {{ padding: 15px; border-radius: 4px; margin: 10px 0; }}\n        .alert.warning {{ background: #fff3cd; border-left: 4px solid #ffc107; }}\n        .alert.danger {{ background: #f8d7da; border-left: 4px solid #dc3545; }}\n        .alert.info {{ background: #d1ecf1; border-left: 4px solid #17a2b8; }}\n        .kpi-table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n        .kpi-table th, .kpi-table td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}\n        .kpi-table th {{ background: #f8f9fa; font-weight: 600; }}\n        .trend-indicator {{ display: inline-block; margin-left: 10px; }}\n        .chart-container {{ margin: 20px 0; padding: 20px; background: #f8f9fa; border-radius: 4px; }}\n        .chart-container canvas {{ max-height: 300px; }}\n        .health-score {{ font-size: 48px; font-weight: bold; margin: 10px 0; }}\n        .health-score.high {{ color: #28a745; }}\n        .health-score.medium {{ color: #ffc107; }}\n        .health-score.low {{ color: #dc3545; }}\n        .correlation-matrix {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }}\n        .correlation-card {{ padding: 15px; background: white; border-radius: 4px; border: 1px solid #ddd; }}\n        .correlation-value {{ font-size: 24px; font-weight: bold; }}\n        .correlation-value.strong {{ color: #28a745; }}\n        .correlation-value.moderate {{ color: #ffc107; }}\n        .correlation-value.weak {{ color: #6c757d; }}\n    </style>\n</head>\n<body>\n    <div class=\"container\">\n        <div class=\"header\">\n            <h1>📊 Daily Business Report</h1>\n            <p>Report Date: {data.get('reportDate', '')[:10]} | Execution ID: {data.get('executionId', 'N/A')[:20]}</p>\n        </div>\n        \n        <div class=\"content\">\n            <!-- Executive Summary -->\n            <div class=\"section\">\n                <h2>📋 Executive Summary</h2>\n                <div class=\"metrics-grid\">\n                    <div class=\"metric-card\">\n                        <h3>Health Score</h3>\n                        <div class=\"health-score {'high' if executive.get('health_score', 0) >= 80 else ('medium' if executive.get('health_score', 0) >= 60 else 'low')}\">{executive.get('health_score', 0)}/100</div>\n                        <p style=\"margin-top: 10px;\">Status: <strong>{executive.get('status', 'unknown').upper()}</strong></p>\n                    </div>\n                </div>\n                <div class=\"metrics-grid\">\n                    <div class=\"metric-card\">\n                        <h3>Total Revenue</h3>\n                        <div class=\"value\">${summary.get('hubspot_total_value', 0) + summary.get('stripe_charges_total', 0):,.2f}</div>\n                        {f\"<div class='change {'positive' if comparative.get('revenue', {}).get('change_pct', 0) >= 0 else 'negative'}'>\" + \n                        (f\"{comparative.get('revenue', {}).get('change_pct', 0):+.2f}% vs previous\" if comparative.get('revenue', {}).get('change_pct') else \"\") + \"</div>\" if comparative.get('revenue') else \"\"}\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Total Deals</h3>\n                        <div class=\"value\">{summary.get('hubspot_deals_count', 0)}</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>New Customers</h3>\n                        <div class=\"value\">{summary.get('stripe_new_customers_count', 0)}</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Avg Deal Value</h3>\n                        <div class=\"value\">${summary.get('hubspot_avg_deal_value', 0):,.2f}</div>\n                    </div>\n                </div>\n            </div>\n            \n            <!-- Alerts -->\n            {''.join([f\"<div class='alert {alert.get('severity', 'info')}'><strong>{alert.get('type', 'Alert').replace('_', ' ').title()}:</strong> {alert.get('message', '')}</div>\" for alert in analytics.get('alerts', [])]) if analytics.get('alerts') else '<p>✅ No alerts</p>'}\n            \n            <!-- KPIs -->\n            <div class=\"section\">\n                <h2>🎯 Key Performance Indicators</h2>\n                <table class=\"kpi-table\">\n                    <tr><th>Metric</th><th>Value</th></tr>\n                    <tr><td>Revenue per Customer</td><td>${analytics.get('kpis', {}).get('revenue_per_customer', 0):,.2f}</td></tr>\n                    <tr><td>Conversion Rate</td><td>{analytics.get('kpis', {}).get('conversion_rate_pct', 0):.2f}%</td></tr>\n                    <tr><td>Estimated LTV</td><td>${analytics.get('kpis', {}).get('estimated_ltv', 0):,.2f}</td></tr>\n                    <tr><td>Revenue Growth Rate</td><td>{analytics.get('kpis', {}).get('revenue_growth_rate', 0):.2f}%</td></tr>\n                </table>\n            </div>\n            \n            <!-- Trend Analysis with Chart -->\n            {f\"\"\"<div class=\"section\">\n                <h2>📈 Trend Analysis</h2>\n                <p><strong>Trend:</strong> {analytics.get('trend_analysis', {}).get('revenue', {}).get('trend', 'N/A').title()}</p>\n                <p><strong>Growth Rate:</strong> {analytics.get('trend_analysis', {}).get('revenue', {}).get('growth_rate_pct', 0):.2f}%</p>\n                <p><strong>Projected Next Day:</strong> ${analytics.get('trend_analysis', {}).get('revenue', {}).get('projection_next_day', 0):,.2f}</p>\n                <div class=\"chart-container\">\n                    <canvas id=\"trendChart\"></canvas>\n                </div>\n                <script>\n                    const trendCtx = document.getElementById('trendChart').getContext('2d');\n                    const trendData = {analytics.get('trend_analysis', {}).get('revenue', {}).get('last_7_days', [])};\n                    new Chart(trendCtx, {{\n                        type: 'line',\n                        data: {{\n                            labels: ['Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5', 'Day 6', 'Day 7'],\n                            datasets: [{{\n                                label: 'Revenue Trend',\n                                data: trendData,\n                                borderColor: 'rgb(102, 126, 234)',\n                                backgroundColor: 'rgba(102, 126, 234, 0.1)',\n                                tension: 0.4\n                            }}]\n                        }},\n                        options: {{\n                            responsive: true,\n                            plugins: {{\n                                legend: {{ display: true }},\n                                title: {{ display: true, text: 'Revenue Trend (Last 7 Days)' }}\n                            }}\n                        }}\n                    }});\n                </script>\n            </div>\"\"\" if analytics.get('trend_analysis') else ''}\n            \n            <!-- Forecasting -->\n            {f\"\"\"<div class=\"section\">\n                <h2>🔮 Forecasting</h2>\n                <div class=\"metrics-grid\">\n                    <div class=\"metric-card\">\n                        <h3>Moving Average Forecast</h3>\n                        <div class=\"value\">${forecasting_data.get('moving_average', {}).get('forecast_next_day', 0):,.2f}</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Exponential Smoothing</h3>\n                        <div class=\"value\">${forecasting_data.get('exponential_smoothing', {}).get('forecast_next_day', 0):,.2f}</div>\n                    </div>\n                    {f\"\"\"<div class=\"metric-card\">\n                        <h3>ML Model Forecast</h3>\n                        <div class=\"value\">${forecasting_data.get('ml_model', {}).get('forecast_next_day', 0):,.2f}</div>\n                        <div class=\"change\">Confidence: {forecasting_data.get('ml_model', {}).get('confidence', 0)*100:.1f}%</div>\n                    </div>\"\"\" if forecasting_data.get('ml_model') else ''}\n                    <div class=\"metric-card\">\n                        <h3>Consensus Forecast</h3>\n                        <div class=\"value\">${forecasting_data.get('forecast_consensus', 0):,.2f}</div>\n                    </div>\n                </div>\n                {f\"\"\"<p><strong>95% Confidence Interval:</strong> ${forecasting_data.get('confidence_interval_95', {}).get('lower', 0):,.2f} - ${forecasting_data.get('confidence_interval_95', {}).get('upper', 0):,.2f}</p>\"\"\" if forecasting_data.get('confidence_interval_95') else ''}\n            </div>\"\"\" if forecasting_data else ''}\n            \n            <!-- Correlation Analysis -->\n            {f\"\"\"<div class=\"section\">\n                <h2>🔗 Correlation Analysis</h2>\n                <div class=\"correlation-matrix\">\n                    <div class=\"correlation-card\">\n                        <h4>Revenue vs Deals</h4>\n                        <div class=\"correlation-value {'strong' if abs(correlation_data.get('revenue_vs_deals', {}).get('correlation', 0)) > 0.7 else ('moderate' if abs(correlation_data.get('revenue_vs_deals', {}).get('correlation', 0)) > 0.4 else 'weak')}\">\n                            {correlation_data.get('revenue_vs_deals', {}).get('correlation', 0):.2f}\n                        </div>\n                        <p>{correlation_data.get('revenue_vs_deals', {}).get('strength', 'unknown').title()} - {correlation_data.get('revenue_vs_deals', {}).get('direction', 'unknown')}</p>\n                    </div>\n                    <div class=\"correlation-card\">\n                        <h4>Revenue vs Customers</h4>\n                        <div class=\"correlation-value {'strong' if abs(correlation_data.get('revenue_vs_customers', {}).get('correlation', 0)) > 0.7 else ('moderate' if abs(correlation_data.get('revenue_vs_customers', {}).get('correlation', 0)) > 0.4 else 'weak')}\">\n                            {correlation_data.get('revenue_vs_customers', {}).get('correlation', 0):.2f}\n                        </div>\n                        <p>{correlation_data.get('revenue_vs_customers', {}).get('strength', 'unknown').title()} - {correlation_data.get('revenue_vs_customers', {}).get('direction', 'unknown')}</p>\n                    </div>\n                </div>\n                {f\"\"\"<ul>{\"\".join([f\"<li>{insight}</li>\" for insight in correlation_data.get('insights', [])])}</ul>\"\"\" if correlation_data.get('insights') else ''}\n            </div>\"\"\" if correlation_data else ''}\n            \n            <!-- Risk Analysis -->\n            {f\"\"\"<div class=\"section\">\n                <h2>⚠️ Risk Analysis</h2>\n                <div class=\"metrics-grid\">\n                    <div class=\"metric-card\">\n                        <h3>Risk Level</h3>\n                        <div class=\"value\">{risk_data.get('risk_level', 'unknown').upper()}</div>\n                        <div class=\"change\">Risk Score: {risk_data.get('risk_score', 0):.1f}/100</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Volatility</h3>\n                        <div class=\"value\">{risk_data.get('volatility', 0)*100:.2f}%</div>\n                        <div class=\"change\">{risk_data.get('volatility_level', 'unknown').title()}</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Value at Risk (95%)</h3>\n                        <div class=\"value\">${risk_data.get('value_at_risk_95', 0):,.2f}</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Current Drawdown</h3>\n                        <div class=\"value {'negative' if risk_data.get('current_drawdown_pct', 0) < 0 else 'positive'}\">{risk_data.get('current_drawdown_pct', 0):.2f}%</div>\n                    </div>\n                </div>\n            </div>\"\"\" if risk_data else ''}\n            \n            <!-- Anomaly Detection -->\n            {f\"\"\"<div class=\"section\">\n                <h2>⚠️ Anomaly Detection</h2>\n                <p><strong>Status:</strong> {'Anomalía detectada' if analytics.get('anomaly_detection', {}).get('revenue', {}).get('is_anomaly', False) else 'Normal'}</p>\n                <p><strong>Z-Score:</strong> {analytics.get('anomaly_detection', {}).get('revenue', {}).get('z_score', 0):.2f}</p>\n            </div>\"\"\" if analytics.get('anomaly_detection') else ''}\n            \n            <!-- Cohort Analysis -->\n            {f\"\"\"<div class=\"section\">\n                <h2>👥 Cohort Analysis</h2>\n                <p><strong>Average Retention Rate:</strong> {cohort_data.get('average_retention_rate', 0)*100:.1f}%</p>\n                <p><strong>Weighted LTV:</strong> ${cohort_data.get('weighted_ltv', 0):,.2f}</p>\n                <p><strong>Retention Trend:</strong> {cohort_data.get('retention_trend', 'unknown').title()}</p>\n            </div>\"\"\" if cohort_data else ''}\n            \n            <!-- Benchmarking -->\n            {f\"\"\"<div class=\"section\">\n                <h2>📊 Benchmarking</h2>\n                <p><strong>Overall Score:</strong> {benchmarking_data.get('overall_score', 0):.1f}/25</p>\n                <p><strong>Rating:</strong> {benchmarking_data.get('score_interpretation', 'unknown').replace('_', ' ').title()}</p>\n            </div>\"\"\" if benchmarking_data else ''}\n            \n            <!-- Funnel Analysis -->\n            {f\"\"\"<div class=\"section\">\n                <h2>🔄 Funnel Analysis</h2>\n                <p><strong>Overall Conversion Rate:</strong> {funnel_data_analysis.get('overall_conversion_rate', 0):.1f}%</p>\n                <p><strong>Bottlenecks Identified:</strong> {len(funnel_data_analysis.get('bottlenecks', []))}</p>\n                {f\"\"\"<ul>{\"\".join([f\"<li>{rec}</li>\" for rec in funnel_data_analysis.get('recommendations', [])])}</ul>\"\"\" if funnel_data_analysis.get('recommendations') else ''}\n            </div>\"\"\" if funnel_data_analysis else ''}\n            \n            <!-- Performance Score -->\n            {f\"\"\"<div class=\"section\">\n                <h2>🏆 Performance Score</h2>\n                <div class=\"metrics-grid\">\n                    <div class=\"metric-card\">\n                        <h3>Total Score</h3>\n                        <div class=\"health-score {'high' if performance_data.get('total_score', 0) >= 80 else ('medium' if performance_data.get('total_score', 0) >= 60 else 'low')}\">{performance_data.get('total_score', 0):.1f}/100</div>\n                        <p style=\"margin-top: 10px;\">Grade: <strong>{performance_data.get('grade', 'N/A')}</strong></p>\n                    </div>\n                </div>\n            </div>\"\"\" if performance_data else ''}\n            \n            <!-- Customer Journey -->\n            {f\"\"\"<div class=\"section\">\n                <h2>🗺️ Customer Journey</h2>\n                <p><strong>Total Journey Days:</strong> {customer_journey.get('total_journey_days', 0)}</p>\n                <p><strong>Overall Conversion:</strong> {customer_journey.get('overall_conversion_rate', 0):.1f}%</p>\n                <p><strong>Problem Stages:</strong> {len(customer_journey.get('problem_stages', []))}</p>\n            </div>\"\"\" if customer_journey else ''}\n            \n            <!-- Churn Prediction -->\n            {f\"\"\"<div class=\"section\">\n                <h2>⚠️ Churn Prediction</h2>\n                <div class=\"alert {'danger' if churn_data.get('churn_level') == 'critical' else ('warning' if churn_data.get('churn_level') == 'high' else 'info')}\">\n                    <p><strong>Churn Probability:</strong> {churn_data.get('churn_probability', 0)*100:.1f}%</p>\n                    <p><strong>Level:</strong> {churn_data.get('churn_level', 'unknown').upper()}</p>\n                    <p><strong>Estimated Churn:</strong> {churn_data.get('estimated_churn_percentage', 0):.1f}%</p>\n                </div>\n            </div>\"\"\" if churn_data else ''}\n            \n            <!-- Operational Efficiency -->\n            {f\"\"\"<div class=\"section\">\n                <h2>⚙️ Operational Efficiency</h2>\n                <p><strong>Overall Efficiency Score:</strong> {operational_data.get('overall_efficiency_score', 0):.1f}/100</p>\n                <p><strong>Grade:</strong> {operational_data.get('efficiency_grade', 'N/A')}</p>\n                <p><strong>Avg Cycle Time:</strong> {operational_data.get('metrics', {}).get('avg_cycle_time_days', 0):.0f} days</p>\n            </div>\"\"\" if operational_data else ''}\n            \n            <!-- Marketing Efficiency -->\n            {f\"\"\"<div class=\"section\">\n                <h2>📈 Marketing Efficiency</h2>\n                <p><strong>ROI:</strong> {marketing_data.get('roi_percentage', 0):.1f}%</p>\n                <p><strong>LTV/CAC Ratio:</strong> {marketing_data.get('ltv_cac_ratio', 0):.2f}</p>\n                <p><strong>Rating:</strong> {marketing_data.get('efficiency_rating', 'unknown').title()}</p>\n            </div>\"\"\" if marketing_data else ''}\n            \n            <!-- Action Recommendations -->\n            {f\"\"\"<div class=\"section\">\n                <h2>🎯 Action Recommendations</h2>\n                <p><strong>Total Actions:</strong> {action_data.get('total_actions', 0)}</p>\n                <p><strong>Priority Score:</strong> {action_data.get('priority_score', 0):.1f}</p>\n                <div class=\"metrics-grid\">\n                    <div class=\"metric-card\">\n                        <h3>Critical</h3>\n                        <div class=\"value\">{action_data.get('summary', {}).get('critical', 0)}</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>High Priority</h3>\n                        <div class=\"value\">{action_data.get('summary', {}).get('high', 0)}</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Medium</h3>\n                        <div class=\"value\">{action_data.get('summary', {}).get('medium', 0)}</div>\n                    </div>\n                </div>\n                {f\"\"\"<div style=\"margin-top: 20px;\">\n                    <h3>Priority Actions:</h3>\n                    <ul>{\"\".join([f\"<li><strong>{action.get('title', 'N/A')}:</strong> {action.get('description', '')} [Priority: {action.get('priority', 'N/A').upper()}]</li>\" for action in action_data.get('actions', [])[:5]])}</ul>\n                </div>\"\"\" if action_data.get('actions') else ''}\n            </div>\"\"\" if action_data else ''}\n            \n            <!-- Advanced Predictive Analysis -->\n            {f\"\"\"<div class=\"section\">\n                <h2>🔮 Advanced Predictive Analysis</h2>\n                <div class=\"metrics-grid\">\n                    <div class=\"metric-card\">\n                        <h3>Expected Revenue (7d)</h3>\n                        <div class=\"value\">${predictive_data.get('expected_revenue', {}).get('7d', 0):,.2f}</div>\n                        <div class=\"change\">+{predictive_data.get('projections', {}).get('7d', {}).get('growth_from_current_pct', 0):.1f}%</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Expected Revenue (30d)</h3>\n                        <div class=\"value\">${predictive_data.get('expected_revenue', {}).get('30d', 0):,.2f}</div>\n                        <div class=\"change\">+{predictive_data.get('projections', {}).get('30d', {}).get('growth_from_current_pct', 0):.1f}%</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Expected Revenue (90d)</h3>\n                        <div class=\"value\">${predictive_data.get('expected_revenue', {}).get('90d', 0):,.2f}</div>\n                        <div class=\"change\">+{predictive_data.get('projections', {}).get('90d', {}).get('growth_from_current_pct', 0):.1f}%</div>\n                    </div>\n                    <div class=\"metric-card\">\n                        <h3>Objective Probability</h3>\n                        <div class=\"value\">{predictive_data.get('objective_analysis', {}).get('probability_to_reach', 0)*100:.1f}%</div>\n                        <div class=\"change\">{predictive_data.get('objective_analysis', {}).get('status', 'unknown').title()}</div>\n                    </div>\n                </div>\n            </div>\"\"\" if predictive_data else ''}\n            \n            <!-- Recommendations -->\n            {f\"\"\"<div class=\"section\">\n                <h2>💡 Recommendations</h2>\n                <ul>{\"\".join([f\"<li>{rec}</li>\" for rec in executive.get('recommendations', [])])}</ul>\n            </div>\"\"\" if executive.get('recommendations') else ''}\n        </div>\n    </div>\n</body>\n</html>\n\"\"\"\n\n# Guardar HTML\nhtml_filename = f\"daily_report_{datetime.now(timezone.utc).strftime('%Y%m%d')}.html\"\nwith open(html_filename, 'w', encoding='utf-8') as f:\n    f.write(html_content)\n\nreturn [{\n    'json': {\n        'htmlFile': html_filename,\n        'htmlGenerated': True\n    },\n    'binary': {\n        'data': html_filename\n    }\n}]"
      },
      "typeVersion": 2,
      "id": "html-report-001",
      "continueOnFail": true,
      "notes": "Genera reporte HTML visual con todos los análisis avanzados"
    },
    {
      "name": "Log Errors",
      "type": "n8n-nodes-base.workflow",
      "position": [1650, 400],
      "parameters": {
        "workflowId": "error-logging-workflow-id",
        "options": {}
      },
      "typeVersion": 1,
      "id": "error-log-001",
      "continueOnFail": true,
      "notes": "Registra errores en sistema de logging"
    },
    {
      "name": "Upload Hyper to Drive",
      "type": "n8n-nodes-base.googleDrive",
      "position": [1450, 400],
      "parameters": {
        "operation": "upload",
        "name": "={{ $node['Process & Export with Pandas'].json.reportDate.split('T')[0] + '_daily_report.hyper' }}",
        "parents": {
          "parent": {
            "parentId": "YOUR_GOOGLE_DRIVE_FOLDER_ID"
          }
        },
        "binaryData": true,
        "options": {
          "appProperties": {
            "property": [
              {
                "key": "reportDate",
                "value": "={{ $node['Process & Export with Pandas'].json.reportDate }}"
              },
              {
                "key": "processedAt",
                "value": "={{ $node['Process & Export with Pandas'].json.summary.processed_at }}"
              }
            ]
          }
        }
      },
      "credentials": {
        "googleDriveOAuth2Api": "YOUR_GOOGLE_DRIVE_CRED"
      },
      "typeVersion": 3,
      "id": "gdrive-001",
      "continueOnFail": false,
      "notes": "Sube el archivo Hyper a Google Drive"
    },
    {
      "name": "Create CSV Backup",
      "type": "n8n-nodes-base.code",
      "position": [1650, 300],
      "parameters": {
        "mode": "python",
        "pythonCode": "import pandas as pd\nfrom datetime import datetime, timezone\n\n# Obtener datos del paso anterior\ninput_data = items[0]['json']\nsummary_data = input_data.get('summary', {})\nreport_date = input_data.get('reportDate', datetime.now(timezone.utc).isoformat())\n\n# Crear DataFrame de resumen\ncsv_df = pd.DataFrame([{\n    'report_date': report_date,\n    'hubspot_deals_count': summary_data.get('hubspot_deals_count', 0),\n    'hubspot_total_value': summary_data.get('hubspot_total_value', 0.0),\n    'stripe_charges_count': summary_data.get('stripe_charges_count', 0),\n    'stripe_charges_total': summary_data.get('stripe_charges_total', 0.0),\n    'manychat_subscribers_count': summary_data.get('manychat_subscribers_count', 0),\n    'mailchimp_members_count': summary_data.get('mailchimp_members_count', 0),\n    'total_revenue': summary_data.get('hubspot_total_value', 0.0) + summary_data.get('stripe_charges_total', 0.0)\n}])\n\n# Exportar a CSV\ncsv_filename = f\"daily_report_{datetime.now(timezone.utc).strftime('%Y%m%d')}.csv\"\ncsv_df.to_csv(csv_filename, index=False)\n\nreturn [{\n    'json': {\n        'csvFile': csv_filename,\n        'csvData': csv_df.to_dict('records')[0]\n    },\n    'binary': {\n        'data': csv_filename\n    }\n}]"
      },
      "typeVersion": 2,
      "id": "csv-001",
      "continueOnFail": true,
      "notes": "Crea un backup en CSV del resumen"
    },
    {
      "name": "Send Report Email",
      "type": "n8n-nodes-base.emailSend",
      "position": [1850, 300],
      "parameters": {
        "fromEmail": "reports@yourdomain.com",
        "toEmail": "={{ $env.REPORT_RECIPIENTS || 'team@yourdomain.com' }}",
        "ccEmail": "",
        "bccEmail": "",
        "subject": "Daily Report – {{ $node['Set Variables'].json.reportDate.split('T')[0] }}",
        "text": "={{ `Resumen del Reporte Diario\n\nFecha: ${$node['Set Variables'].json.reportDate.split('T')[0]}\n\nMétricas:\n- HubSpot Deals: ${$node['Process & Export with Pandas'].json.summary.hubspot_deals_count || 0}\n- HubSpot Total Value: $${$node['Process & Export with Pandas'].json.summary.hubspot_total_value || 0}\n- Stripe Charges: ${$node['Process & Export with Pandas'].json.summary.stripe_charges_count || 0}\n- Stripe Total: $${$node['Process & Export with Pandas'].json.summary.stripe_charges_total || 0}\n- ManyChat Subscribers: ${$node['Process & Export with Pandas'].json.summary.manychat_subscribers_count || 0}\n- Mailchimp Members: ${$node['Process & Export with Pandas'].json.summary.mailchimp_members_count || 0}\n- Total Revenue: $${($node['Process & Export with Pandas'].json.summary.hubspot_total_value || 0) + ($node['Process & Export with Pandas'].json.summary.stripe_charges_total || 0)}\n\n${$node['Process & Export with Pandas'].json.hasErrors ? '⚠️ Se encontraron errores durante el procesamiento. Ver logs para detalles.' : '✓ Procesamiento completado sin errores.'}\n\nEl reporte completo está disponible en Google Drive y en formato compatible con Tableau (.hyper).` }}",
        "attachments": [
          {
            "name": "={{ $node['Process & Export with Pandas'].json.hyperFilename }}",
            "dataPropertyName": "data"
          }
        ],
        "options": {
          "allowUnauthorizedCerts": false
        }
      },
      "credentials": {
        "smtp": "YOUR_SMTP_CRED"
      },
      "typeVersion": 2,
      "id": "email-001",
      "continueOnFail": true,
      "notes": "Envía el reporte por email"
    },
    {
      "name": "Send Notification (Success)",
      "type": "n8n-nodes-base.slack",
      "position": [2050, 200],
      "parameters": {
        "channel": "#reports",
        "text": "={{ `✅ Daily Report Generated Successfully\\n\\nDate: ${$node['Set Variables'].json.reportDate.split('T')[0]}\\nTotal Revenue: $${($node['Process & Export with Pandas'].json.summary.hubspot_total_value || 0) + ($node['Process & Export with Pandas'].json.summary.stripe_charges_total || 0)}\\nView in Drive: [Link]` }}",
        "options": {}
      },
      "credentials": {
        "slackApi": "YOUR_SLACK_CRED"
      },
      "typeVersion": 2,
      "id": "slack-001",
      "continueOnFail": true,
      "notes": "Notifica éxito en Slack"
    },
    {
      "name": "Send Notification (Errors)",
      "type": "n8n-nodes-base.slack",
      "position": [2050, 400],
      "parameters": {
        "channel": "#alerts",
        "text": "={{ `⚠️ Daily Report Generated with Errors\\n\\nDate: ${$node['Set Variables'].json.reportDate.split('T')[0]}\\nErrors: ${$node['Process & Export with Pandas'].json.errors.length || 0}\\n\\nErrors:\\n${$node['Process & Export with Pandas'].json.errors.join('\\n')}` }}",
        "options": {}
      },
      "credentials": {
        "slackApi": "YOUR_SLACK_CRED"
      },
      "typeVersion": 2,
      "id": "slack-002",
      "continueOnFail": true,
      "notes": "Notifica errores en Slack"
    }
  ],
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "saveExecutionProgress": true,
    "saveDataErrorExecution": "all",
    "saveDataSuccessExecution": "all",
    "saveManualExecutions": true,
    "timezone": "UTC"
  },
  "connections": {
    "Schedule Trigger – Daily 08:00 UTC": {
      "main": [
        [
          { "node": "Initialize Workflow", "type": "main", "index": 0 }
        ]
      ]
    },
    "Initialize Workflow": {
      "main": [
        [
          { "node": "Set Variables", "type": "main", "index": 0 }
        ]
      ]
    },
    "Set Variables": {
      "main": [
        [
          { "node": "Fetch HubSpot Deals", "type": "main", "index": 0 },
          { "node": "Fetch Stripe Charges", "type": "main", "index": 0 },
          { "node": "Fetch Stripe Customers", "type": "main", "index": 0 },
          { "node": "Fetch ManyChat Subscribers", "type": "main", "index": 0 },
          { "node": "Fetch Mailchimp Activity", "type": "main", "index": 0 }
        ]
      ]
    },
    "Fetch HubSpot Deals": {
      "main": [
        [
          { "node": "Normalize & Validate Data", "type": "main", "index": 0 }
        ]
      ]
    },
    "Fetch Stripe Charges": {
      "main": [
        [
          { "node": "Normalize & Validate Data", "type": "main", "index": 0 }
        ]
      ]
    },
    "Fetch Stripe Customers": {
      "main": [
        [
          { "node": "Normalize & Validate Data", "type": "main", "index": 0 }
        ]
      ]
    },
    "Fetch ManyChat Subscribers": {
      "main": [
        [
          { "node": "Normalize & Validate Data", "type": "main", "index": 0 }
        ]
      ]
    },
    "Fetch Mailchimp Activity": {
      "main": [
        [
          { "node": "Normalize & Validate Data", "type": "main", "index": 0 }
        ]
      ]
    },
    "Normalize & Validate Data": {
      "main": [
        [
          { "node": "Process & Export with Pandas", "type": "main", "index": 0 }
        ]
      ]
    },
    "Process & Export with Pandas": {
      "main": [
        [
          { "node": "Advanced Analytics & Insights", "type": "main", "index": 0 }
        ]
      ]
    },
    "Advanced Analytics & Insights": {
      "main": [
        [
          { "node": "Check Processing Errors", "type": "main", "index": 0 }
        ]
      ]
    },
    "Check Processing Errors": {
      "main": [
        [
          {
            "node": "Send Notification (Errors)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Log Errors",
            "type": "main",
            "index": 0
          }
        ],
        [
          { "node": "Generate HTML Report", "type": "main", "index": 0 },
          { "node": "Upload Hyper to Drive", "type": "main", "index": 0 }
        ]
      ]
    },
    "Generate HTML Report": {
      "main": [
        [
          { "node": "Upload Hyper to Drive", "type": "main", "index": 0 }
        ]
      ]
    },
    "Upload Hyper to Drive": {
      "main": [
        [
          { "node": "Create CSV Backup", "type": "main", "index": 0 }
        ]
      ]
    },
    "Create CSV Backup": {
      "main": [
        [
          { "node": "Send Report Email", "type": "main", "index": 0 }
        ]
      ]
    },
    "Send Report Email": {
      "main": [
        [
          { "node": "Send Notification (Success)", "type": "main", "index": 0 }
        ]
      ]
    }
  },
  "pinData": {},
  "description": "Workflow diario mejorado que procesa datos de múltiples fuentes (HubSpot, Stripe, ManyChat, Mailchimp), los normaliza, valida, procesa con pandas, exporta a formato Tableau (.hyper), crea backups CSV, sube a Google Drive y envía notificaciones. Incluye manejo robusto de errores, validaciones y logging detallado."
}
