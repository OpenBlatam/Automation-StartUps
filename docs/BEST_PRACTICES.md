# ‚úÖ Mejores Pr√°cticas

> **Versi√≥n**: 1.0 | **√öltima actualizaci√≥n**: 2024

Mejores pr√°cticas y patrones recomendados para desarrollar en la plataforma.

## üìã Tabla de Contenidos

- [Principios Generales](#-principios-generales)
- [Mejores Pr√°cticas de Airflow](#-mejores-pr√°cticas-de-airflow)
- [Mejores Pr√°cticas de C√≥digo](#-mejores-pr√°cticas-de-c√≥digo)
- [Mejores Pr√°cticas de Performance](#-mejores-pr√°cticas-de-performance)
- [Mejores Pr√°cticas de Seguridad](#-mejores-pr√°cticas-de-seguridad)
- [Anti-Patrones](#-anti-patrones)

---

## üéØ Principios Generales

### 1. Modularidad

‚úÖ **Bueno**: C√≥digo dividido en m√≥dulos reutilizables
```python
from data.airflow.plugins.approval_cleanup_ops import get_pg_hook
```

‚ùå **Malo**: C√≥digo duplicado en cada DAG
```python
def get_pg_hook():
    return PostgresHook(postgres_conn_id="approvals_db")
# Repetido en cada DAG
```

### 2. Idempotencia

‚úÖ **Bueno**: Tareas idempotentes
```python
@task
def cargar_datos():
    # Verificar si ya existe
    if datos_ya_existen():
        return {"status": "skipped"}
    # Cargar datos
    return {"status": "loaded"}
```

‚ùå **Malo**: Siempre inserta sin verificar
```python
@task
def cargar_datos():
    # Siempre inserta, puede duplicar
    insertar_datos()
```

### 3. Manejo de Errores

‚úÖ **Bueno**: Manejo robusto de errores
```python
@task(retries=3, retry_delay=timedelta(minutes=5))
def procesar():
    try:
        # L√≥gica
        return result
    except TransientError as e:
        logger.warning(f"Error temporal: {e}")
        raise  # Retry autom√°tico
    except PermanentError as e:
        logger.error(f"Error permanente: {e}")
        raise AirflowFailException(e)  # Falla inmediatamente
```

‚ùå **Malo**: Sin manejo de errores
```python
@task
def procesar():
    # Sin try/except, cualquier error falla el DAG
    resultado = operacion_riesgosa()
```

---

## ‚úàÔ∏è Mejores Pr√°cticas de Airflow

### 1. Configuraci√≥n del DAG

‚úÖ **Bueno**: Configuraci√≥n completa y clara
```python
@dag(
    dag_id="mi_dag",
    description="Descripci√≥n clara del prop√≥sito",
    schedule_interval="@daily",
    start_date=pendulum.datetime(2024, 1, 1, tz="UTC"),
    catchup=False,  # Importante para evitar backfills no deseados
    tags=["etl", "datos"],
    default_args={
        "retries": 3,
        "retry_delay": timedelta(minutes=5),
        "on_failure_callback": on_task_failure,
    },
)
```

‚ùå **Malo**: Configuraci√≥n incompleta
```python
@dag(
    dag_id="mi_dag",
    # Falta descripci√≥n, tags, default_args
)
```

### 2. Nombres Descriptivos

‚úÖ **Bueno**: Nombres claros y descriptivos
```python
@task
def extraer_datos_de_api_hubspot():
    """Extrae datos de la API de HubSpot."""
    pass

@task
def transformar_datos_de_clientes():
    """Transforma datos de clientes."""
    pass
```

‚ùå **Malo**: Nombres gen√©ricos
```python
@task
def task1():
    pass

@task
def process():
    pass
```

### 3. Uso de Task Groups

‚úÖ **Bueno**: Organizar tareas en grupos
```python
@task_group(group_id="extraction")
def extraction_group():
    api_data = extract_from_api()
    db_data = extract_from_db()
    return [api_data, db_data]
```

‚ùå **Malo**: Todas las tareas al mismo nivel
```python
# 50+ tareas sin organizaci√≥n
task1 = extract1()
task2 = extract2()
# ... 50+ m√°s
```

### 4. Documentaci√≥n

‚úÖ **Bueno**: Documentaci√≥n completa
```python
@task
def procesar_datos(
    datos: List[Dict[str, Any]],
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Procesa los datos seg√∫n la configuraci√≥n.
    
    Args:
        datos: Lista de diccionarios con los datos a procesar
        config: Configuraci√≥n opcional para el procesamiento
        
    Returns:
        Diccionario con resultados del procesamiento
        
    Raises:
        ValueError: Si los datos son inv√°lidos
        AirflowFailException: Si el procesamiento falla
    """
    pass
```

‚ùå **Malo**: Sin documentaci√≥n
```python
@task
def procesar(datos):
    # Sin docstring, sin type hints
    pass
```

---

## üíª Mejores Pr√°cticas de C√≥digo

### 1. Type Hints

‚úÖ **Bueno**: Type hints completos
```python
from typing import List, Dict, Any, Optional

def procesar_datos(
    datos: List[Dict[str, Any]],
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    pass
```

‚ùå **Malo**: Sin type hints
```python
def procesar_datos(datos, config=None):
    pass
```

### 2. Logging Estructurado

‚úÖ **Bueno**: Logging con contexto
```python
from data.airflow.plugins.approval_cleanup_utils import log_with_context

log_with_context('info', 'Procesando datos', extra={
    'task_id': context['task_instance'].task_id,
    'record_count': len(records),
    'duration_ms': duration
})
```

‚ùå **Malo**: Print statements
```python
print(f"Processing {len(records)} records")  # No usar print
```

### 3. Configuraci√≥n Centralizada

‚úÖ **Bueno**: Configuraci√≥n en plugins
```python
from data.airflow.plugins.approval_cleanup_config import get_config

config = get_config()
batch_size = config['processing']['batch_size']
```

‚ùå **Malo**: Valores hardcodeados
```python
batch_size = 1000  # Hardcodeado
```

### 4. Validaci√≥n de Par√°metros

‚úÖ **Bueno**: Validar par√°metros
```python
from data.airflow.plugins.approval_cleanup_utils import validate_params

@dag(
    params={
        "batch_size": Param(1000, type="integer", minimum=100, maximum=10000),
    }
)
def mi_dag():
    @task
    def procesar(**context):
        params = context["params"]
        validate_params({
            'batch_size': (100, 10000)
        })
        batch_size = params['batch_size']
```

‚ùå **Malo**: Sin validaci√≥n
```python
@task
def procesar(**context):
    batch_size = context["params"].get("batch_size", 1000)
    # Sin validar que est√° en rango v√°lido
```

---

## ‚ö° Mejores Pr√°cticas de Performance

### 1. Procesamiento en Lotes

‚úÖ **Bueno**: Procesar en lotes
```python
def procesar_registros(registros: List[Dict]) -> None:
    batch_size = 1000
    for i in range(0, len(registros), batch_size):
        batch = registros[i:i + batch_size]
        procesar_lote(batch)
```

‚ùå **Malo**: Uno por uno
```python
def procesar_registros(registros: List[Dict]) -> None:
    for registro in registros:
        procesar(registro)  # Muy lento
```

### 2. Connection Pooling

‚úÖ **Bueno**: Reutilizar conexiones
```python
from data.airflow.plugins.approval_cleanup_ops import get_pg_hook

# El plugin maneja connection pooling
pg_hook = get_pg_hook()  # Reutiliza conexiones
```

‚ùå **Malo**: Nueva conexi√≥n por query
```python
def ejecutar_query(sql):
    hook = PostgresHook(postgres_conn_id="db")  # Nueva conexi√≥n cada vez
    return hook.get_records(sql)
```

### 3. Caching

‚úÖ **Bueno**: Cachear resultados costosos
```python
from functools import lru_cache

@lru_cache(maxsize=1)
def get_config():
    # Carga configuraci√≥n una vez
    return load_config()
```

‚ùå **Malo**: Cargar cada vez
```python
def get_config():
    # Carga desde archivo cada vez
    return load_config()
```

### 4. Timeouts Apropiados

‚úÖ **Bueno**: Timeouts configurados
```python
@task(execution_timeout=timedelta(hours=2))
def tarea_larga():
    # Tarea que puede tardar
    pass
```

‚ùå **Malo**: Sin timeout
```python
@task
def tarea_larga():
    # Puede colgar indefinidamente
    pass
```

---

## üîí Mejores Pr√°cticas de Seguridad

### 1. Secrets Management

‚úÖ **Bueno**: Usar Airflow Connections
```python
from airflow.providers.postgres.hooks.postgres import PostgresHook

hook = PostgresHook(postgres_conn_id="my_db")  # Secret en Airflow
```

‚ùå **Malo**: Credenciales en c√≥digo
```python
password = "my_secret_password"  # ‚ùå NUNCA hacer esto
```

### 2. Validaci√≥n de Inputs

‚úÖ **Bueno**: Validar inputs
```python
def procesar_datos(datos: List[Dict]) -> None:
    if not datos:
        raise ValueError("Datos no pueden estar vac√≠os")
    if not isinstance(datos, list):
        raise TypeError("Datos debe ser una lista")
    # Procesar
```

‚ùå **Malo**: Sin validaci√≥n
```python
def procesar_datos(datos):
    # Asume que datos es v√°lido
    for item in datos:
        procesar(item)
```

### 3. Queries Parametrizadas

‚úÖ **Bueno**: Queries parametrizadas
```python
sql = "SELECT * FROM tabla WHERE id = %s"
hook.get_records(sql, parameters=(user_id,))
```

‚ùå **Malo**: String formatting (SQL injection)
```python
sql = f"SELECT * FROM tabla WHERE id = {user_id}"  # ‚ùå Vulnerable
```

---

## üö´ Anti-Patrones

### 1. Variables Globales

‚ùå **Malo**:
```python
# Variables globales
BATCH_SIZE = 1000
CONFIG = load_config()

@task
def procesar():
    global BATCH_SIZE  # ‚ùå Evitar
    BATCH_SIZE = 2000
```

‚úÖ **Bueno**:
```python
@task
def procesar():
    config = get_config()
    batch_size = config['batch_size']
    # Usar localmente
```

### 2. Efectos Secundarios en Tareas

‚ùå **Malo**:
```python
@task
def procesar():
    # Modifica estado global
    global_counter += 1
    # Escribe a archivos del sistema
    open('/tmp/data.txt', 'w').write('data')
```

‚úÖ **Bueno**:
```python
@task
def procesar():
    # Retorna resultado, no modifica estado
    result = compute()
    return result
```

### 3. Dependencias Circulares

‚ùå **Malo**:
```python
task1 = tarea1(task2)  # task1 depende de task2
task2 = tarea2(task1)  # task2 depende de task1 (circular!)
```

‚úÖ **Bueno**:
```python
# Dise√±ar flujo lineal o en √°rbol
data = extract()
transformed = transform(data)
loaded = load(transformed)
```

### 4. C√≥digo Duplicado

‚ùå **Malo**:
```python
# Misma funci√≥n en m√∫ltiples DAGs
def get_pg_hook():
    return PostgresHook(postgres_conn_id="db")
```

‚úÖ **Bueno**:
```python
# En plugin reutilizable
from data.airflow.plugins.approval_cleanup_ops import get_pg_hook
```

---

## üìö Referencias

- [`docs/DESARROLLO.md`](./DESARROLLO.md) - Gu√≠a de desarrollo completa
- [`docs/EJEMPLOS_PRACTICOS.md`](./EJEMPLOS_PRACTICOS.md) - Ejemplos pr√°cticos
- [Airflow Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)

---

**Versi√≥n**: 1.0 | **Estado**: Producci√≥n Ready ‚úÖ  
**Mantenido por**: platform-team  
**√öltima actualizaci√≥n**: 2024

