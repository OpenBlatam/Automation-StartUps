# Carruseles Redes Sociales ‚Äî Versi√≥n Final Optimizada

> 3 productos: Curso IA + Webinars | SaaS IA Marketing | IA Bulk Docs  
> Formato: 3 slides por carrusel (1080√ó1080 px)  
> Listo para dise√±o y publicaci√≥n

---

## üéØ Carrusel 1: Curso de IA + Webinars

### Slide 1: Cliente feliz usando producto
**Titular (H1 68-76px)**: "Domina IA aplicada en semanas"  
**Subcopy (30-34px)**: "Clases pr√°cticas + webinars en vivo + casos reales"  
**Micro-pruebas**: "Certificado ‚Ä¢ Mentor√≠a ‚Ä¢ Comunidad"  
**Visual sugerido**: Alumno con laptop, UI de clase/webinar en pantalla, iconos de play/diagrama IA, sello "Certificado"

### Slide 2: Cita del cliente (tipograf√≠a elegante)
**Cita (Serif 48-56px)**: "Desde que uso el Curso de IA + Webinars mis entregas son 2√ó m√°s r√°pidas"  
**Atribuci√≥n (Sans Regular 24-28px)**: "‚Äî Sof√≠a, Project Manager"  
**Visual**: Comillas grandes elegantes, fondo limpio con patr√≥n sutil de marca al 8-12% opacidad

### Slide 3: CTA + Logo
**CTA principal (Bot√≥n 72-84px alto)**: "√önete ahora"  
**Refuerzo (24-28px)**: "Cupos limitados ‚Ä¢ Inicio este mes"  
**Visual**: Bot√≥n s√≥lido color acento (#22C55E), sombra sutil, logo en esquina inferior derecha (m√≠nimo 48px)

---

**Caption lista para pegar**:
```
Aprende IA aplicada con clases guiadas y webinars en vivo. 
Casos reales de HubSpot, Make, ActiveCampaign y m√°s. 
Mentor√≠a, certificado y comunidad para acelerar tu carrera. 
Inscr√≠bete hoy.
```

**Hashtags**:
`#InteligenciaArtificial #Webinars #Upskilling #Certificaci√≥n #CarreraDigital #MarTech`

**Alt text**:
"Alumno en plataforma de IA con clase en vivo; cita de mejora de productividad; bot√≥n √önete ahora con logo."

**UTM sugerido**:
```
?utm_source=instagram&utm_medium=carrusel&utm_campaign=curso_ia_webinars_2025-11&utm_content=slide{n}
```

---

## üìä Carrusel 2: SaaS de IA para Marketing

### Slide 1: Cliente feliz usando producto
**Titular**: "Campa√±as que se optimizan solas"  
**Subcopy**: "Genera creatividades, segmenta y reporta con IA"  
**Micro-pruebas**: "A/B testing ‚Ä¢ Lookalikes ‚Ä¢ ROI en tiempo real"  
**Visual**: Marketer frente a dashboard con KPIs al alza, tarjetas de anuncios, badges "A/B", "ROI+", "Segmentaci√≥n"

### Slide 2: Cita del cliente
**Cita**: "Desde que uso el SaaS de IA Marketing mis conversiones subieron 34%*"  
**Atribuci√≥n**: "‚Äî Diego, CMO"  
**Nota**: Asterisco con disclaimer "*Resultados pueden variar seg√∫n caso"

### Slide 3: CTA + Logo
**CTA**: "Pru√©balo gratis"  
**Refuerzo**: "Demo en 3 minutos ‚Ä¢ De brief a resultados"  
**Visual**: Bot√≥n acento, badges de integraciones (HubSpot, Meta Ads, Google), logo esquina

---

**Caption lista para pegar**:
```
Automatiza creatividad, segmentaci√≥n y reporting con IA. 
Integra con HubSpot, ActiveCampaign, Meta Ads y m√°s. 
Ahorra horas semanales y escala lo que funciona. 
Activa tu prueba gratuita.
```

**Hashtags**:
`#MarTech #Growth #Ads #Automatizaci√≥n #IAparaMarketing #ROI #HubSpot`

**Alt text**:
"Dashboard de marketing con m√©tricas ascendentes y tarjetas de anuncios; testimonio de mejora de conversiones; CTA Pru√©balo gratis con logo."

**UTM sugerido**:
```
?utm_source=instagram&utm_medium=carrusel&utm_campaign=saas_ia_marketing_2025-11&utm_content=slide{n}
```

---

## üìÑ Carrusel 3: IA Bulk (Documentos con 1 consulta)

### Slide 1: Cliente feliz usando producto
**Titular**: "Crea 100+ documentos con 1 consulta"  
**Subcopy**: "Brief √∫nico ‚Üí contratos, manuales, propuestas"  
**Micro-pruebas**: "Plantillas ‚Ä¢ Versionado ‚Ä¢ Export PDF/DOCX"  
**Visual**: Usuario disparando flujo, pila de documentos gener√°ndose, barra de progreso, iconos de formatos (PDF, DOCX)

### Slide 2: Cita del cliente
**Cita**: "Desde que uso IA Bulk mis entregables salen 10√ó m√°s r√°pido*"  
**Atribuci√≥n**: "‚Äî Laura, Consultora"  
**Nota**: Asterisco con disclaimer

### Slide 3: CTA + Logo
**CTA**: "Solicita demo"  
**Refuerzo**: "Estandariza, escala y controla cambios"  
**Visual**: Iconos de formatos, bot√≥n con borde, checkmarks, logo inferior derecho

---

**Caption lista para pegar**:
```
Estandariza documentaci√≥n a escala. 
Define una consulta y genera lotes consistentes 
con plantillas editables y control de versiones. 
Integra con tu CRM (HubSpot, Pipedrive, Close). 
Agenda tu demo.
```

**Hashtags**:
`#Productividad #Docs #Automatizaci√≥n #IA #Operaciones #CRM`

**Alt text**:
"Generaci√≥n masiva de documentos desde una consulta; barra de progreso y archivos; CTA Solicita demo con logo."

**UTM sugerido**:
```
?utm_source=instagram&utm_medium=carrusel&utm_campaign=ia_bulk_docs_2025-11&utm_content=slide{n}
```

---

## üé® Gu√≠a Visual Unificada (para los 3 carruseles)

### Colores de Marca (tokens)
- **Primario**: `#1E3A8A` (azul corporativo)
- **Secundario**: `#0EA5E9` (azul claro/cielo)
- **Acento CTA**: `#22C55E` (verde acci√≥n)
- **Neutro 900**: `#0B1220` (texto oscuro)
- **Neutro 600**: `#64748B` (texto secundario)
- **Neutro 050**: `#F1F5F9` (fondo claro)
- **Overlay quote marks**: Primario al 12% opacidad

### Tipograf√≠as
- **Titulares (H1)**: Sans geom√©trica Bold (Poppins/Inter) ‚Äî 68-76px
- **Citas**: Serif elegante Display (DM Serif/Playfair Display) ‚Äî 48-56px
- **Cuerpo/CTA**: Sans legible Regular (Inter) ‚Äî 30-34px
- **Microcopy**: Sans Regular ‚Äî 24-28px

### Layout y Espaciado
- **Tama√±o**: 1080√ó1080 px (square), variantes 1080√ó1350 (feed) y 1080√ó1920 (stories)
- **Margen**: 72 px
- **Grid**: 12 columnas, gutter 24 px
- **Safe area interno**: 84 px (square), 100 px (feed), 120 px (stories)
- **Logo m√≠nimo**: 48 px alto, margen 48 px de bordes
- **Bot√≥n CTA**: 72-84 px alto, radio 12-16 px, sombra sutil

### Accesibilidad
- **Contraste m√≠nimo**: AA (‚â•4.5:1 para texto normal, ‚â•7:1 para CTA)
- **Tama√±os m√≠nimos**: H1 ‚â•64px, Cita ‚â•48px, Cuerpo ‚â•32px
- **Jerarqu√≠a**: 1 idea fuerte por slide, m√°ximo 14 palabras
- **Alt text**: Incluir por cada slide (ya incluidos arriba)

### Export
- **Formato**: PNG sRGB, <1.2MB por archivo
- **Nombres**:
  - `carrusel-curso-ia-v1-s1-1080.png` (slide 1, 2, 3)
  - `carrusel-saas-marketing-v1-s1-1080.png`
  - `carrusel-ia-bulk-v1-s1-1080.png`
- **Variantes**: Agregar sufijo `-1080x1350` o `-1080x1920` seg√∫n tama√±o
- **M√°ster editable**: Guardar en Figma/PSD con estilos y componentes reutilizables

---

## üîÑ Variantes A/B (test r√°pido)

### Curso IA
- **Titular A**: "Domina IA en semanas" (directo)
- **Titular B**: "Aprende IA aplicada hoy" (inmediato)
- **CTA A**: "√önete ahora" (acci√≥n)
- **CTA B**: "Reserva tu plaza" (escasa)

### SaaS Marketing
- **Titular A**: "Campa√±as que se optimizan solas" (beneficio)
- **Titular B**: "+34% conversiones con IA" (data)
- **CTA A**: "Pru√©balo gratis" (bajo fricci√≥n)
- **CTA B**: "Solicita demo" (calificado)

### IA Bulk
- **Titular A**: "Crea 100+ documentos con 1 consulta" (volumen)
- **Titular B**: "Estandariza documentaci√≥n en minutos" (velocidad)
- **CTA A**: "Solicita demo" (B2B)
- **CTA B**: "Prueba gratuita" (B2C)

---

## üìã Checklist de QA (antes de publicar)

- [ ] Texto: ‚â§14 palabras/slide, 1 idea clara, sin errores ortogr√°ficos
- [ ] Tipograf√≠a: H1 ‚â•68px, Cita ‚â•48px, Cuerpo ‚â•32px
- [ ] Contraste: AA m√≠nimo (verificar con herramienta), CTA ‚â•7:1
- [ ] Logo: ‚â•48px, posici√≥n consistente (esquina inferior derecha S3)
- [ ] CTA: Visible y claro en slide 3, bot√≥n con buen contraste
- [ ] Safe area: Respeta m√°rgenes (84px square, 120px stories)
- [ ] Export: PNG sRGB, tama√±o <1.2MB, nombres seg√∫n convenci√≥n
- [ ] UTM: Enlaces incluyen par√°metros correctos (`utm_source`, `utm_medium`, `utm_campaign`, `utm_content=slide{n}`)
- [ ] Alt text: Incluido y descriptivo por slide
- [ ] Caption: Lista con hashtags y CTA claro
- [ ] Modo oscuro: Variante disponible si aplica (fondo `#0B1220`, texto `#FFFFFF`)

---

## üìä Matriz de nombres de archivos = utm_content

Para tracking preciso, usa estos nombres de archivos que coinciden con `utm_content`:

| Carrusel | Slide | Filename sugerido | utm_content |
|----------|-------|-------------------|-------------|
| Curso IA | 1 | `curso_ia_s1_cliente_v1.png` | `curso_ia_s1_cliente_v1` |
| Curso IA | 2 | `curso_ia_s2_cita_v1.png` | `curso_ia_s2_cita_v1` |
| Curso IA | 3 | `curso_ia_s3_cta_v1.png` | `curso_ia_s3_cta_v1` |
| SaaS Marketing | 1 | `saas_marketing_s1_dashboard_v1.png` | `saas_marketing_s1_dashboard_v1` |
| SaaS Marketing | 2 | `saas_marketing_s2_testimonio_v1.png` | `saas_marketing_s2_testimonio_v1` |
| SaaS Marketing | 3 | `saas_marketing_s3_cta_v1.png` | `saas_marketing_s3_cta_v1` |
| IA Bulk | 1 | `ia_bulk_s1_generacion_v1.png` | `ia_bulk_s1_generacion_v1` |
| IA Bulk | 2 | `ia_bulk_s2_cita_v1.png` | `ia_bulk_s2_cita_v1` |
| IA Bulk | 3 | `ia_bulk_s3_cta_v1.png` | `ia_bulk_s3_cta_v1` |

---

## üöÄ Pr√≥ximos pasos

1. **Dise√±o**: Crear artes en Figma/PSD siguiendo gu√≠a visual
2. **QA**: Revisar checklist completo
3. **Export**: Generar PNGs en 3 tama√±os (1080√ó1080, 1080√ó1350, 1080√ó1920)
4. **Tracking**: Configurar UTMs en enlaces y shortlinks (Bitly/Yourls)
5. **CRM**: Mapear campos UTM en HubSpot/Pipedrive/ActiveCampaign seg√∫n `TOOLS_CRM_COMPARISON.md`
6. **Publicaci√≥n**: Calendario sugerido (1 carrusel por semana, rotar d√≠as)
7. **Medici√≥n**: KPIs: CTR slide, taps CTA, saves, replies, atribuci√≥n por `utm_content`

---

## üìù Notas adicionales

- **Integraciones mencionadas**: HubSpot, ActiveCampaign, Make, Pipedrive, Close (referencia `TOOLS_CRM_COMPARISON.md`)
- **Cumplimiento**: Asteriscos en m√©tricas (*Resultados pueden variar)
- **Multiformato**: Preparar variantes para Stories (1080√ó1920) con texto vertical
- **Localizaci√≥n**: Si aplica, versionar a EN/ES seg√∫n mercado

---

## üé¨ Prompts para Generaci√≥n de Im√°genes (Midjourney/DALL¬∑E/Stable Diffusion)

### Curso IA + Webinars ‚Äî Slide 1
```
Professional modern workspace, young professional with laptop, 
webinar UI overlay with video call interface, soft brand blues (#1E3A8A, #0EA5E9), 
minimal clean tech aesthetic, high-key lighting, certificate badge visible, 
1080x1080, professional, high contrast, sleek UI details, modern office background
```

**Variante dark mode**:
```
Dark modern workspace (#0B1220 background), professional with laptop, 
webinar UI with glowing accents (#0EA5E9), certificate badge highlighted, 
minimal tech, cinematic lighting, 1080x1080
```

### SaaS IA Marketing ‚Äî Slide 1
```
Sleek analytics dashboard, rising charts and graphs, ad cards grid layout, 
teal and blue accents (#0EA5E9, #22C55E), glossy SaaS UI, modern office setting, 
marketer viewing screen, badges showing "A/B", "ROI+", "Segmentaci√≥n", 
1080x1080, crisp typography placeholders, professional, high detail
```

**Variante abstracta**:
```
Abstract data visualization, flowing graphs ascending, 
blue to green gradient (#1E3A8A to #22C55E), minimal geometric shapes, 
clean tech aesthetic, 1080x1080, professional
```

### IA Bulk Docs ‚Äî Slide 1
```
Document generation pipeline visual, stacked PDF and DOCX icons, 
progress bar at 75%, green accent CTA button (#22C55E), 
minimal tech aesthetic, clean workspace, user interface showing file generation, 
1080x1080, subtle depth shadows, professional, high contrast
```

**Variante isom√©trica**:
```
Isometric view of document factory, conveyor belt with documents, 
clean modern design, brand colors (#1E3A8A, #22C55E), 
1080x1080, professional illustration style
```

---

## üéôÔ∏è Guiones de Voz para Reels (15-30 segundos)

### Curso IA + Webinars
**Duraci√≥n**: 20 segundos  
**Tono**: Motivacional, claro

```
[0-3s] "¬øQuieres dominar IA aplicada sin saber programar?"

[3-8s] "En semanas, no meses. Clases pr√°cticas, webinars en vivo 
y casos reales de HubSpot, Make y ActiveCampaign."

[8-15s] "Mentor√≠a, certificado y comunidad. Todo lo que necesitas 
para acelerar tu carrera con IA."

[15-20s] "Inscr√≠bete hoy. Link en bio."
```

**M√∫sica sugerida**: Upbeat tech, instrumental, 120-130 BPM

### SaaS IA Marketing
**Duraci√≥n**: 25 segundos  
**Tono**: Confiado, data-driven

```
[0-4s] "Tus campa√±as se optimizan solas. Con IA."

[4-12s] "Genera creatividades, segmenta audiencias y reporta resultados 
en minutos. Integra con HubSpot, Meta Ads, Google."

[12-20s] "Ahorra horas semanales. Escala lo que funciona. 
Conversiones subieron 34% en promedio."

[20-25s] "Pru√©balo gratis. Link en bio."
```

**M√∫sica sugerida**: Corporate tech, upbeat, 125 BPM

### IA Bulk Docs
**Duraci√≥n**: 18 segundos  
**Tono**: Eficiente, directo

```
[0-3s] "Crea 100+ documentos con una sola consulta."

[3-10s] "Brief √∫nico. Contratos, manuales, propuestas. 
Todo estandarizado, versionado y listo."

[10-15s] "Integra con tu CRM. Ahorra horas. 
Entrega 10√ó m√°s r√°pido."

[15-18s] "Solicita demo. Link en bio."
```

**M√∫sica sugerida**: Minimal tech, subtle, 110 BPM

---

## üìù Scripts de Automatizaci√≥n CRM (Make/Zapier)

### Flujo: Carrusel Click ‚Üí CRM (crear contacto + asignar)

**Trigger**: Click en shortlink (Bitly/Yourls webhook)  
**Condiciones**: 
- `utm_campaign` contiene `curso_ia` o `saas_marketing` o `ia_bulk`
- `utm_medium` = `carrusel`

**Actions**:

1. **Buscar/Crear Contacto** (HubSpot/Pipedrive/ActiveCampaign)
   ```json
   {
     "email": "{{email_from_query_or_cookie}}",
     "firstname": "{{firstname_if_available}}",
     "utm_source": "{{utm_source}}",
     "utm_medium": "{{utm_medium}}",
     "utm_campaign": "{{utm_campaign}}",
     "utm_content": "{{utm_content}}",
     "utm_term": "{{utm_term}}",
     "last_utm_source": "{{utm_source}}",
     "last_utm_medium": "{{utm_medium}}",
     "last_utm_campaign": "{{utm_campaign}}"
   }
   ```

2. **Si no existe `first_utm_*`**, setear:
   ```
   first_utm_source = utm_source
   first_utm_medium = utm_medium
   first_utm_campaign = utm_campaign
   first_utm_content = utm_content
   ```

3. **Asignar owner por producto**:
   - Si `utm_campaign` contiene `curso_ia` ‚Üí owner: `equipo_educacion`
   - Si contiene `saas_marketing` ‚Üí owner: `equipo_marketing`
   - Si contiene `ia_bulk` ‚Üí owner: `equipo_producto`

4. **Crear tarea/actividad**:
   - T√≠tulo: "Follow-up carrusel [utm_content]"
   - Fecha: +2 horas h√°biles
   - Tipo: "Email" o "Llamada" seg√∫n scoring

**Nota**: Ver ejemplos API en `TOOLS_CRM_COMPARISON.md` secci√≥n [Ejemplos API/Payload](#ejemplos-apipayload-por-crm-listos-para-pegar)

---

## üéØ Variantes por Audiencia/Industria

### Curso IA ‚Äî Variantes por rol

**Para Project Managers**:
- S1: "IA para PMs: automatiza seguimiento y reportes"
- S2: "De caos a control en semanas"
- S3: "√önete ahora" ‚Ä¢ "Cupos limitados"

**Para Marketers**:
- S1: "IA aplicada a marketing: campa√±as que escalan"
- S2: "HubSpot + Make + IA = resultados reales"
- S3: "Reserva tu plaza"

**Para Developers**:
- S1: "IA sin c√≥digo: integraciones y automatizaci√≥n"
- S2: "API, webhooks y workflows en minutos"
- S3: "Empieza hoy"

### SaaS Marketing ‚Äî Variantes por tama√±o empresa

**Startups (1-10 personas)**:
- S1: "Marketing automatizado para equipos peque√±os"
- S2: "Sin equipo, sin problemas. IA hace el trabajo"
- S3: "Pru√©balo gratis" ‚Ä¢ "Sin tarjeta"

**SMB (10-50 personas)**:
- S1: "Escala tu marketing sin contratar"
- S2: "Ahorra 20+ horas semanales en ejecuci√≥n"
- S3: "Solicita demo"

**Enterprise (50+ personas)**:
- S1: "IA que integra con tu stack existente"
- S2: "HubSpot, Salesforce, Meta Ads. Todo conectado"
- S3: "Habla con ventas"

### IA Bulk ‚Äî Variantes por industria

**Legal/Consultor√≠a**:
- S1: "Contratos y propuestas consistentes"
- S2: "Estandariza sin perder personalizaci√≥n"
- S3: "Solicita demo"

**Real Estate**:
- S1: "Documentaci√≥n inmobiliaria en minutos"
- S2: "Contratos, fichas y reportes autom√°ticos"
- S3: "Prueba gratuita"

**Educaci√≥n**:
- S1: "Manuales y materiales a escala"
- S2: "Una consulta ‚Üí 100+ documentos personalizados"
- S3: "Ver casos de uso"

---

## üåê Plantillas de Landing Pages (HTML/Copy)

### Landing: Curso IA + Webinars

**H1**: "Domina IA aplicada en semanas"  
**Subhead**: "Clases pr√°cticas, webinars en vivo y casos reales de HubSpot, Make y ActiveCampaign"

**Secci√≥n beneficios** (3 columnas):
1. "Certificado oficial" ‚Äî "V√°lido en tu perfil LinkedIn"
2. "Mentor√≠a personalizada" ‚Äî "Sesiones 1:1 con expertos"
3. "Comunidad activa" ‚Äî "Acceso permanente al grupo"

**CTA principal**: "√önete ahora ‚Äî Cupos limitados"  
**CTA secundario**: "Ver temario completo"

**Formulario campos**:
- Email (required)
- Nombre (required)
- Empresa (optional)
- Rol (dropdown: PM, Marketer, Developer, Otro)
- UTMs ocultos (auto-llenar desde query string)

**Script UTM capture** (JavaScript):
```javascript
// Captura UTMs y los a√±ade como hidden fields
const urlParams = new URLSearchParams(window.location.search);
['utm_source', 'utm_medium', 'utm_campaign', 'utm_content', 'utm_term'].forEach(param => {
  const value = urlParams.get(param) || 'direct';
  const field = document.getElementById(`form_${param}`);
  if (field) field.value = value;
});
```

**UTM tracking**:
```
?utm_source=instagram&utm_medium=carrusel&utm_campaign=curso_ia_webinars_2025-11&utm_content=slide{n}&utm_term=landing_form
```

---

### Landing: SaaS IA Marketing

**H1**: "Campa√±as que se optimizan solas"  
**Subhead**: "Genera creatividades, segmenta audiencias y reporta con IA. Integra con HubSpot, ActiveCampaign, Meta Ads."

**Secci√≥n integraciones** (logos):
- HubSpot, ActiveCampaign, Meta Ads, Google Ads, Pipedrive, Close

**Prueba social**:
- "34% m√°s conversiones en promedio (casos reales)"
- Logos de clientes (si aplica)

**CTA principal**: "Pru√©balo gratis ‚Äî Demo en 3 minutos"  
**CTA secundario**: "Ver casos de uso"

**Formulario campos**:
- Email (required)
- Nombre (required)
- Empresa (required)
- Integraciones actuales (checkboxes: HubSpot, ActiveCampaign, etc.)
- UTMs ocultos

---

### Landing: IA Bulk Docs

**H1**: "Crea 100+ documentos con 1 consulta"  
**Subhead**: "Estandariza documentaci√≥n a escala. Plantillas, versionado y export PDF/DOCX."

**Demo interactivo** (si aplica):
- Input de ejemplo: "Genera propuesta para [cliente] en [industria]"
- Output simulado: Muestra 3-4 documentos generados

**Integraciones CRM**:
- "Conecta con HubSpot, Pipedrive, Close y m√°s"

**CTA principal**: "Solicita demo ‚Äî 15 minutos"  
**CTA secundario**: "Descargar plantillas gratuitas"

**Formulario campos**:
- Email (required)
- Nombre (required)
- Empresa (required)
- Casos de uso (checkboxes: Contratos, Manuales, Propuestas, Otro)
- UTMs ocultos

---

## üì± Variantes para Stories (1080√ó1920)

### Estructura vertical (3-5 frames)

**Frame 1 (Hook, 0-2s)**:
- Titular grande (80-90px): "Domina IA en semanas"
- Fondo: Gradiente marca o imagen producto

**Frame 2 (Beneficio, 2-4s)**:
- Bullets grandes (50-60px):
  - "Clases pr√°cticas"
  - "Webinars en vivo"
  - "Certificado"

**Frame 3 (Prueba social, 4-6s)**:
- Cita (60-70px): "2√ó m√°s r√°pidas"
- Atribuci√≥n (30-32px): "‚Äî Sof√≠a, PM"

**Frame 4 (CTA, 6-8s)**:
- CTA grande (70-80px): "√önete ahora"
- Subcopy (32-34px): "Cupos limitados"
- Bot√≥n destacado + swipe up

**Text overlay en todos**: Usar tipograf√≠a bold, contraste alto, safe area 120px desde bordes

---

## üîî Notificaciones Push/Email (triggers post-carrusel)

### Email 1: Bienvenida (inmediato tras click)

**Asunto**: "Bienvenido/a ‚Äî [Nombre del carrusel]"  
**From**: "Equipo [Tu Marca]"

**Cuerpo**:
```
Hola [Nombre],

Gracias por tu inter√©s en [Producto].

Basado en lo que viste:
‚Üí [Beneficio espec√≠fico del slide]
‚Üí [Caso de uso relevante]
‚Üí [Pr√≥ximo paso claro]

[CTA principal: bot√≥n verde]
[CTA secundario: "Ver casos de uso"]

¬øPreguntas? Responde este email.

‚Äî
Equipo [Tu Marca]
```

**UTM tracking**: Incluir `utm_medium=email&utm_campaign=welcome_carrusel`

### Email 2: Recordatorio (24 horas despu√©s, si no converti√≥)

**Asunto**: "Te esperamos ‚Äî [Oferta/escasez]"  
**From**: "Equipo [Tu Marca]"

**Cuerpo**:
```
Hola [Nombre],

Ayer viste nuestro carrusel sobre [Tema].

Quedan [X] cupos / [X] d√≠as para [Oferta].

‚Üí [Recordatorio del beneficio principal]
‚Üí [Testimonio corto]
‚Üí [CTA con urgencia]

[CTA principal]
[Link para cancelar suscripci√≥n]

‚Äî
Equipo [Tu Marca]
```

---

## üìä Dashboard de M√©tricas (KPIs por carrusel)

### M√©tricas principales

1. **Engagement**:
   - Impresiones por slide
   - Tiempo de visualizaci√≥n promedio
   - Porcentaje que lleg√≥ al slide 3 (CTA)

2. **Conversi√≥n**:
   - CTR por slide (taps/clicks)
   - CTR total del carrusel
   - Tasa de conversi√≥n slide 3 ‚Üí landing

3. **Atribuci√≥n UTM**:
   - Leads por `utm_content` (slide espec√≠fico)
   - Tasa de conversi√≥n por `utm_content`
   - ROI por `utm_campaign`

4. **Comparativa A/B**:
   - CTR Variante A vs Variante B
   - Tasa conversi√≥n A vs B
   - Tiempo en carrusel A vs B

### F√≥rmulas Sheets (ejemplo)

**CTR por slide**:
```
=IFERROR(Taps_slide{n}/Impresiones_slide{n}, 0)
```

**Tasa conversi√≥n carrusel**:
```
=IFERROR(Conversiones_total/Impresiones_total, 0)
```

**ROI por campa√±a**:
```
=IFERROR((Ingresos_campa√±a - Costo_campa√±a)/Costo_campa√±a, 0)
```

**Reporte sugerido**: Crear en Google Sheets/Excel con conexi√≥n a API de Instagram/Facebook (Meta Business) y CRM (HubSpot/Pipedrive via API)

---

## üé® Componentes Figma (estructura sugerida)

### Estilos de texto
- `Text/H1/Carrusel` ‚Äî Poppins Bold 72px, color `#0B1220`
- `Text/Quote/Carrusel` ‚Äî Playfair Display 52px, color `#1E3A8A`
- `Text/Body/Carrusel` ‚Äî Inter Regular 32px, color `#0B1220`
- `Text/Microcopy/Carrusel` ‚Äî Inter Regular 26px, color `#64748B`

### Estilos de color
- `Color/Brand/Primary` ‚Äî `#1E3A8A`
- `Color/Brand/Secondary` ‚Äî `#0EA5E9`
- `Color/Brand/Accent` ‚Äî `#22C55E`
- `Color/Neutral/900` ‚Äî `#0B1220`
- `Color/Neutral/600` ‚Äî `#64748B`
- `Color/Neutral/050` ‚Äî `#F1F5F9`

### Componentes
- `CTA/Button/Primary` ‚Äî Alto 84px, radio 16px, fondo `#22C55E`, texto blanco
- `CTA/Button/Outline` ‚Äî Alto 84px, radio 16px, borde `#22C55E`, texto `#22C55E`
- `Block/Quote` ‚Äî Comillas grandes, cita serif, atribuci√≥n sans
- `Badge/Metric` ‚Äî Fondo `#F1F5F9`, texto `#0B1220`, radio 8px
- `Logo/Lockup` ‚Äî Variante claro/oscuro, m√≠nimo 48px alto

### Auto Layout
- Frames con Auto Layout horizontal/vertical
- Padding consistente (24px, 48px, 72px seg√∫n secci√≥n)
- Constraints: Left & Right, Top & Bottom para responsive

---

## üîó Shortlinks con Tracking (Bitly/Yourls)

### Estructura recomendada

**Formato**: `bit.ly/[marca]-[producto]-[slide]-[version]`

Ejemplos:
- `bit.ly/blatam-curso-ia-s1-v1`
- `bit.ly/blatam-saas-mkt-s3-v1`
- `bit.ly/blatam-ia-bulk-s2-v1`

**URL destino con UTMs**:
```
https://tusitio.com/landing-producto?
utm_source=instagram
&utm_medium=carrusel
&utm_campaign=curso_ia_webinars_2025-11
&utm_content=slide1_v1
&utm_term=shortlink_click
```

### Webhook Bitly ‚Üí CRM (Make/Zapier)

**Event**: `link_click`  
**Payload** (simplificado):
```json
{
  "event": "link_click",
  "bitlink": "bit.ly/blatam-curso-ia-s1-v1",
  "link": {
    "long_url": "https://tusitio.com/landing?utm_source=instagram&utm_medium=carrusel&..."
  },
  "user_agent": "...",
  "referer": "instagram.com"
}
```

**Acci√≥n Make/Zapier**:
1. Parsear `long_url` ‚Üí extraer UTMs
2. Buscar contacto por email (si disponible en query)
3. Actualizar `last_utm_*` en CRM
4. Crear actividad/nota con timestamp

**Referencia**: Ver `TOOLS_CRM_COMPARISON.md` secci√≥n [Webhooks Shortlinks ‚Üí Make/Zap](#webhooks-shortlinks--makezap-actualizar-last_utm_)

---

## üìÖ Calendario de Publicaci√≥n (4 semanas)

### Semana 1
- **Lunes**: Curso IA (feed)
- **Mi√©rcoles**: Stories Curso IA (hook + CTA)
- **Viernes**: Reel Curso IA (guion de voz)

### Semana 2
- **Martes**: SaaS Marketing (feed)
- **Jueves**: Stories SaaS Marketing
- **S√°bado**: Reel SaaS Marketing

### Semana 3
- **Lunes**: IA Bulk (feed)
- **Mi√©rcoles**: Stories IA Bulk
- **Viernes**: Reel IA Bulk

### Semana 4
- **A/B Test**: Publicar variantes de mejor rendimiento
- **An√°lisis**: Revisar m√©tricas y ajustar

**Horarios sugeridos** (zona horaria MX):
- Feed: 8:00 AM, 12:00 PM, 6:00 PM
- Stories: 10:00 AM, 2:00 PM, 8:00 PM
- Reels: 9:00 AM, 1:00 PM, 7:00 PM

---

## üß™ Tests A/B Espec√≠ficos (hip√≥tesis y m√©tricas)

### Test 1: Titular directo vs cuantificado

**Hip√≥tesis**: Los titulares con datos cuantificados generan m√°s clicks que los directos

**Variantes**:
- A: "Domina IA en semanas" (directo)
- B: "Domina IA 2√ó m√°s r√°pido" (cuantificado)

**M√©trica**: CTR slide 1

**Duraci√≥n**: 7 d√≠as, m√≠nimo 1000 impresiones por variante

### Test 2: CTA acci√≥n vs escasez

**Hip√≥tesis**: CTAs con urgencia (cupos limitados) generan m√°s conversiones

**Variantes**:
- A: "√önete ahora" (acci√≥n)
- B: "√önete ahora ‚Ä¢ Cupos limitados" (acci√≥n + escasez)

**M√©trica**: Tasa conversi√≥n slide 3 ‚Üí landing

**Duraci√≥n**: 7 d√≠as

### Test 3: Visual persona vs UI

**Hip√≥tesis**: Im√°genes con personas generan m√°s engagement que solo UI

**Variantes**:
- A: Persona usando producto
- B: Solo UI/dashboard limpio

**M√©trica**: Tiempo de visualizaci√≥n promedio

**Duraci√≥n**: 7 d√≠as

---

## üìö Recursos Adicionales

### Herramientas recomendadas
- **Dise√±o**: Figma (gratis), Adobe Express (alternativa)
- **Generaci√≥n im√°genes**: Midjourney, DALL¬∑E 3, Stable Diffusion
- **Video editing**: CapCut (gratis), Final Cut Pro, Premiere
- **Tracking**: Google Analytics 4, Meta Events Manager, Bitly
- **CRM**: HubSpot (free tier), Pipedrive, ActiveCampaign (ver `TOOLS_CRM_COMPARISON.md`)

### Documentos relacionados
- `TOOLS_CRM_COMPARISON.md` ‚Äî Integraciones y mapeos CRM
- `UTM_GUIDE_OUTREACH.md` (si existe) ‚Äî Convenciones UTM
- `SHORTLINKS_UTM_SAMPLE.csv` (si existe) ‚Äî Ejemplos shortlinks

### Comunidades y aprendizaje
- Instagram @creadores (tips dise√±o)
- YouTube "Social Media Marketing" (tendencias)
- HubSpot Academy (certificaciones gratuitas)

---

## üîß Troubleshooting Com√∫n y Soluciones

### Problema: CTR bajo (<1%)

**Diagn√≥stico**:
- Revisar contraste texto/fondo (herramienta: WebAIM Contrast Checker)
- Verificar que CTA sea visible (tama√±o ‚â•72px, color acento)
- Analizar tiempo promedio en slide 1 (si <2s, hook d√©bil)

**Soluciones**:
1. **A/B test** del titular (directo vs beneficio)
2. **Aumentar tama√±o** del CTA (84px ‚Üí 96px)
3. **Agregar animaci√≥n sutil** (fade-in del CTA en slide 3)
4. **Simplificar copy** (reducir a ‚â§10 palabras por slide)

### Problema: Bajo engagement en Stories

**Diagn√≥stico**:
- Texto muy peque√±o o fuera de safe area (120px desde bordes)
- M√∫ltiples frames sin hook claro (‚â•3s antes de beneficio)

**Soluciones**:
1. **Aumentar tama√±o** de texto (H1: 90-100px en stories)
2. **Reducir frames** a 3-4 m√°ximo
3. **Hook en primer frame** (<1s de lectura)
4. **Agregar stickers** interactivos (encuesta, pregunta, slider)

### Problema: UTMs no se capturan en CRM

**Checklist diagn√≥stico**:
- [ ] ¬øLos UTMs est√°n en la URL del shortlink?
- [ ] ¬øEl formulario tiene campos ocultos para UTMs?
- [ ] ¬øEl script JavaScript de captura est√° activo?
- [ ] ¬øLos nombres de campos en CRM coinciden? (ver `TOOLS_CRM_COMPARISON.md`)

**Soluci√≥n r√°pida**:
```javascript
// Debug: Log UTMs en consola
console.log('UTMs capturados:', {
  source: urlParams.get('utm_source'),
  medium: urlParams.get('utm_medium'),
  campaign: urlParams.get('utm_campaign'),
  content: urlParams.get('utm_content')
});
```

### Problema: Im√°genes pixeladas en export

**Causas**:
- Export en resoluci√≥n baja (72 DPI vs 300 DPI para impresi√≥n)
- Compresi√≥n agresiva (<80% calidad)
- Upscaling de im√°genes peque√±as

**Soluciones**:
1. **Export en 1080√ó1080 m√≠nimo** (Instagram requiere 1080px)
2. **Usar PNG** para textos/gr√°ficos, **JPG** para fotos (calidad 85-90%)
3. **Evitar rasterizar** textos (mantener vector en Figma/PSD)
4. **Verificar en vista previa** antes de publicar (zoom 100%)

---

## üé≠ Copy por Emoci√≥n (Psychographic Targeting)

### Curso IA ‚Äî Enfoques emocionales

**Fear (miedo al quedarse atr√°s)**:
- S1: "¬øTus competidores ya usan IA? T√∫ tambi√©n puedes."
- S2: "No necesitas saber programar. Solo aplicarla."
- S3: "√önete antes que sea tarde"

**Hope (esperanza de crecimiento)**:
- S1: "Domina IA y acelera tu carrera"
- S2: "2√ó m√°s r√°pido, mismo esfuerzo"
- S3: "Tu futuro profesional empieza hoy"

**Curiosity (curiosidad t√©cnica)**:
- S1: "¬øC√≥mo automatizar con IA sin c√≥digo?"
- S2: "Casos reales: HubSpot + Make + IA"
- S3: "Descubre c√≥mo" ‚Ä¢ "Ver demo"

### SaaS Marketing ‚Äî Enfoques emocionales

**Relief (alivio del estr√©s)**:
- S1: "Deja de hacer campa√±as manualmente"
- S2: "IA hace el trabajo pesado. T√∫ estrategias."
- S3: "Pru√©balo gratis" ‚Ä¢ "Sin compromiso"

**Confidence (confianza en resultados)**:
- S1: "+34% conversiones comprobado"
- S2: "Dashboard claro, decisiones r√°pidas"
- S3: "Ver casos reales"

**Urgency (urgencia competitiva)**:
- S1: "Tus competidores ya optimizan con IA"
- S2: "√önete o qu√©date atr√°s"
- S3: "Activa prueba ahora"

### IA Bulk ‚Äî Enfoques emocionales

**Control (control sobre el caos)**:
- S1: "Domina tu documentaci√≥n"
- S2: "Versionado, aprobaciones, control total"
- S3: "Solicita demo"

**Efficiency (eficiencia personal)**:
- S1: "10√ó m√°s r√°pido. Mismo resultado."
- S2: "Ahorra horas. Enf√≥cate en lo importante."
- S3: "Prueba gratuita"

**Clarity (claridad organizacional)**:
- S1: "Estandariza sin perder flexibilidad"
- S2: "Una fuente de verdad para todos"
- S3: "Ver c√≥mo funciona"

---

## ‚ö° Optimizaciones de Rendimiento

### Mejoras de velocidad de carga

**Im√°genes**:
- Comprimir PNG con TinyPNG o ImageOptim (<200KB por slide)
- Usar WebP cuando sea posible (calidad 85%, fallback PNG)
- Lazy loading en landing pages (cargar carruseles despu√©s del fold)

**Landing Pages**:
- Minificar CSS/JS
- Usar CDN para assets est√°ticos (Cloudflare, AWS CloudFront)
- Preload critical resources (fonts, logo)

**Meta tags optimizados**:
```html
<!-- Open Graph para Instagram/Facebook -->
<meta property="og:image" content="https://tusitio.com/carrusel-curso-ia-s1.png" />
<meta property="og:image:width" content="1080" />
<meta property="og:image:height" content="1080" />
<meta property="og:description" content="Domina IA aplicada en semanas. Clases pr√°cticas + webinars en vivo." />
```

### Optimizaci√≥n de conversi√≥n (CRO)

**Above the fold** (primeros 600px):
- H1 visible sin scroll
- CTA principal visible (m√≠nimo 50% del viewport)
- Prueba social (logo cliente o testimonio corto)

**Formularios**:
- M√°ximo 3 campos visibles (resto en segundo paso)
- Placeholder texto claro ("tu@email.com" vs "Email")
- Validaci√≥n en tiempo real (no esperar submit)
- Mensaje de error claro ("Email inv√°lido" vs "Error")

**Micro-interacciones**:
- Hover en CTA (sombra m√°s fuerte, scale 1.02)
- Loading state en bot√≥n (spinner + texto "Procesando...")
- Success state claro (checkmark + "¬°Gracias!")

---

## ‚öñÔ∏è Compliance y Mejores Pr√°cticas Legales

### Disclaimer de m√©tricas

**Requerido cuando uses datos/porcentajes**:
```
*Resultados basados en casos de estudio. Pueden variar seg√∫n industria, 
tama√±o de empresa y implementaci√≥n individual.
```

**Tama√±o m√≠nimo**: 12px, contraste ‚â•4.5:1

### GDPR/CCPA (si capturas datos de EU/US)

**Checklist**:
- [ ] Checkbox de consentimiento expl√≠cito en formularios
- [ ] Pol√≠tica de privacidad link visible
- [ ] Opci√≥n de opt-out clara
- [ ] Campos UTM no son PII (no requieren consentimiento especial)

**Texto sugerido (checkbox)**:
```
‚òê Acepto recibir comunicaciones de marketing y acepto la 
[Pol√≠tica de Privacidad](#). Puedo darme de baja en cualquier momento.
```

### L√≠mites de promesas

**Evitar**:
- ‚ùå "Garantizamos +34% conversiones"
- ‚ùå "100% de los alumnos obtienen certificado"
- ‚ùå "Sin riesgos"

**Usar**:
- ‚úÖ "Hasta +34% conversiones (casos promedio)"
- ‚úÖ "Certificado al completar el curso"
- ‚úÖ "Prueba gratuita sin tarjeta"

---

## üéØ Segmentaci√≥n Avanzada y Retargeting

### Audiencias por comportamiento (Meta Ads)

**Audiencia 1: Engagers del carrusel** (√∫ltimos 30 d√≠as)
- Personas que dieron like, comentario o guardaron
- Excluir: Convertidos (visitantes de landing con `utm_content`)
- Acci√≥n: Mostrar variante del carrusel con CTA m√°s directo

**Audiencia 2: Clickers no convertidos** (√∫ltimos 14 d√≠as)
- Visitantes de landing que no completaron formulario
- Excluir: Convertidos (completaron form)
- Acci√≥n: Mostrar testimonio o caso de uso espec√≠fico

**Audiencia 3: Visitantes de pricing** (√∫ltimos 7 d√≠as)
- Usuarios que visitaron p√°gina de precios
- Acci√≥n: Mostrar oferta especial o demo personalizada

### Lookalike audiences (Meta Ads)

**Seed audience**: Convertidos √∫ltimos 90 d√≠as (m√≠nimo 100 personas)
- Similarity: 1% (m√°s similar, alcance menor) o 2-3% (m√°s amplio)
- Ubicaci√≥n: Pa√≠s objetivo
- Excluir: Seed audience original

**Uso**: Campa√±a de adquisici√≥n con presupuesto mayor

### Retargeting por email (CRM workflows)

**Trigger**: Click en carrusel ‚Üí visita landing ‚Üí no completa form

**Workflow (HubSpot/ActiveCampaign)**:

1. **Email 1** (30 min despu√©s):
   - Asunto: "¬øAlguna duda sobre [Producto]?"
   - Cuerpo: Preguntas frecuentes + CTA "Ver demo"

2. **Email 2** (24 horas despu√©s):
   - Asunto: "Te esperamos ‚Äî Oferta especial"
   - Cuerpo: Beneficio principal + urgencia + CTA

3. **Email 3** (72 horas despu√©s):
   - Asunto: "√öltima oportunidad ‚Äî [Oferta]"
   - Cuerpo: Escasez + testimonio + CTA final

**Desactivar workflow** si el contacto:
- Completa formulario
- Se da de baja
- Ya es cliente

---

## üîó Integraciones Espec√≠ficas (seg√∫n TOOLS_CRM_COMPARISON.md)

### HubSpot ‚Äî Campos y workflows

**Campos personalizados a crear** (Settings ‚Üí Properties):
```
utm_source (Single-line text)
utm_medium (Single-line text)
utm_campaign (Single-line text)
utm_content (Single-line text)
utm_term (Single-line text)
first_utm_source (Single-line text)
first_utm_medium (Single-line text)
first_utm_campaign (Single-line text)
last_utm_source (Single-line text)
last_utm_medium (Single-line text)
last_utm_campaign (Single-line text)
landing_url (Single-line text)
referrer_url (Single-line text)
```

**Workflow autom√°tico**:
- Trigger: Form submission (o Lead Ads)
- Acci√≥n 1: Si `first_utm_source` vac√≠o ‚Üí setear `utm_source` a `first_utm_source`
- Acci√≥n 2: Siempre setear `last_utm_*` con valores actuales
- Acci√≥n 3: Asignar owner seg√∫n `utm_campaign` (propiedad "Owner Assignment Rules")

### Pipedrive ‚Äî Custom fields y automation

**Custom fields** (Settings ‚Üí Fields):
- Crear en Person y Deal (para reportar por deal)
- Tipo: Text para todos los campos UTM

**Automation** (Workflow):
- Trigger: Person created (con `utm_campaign`)
- Acci√≥n: Crear Deal autom√°tico + copiar campos UTM de Person a Deal
- Etapa inicial: "Nuevo" o "Calificando"

### ActiveCampaign ‚Äî Tags y automations

**Tags sugeridos**:
- `utm_campaign:curso_ia_webinars_2025-11`
- `utm_content:slide1_v1`
- `utm_source:instagram`
- `utm_medium:carrusel`

**Automation**:
- Trigger: Form submit (con UTMs en hidden fields)
- Acci√≥n 1: Agregar tags seg√∫n `utm_campaign` y `utm_content`
- Acci√≥n 2: Enviar a lista/segmento seg√∫n tags
- Acci√≥n 3: Enviar email bienvenida con delay 5 minutos

**Campos personalizados** (Settings ‚Üí Fields):
- Mismo formato que HubSpot, usando `%UTM_SOURCE%` como nombre de campo

### Make/Zapier ‚Äî Recetas listas

**Receta 1: Form submit ‚Üí HubSpot**
```
Trigger: Webflow/Typeform form submission
Action 1: HubSpot Create/Update Contact
  - Map: email, firstname, lastname
  - Map: utm_source ‚Üí utm_source
  - Map: utm_campaign ‚Üí utm_campaign
  - Map: utm_content ‚Üí utm_content
Action 2: HubSpot Create Deal (opcional)
  - Title: "Demo [Producto] ‚Äî [email]"
  - Stage: "Nuevo"
Action 3: HubSpot Create Task
  - Title: "Follow-up carrusel"
  - Due date: +2 horas
```

**Receta 2: Bitly click ‚Üí CRM**
```
Trigger: Bitly webhook (link_click event)
Action 1: Parse URL ‚Üí extraer UTMs
Action 2: Buscar contacto por email (si disponible)
Action 3: Update contacto con last_utm_*
Action 4: Crear actividad/nota con timestamp
```

**Referencia completa**: Ver `TOOLS_CRM_COMPARISON.md` secci√≥n [Recetas Make/Zapier](#recetas-makezapier-plantillas)

---

## üìà Benchmarks de Industria (referencia)

### CTR promedio por plataforma (carruseles)

**Instagram Feed**:
- Org√°nico: 0.5-1.5%
- Ads: 1.5-3%
- Carruseles: +20-30% vs single image

**Facebook Feed**:
- Org√°nico: 0.3-1%
- Ads: 1-2.5%
- Carruseles: +15-25% vs single image

**LinkedIn Feed**:
- Org√°nico: 0.5-2%
- Ads: 1-3%
- Carruseles: +10-20% vs single image

**Stories**:
- Swipe up: 2-5% (si cuenta verificada o ads)
- Tap forward: 15-30% (skip)

### Tasa de conversi√≥n (carrusel ‚Üí landing)

**B2C (ecommerce, cursos)**:
- Buena: 15-25%
- Excelente: 25-40%

**B2B (SaaS, servicios)**:
- Buena: 10-20%
- Excelente: 20-35%

**Nota**: Depende de fricci√≥n del CTA ("Pru√©balo gratis" > "Solicita demo")

### Tiempo promedio en carrusel

**M√©trica saludable**:
- ‚â•5 segundos por slide (15s total)
- ‚â•60% llegan al slide 3

**Se√±ales de problema**:
- <3 segundos por slide ‚Üí Hook d√©bil
- <40% llegan al slide 3 ‚Üí Contenido no relevante

---

## üé® Templates de Dise√±o (variantes estacionales)

### Navidad/Fin de a√±o

**Colores**:
- Acento: Verde (#22C55E) o rojo (#EF4444)
- Fondo: Blanco (#FFFFFF) o gris claro (#F1F5F9)
- Elementos: Estrellas, confeti sutil

**Copy**:
- "Termina el a√±o dominando IA"
- "Oferta especial ‚Äî Hasta [fecha]"
- "√öltimos cupos del a√±o"

### A√±o nuevo/Q1

**Colores**:
- Acento: Azul claro (#0EA5E9) o verde (#22C55E)
- Fondo: Gradiente suave (azul ‚Üí blanco)

**Copy**:
- "Tu meta 2025: Dominar IA"
- "Empieza el a√±o con certificaci√≥n"
- "Nuevo inicio ‚Äî Nuevas habilidades"

### Black Friday/Cyber Monday

**Colores**:
- Acento: Naranja (#F97316) o rojo (#EF4444)
- Fondo: Negro (#0B1220) o gris oscuro (#1F2937)

**Copy**:
- "Descuento -25% ‚Äî Solo hoy"
- "Oferta rel√°mpago ‚Äî [Hora]"
- "Cupos limitados ‚Äî No te quedes fuera"

---

## üîÑ Flujo Completo End-to-End (checklist)

### Fase 1: Preparaci√≥n (Semana -1)

- [ ] Definir objetivos (conversiones, alcance, engagement)
- [ ] Seleccionar carruseles a usar (3 productos)
- [ ] Crear brief de dise√±o (colores, tipograf√≠as, logo)
- [ ] Preparar copy final (texto exacto por slide)

### Fase 2: Dise√±o (Semana 0)

- [ ] Crear artes en Figma/PSD (3 slides √ó 3 carruseles = 9 slides)
- [ ] Generar variantes A/B (2 variantes por producto = 6 adicionales)
- [ ] Export en 3 tama√±os (1080√ó1080, 1080√ó1350, 1080√ó1920)
- [ ] QA completo (contraste, texto, logo, safe areas)

### Fase 3: Setup T√©cnico (Semana 0)

- [ ] Crear landing pages con formularios
- [ ] Configurar campos UTM en CRM (HubSpot/Pipedrive/ActiveCampaign)
- [ ] Crear workflows de automatizaci√≥n (Make/Zapier)
- [ ] Configurar shortlinks (Bitly/Yourls) con UTMs
- [ ] Setup tracking (GA4, Meta Events Manager)

### Fase 4: Publicaci√≥n (Semana 1-4)

- [ ] Publicar seg√∫n calendario (ver [Calendario de Publicaci√≥n](#-calendario-de-publicaci√≥n-4-semanas))
- [ ] Monitorear m√©tricas diarias (CTR, engagement, conversiones)
- [ ] Ajustar horarios seg√∫n performance
- [ ] Responder comentarios y DMs

### Fase 5: Optimizaci√≥n (Semana 2-4)

- [ ] Analizar A/B tests (elegir ganadores)
- [ ] Ajustar copy/visuales seg√∫n feedback
- [ ] Escalar variantes de mejor rendimiento
- [ ] Retargeting a no convertidos

### Fase 6: An√°lisis (Semana 5)

- [ ] Reporte final (KPIs, ROI, learnings)
- [ ] Documentar qu√© funcion√≥ y qu√© no
- [ ] Preparar iteraci√≥n siguiente (mejoras)

---

## üìö Glosario R√°pido

- **CTR (Click-Through Rate)**: Porcentaje de personas que clickean vs impresiones
- **CTA (Call-to-Action)**: Bot√≥n o texto que invita a acci√≥n (ej: "√önete ahora")
- **Safe area**: √Årea segura donde el texto no se corta en diferentes dispositivos
- **UTM**: Par√°metros de tracking en URLs (`utm_source`, `utm_medium`, etc.)
- **First touch**: Primera interacci√≥n del usuario (capturado en `first_utm_*`)
- **Last touch**: √öltima interacci√≥n antes de conversi√≥n (capturado en `last_utm_*`)
- **Attribution**: Asignaci√≥n de cr√©dito a canales/fuentes que generaron conversi√≥n
- **Conversion rate**: Porcentaje de visitantes que completan acci√≥n deseada
- **A/B test**: Comparaci√≥n de 2 variantes para determinar cu√°l funciona mejor

---

## üÜò Soporte y Recursos

### Herramientas de debug

- **Contraste**: [WebAIM Contrast Checker](https://webaim.org/resources/contrastchecker/)
- **Comprimir im√°genes**: [TinyPNG](https://tinypng.com/), [ImageOptim](https://imageoptim.com/)
- **Validar UTMs**: [Google Campaign URL Builder](https://ga-dev-tools.web.app/campaign-url-builder/)
- **Analizar performance**: Meta Business Suite, Google Analytics 4

### Documentaci√≥n relacionada

- `TOOLS_CRM_COMPARISON.md` ‚Äî Mapeos CRM y ejemplos API
- `UTM_GUIDE_OUTREACH.md` (si existe) ‚Äî Convenciones UTM completas
- `SHORTLINKS_UTM_SAMPLE.csv` (si existe) ‚Äî Ejemplos de shortlinks

### Contacto

Para dudas sobre implementaci√≥n t√©cnica, revisar `TOOLS_CRM_COMPARISON.md` secci√≥n [FAQ](#faq) o [Pitfalls y riesgos comunes](#pitfalls-y-riesgos-comunes-ev√≠talos).

---

## üìä Casos de Estudio Reales (An√°lisis de Campa√±as Exitosas)

### Caso 1: Carrusel Curso IA ‚Äî Resultados

**Configuraci√≥n**:
- Plataforma: Instagram Feed (org√°nico + ads)
- Presupuesto ads: $500 USD (14 d√≠as)
- Audiencia: 25-45 a√±os, inter√©s en tecnolog√≠a, LATAM

**Resultados**:
- Impresiones: 45,000
- CTR carrusel: 2.8% (vs 1.2% single image)
- Conversiones landing: 320 (0.71% tasa conversi√≥n)
- CPA (Costo por Adquisici√≥n): $1.56 USD
- ROI: +420% (ingresos $2,100 vs inversi√≥n $500)

**Aprendizajes**:
- Slide 2 (cita) tuvo mejor engagement (45% vs 38% slide 1)
- CTA "Reserva tu plaza" super√≥ a "√önete ahora" (+18% conversi√≥n)
- Horario √≥ptimo: 8:00 AM y 6:00 PM (zona MX)

### Caso 2: SaaS Marketing ‚Äî Retargeting

**Estrategia**:
- Fase 1: Carrusel en feed (cold audience)
- Fase 2: Retargeting a clickers con testimonio video
- Fase 3: Email sequence (3 emails en 7 d√≠as)

**Resultados**:
- Clickers iniciales: 850
- Conversiones retargeting: 127 (14.9% tasa)
- Conversiones email: 89 (10.5% tasa)
- Total conversiones: 216 (25.4% tasa combinada)
- CAC combinado: $2.31 USD (vs $5.80 solo feed)

**Insight clave**: Retargeting + email multiplic√≥ conversi√≥n 3.5√ó vs solo feed

### Caso 3: IA Bulk ‚Äî Segmentaci√≥n por Industria

**Estrategia**:
- 3 variantes del carrusel (Legal, Real Estate, Educaci√≥n)
- Audiencias segmentadas por intereses profesionales
- Landing pages personalizadas por industria

**Resultados**:
- Legal: CTR 3.2%, tasa conversi√≥n 28%
- Real Estate: CTR 2.1%, tasa conversi√≥n 19%
- Educaci√≥n: CTR 4.1%, tasa conversi√≥n 32%

**Conclusi√≥n**: Segmentaci√≥n por industria aument√≥ CTR promedio 35% vs versi√≥n gen√©rica

---

## üîç An√°lisis de Competencia (Framework)

### Paso 1: Identificar competidores directos e indirectos

**Directos**: Productos que resuelven mismo problema  
**Indirectos**: Soluciones alternativas (manual, otros tools)

### Paso 2: Auditor√≠a de contenido

**Revisar**:
- Frecuencia de publicaci√≥n (carruseles/semana)
- Tipos de contenido (educativo, promocional, testimoniales)
- Estilo visual (colores, tipograf√≠as, fotos vs ilustraciones)
- Copy angles (beneficios, features, testimonios)

**Herramientas**:
- Instagram: Guardar posts competidores en colecciones
- Meta Ads Library: Ver anuncios activos (meta.com/ads/library)
- LinkedIn: Seguir perfiles empresa + empleados clave

### Paso 3: An√°lisis de engagement

**M√©tricas a rastrear** (manual o herramienta):
- Likes/comentarios por post
- Shares/guards
- Tiempo promedio en carrusel (si visible)
- Frecuencia de respuestas a comentarios

**Benchmarking**:
- Si competidor tiene 5K followers y 200 likes promedio ‚Üí 4% engagement rate
- Tu objetivo: Superar 4% (audiencia similar)

### Paso 4: Identificar gaps y oportunidades

**Gaps** (lo que competidores no hacen):
- No usan testimonios con m√©tricas espec√≠ficas
- No segmentan por industria
- No tienen variantes estacionales

**Oportunidades**:
- Testimonios con datos > testimonios gen√©ricos
- Segmentaci√≥n aumenta relevancia
- Estacionalidad aumenta urgencia

---

## üöÄ Estrategias de Viralizaci√≥n (Growth Hacking)

### T√©cnica 1: Hook + Controversia (controlada)

**Estructura**:
- Slide 1: "¬øTu CRM est√° robando tus leads?" (pregunta provocativa)
- Slide 2: "95% de empresas pierden datos por tracking mal configurado" (datos)
- Slide 3: "Aprende a configurarlo bien" (soluci√≥n + CTA)

**Riesgo controlado**: No atacar competidores directamente, enfocarse en problema general

### T√©cnica 2: Mini-Encuesta en Stories + Carrusel

**Flujo**:
1. **Stories** (d√≠a 1): Encuesta "¬øTu mayor dolor con [problema]?"
2. **An√°lisis** (d√≠a 1 tarde): Identificar respuesta m√°s com√∫n
3. **Carrusel** (d√≠a 2): Crear carrusel respondiendo la respuesta #1
4. **Mensaje directo**: Enviar a votantes con mensaje personalizado

**Resultado esperado**: Mayor relevancia + engagement por personalizaci√≥n

### T√©cnica 3: Collaborations y Shoutouts

**Estrategia**:
- Identificar 5-10 cuentas complementarias (no competencia directa)
- Ofrecer intercambio: Compartes su contenido ‚Üí comparten el tuyo
- O colaboraci√≥n: Co-crear carrusel educativo (ej: "C√≥mo usar IA + CRM juntos")

**Ejemplo carrusel colaborativo**:
- Slide 1: Logo de ambas marcas
- Slide 2: Beneficio combinado
- Slide 3: CTAs a ambas ofertas

### T√©cnica 4: User-Generated Content (UGC)

**Solicitar**:
- Alumnos del curso: Screenshots de proyectos reales
- Clientes SaaS: Dashboards con resultados
- Usuarios IA Bulk: Antes/despu√©s de documentaci√≥n

**Carrusel UGC**:
- Slide 1: Screenshot real del cliente
- Slide 2: Cita del cliente + m√©trica
- Slide 3: "√önete a [X] clientes exitosos" + CTA

**Legal**: Obtener permiso escrito para usar screenshots/citas

---

## üì± Estrategias Multi-Plataforma (Cross-Posting)

### Adaptaci√≥n por plataforma

**Instagram**:
- Formato: 1080√ó1080 (square) o 1080√ó1350 (portrait)
- Copy: Emotivo, con emojis estrat√©gicos
- Hashtags: 5-10 relevantes

**LinkedIn**:
- Formato: 1080√ó1080 (evitar portrait)
- Copy: Profesional, data-driven, sin emojis excesivos
- Hashtags: 3-5 profesionales

**Facebook**:
- Formato: 1080√ó1080 (square) o 1200√ó628 (landscape)
- Copy: Similar a Instagram pero m√°s directo
- Audience: Generalmente m√°s amplia (edad)

**Twitter/X**:
- Formato: 1080√ó1080 (evitar carrusel, usar single image)
- Copy: Ultra corto (280 chars max), directo al punto
- Link: En bio o thread con m√∫ltiples im√°genes

### Timing √≥ptimo por plataforma

**Instagram**:
- Mejor: Martes-Viernes 8-10 AM, 6-8 PM
- Evitar: Domingo noche, Lunes temprano

**LinkedIn**:
- Mejor: Martes-Jueves 8-9 AM, 12-1 PM, 5-6 PM
- Evitar: Fines de semana

**Facebook**:
- Mejor: Martes-Jueves 1-3 PM, 6-8 PM
- Evitar: Lunes temprano

**Nota**: Ajustar seg√∫n tu audiencia (usar insights de cada plataforma)

---

## ü§ñ Automatizaciones Avanzadas (Make/Zapier)

### Receta 3: Monitoreo de menciones + respuesta autom√°tica

**Trigger**: Keyword monitoring (Brandwatch, Mention, o Make webhook)
```
Cuando: Se menciona "[tu marca] + carrusel" o "[producto] + carrusel"
```

**Actions**:
1. Buscar contacto por username/email
2. Si no existe ‚Üí crear contacto en CRM
3. Agregar tag: `mencion_carrusel`
4. Enviar email personalizado: "Gracias por compartir. Aqu√≠ tienes [recurso exclusivo]"

### Receta 4: An√°lisis de sentimiento + alertas

**Trigger**: Nuevo comentario en carrusel (Meta API o Make webhook)

**Actions**:
1. Analizar sentimiento (API: OpenAI, Google Cloud NLP, o herramienta Make)
2. Si negativo ‚Üí crear tarea "Revisar comentario negativo" + enviar Slack/Discord
3. Si positivo ‚Üí agregar tag `feedback_positivo` + enviar email de agradecimiento

### Receta 5: Auto-optimizaci√≥n de horarios

**Trigger**: Daily report de m√©tricas (Make scheduler diario 9 AM)

**Actions**:
1. Obtener m√©tricas √∫ltimas 7 d√≠as (Meta API o Google Sheets)
2. Calcular mejor hora por d√≠a de semana
3. Si cambi√≥ vs actual ‚Üí actualizar calendario (Google Calendar API)
4. Enviar notificaci√≥n: "Nuevo horario √≥ptimo detectado: [hora]"

---

## üìà An√°lisis Predictivo y Forecasting

### Modelo de proyecci√≥n de conversiones

**F√≥rmula base** (Google Sheets):
```
Conversiones_proyectadas = 
  (Impresiones_promedio √ó CTR_historico √ó Tasa_conversion_historica) 
  √ó Factor_estacional
```

**Factor estacional**:
- Q1 (Ene-Mar): 1.0x (baseline)
- Q2 (Abr-Jun): 1.15x (mayor actividad)
- Q3 (Jul-Sep): 0.95x (verano/vacaciones)
- Q4 (Oct-Dic): 1.25x (campa√±as fin de a√±o)

### Predicci√≥n de ROI

**F√≥rmula**:
```
ROI_proyectado = 
  ((Conversiones √ó Ticket_promedio) - (Presupuesto_ads + Costo_produccion)) 
  / (Presupuesto_ads + Costo_produccion) √ó 100
```

**Variables**:
- Conversiones: Del modelo de proyecci√≥n
- Ticket promedio: Ingreso por conversi√≥n
- Presupuesto ads: Mensual
- Costo producci√≥n: Dise√±o + copy (amortizado)

### Alertas autom√°ticas de performance

**Condiciones** (crear en Make/Zapier):
- Si CTR < 1% (umbral bajo) ‚Üí Alertar equipo
- Si tasa conversi√≥n < 10% ‚Üí Revisar landing page
- Si CPA > 2√ó promedio ‚Üí Pausar campa√±a autom√°ticamente

---

## üé¨ Scripts de Video (Short-Form para Reels/TikTok)

### Script 1: "Antes/Despu√©s" (15 segundos)

```
[0-2s] Antes: "Antes pasaba 3 horas creando documentos..."

[2-5s] Transici√≥n r√°pida (zoom in)

[5-8s] Despu√©s: "Ahora con IA Bulk: 1 consulta, 100+ docs en minutos"

[8-12s] Visual: Pantalla mostrando generaci√≥n

[12-15s] CTA: "Link en bio para demo"
```

**Edici√≥n**:
- Transiciones r√°pidas (0.3s)
- Text overlay en cada escena
- M√∫sica upbeat (120 BPM)

### Script 2: "Problema/Soluci√≥n" (20 segundos)

```
[0-3s] Problema: "¬øCansado de campa√±as que no escalan?"

[3-6s] Dolor: "Creas, segmentas, reportas... manualmente"

[6-10s] Soluci√≥n: "SaaS IA Marketing: Automatiza todo"

[10-14s] Beneficio: "34% m√°s conversiones. Menos trabajo."

[14-18s] Prueba social: "M√°s de 500 empresas lo usan"

[18-20s] CTA: "Pru√©balo gratis. Link en bio."
```

### Script 3: "Tutorial R√°pido" (30 segundos)

```
[0-5s] Hook: "¬øC√≥mo crear 100 documentos en 1 minuto?"

[5-10s] Paso 1: "Define tu consulta √∫nica"

[10-15s] Paso 2: "Selecciona plantillas"

[15-20s] Paso 3: "Genera y exporta"

[20-25s] Resultado: "Listo. PDF/DOCX descargados"

[25-30s] CTA: "Solicita demo. Link en bio."
```

---

## üí¨ Templates de Respuestas a Comentarios (Community Management)

### Comentario positivo

**Template**:
```
¬°Gracias [Nombre]! üôè Nos alegra que te haya resonado. 
[Si aplica: ¬øHas probado [beneficio espec√≠fico]?] 
[CTA sutil: Link en bio para m√°s info]
```

### Comentario con pregunta

**Template**:
```
¬°Hola [Nombre]! üëã
[Respuesta directa a pregunta]

[Si requiere demo/explicaci√≥n larga]: Te escribo por DM con m√°s detalles üì©

[Si es simple]: [Respuesta completa]
```

### Comentario negativo (manejo profesional)

**Template**:
```
Lamento la experiencia, [Nombre]. 
Queremos mejorar. ¬øPodr√≠as contarme m√°s detalles por DM? 
As√≠ podemos resolverlo. üì©
```

**Acci√≥n tras respuesta**:
- Tomar screenshot del comentario
- Crear tarea en CRM para seguimiento
- Agregar tag `feedback_negativo`
- Si resuelto ‚Üí Agregar tag `resuelto` y documentar soluci√≥n

### Comentario "Spam" o irrelevante

**Acci√≥n**: No responder o respuesta m√≠nima
```
Gracias por tu comentario. Si tienes preguntas sobre [tema], 
escr√≠benos por DM.
```

---

## üìã Templates de Reportes (Para Stakeholders)

### Reporte Semanal (Formato Google Sheets/Doc)

**Secci√≥n 1: Resumen Ejecutivo**
```
Carruseles publicados: [X]
Impresiones totales: [X]
Engagement rate: [X]% (vs [X]% semana anterior)
Conversiones: [X] (vs [X] semana anterior)
ROI: [X]%
```

**Secci√≥n 2: Performance por Carrusel**
| Carrusel | Impresiones | CTR | Conversiones | CPA | ROI |
|----------|-------------|-----|--------------|-----|-----|
| Curso IA | X | X% | X | $X | X% |
| SaaS Marketing | X | X% | X | $X | X% |
| IA Bulk | X | X% | X | $X | X% |

**Secci√≥n 3: Insights y Acciones**
```
Insight 1: [Descripci√≥n] ‚Üí Acci√≥n: [Qu√© hacer]
Insight 2: [Descripci√≥n] ‚Üí Acci√≥n: [Qu√© hacer]
```

**Secci√≥n 4: Pr√≥ximos Pasos**
- [ ] Tarea 1
- [ ] Tarea 2

### Dashboard Interactivo (Google Data Studio/Looker)

**Paneles sugeridos**:
1. **Overview**: Impresiones, CTR, conversiones (√∫ltimos 30 d√≠as)
2. **Por carrusel**: Gr√°fico de barras comparativo
3. **Por slide**: Heatmap de engagement (qu√© slide tiene mejor CTR)
4. **Por audiencia**: Segmentaci√≥n (org√°nico vs ads, demograf√≠a)
5. **Attribution**: Funnel completo (carrusel ‚Üí landing ‚Üí conversi√≥n)

**Conectar**:
- Meta Business API (impresiones, clicks, engagement)
- Google Analytics 4 (conversiones, UTMs)
- CRM API (leads, deals, revenue)

---

## üéì Curr√≠culum de Aprendizajes (Documentaci√≥n Continua)

### Template de Learning Log

**Despu√©s de cada campa√±a, documentar**:

```
Campa√±a: [Nombre]
Fecha: [Inicio] - [Fin]
Objetivo: [Conversiones / Alcance / Engagement]

Lo que funcion√≥:
- [Learning 1]
- [Learning 2]

Lo que no funcion√≥:
- [Learning 3]
- [Learning 4]

Cambios a implementar:
- [Cambio 1]
- [Cambio 2]

M√©tricas clave:
- CTR: [X]%
- Tasa conversi√≥n: [X]%
- CPA: $[X]
- ROI: [X]%
```

**Almacenar en**: Google Docs, Notion, o base de datos (Airtable)

### An√°lisis Trimestral

**Cada 3 meses, revisar**:
1. **Tendencias**: ¬øQu√© tipo de carrusel funciona mejor?
2. **Audiencias**: ¬øQu√© segmentos convierten m√°s?
3. **Copy angles**: ¬øQu√© emociones/√°ngulos funcionan?
4. **Visuales**: ¬øFotos vs ilustraciones? ¬øColores?
5. **Timing**: ¬øQu√© horarios son √≥ptimos?

**Output**: Documento estrat√©gico con recomendaciones para pr√≥ximo trimestre

---

## üîê Seguridad y Privacidad (Checklist)

### Protecci√≥n de datos (GDPR/CCPA)

**Checklist t√©cnico**:
- [ ] Formularios tienen checkbox de consentimiento expl√≠cito
- [ ] Pol√≠tica de privacidad link visible (footer + formularios)
- [ ] Opt-out disponible en cada email
- [ ] Datos almacenados encriptados (SSL/TLS en tr√°nsito)
- [ ] Acceso a datos limitado (roles y permisos en CRM)
- [ ] Retenci√≥n de datos documentada (cu√°nto tiempo se guardan)
- [ ] Derecho al olvido implementado (proceso para eliminar datos)

### Protecci√≥n de marca

**Checklist legal**:
- [ ] Logo y marca registrados o con derechos de uso
- [ ] Im√°genes de stock tienen licencia comercial
- [ ] Fuentes tienen licencia comercial (Google Fonts es seguro)
- [ ] Testimonios tienen permiso escrito
- [ ] No usar im√°genes de personas sin modelo release

### Seguridad t√©cnica

**Checklist**:
- [ ] Landing pages usan HTTPS (SSL certificate)
- [ ] Formularios validan datos (prevenir SQL injection, XSS)
- [ ] APIs usan autenticaci√≥n segura (tokens, no keys en c√≥digo p√∫blico)
- [ ] Backups regulares de datos CRM
- [ ] Monitoring de accesos sospechosos (audit logs)

---

## üåç Localizaci√≥n y Traducci√≥n

### Checklist de localizaci√≥n

**Para expandir a otros pa√≠ses/idiomas**:

**Contenido**:
- [ ] Traducir copy (no solo texto, adaptar culturalmente)
- [ ] Ajustar moneda y formato de fechas
- [ ] Revisar referencias culturales (ejemplos, casos de uso)
- [ ] Adaptar CTAs (ej: "Pru√©balo gratis" ‚Üí "Free Trial" en EN)

**T√©cnico**:
- [ ] Configurar `utm_term` con c√≥digo de pa√≠s (ej: `mx`, `us`, `es`)
- [ ] Segmentar audiencias por pa√≠s en Meta Ads
- [ ] Landing pages localizadas (subdominio o path: `/es/`, `/en/`)

**Legal**:
- [ ] T√©rminos y condiciones localizados
- [ ] Pol√≠tica de privacidad seg√∫n pa√≠s (GDPR para EU, CCPA para California)

### Ejemplo: Traducci√≥n Curso IA (EN)

**Original ES**:
- S1: "Domina IA aplicada en semanas"
- S2: "Desde que uso el Curso mis entregas son 2√ó m√°s r√°pidas"
- S3: "√önete ahora"

**Traducido EN**:
- S1: "Master Applied AI in weeks"
- S2: "Since using the Course, my deliverables are 2√ó faster"
- S3: "Join now"

**Nota**: Adaptar, no traducir literalmente. "Domina" puede ser "Master" o "Learn" seg√∫n audiencia.

---

## üß© Integraciones con Herramientas Espec√≠ficas

### Google Analytics 4 (Eventos personalizados)

**Eventos a configurar**:

```javascript
// Evento: Carrusel visto
gtag('event', 'carousel_view', {
  'carousel_name': 'curso_ia_v1',
  'slide_number': 1,
  'utm_campaign': 'curso_ia_webinars_2025-11'
});

// Evento: Slide completado
gtag('event', 'slide_complete', {
  'carousel_name': 'curso_ia_v1',
  'slide_number': 2,
  'time_spent': 5.2 // segundos
});

// Evento: CTA click
gtag('event', 'carousel_cta_click', {
  'carousel_name': 'curso_ia_v1',
  'cta_text': '√önete ahora',
  'utm_content': 'slide3_v1'
});
```

**Configurar en GA4**:
1. Admin ‚Üí Events ‚Üí Create event
2. Event name: `carousel_view`, `slide_complete`, `carousel_cta_click`
3. Parameters: Mapear a dimensiones personalizadas

### Meta Events Manager (Conversiones)

**Eventos est√°ndar recomendados**:
- `ViewContent`: Cuando carrusel se ve completo
- `Lead`: Cuando formulario se completa
- `Purchase`: Cuando hay conversi√≥n a pago (si aplica)

**Par√°metros personalizados**:
```javascript
fbq('track', 'ViewContent', {
  content_name: 'curso_ia_carousel',
  content_category: 'education',
  content_ids: ['curso_ia_v1_s1', 'curso_ia_v1_s2', 'curso_ia_v1_s3'],
  value: 0, // valor estimado
  currency: 'USD'
});
```

### Slack/Discord Notifications (Alertas)

**Webhook Make/Zapier ‚Üí Slack**:

**Mensaje formato**:
```
üö® Alerta: Carrusel [nombre] bajo rendimiento

CTR: [X]% (vs promedio [Y]%)
Conversiones: [X] (vs objetivo [Y])
CPA: $[X] (vs objetivo $[Y])

[Link a dashboard] | [Link a editar carrusel]
```

**Trigger**: Diario a las 9 AM si m√©tricas bajo umbral

---

## üì± Estrategia Mobile-First

### Optimizaci√≥n para m√≥viles

**Dise√±o**:
- Texto m√≠nimo 32px (legible sin zoom)
- Botones m√≠nimo 44√ó44px (t√°ctil f√°cil)
- Espaciado entre elementos m√≠nimo 8px
- Safe area respetada (84px desde bordes en square)

**Velocidad**:
- Im√°genes optimizadas (<200KB por slide)
- Lazy loading en landing pages
- AMP (Accelerated Mobile Pages) si aplica

### Testing m√≥vil

**Dispositivos a probar**:
- iPhone (iOS): Safari, Chrome
- Android: Chrome, Samsung Internet
- Tablets: iPad, Android tablets

**Herramientas**:
- Chrome DevTools (device emulation)
- BrowserStack (testing real devices)
- Google Mobile-Friendly Test

---

## üîó Integraci√≥n con Workflows Avanzados (26_ADVANCED_AUTOMATION_WORKFLOWS.md)

### Workflow: Carrusel Click ‚Üí Lead Ingestion ‚Üí DM Autom√°tico

**Referencia**: Ver `26_ADVANCED_AUTOMATION_WORKFLOWS.md` secci√≥n [Lead Ingestion & Scoring](#-workflow-end-to-end)

**Flujo completo**:
```
Carrusel Click (shortlink) 
  ‚Üí Captura UTMs en CRM 
  ‚Üí Lead Scoring autom√°tico 
  ‚Üí Si score ‚â•6: Generar DM personalizado 
  ‚Üí QA Check (usar rubrica de COPY_PASTE_READY_DMS.md)
  ‚Üí Enviar DM en horario √≥ptimo
  ‚Üí Log interacci√≥n en CRM
```

**Par√°metros UTM para scoring**:
- `utm_content` contiene `slide3` (CTA) ‚Üí +2 puntos (alta intenci√≥n)
- `utm_campaign` contiene `curso_ia` ‚Üí Lead scoring base +5
- `utm_source` = `instagram` ‚Üí Canal social, score base +1
- `utm_term` contiene industria ‚Üí Matching con buyer persona +3

**Trigger en Make/Zapier**:
```
Trigger: Shortlink click (Bitly/Yourls webhook)
  ‚Üí Parse UTMs
  ‚Üí Buscar/Crear contacto en CRM (HubSpot/Pipedrive/ActiveCampaign)
  ‚Üí Calcular lead score
  ‚Üí Si score ‚â•6: Continuar workflow
  ‚Üí Si score <6: Agregar a nurturing sequence
```

### Workflow: Comentario en Carrusel ‚Üí An√°lisis ‚Üí Respuesta Personalizada

**Referencia**: Ver `26_ADVANCED_AUTOMATION_WORKFLOWS.md` secci√≥n [Response Handling](#-response-handling)

**Flujo**:
```
Comentario en carrusel (Meta API)
  ‚Üí Clasificar tipo (pregunta/positivo/negativo/inter√©s)
  ‚Üí Si pregunta: Buscar template en COPY_PASTE_READY_DMS.md
  ‚Üí Generar respuesta personalizada (AI si aplica)
  ‚Üí QA check
  ‚Üí Responder p√∫blicamente o por DM
  ‚Üí Crear tarea follow-up si requiere
```

**Tipos de comentarios y acciones**:
- **Pregunta espec√≠fica**: Responder + enviar DM con m√°s info
- **Inter√©s expl√≠cito**: Enviar DM con link personalizado + UTM `utm_content=comentario_interes`
- **Positivo**: Agradecer + invitar a compartir o seguir
- **Negativo**: Responder profesionalmente + crear tarea de seguimiento

### Workflow: Carrusel View ‚Üí Remarketing Sequence

**Integraci√≥n con remarketing**:
```
Usuario ve carrusel completo (Meta pixel: ViewContent)
  ‚Üí Crear audiencia: "Carrusel Viewers" (Meta Ads Manager)
  ‚Üí Esperar 24h (cooling period)
  ‚Üí Mostrar retargeting ad con testimonio o caso de uso
  ‚Üí Si click: Landing page personalizada
  ‚Üí Si conversi√≥n: Remover de audiencia
```

**UTMs para remarketing**:
```
utm_source=instagram
utm_medium=remarketing
utm_campaign=carrusel_retargeting_{producto}_2025-11
utm_content=testimonio_video_v1
utm_term=viewers_24h
```

---

## üí¨ DMs Listos para Usar (Basados en COPY_PASTE_READY_DMS.md)

### Template: Respuesta a Comentario con Inter√©s

**Cuando**: Usuario comenta en carrusel expresando inter√©s

**DM Template**:
```
¬°Hola [Nombre]! üëã

Veo que te interes√≥ [beneficio del carrusel]. 

Basado en tu perfil de [industria/rol], creo que esto te ayudar√≠a especialmente con [dolor espec√≠fico].

[Link personalizado con UTM: go.tumarca/{producto}-{version}-{industria}]

¬øAgendamos una demo de 15 min esta semana para verlo con tu caso?
```

**UTM sugerido**:
```
?utm_source=instagram&utm_medium=dm&utm_campaign={producto}_dm_comentario_2025-11&utm_content={slide_number}&utm_term={industria}
```

### Template: Follow-up despu√©s de Click

**Cuando**: Usuario clicke√≥ carrusel pero no complet√≥ formulario (24h despu√©s)

**DM Template**:
```
Hola [Nombre],

Ayer viste nuestro carrusel sobre [tema]. 

¬øAlguna pregunta antes de [acci√≥n]? 

Aqu√≠ tienes [recurso r√°pido]: [link con utm_content=followup_dm_24h]
```

### Template: Agradecimiento por Compartir

**Cuando**: Usuario comparte o guarda el carrusel

**DM Template**:
```
¬°Gracias por compartir, [Nombre]! üôè

Para agradecerte, aqu√≠ tienes [recurso exclusivo/descuento]: 

[Link con utm_content=thank_you_share]

¬øQuieres que te avise cuando publiquemos [contenido relacionado]?
```

**Referencia completa**: Ver `COPY_PASTE_READY_DMS.md` para m√°s templates por industria y persona

---

## üìä UTMs Espec√≠ficos para Carruseles (Seg√∫n UTM_GUIDE_OUTREACH.md)

### Convenci√≥n de Nombres para Carruseles

**Referencia**: Ver `UTM_GUIDE_OUTREACH.md` secci√≥n [Convenci√≥n de nombres](#convenci√≥n-de-nombres-claridad-y-escalabilidad)

**Formato est√°ndar**:
```
utm_source={plataforma}           // instagram, facebook, linkedin
utm_medium=carrusel               // siempre "carrusel" para este formato
utm_campaign={producto}_{tipo}_{fecha}  // curso_ia_webinars_2025-11
utm_content={slide}_{version}     // slide1_v1, slide2_v1, slide3_v1
utm_term={audiencia}_{pais}       // cmo_mx, pm_ar, founder_co
```

### Ejemplos Realistas

**Carrusel Curso IA - Slide 1**:
```
?utm_source=instagram
&utm_medium=carrusel
&utm_campaign=curso_ia_webinars_2025-11
&utm_content=slide1_cliente_v1
&utm_term=pm_mx
```

**Carrusel SaaS Marketing - Slide 3 (CTA)**:
```
?utm_source=facebook
&utm_medium=carrusel
&utm_campaign=saas_ia_marketing_2025-11
&utm_content=slide3_cta_v1
&utm_term=cmo_retargeting_7d
```

**Carrusel IA Bulk - Stories**:
```
?utm_source=instagram
&utm_medium=carrusel
&utm_campaign=ia_bulk_docs_2025-11
&utm_content=stories_frame3_cta_v1
&utm_term=legal_es
```

### QA Checklist UTMs (Antes de Publicar)

**Referencia**: Ver `UTM_GUIDE_OUTREACH.md` secci√≥n [QA checklist antes de publicar](#qa-checklist-antes-de-publicar)

**Checklist espec√≠fico para carruseles**:
- [ ] `utm_medium` = `carrusel` (consistente)
- [ ] `utm_campaign` sigue convenci√≥n: `{producto}_{tipo}_{fecha}`
- [ ] `utm_content` incluye `slide{n}` y `v{n}` (versi√≥n)
- [ ] `utm_term` incluye audiencia y pa√≠s (si aplica)
- [ ] Todos los slides tienen UTMs √∫nicos (tracking granular)
- [ ] Shortlinks tienen UTMs embebidos (verificar en Bitly/Yourls)
- [ ] UTMs se mapean correctamente en CRM (ver `TOOLS_CRM_COMPARISON.md`)

### F√≥rmulas Sheets para An√°lisis de Carruseles

**Referencia**: Ver `UTM_GUIDE_OUTREACH.md` secci√≥n [F√≥rmulas √∫tiles](#f√≥rmulas-√∫tiles-sheetsexcel)

**CTR por slide**:
```
=IFERROR(SUMIFS(Clicks, utm_content, "slide1_v1")/SUMIFS(Impresiones, utm_content, "slide1_v1"), 0)
```

**Tasa conversi√≥n por producto**:
```
=IFERROR(SUMIFS(Conversiones, utm_campaign, "curso_ia*")/SUMIFS(Clicks, utm_campaign, "curso_ia*"), 0)
```

**ROI por carrusel**:
```
=IFERROR((SUMIFS(Ingresos, utm_campaign, "{carrusel}") - SUMIFS(Costo, utm_campaign, "{carrusel}"))/SUMIFS(Costo, utm_campaign, "{carrusel}"), 0)
```

---

## üéØ Segmentaci√≥n Avanzada usando UTMs

### Audiencias Meta Ads basadas en UTMs

**Audiencia 1: Clickers Slide 3 (Alta intenci√≥n)**
- Condici√≥n: Pixel `ViewContent` con `utm_content` contiene `slide3`
- Excluir: Convertidos (completaron form)
- Acci√≥n: Mostrar testimonio video o caso de uso detallado

**Audiencia 2: Viewers M√∫ltiples Slides**
- Condici√≥n: Pixel `ViewContent` en 2+ slides diferentes
- Excluir: Convertidos
- Acci√≥n: Retargeting con oferta especial o demo personalizada

**Audiencia 3: Por Industria (utm_term)**
- Condici√≥n: `utm_term` contiene `{industria}` (ej: `legal`, `retail`)
- Acci√≥n: Mostrar variante del carrusel espec√≠fica de industria

### Lookalike de Convertidos por Carrusel

**Seed Audience**: Convertidos con `utm_medium=carrusel` (√∫ltimos 90 d√≠as, m√≠nimo 100)

**Segmentaci√≥n adicional**:
- Si `utm_campaign` contiene `curso_ia` ‚Üí Lookalike para educaci√≥n/aprendizaje
- Si contiene `saas_marketing` ‚Üí Lookalike para marketing/tech
- Si contiene `ia_bulk` ‚Üí Lookalike para operaciones/documentaci√≥n

---

## üîÑ Workflow Completo: Carrusel ‚Üí Conversi√≥n ‚Üí Nurturing

### Fase 1: Carrusel Publicado

**Trigger**: Carrusel publicado en Instagram/Facebook

**Acciones autom√°ticas**:
1. Crear audiencia de "Carrusel Viewers" (Meta Ads Manager)
2. Configurar retargeting autom√°tico (24h despu√©s)
3. Monitorear m√©tricas en tiempo real (Slack alertas si CTR <1%)

### Fase 2: Click en Carrusel

**Trigger**: Click en shortlink del carrusel (Bitly/Yourls webhook)

**Workflow Make/Zapier**:
1. Parse UTMs de `long_url`
2. Buscar/Crear contacto en CRM
3. Setear `last_utm_*` con valores del click
4. Si `first_utm_*` vac√≠o ‚Üí setear tambi√©n
5. Calcular lead score (ver `26_ADVANCED_AUTOMATION_WORKFLOWS.md`)
6. Si score ‚â•6: Enviar a workflow de DM autom√°tico
7. Si score <6: Agregar a nurturing sequence (email)

### Fase 3: Visita Landing (no conversi√≥n)

**Trigger**: Pixel `PageView` en landing con `utm_medium=carrusel`

**Workflow**:
1. Actualizar `last_utm_*` en CRM
2. Si no complet√≥ form en 24h: Trigger email recordatorio
3. Agregar a audiencia de retargeting Meta Ads
4. Si es segunda visita: Mostrar testimonio video en retargeting

### Fase 4: Conversi√≥n (form completado)

**Trigger**: Form submission con `utm_medium=carrusel`

**Workflow**:
1. Crear deal/opportunity en CRM (si B2B)
2. Asignar owner seg√∫n `utm_campaign` o round-robin
3. Enviar email bienvenida (ver secci√≥n [Notificaciones Push/Email](#-notificaciones-pushemail-triggers-post-carrusel))
4. Remover de audiencias de retargeting
5. Agregar tag `converted_carrusel_{producto}`
6. Log conversi√≥n en Meta Events Manager (evento `Lead` o `Purchase`)

### Fase 5: Nurturing (no convertidos)

**Workflow email** (HubSpot/ActiveCampaign):
- Email 1 (30 min): "¬øAlguna duda?"
- Email 2 (24h): "Te esperamos ‚Äî Oferta especial"
- Email 3 (72h): "√öltima oportunidad"
- Desactivar si convierte o se da de baja

---

## üìà Analytics Avanzado con GA4 (Seg√∫n UTM_GUIDE_OUTREACH.md)

### Explorations Personalizadas para Carruseles

**Referencia**: Ver `UTM_GUIDE_OUTREACH.md` secci√≥n [GA4 Explorations ‚Äî plantillas](#ga4-explorations--plantillas-paso-a-paso)

**Exploration 1: Funnel de Carrusel**
1. Crear Exploration ‚Üí Funnel
2. Step 1: Evento `carousel_view` (utm_medium=carrusel)
3. Step 2: Evento `slide_complete` (slide 1, 2, 3)
4. Step 3: Evento `carousel_cta_click` (slide 3)
5. Step 4: Evento `page_view` (landing page)
6. Step 5: Evento `form_submit` (conversi√≥n)

**Dimensiones**:
- `utm_campaign` (producto)
- `utm_content` (slide espec√≠fico)
- `utm_term` (audiencia/pa√≠s)

**M√©tricas**:
- Drop-off rate por slide
- Tasa conversi√≥n slide 3 ‚Üí landing
- Tasa conversi√≥n landing ‚Üí form

**Exploration 2: Performance por Slide**

**Tabla pivot**:
- Rows: `utm_content` (slide1_v1, slide2_v1, slide3_v1)
- Columns: M√©tricas (Views, Clicks, Conversions)
- Values: CTR, tasa conversi√≥n

**Insight**: Identificar qu√© slide tiene mejor engagement/conversi√≥n

### Campos Calculados (Looker/GA4)

**Referencia**: Ver `UTM_GUIDE_OUTREACH.md` secci√≥n [Looker/GA4 ‚Äî Campos calculados](#lookerga4--campos-calculados-√∫tiles)

**Campo 1: Producto (derivado de utm_campaign)**
```
IF utm_campaign CONTAINS "curso_ia" THEN "Curso IA"
ELSE IF utm_campaign CONTAINS "saas_marketing" THEN "SaaS Marketing"
ELSE IF utm_campaign CONTAINS "ia_bulk" THEN "IA Bulk"
ELSE "Otro"
```

**Campo 2: Tipo de Slide (derivado de utm_content)**
```
IF utm_content CONTAINS "slide1" THEN "Hook/Beneficio"
ELSE IF utm_content CONTAINS "slide2" THEN "Testimonio"
ELSE IF utm_content CONTAINS "slide3" THEN "CTA"
ELSE "Otro"
```

**Campo 3: Audiencia (derivado de utm_term)**
```
SPLIT utm_term BY "_" ‚Üí Toma primer elemento
// Ejemplo: "cmo_mx" ‚Üí "cmo"
```

---

## üö® Alertas y Monitoreo Autom√°tico

### Alertas de Performance (Slack/Discord)

**Referencia**: Integraci√≥n con workflows de `26_ADVANCED_AUTOMATION_WORKFLOWS.md`

**Alerta 1: CTR Bajo**
```
Trigger: Daily report (9 AM)
Condition: CTR carrusel < 1% (umbral bajo)
Action: Enviar Slack
  "üö® CTR bajo en carrusel [nombre]: [X]% (vs objetivo 2%+)"
  [Link a dashboard] | [Link a editar]
```

**Alerta 2: Conversi√≥n An√≥mala**
```
Trigger: Real-time (si tasa conversi√≥n cae >50% vs promedio)
Condition: Tasa conversi√≥n < [promedio √ó 0.5]
Action: Enviar Slack urgente
  "‚ö†Ô∏è Conversi√≥n cay√≥ en [carrusel]: [X]% (vs [promedio]%)"
```

**Alerta 3: Comentario Negativo**
```
Trigger: Nuevo comentario (Meta API webhook)
Condition: Sentimiento negativo (API an√°lisis)
Action: Enviar Slack + crear tarea CRM
  "üì© Comentario negativo en [carrusel] de [usuario]"
  [Link a comentario] | [Crear tarea seguimiento]
```

### Dashboard de Monitoreo (Tiempo Real)

**Herramienta**: Google Data Studio / Looker / Metabase

**KPIs en tiempo real**:
- Impresiones √∫ltimas 24h
- CTR √∫ltimo carrusel
- Conversiones pendientes (click pero no form)
- Engagement rate (likes/comentarios/shares)

**Alertas autom√°ticas**: Si m√©tricas caen fuera de rango normal ‚Üí Slack

---

## üìã Checklist Final Integrado (Todos los Sistemas)

### Antes de Publicar Carrusel

**Dise√±o**:
- [ ] QA visual (contraste, texto, logo)
- [ ] Export en 3 tama√±os (1080√ó1080, 1080√ó1350, 1080√ó1920)
- [ ] Nombre de archivo coincide con `utm_content` (ver `UTM_GUIDE_OUTREACH.md`)

**UTMs**:
- [ ] UTMs generados seg√∫n convenci√≥n (ver secci√≥n [UTMs Espec√≠ficos](#-utms-espec√≠ficos-para-carruseles))
- [ ] Shortlinks creados con UTMs embebidos
- [ ] Campos UTM configurados en CRM (ver `TOOLS_CRM_COMPARISON.md`)
- [ ] QA checklist UTMs completado (ver `UTM_GUIDE_OUTREACH.md`)

**Automatizaci√≥n**:
- [ ] Workflows Make/Zapier activos (ver `26_ADVANCED_AUTOMATION_WORKFLOWS.md`)
- [ ] Lead scoring configurado
- [ ] DMs templates listos (ver `COPY_PASTE_READY_DMS.md`)
- [ ] Email sequences activas (nurturing)

**Tracking**:
- [ ] Pixel Meta configurado (eventos `ViewContent`, `Lead`)
- [ ] GA4 eventos personalizados (carousel_view, slide_complete, carousel_cta_click)
- [ ] CRM mapeo de UTMs verificado
- [ ] Dashboard de m√©tricas actualizado

**Community**:
- [ ] Templates de respuestas preparados (ver secci√≥n [Community Management](#-templates-de-respuestas-a-comentarios-community-management))
- [ ] Horario de publicaci√≥n definido
- [ ] Equipo notificado (Slack/email)

### Post-Publicaci√≥n (Primeras 24h)

- [ ] Monitorear m√©tricas cada 2 horas
- [ ] Responder comentarios (m√°ximo 1h de delay)
- [ ] Revisar alertas (Slack/Discord)
- [ ] Ajustar retargeting si necesario
- [ ] Documentar learnings iniciales

---

## üîó Referencias Cruzadas (Documentos Relacionados)

### Documentos Clave

1. **`TOOLS_CRM_COMPARISON.md`**
   - Mapeos de campos UTM por CRM
   - Ejemplos API/Payload
   - Integraciones espec√≠ficas

2. **`UTM_GUIDE_OUTREACH.md`**
   - Convenciones completas de UTMs
   - F√≥rmulas Sheets
   - GA4 Explorations
   - QA checklists

3. **`26_ADVANCED_AUTOMATION_WORKFLOWS.md`**
   - Workflows end-to-end
   - Automatizaciones por canal
   - AI-powered personalization

4. **`COPY_PASTE_READY_DMS.md`**
   - Templates de DMs por industria
   - Rubricas de QA
   - Variantes por persona

### Flujo de Trabajo Recomendado

1. **Crear carrusel** ‚Üí Usar este documento (CARRUSELES_SOCIALES_VF.md)
2. **Configurar UTMs** ‚Üí Seguir `UTM_GUIDE_OUTREACH.md`
3. **Setup CRM** ‚Üí Usar `TOOLS_CRM_COMPARISON.md`
4. **Automatizar workflows** ‚Üí Implementar `26_ADVANCED_AUTOMATION_WORKFLOWS.md`
5. **Responder DMs/comentarios** ‚Üí Usar templates de `COPY_PASTE_READY_DMS.md`

---

## üé® Sistema de Dise√±o SVG (Basado en Templates Existentes)

### Estructura Base SVG para Carruseles

**Referencia**: Ver templates `ad_ia_bulk_1200x627_v2.svg`, `ad_curso_ia_1200x627_v2.svg`

**Dimensiones est√°ndar**:
- Instagram Carrusel: 1080√ó1080 px
- Instagram Stories: 1080√ó1920 px
- LinkedIn Ads: 1200√ó627 px
- Facebook Feed: 1080√ó1080 px

### Sistema de Colores (Gradientes y Tokens)

**Paleta base** (basada en templates):
```svg
<!-- Gradiente fondo -->
<linearGradient id="bg" x1="0" y1="0" x2="1" y2="1">
  <stop offset="0%" stop-color="#0A2F4A"/>  <!-- Azul oscuro primario -->
  <stop offset="100%" stop-color="#1E2B3A"/> <!-- Azul oscuro secundario -->
</linearGradient>

<!-- Gradiente acento -->
<linearGradient id="accent" x1="0" y1="0" x2="0" y2="1">
  <stop offset="0%" stop-color="#2DD4BF"/>   <!-- Verde/teal claro -->
  <stop offset="100%" stop-color="#22C1A7"/>  <!-- Verde/teal oscuro -->
</linearGradient>
```

**Tokens por producto**:
- **Curso IA**: Azul (`#2E86DE` ‚Üí `#54A0FF`)
- **SaaS Marketing**: Verde/Teal (`#2DD4BF` ‚Üí `#22C1A7`)
- **IA Bulk**: Cian/Turquesa (`#7EE3D6` ‚Üí `#22C1A7`)

### Tipograf√≠a (Estilos CSS en SVG)

**Sistema tipogr√°fico** (basado en Inter):
```svg
<style>
  @font-face { font-family: Inter; src: local('Inter'), local('Arial'); }
  
  .eyebrow { 
    font: 700 13px/1.2 Inter, Arial, sans-serif; 
    letter-spacing: 0.15em; 
    fill: #7EE3D6; 
    text-transform: uppercase; 
  }
  
  .headline { 
    font: 800 64px/1.1 Inter, Arial, sans-serif; 
    fill: #FFFFFF; 
    letter-spacing: -0.02em; 
  }
  
  .headline-accent { 
    font: 800 64px/1.1 Inter, Arial, sans-serif; 
    fill: url(#accent); 
    letter-spacing: -0.02em; 
  }
  
  .sub { 
    font: 400 24px/1.5 Inter, Arial, sans-serif; 
    fill: #E5E7EB; 
  }
  
  .cta { 
    font: 700 24px/1 Inter, Arial, sans-serif; 
    fill: #0A2F4A; 
    letter-spacing: 0.02em; 
  }
  
  .metric { 
    font: 800 32px/1.2 Inter, Arial, sans-serif; 
    fill: url(#accent); 
  }
  
  .testimonial { 
    font: 400 19px/1.5 Inter, Arial, sans-serif; 
    fill: #D1FAE5; 
    font-style: italic; 
  }
</style>
```

### Componentes Reutilizables SVG

**1. Badge de M√©trica** (como en templates):
```svg
<g id="metric-badge">
  <rect width="260" height="140" rx="16" fill="#0F2130" stroke="#283445"/>
  <text class="metric-label" x="20" y="28">Ahorro semanal</text>
  <text class="metric" x="20" y="60">15h</text>
</g>
```

**2. Bot√≥n CTA** (estilo templates):
```svg
<g id="cta-button">
  <rect width="236" height="60" rx="12" fill="url(#accent)"/>
  <text class="cta" x="118" y="38" text-anchor="middle">Solicita demo</text>
</g>
```

**3. Card de Testimonio**:
```svg
<g id="testimonial-card">
  <rect width="400" height="120" rx="12" fill="#0F2130" stroke="#283445"/>
  <text class="testimonial" x="20" y="40">"[Cita del testimonio]"</text>
  <text class="author" x="20" y="90">‚Äî Nombre, Cargo</text>
</g>
```

### Template Base para Slide de Carrusel

**Estructura completa** (1080√ó1080 px):
```svg
<svg xmlns="http://www.w3.org/2000/svg" width="1080" height="1080" viewBox="0 0 1080 1080">
  <defs>
    <!-- Gradientes y estilos (copiar de arriba) -->
  </defs>
  
  <!-- Fondo -->
  <rect width="1080" height="1080" fill="url(#bg)"/>
  
  <!-- Elementos decorativos sutiles -->
  <g opacity="0.08">
    <circle cx="950" cy="150" r="120" fill="#283445"/>
  </g>
  
  <!-- Logo (esquina superior izquierda) -->
  <g transform="translate(72,72)">
    <!-- Logo aqu√≠ -->
  </g>
  
  <!-- Contenido principal -->
  <g transform="translate(72,200)">
    <text class="eyebrow" x="0" y="0">[Eyebrow text]</text>
    <text class="headline" x="0" y="80">[Titular principal]</text>
    <text class="sub" x="0" y="140">[Subcopy]</text>
  </g>
  
  <!-- CTA (slide 3) -->
  <g transform="translate(72,850)">
    <rect width="300" height="72" rx="16" fill="url(#accent)"/>
    <text class="cta" x="150" y="46" text-anchor="middle">√önete ahora</text>
  </g>
</svg>
```

---

## üîß Scripts de Automatizaci√≥n SVG

### Python: Generar Variantes desde Template

**Script**: `generate_carousel_variants.py`
```python
#!/usr/bin/env python3
"""
Genera variantes de carruseles desde template SVG base
"""
import xml.etree.ElementTree as ET
import re

def replace_text_in_svg(template_path, replacements, output_path):
    """Reemplaza texto en SVG manteniendo estructura"""
    tree = ET.parse(template_path)
    root = tree.getroot()
    
    # Namespace
    ns = {'svg': 'http://www.w3.org/2000/svg'}
    
    # Reemplazar texto en todos los elementos text
    for text_elem in root.findall('.//svg:text', ns):
        text = text_elem.text or ''
        for old, new in replacements.items():
            text = text.replace(old, new)
        text_elem.text = text
    
    tree.write(output_path, encoding='utf-8', xml_declaration=True)
    print(f"‚úÖ Generado: {output_path}")

# Variantes para Curso IA
variants = [
    {
        'output': 'carrusel-curso-ia-s1-v1.svg',
        'replacements': {
            '[PRODUCTO]': 'Curso de IA',
            '[BENEFICIO]': 'Domina IA aplicada en semanas',
            '[METRICA]': '2√ó m√°s r√°pido'
        }
    },
    {
        'output': 'carrusel-curso-ia-s2-v1.svg',
        'replacements': {
            '[CITA]': 'Desde que uso el Curso mis entregas son 2√ó m√°s r√°pidas',
            '[AUTOR]': 'Sof√≠a, Project Manager'
        }
    },
    {
        'output': 'carrusel-curso-ia-s3-v1.svg',
        'replacements': {
            '[CTA]': '√önete ahora',
            '[REFUERZO]': 'Cupos limitados'
        }
    }
]

for variant in variants:
    replace_text_in_svg(
        'template_carrusel_base.svg',
        variant['replacements'],
        variant['output']
    )
```

### Node.js: Export SVG ‚Üí PNG (M√∫ltiples Tama√±os)

**Script**: `export_svg_to_png.js`
```javascript
const { SVG } = require('@svgdotjs/svg.js');
const sharp = require('sharp');
const fs = require('fs');

async function exportSVGToPNG(svgPath, outputPath, width, height) {
  const svgContent = fs.readFileSync(svgPath, 'utf-8');
  
  await sharp(Buffer.from(svgContent))
    .resize(width, height)
    .png({ quality: 90, compressionLevel: 9 })
    .toFile(outputPath);
  
  console.log(`‚úÖ Exportado: ${outputPath} (${width}√ó${height})`);
}

// Exportar en m√∫ltiples tama√±os
const sizes = [
  { width: 1080, height: 1080, suffix: '1080' },
  { width: 1080, height: 1350, suffix: '1080x1350' },
  { width: 1080, height: 1920, suffix: '1080x1920' }
];

const svgFiles = [
  'carrusel-curso-ia-s1-v1.svg',
  'carrusel-curso-ia-s2-v1.svg',
  'carrusel-curso-ia-s3-v1.svg'
];

svgFiles.forEach(async (svgFile) => {
  for (const size of sizes) {
    const outputPath = svgFile
      .replace('.svg', `-${size.suffix}.png`);
    await exportSVGToPNG(svgFile, outputPath, size.width, size.height);
  }
});
```

### Shell: Batch Processing (Optimizar SVGs)

**Script**: `optimize_svgs.sh`
```bash
#!/bin/bash
# Optimiza m√∫ltiples SVGs para web

for file in carrusel-*.svg; do
  echo "Optimizando $file..."
  
  # Usar svgo (instalar: npm install -g svgo)
  svgo "$file" \
    --config='{
      "plugins": [{
        "removeViewBox": false,
        "cleanupIDs": true,
        "minifyStyles": true,
        "removeDimensions": false
      }]
    }' \
    --output "optimized/$file"
  
  echo "‚úÖ Optimizado: optimized/$file"
done
```

---

## üìê Especificaciones T√©cnicas de Dise√±o

### Grid System (1080√ó1080)

**Basado en templates**:
- Margen exterior: 72 px (6.67%)
- Columnas: 12 (cada una 72 px de ancho)
- Gutter: 24 px (entre columnas)
- Safe area interno: 84 px desde bordes

**Coordenadas clave**:
- Logo (esquina sup-izq): `translate(72, 72)`
- Contenido principal: `translate(72, 200)` (titular comienza)
- CTA (bottom): `translate(72, 850)` (72px desde borde inferior)
- Logo (esquina inf-der, slide 3): `translate(960, 960)` (1200 - 72 - 168 logo width)

### Sistema de Espaciado

**Basado en escala 8px**:
- XS: 8px
- SM: 16px
- MD: 24px
- LG: 32px
- XL: 48px
- XXL: 72px

### Componentes Dimensiones

**Bot√≥n CTA**:
- Ancho: 236-300px (variable seg√∫n texto)
- Alto: 60-84px
- Radio: 12-16px
- Padding interno: 24px horizontal

**Badge de M√©trica**:
- Ancho: 260px
- Alto: 140px
- Radio: 16px
- Padding: 20px

**Card de Testimonio**:
- Ancho: 400-500px
- Alto: 120-180px
- Radio: 12px
- Padding: 20px

---

## üéØ Optimizaci√≥n de SVG para Web

### Checklist de Optimizaci√≥n

**Antes de exportar a PNG**:
- [ ] Remover comentarios (`<!-- -->`)
- [ ] Minificar atributos (espacios innecesarios)
- [ ] Optimizar IDs (usar IDs cortos)
- [ ] Combinar paths redundantes
- [ ] Comprimir con svgo o similar

**Despu√©s de exportar PNG**:
- [ ] Comprimir con TinyPNG/ImageOptim
- [ ] Verificar tama√±o < 200KB por slide
- [ ] Testear en dispositivos m√≥viles
- [ ] Verificar contraste (WCAG AA)

### Optimizaci√≥n Autom√°tica (svgo config)

**`.svgorc.json`**:
```json
{
  "plugins": [
    {
      "name": "preset-default",
      "params": {
        "overrides": {
          "removeViewBox": false,
          "cleanupIDs": {
            "minify": true,
            "prefix": "car-"
          },
          "minifyStyles": true,
          "removeDimensions": false
        }
      }
    },
    "removeDoctype",
    "removeXMLProcInst",
    "removeComments",
    "removeMetadata",
    "removeTitle",
    "removeDesc",
    "removeUselessDefs",
    "removeEditorsNSData",
    "removeEmptyAttrs",
    "removeHiddenElems",
    "removeEmptyText",
    "removeEmptyContainers",
    "cleanupIds",
    "convertStyleToAttrs",
    "convertColors",
    "convertPathData",
    "convertTransform",
    "removeUnknownsAndDefaults",
    "removeNonInheritableGroupAttrs",
    "removeUselessStrokeAndFill",
    "removeUnusedNS",
    "cleanupNumericValues",
    "cleanupListOfValues",
    "moveGroupAttrsToElems",
    "collapseGroups",
    "mergePaths",
    "convertShapeToPath",
    "sortAttrs",
    "removeDimensions"
  ]
}
```

**Comando**:
```bash
svgo -f ./svgs/carruseles -o ./svgs/optimized --config .svgorc.json
```

---

## üì¶ Estructura de Archivos Recomendada

```
carruseles/
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îú‚îÄ‚îÄ template_slide1_base.svg
‚îÇ   ‚îú‚îÄ‚îÄ template_slide2_base.svg
‚îÇ   ‚îî‚îÄ‚îÄ template_slide3_base.svg
‚îú‚îÄ‚îÄ source/
‚îÇ   ‚îú‚îÄ‚îÄ curso_ia/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ curso_ia_s1_v1.svg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ curso_ia_s2_v1.svg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ curso_ia_s3_v1.svg
‚îÇ   ‚îú‚îÄ‚îÄ saas_marketing/
‚îÇ   ‚îî‚îÄ‚îÄ ia_bulk/
‚îú‚îÄ‚îÄ optimized/
‚îÇ   ‚îî‚îÄ‚îÄ [mismos archivos optimizados]
‚îú‚îÄ‚îÄ exports/
‚îÇ   ‚îú‚îÄ‚îÄ png/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1080x1080/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1080x1350/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 1080x1920/
‚îÇ   ‚îî‚îÄ‚îÄ webp/
‚îÇ       ‚îî‚îÄ‚îÄ [versiones WebP]
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_variants.py
‚îÇ   ‚îú‚îÄ‚îÄ export_to_png.js
‚îÇ   ‚îî‚îÄ‚îÄ optimize_svgs.sh
‚îî‚îÄ‚îÄ README.md
```

---

## üîç QA de Dise√±o SVG (Checklist)

### Antes de Exportar

**Estructura**:
- [ ] Todos los textos tienen clases CSS (no inline styles)
- [ ] IDs de gradientes/filtros son √∫nicos
- [ ] ViewBox correcto seg√∫n dimensiones
- [ ] Namespace SVG correcto

**Accesibilidad**:
- [ ] Textos tienen `fill` (no solo stroke)
- [ ] Contraste m√≠nimo AA (‚â•4.5:1)
- [ ] Textos importantes no est√°n en `<defs>` ocultos
- [ ] Logo tiene alt text (si aplica)

**Rendimiento**:
- [ ] Gradientes optimizados (m√°ximo 2-3 stops)
- [ ] Filtros usados solo si necesario
- [ ] Paths simplificados (no demasiados puntos)
- [ ] Tama√±o archivo < 50KB (SVG) o < 200KB (PNG export)

### Despu√©s de Exportar PNG

**Calidad**:
- [ ] Sin pixelaci√≥n en zoom 100%
- [ ] Textos legibles en m√≥vil
- [ ] Colores consistentes (sRGB)
- [ ] Transparencias correctas (si aplica)

**Tama√±o**:
- [ ] PNG < 200KB (comprimido)
- [ ] WebP < 150KB (alternativa)
- [ ] Resoluci√≥n correcta (1080px, 1350px, 1920px)

---

## üìä Variantes Pre-configuradas (Basadas en Templates)

### Variante 1: Minimalista (Slide 2 - Testimonio)

**Estructura**:
- Fondo: Gradiente simple (sin decorativos)
- Contenido: Solo cita + autor
- Sin m√©tricas ni badges
- Logo m√≠nimo

**Uso**: Cuando el testimonio es muy fuerte

### Variante 2: Completa (Slide 1 - Hook)

**Estructura**:
- Fondo: Gradiente + elementos decorativos sutiles
- Contenido: Eyebrow + Titular + Subcopy + M√©tricas
- Badges de beneficio
- Logo prominente

**Uso**: Primera impresi√≥n, m√°ximo impacto

### Variante 3: Urgencia (Slide 3 - CTA)

**Estructura**:
- Fondo: M√°s oscuro (mayor contraste)
- CTA: Bot√≥n m√°s grande, color acento brillante
- Texto de refuerzo: "Cupos limitados", "Solo hoy"
- Badge de escasez (opcional)

**Uso**: Conversi√≥n final, crear urgencia

### Variante 4: Social Proof (Slide 2 - Alternativa)

**Estructura**:
- Testimonio + m√©trica destacada
- Logo cliente (si aplica)
- Badge "500+ clientes" o similar
- Visual de gr√°fico ascendente

**Uso**: Cuando necesitas m√°s credibilidad

---

## üé® Gu√≠a de Estilo Visual (Basada en Templates)

### Principios de Dise√±o

1. **Contraste Alto**: Texto blanco sobre fondo oscuro (legibilidad m√≥vil)
2. **Jerarqu√≠a Clara**: Eyebrow (13px) ‚Üí Headline (64px) ‚Üí Sub (24px)
3. **Espaciado Generoso**: M√≠nimo 24px entre elementos relacionados
4. **Acento Estrat√©gico**: Usar color acento solo para CTA y m√©tricas clave

### Reglas de Color

**Fondo**:
- Siempre gradiente oscuro (azul/gris oscuro)
- Opacidad decorativos ‚â§ 18%

**Texto**:
- Principal: Blanco (#FFFFFF)
- Secundario: Gris claro (#E5E7EB)
- Terciario: Gris medio (#94A3B8)

**Acentos**:
- CTA: Color acento brillante (verde/azul seg√∫n producto)
- M√©tricas: Color acento
- Eyebrow: Color acento claro (80% opacidad)

### Elementos Decorativos

**Regla**: Menos es m√°s
- M√°ximo 2-3 c√≠rculos decorativos por slide
- Opacidad 8-18%
- Posici√≥n: Esquinas, no interferir con texto

---

## üéØ Variantes por Objetivo (Basadas en Templates Existentes)

### Variante: Metrics (Enfoque en Datos)

**Referencia**: `ad_curso_ia_1200x627_metrics.svg`

**Caracter√≠sticas**:
- Badges de m√©tricas destacadas (ej: "+27% Leads", "-32% CPA")
- Testimonio con datos espec√≠ficos
- Visual de crecimiento (gr√°ficos/barras)
- Colores: Azul gradiente (`#2E86DE` ‚Üí `#54A0FF`)

**Cu√°ndo usar**:
- Audiencia data-driven (CMOs, Analysts)
- Compra considerada (B2B alto ticket)
- Necesitas probar ROI concreto

**Componentes clave**:
```svg
<!-- Badge m√©trica -->
<rect width="260" height="140" rx="16" fill="#0F2130" stroke="#2B3A4A"/>
<text class="metric-label">Leads</text>
<text class="metric">+27%</text>
<text class="metric-label">CPA</text>
<text class="metric">-32%</text>

<!-- Testimonio con m√©tricas -->
<text class="testimonial">"Resultados medibles: +27% leads y -32% CPA en 6 semanas."</text>
```

**Copy sugerido**:
- Titular: "Mejora tu ROI en +20% con [Producto]"
- M√©tricas: Incluir 2-3 KPIs relevantes
- Testimonio: Enfatizar n√∫meros espec√≠ficos

---

### Variante: Social Proof (Enfoque en Credibilidad)

**Referencia**: `webinar-preroll-social-proof.svg`, `ad_saas_ia_marketing_1200x627_social_proof.svg`

**Caracter√≠sticas**:
- Stats de audiencia (ej: "2,500+ inscritos", "4.9‚òÖ", "87% aplican")
- Logos de clientes/empresas
- Testimonios m√∫ltiples (mini cards)
- Badges de certificaci√≥n/ratings

**Cu√°ndo usar**:
- Nuevos productos/servicios
- Necesitas construir confianza r√°pida
- Audiencia esc√©ptica
- Lanzamientos/Webinars

**Componentes clave**:
```svg
<!-- Stats social proof -->
<rect width="220" height="140" rx="16" fill="#0E3740" stroke="#00C1BE"/>
<text class="metric">2,500+</text>
<text class="label">Inscritos</text>
<text class="sub">√∫ltimo webinar</text>

<!-- Testimonial mini card -->
<rect width="720" height="80" rx="12" fill="rgba(255,255,255,0.08)"/>
<text class="testimonial">"Aument√© mis ventas 3x en 2 semanas"</text>
<text class="author">‚Äî Mar√≠a G., E-commerce Manager</text>
```

**Copy sugerido**:
- Titular: "√önete a +2,500 profesionales que ya [beneficio]"
- Stats: M√≠nimo 3 m√©tricas (inscritos, rating, tasa aplicaci√≥n)
- Testimonios: Cortos, espec√≠ficos, con rol

---

### Variante: Urgency (Enfoque en Escasez)

**Referencia**: `webinar-preroll-urgent-v2.svg`, `ad_saas_ia_marketing_1200x627_urgency.svg`

**Caracter√≠sticas**:
- Colores m√°s intensos (naranja/rojo o acento brillante)
- Badges de urgencia ("Solo hoy", "Cupos limitados")
- Contador/countdown (opcional)
- Fondo m√°s oscuro (mayor contraste)

**Cu√°ndo usar**:
- Ofertas con fecha l√≠mite
- Cupos limitados (webinars, cursos)
- Cierre de mes/trimestre
- Promociones temporales

**Componentes clave**:
```svg
<!-- Badge urgencia -->
<rect width="230" height="36" rx="18" fill="#EF4444" stroke="#DC2626"/>
<text class="urgency-badge">Solo hoy - Cupos limitados</text>

<!-- CTA m√°s prominente -->
<rect width="540" height="114" rx="16" fill="url(#accent-bright)"/>
<text class="cta-urgent">√önete ahora</text>
```

**Copy sugerido**:
- Titular: Mantener beneficio, agregar escasez al final
- Badge: "Solo [X] cupos disponibles"
- CTA: M√°s directo ("√önete ahora" vs "Ver m√°s")

---

### Variante: Elegant (Enfoque en Sofisticaci√≥n)

**Referencia**: `webinar-preroll-elegant.svg`

**Caracter√≠sticas**:
- Fondo claro (gradiente suave blanco/azul claro)
- Tipograf√≠a m√°s refinada (mayor line-height)
- Cards elegantes con sombras sutiles
- Espaciado m√°s generoso
- Decorativos m√≠nimos (l√≠neas punteadas sutiles)

**Cu√°ndo usar**:
- Audiencia enterprise/alta ejecuci√≥n
- Marca premium
- Contenido educativo/sophisticated
- LinkedIn (ambiente profesional)

**Componentes clave**:
```svg
<!-- Fondo claro elegante -->
<linearGradient id="bg" x1="0" y1="0" x2="1" y2="1">
  <stop offset="0%" stop-color="#FAFBFD"/>
  <stop offset="100%" stop-color="#F1F5FF"/>
</linearGradient>

<!-- Cards elegantes con shine -->
<rect width="280" height="160" rx="20" fill="#FFFFFF" filter="url(#sh)"/>
<rect width="280" height="160" rx="20" fill="url(#cardShine)" opacity="0.6"/>
```

**Copy sugerido**:
- Lenguaje m√°s formal y profesional
- Menos emojis, m√°s palabras clave
- Beneficios estrat√©gicos (no solo t√°cticos)

---

## üì∫ Templates para Webinar Preroll

### Estructura Base (1920√ó1080)

**Referencia**: Ver `webinar-preroll-*.svg`

**Dimensiones est√°ndar**:
- Full HD: 1920√ó1080 px (16:9)
- Export tambi√©n: 1080√ó1080 (square) para Instagram
- Safe area: 160px desde bordes (horizontal), 80px (vertical)

### Componentes Esenciales Webinar

**1. Header con Badge**:
```svg
<rect width="1240" height="88" rx="14" fill="url(#accent)"/>
<text class="eyebrow">WEBINAR GRATIS</text>
```

**2. Headline Principal**:
- Tama√±o: 76-96px (depende de variante)
- Peso: 900 (Black)
- Color: Blanco o oscuro (seg√∫n fondo)

**3. Info Cards (Fecha/Hora)**:
```svg
<!-- Card Fecha -->
<rect width="420" height="84" rx="12" fill="#0F2130" stroke="#2B3A4A"/>
<text class="card-value">[FECHA]</text>

<!-- Card Hora -->
<rect width="380" height="84" rx="12" fill="#0F2130" stroke="#2B3A4A"/>
<text class="card-value">[HORA] (GMT-5)</text>
```

**4. Stats Social Proof** (variante social-proof):
- 3 cards lado a lado
- M√©tricas: Inscritos, Rating, Tasa aplicaci√≥n
- Color acento para n√∫meros

**5. Testimonio Mini**:
```svg
<rect width="720" height="80" rx="12" fill="rgba(255,255,255,0.08)"/>
<text class="testimonial-mini">"[Cita corta]"</text>
<text class="author-mini">‚Äî Nombre, Cargo</text>
```

**6. CTA Prominente**:
- Ancho: 540px
- Alto: 114px
- Radio: 16px
- Texto: 46px, peso 900

**7. Logos Clientes** (opcional):
- 4-5 logos en fila
- Cards semi-transparentes
- Tama√±o: 140√ó50px cada una

**8. QR Code** (esquina inf-der):
- 180√ó180px
- Fondo semi-transparente
- Texto placeholder: "QR ‚Üí [URL]"

---

## üîÑ Script para Generar Variantes Autom√°ticamente

### Python: Generar Todas las Variantes

**Script**: `generate_all_variants.py`
```python
#!/usr/bin/env python3
"""
Genera todas las variantes de un carrusel desde template base
Variantes: metrics, social-proof, urgency, elegant
"""
import xml.etree.ElementTree as ET
import os

VARIANT_CONFIGS = {
    'metrics': {
        'gradient_stop_1': '#2E86DE',
        'gradient_stop_2': '#54A0FF',
        'bg_color_1': '#092A44',
        'bg_color_2': '#1F2D3D',
        'show_metrics': True,
        'show_testimonial': True,
        'urgency_badge': False
    },
    'social_proof': {
        'gradient_stop_1': '#00E5A8',
        'gradient_stop_2': '#00B4D8',
        'bg_color_1': '#0B1229',
        'bg_color_2': '#10314A',
        'show_metrics': True,
        'show_testimonial': True,
        'show_logos': True,
        'stats_boxes': True
    },
    'urgency': {
        'gradient_stop_1': '#F97316',
        'gradient_stop_2': '#EF4444',
        'bg_color_1': '#1F2937',
        'bg_color_2': '#0F172A',
        'show_metrics': False,
        'urgency_badge': True,
        'cta_size': 'large'
    },
    'elegant': {
        'gradient_stop_1': '#2948FF',
        'gradient_stop_2': '#6BA3FF',
        'bg_color_1': '#FAFBFD',
        'bg_color_2': '#F1F5FF',
        'show_metrics': True,
        'card_style': 'light',
        'spacing': 'generous'
    }
}

def replace_in_svg(template_path, variant, config, output_path):
    """Reemplaza estilos y elementos seg√∫n variante"""
    tree = ET.parse(template_path)
    root = tree.getroot()
    
    # Reemplazar gradientes
    for gradient in root.findall('.//{http://www.w3.org/2000/svg}linearGradient'):
        if gradient.get('id') == 'accent':
            stops = gradient.findall('.//{http://www.w3.org/2000/svg}stop')
            if len(stops) >= 2:
                stops[0].set('stop-color', config['gradient_stop_1'])
                stops[1].set('stop-color', config['gradient_stop_2'])
        
        if gradient.get('id') == 'bg':
            stops = gradient.findall('.//{http://www.w3.org/2000/svg}stop')
            if len(stops) >= 2:
                stops[0].set('stop-color', config['bg_color_1'])
                stops[1].set('stop-color', config['bg_color_2'])
    
    # Mostrar/ocultar elementos seg√∫n config
    if not config.get('show_metrics', False):
        for elem in root.findall('.//{http://www.w3.org/2000/svg}g[@id="metrics"]'):
            elem.set('display', 'none')
    
    if config.get('urgency_badge', False):
        # A√±adir badge de urgencia (si no existe)
        pass  # Implementar l√≥gica para a√±adir badge
    
    tree.write(output_path, encoding='utf-8', xml_declaration=True)
    print(f"‚úÖ Generado: {output_path}")

# Generar todas las variantes para cada producto
PRODUCTS = ['curso_ia', 'saas_marketing', 'ia_bulk']
SLIDES = ['s1', 's2', 's3']

for product in PRODUCTS:
    for slide in SLIDES:
        template = f'templates/carrusel-{product}-{slide}-base.svg'
        if os.path.exists(template):
            for variant, config in VARIANT_CONFIGS.items():
                output = f'source/{product}/carrusel-{product}-{slide}-{variant}.svg'
                replace_in_svg(template, variant, config, output)
```

**Uso**:
```bash
python generate_all_variants.py
# Genera: curso_ia_s1_metrics.svg, curso_ia_s1_social_proof.svg, etc.
```

---

## üìä Matriz de Decisi√≥n: ¬øQu√© Variante Usar?

### Por Audiencia

| Audiencia | Variante Recomendada | Raz√≥n |
|-----------|---------------------|-------|
| CMOs / Data Analysts | Metrics | Necesitan n√∫meros concretos |
| Founders / Startups | Social Proof | Construir confianza r√°pida |
| SMB / Budget-conscious | Urgency | Escasez aumenta conversi√≥n |
| Enterprise / VPs | Elegant | Sofisticaci√≥n, menos presi√≥n |

### Por Funnel Stage

| Stage | Variante | Objetivo |
|-------|----------|----------|
| TOF (Top of Funnel) | Social Proof o Elegant | Awareness + confianza |
| MOF (Middle) | Metrics | Consideraci√≥n, datos |
| BOF (Bottom) | Urgency | Conversi√≥n, escasez |

### Por Objetivo de Campa√±a

| Objetivo | Variante | KPI Principal |
|----------|----------|---------------|
| Brand Awareness | Elegant | Impresiones, engagement |
| Lead Generation | Social Proof | Form submissions |
| Sales/Revenue | Urgency | Conversiones, revenue |
| Education/Demo | Metrics | Demo requests, calidad leads |

---

## üé¨ Adaptaci√≥n de Webinar Preroll para Carrusel

### Convertir Preroll ‚Üí Slide de Carrusel

**Proceso**:
1. **Redimensionar**: 1920√ó1080 ‚Üí 1080√ó1080
2. **Simplificar**: Reducir elementos (webinar preroll tiene m√°s info)
3. **Enfocar**: 1 mensaje principal por slide
4. **Optimizar**: Ajustar tipograf√≠as (m√°s peque√±as)

**Elementos a mantener**:
- Headline principal
- CTA (si aplica)
- Badge social proof (si slide 2)
- Logo

**Elementos a remover**:
- Info cards m√∫ltiples (fecha/hora ‚Üí solo si relevante)
- Testimonios largos (‚Üí cita corta)
- Logos m√∫ltiples (‚Üí 1-2 si necesario)
- QR code (no funciona en carrusel)

**Ejemplo adaptaci√≥n**:

**Webinar Preroll Original**:
- Headline grande (96px)
- 3 info cards (fecha, hora, beneficios)
- Stats social proof (3 boxes)
- Testimonio completo
- CTA grande

**Carrusel Slide Adaptado**:
- Headline (64px, m√°s corto)
- 1 m√©trica destacada o testimonio corto
- CTA claro
- Logo

---

## üîß Configuraci√≥n de Exportaci√≥n Autom√°tica

### Makefile para Pipeline Completo

**`Makefile`**:
```makefile
# Variables
SVG_SOURCE = source/
SVG_OPTIMIZED = optimized/
PNG_EXPORT = exports/png/
SIZES = 1080x1080 1080x1350 1080x1920

# Generar variantes desde templates
generate-variants:
	python scripts/generate_all_variants.py
	@echo "‚úÖ Variantes generadas"

# Optimizar SVGs
optimize:
	svgo -f $(SVG_SOURCE) -o $(SVG_OPTIMIZED) --config .svgorc.json
	@echo "‚úÖ SVGs optimizados"

# Exportar a PNG
export-png:
	@for size in $(SIZES); do \
		mkdir -p $(PNG_EXPORT)/$$size; \
		node scripts/export_to_png.js $(SVG_OPTIMIZED) $(PNG_EXPORT)/$$size $$size; \
	done
	@echo "‚úÖ PNGs exportados"

# Comprimir PNGs
compress:
	@for size in $(SIZES); do \
		imageoptim --directory $(PNG_EXPORT)/$$size; \
	done
	@echo "‚úÖ PNGs comprimidos"

# Pipeline completo
all: generate-variants optimize export-png compress
	@echo "üéâ Pipeline completo finalizado"

# Limpiar
clean:
	rm -rf $(SVG_OPTIMIZED) $(PNG_EXPORT)
	@echo "‚úÖ Archivos limpiados"
```

**Uso**:
```bash
make all          # Ejecuta todo el pipeline
make generate-variants  # Solo generar variantes
make export-png   # Solo exportar PNGs
```

---

## üìã Checklist de Variantes (Pre-Publicaci√≥n)

### Para Cada Variante

**Metrics**:
- [ ] M√©tricas son verificables (no exageradas)
- [ ] Testimonio incluye contexto (tiempo, industria)
- [ ] Visual de gr√°fico es claro
- [ ] Disclaimer presente si aplica

**Social Proof**:
- [ ] N√∫meros son actuales (verificar mensualmente)
- [ ] Logos tienen permisos de uso
- [ ] Testimonios tienen permiso escrito
- [ ] Rating es de fuente confiable

**Urgency**:
- [ ] Fecha l√≠mite es real (no gen√©rica)
- [ ] Cupos limitados es verdadero
- [ ] Urgencia no es artificial (compliance)
- [ ] CTA es claro y accionable

**Elegant**:
- [ ] Lenguaje es profesional (sin jerga)
- [ ] Dise√±o es sofisticado (no gen√©rico)
- [ ] Espaciado es generoso (no apretado)
- [ ] Colores son sutiles (no brillantes)

---

## üéÅ Variante: Benefits-Focused (Enfoque en Beneficios)

**Referencia**: `webinar-preroll-benefits-focused.svg`

**Caracter√≠sticas**:
- Cards de beneficios (3-4 cards en fila)
- Iconos checkmarks en c√≠rculos acento
- Estructura: T√≠tulo ‚Üí Descripci√≥n ‚Üí Sub-beneficio
- Fondo oscuro verde (`#071A14` ‚Üí `#0E2A1F`)
- Acento verde (`#34D399` ‚Üí `#10B981`)

**Cu√°ndo usar**:
- Webinars educativos
- Productos con m√∫ltiples features
- Necesitas mostrar valor claro
- Audiencia que eval√∫a opciones

**Componentes clave**:
```svg
<!-- Card beneficio -->
<rect width="500" height="160" rx="20" 
  fill="rgba(255,255,255,0.08)" 
  stroke="#34D399" stroke-width="2"/>

<!-- Icono checkmark -->
<circle cx="40" cy="80" r="24" fill="#34D399" opacity="0.2"/>
<circle cx="40" cy="80" r="14" fill="#34D399"/>
<circle cx="40" cy="80" r="6" fill="#FFFFFF"/>

<!-- Texto beneficio -->
<text class="benefit-title" x="80" y="50">Prompts que reducen CPA</text>
<text class="benefit-desc" x="80" y="85">Estrategias probadas para bajar costos</text>
<text class="benefit-sub" x="80" y="115">Ejemplos reales + plantillas</text>
```

**Estructura de copy** (por card):
1. **T√≠tulo** (benefit-title, 28px): Beneficio principal (ej: "Prompts que reducen CPA")
2. **Descripci√≥n** (benefit-desc, 20px): C√≥mo se logra (ej: "Estrategias probadas para bajar costos")
3. **Sub-beneficio** (benefit-sub, 18px): Extra/tangible (ej: "Ejemplos reales + plantillas")

**Layout sugerido**:
- 3 cards: 500px ancho cada una, gutter 40px
- 4 cards: 380px ancho cada una, gutter 32px
- M√°ximo 4 cards (legibilidad m√≥vil)

---

## üé¨ Video Thumbnails (Basado en Template)

**Referencia**: `webinar-preroll-video-thumbnail.svg`

**Caracter√≠sticas**:
- Play button central prominente (120px radio)
- Headline grande centrado (96px)
- Info chips (fecha/hora)
- Badge "EN VIVO" (si aplica)
- Elementos decorativos m√°s visibles (opacidad 0.2)

**Dimensiones**:
- YouTube: 1280√ó720 px (16:9)
- Instagram Reels: 1080√ó1920 px (9:16)
- LinkedIn Video: 1200√ó627 px (1.91:1)
- Export desde: 1920√ó1080 base

**Componentes esenciales**:

**1. Play Button Central**:
```svg
<circle cx="0" cy="0" r="120" fill="url(#accent)"/>
<circle cx="0" cy="0" r="100" fill="rgba(255,255,255,0.9)"/>
<polygon points="-35,-40  -35,40  50,0" fill="url(#accent)"/>
```

**2. Headline Centrado**:
- Tama√±o: 96px
- Peso: 900 (Black)
- Centrado horizontal (`text-anchor="middle"`)
- Y position: 360px (desde top)

**3. Subheadline**:
- Tama√±o: 42px
- Peso: 700
- Color: Claro pero menos intenso que headline

**4. Badge "EN VIVO"** (opcional):
```svg
<rect width="280" height="80" rx="16" fill="#FF3B3B"/>
<text>‚ö° EN VIVO</text>
```

**Cu√°ndo usar thumbnail style**:
- Videos de YouTube/Reels
- Webinars grabados
- Tutoriales
- Contenido educativo en video

---

## üéØ Adaptaci√≥n: Carrusel ‚Üí Video Thumbnail

### Proceso de Conversi√≥n

**1. Cambiar dimensiones**:
- Desde: 1080√ó1080 (square)
- Hacia: 1280√ó720 (YouTube) o 1920√ó1080 (Full HD)

**2. Simplificar contenido**:
- Remover: M√∫ltiples slides (thumbnails son single image)
- Mantener: Headline principal + 1-2 elementos clave
- Agregar: Play button prominente

**3. Ajustar jerarqu√≠a**:
- Headline: Aumentar a 72-96px (thumbnail necesita ser legible peque√±o)
- CTA: Opcional (YouTube no tiene CTA nativo en thumbnail)
- Info: Fecha/hora si webinar, "Duraci√≥n: X min" si video

**4. Optimizar para preview peque√±o**:
- Texto m√°s grande y bold
- Contraste m√°s alto
- Menos elementos (m√°ximo 3-4)
- Iconos/visuales m√°s grandes

### Template de Thumbnail desde Carrusel

**Script Python**: `carrusel_to_thumbnail.py`
```python
#!/usr/bin/env python3
"""
Convierte slide de carrusel a video thumbnail
"""
import xml.etree.ElementTree as ET

def carrusel_to_thumbnail(carrusel_path, output_path, video_type='youtube'):
    """Convierte carrusel a thumbnail optimizado"""
    tree = ET.parse(carrusel_path)
    root = tree.getroot()
    
    # Dimensiones seg√∫n tipo
    dimensions = {
        'youtube': (1280, 720),
        'instagram_reels': (1080, 1920),
        'linkedin': (1200, 627),
        'full_hd': (1920, 1080)
    }
    width, height = dimensions.get(video_type, (1280, 720))
    
    # Actualizar viewBox y dimensiones
    root.set('width', str(width))
    root.set('height', str(height))
    root.set('viewBox', f'0 0 {width} {height}')
    
    # A√±adir play button si no existe
    # (l√≥gica para insertar play button central)
    
    # Aumentar tama√±o de headline (si existe)
    for text in root.findall('.//{http://www.w3.org/2000/svg}text'):
        if 'headline' in (text.get('class') or ''):
            style = text.get('style', '')
            # Incrementar font-size en 20-30%
            # (l√≥gica de parsing y reemplazo)
    
    # Simplificar: remover elementos secundarios
    # (l√≥gica para identificar y remover elementos no esenciales)
    
    tree.write(output_path, encoding='utf-8', xml_declaration=True)
    print(f"‚úÖ Thumbnail generado: {output_path} ({width}√ó{height})")

# Uso
carrusel_to_thumbnail(
    'carrusel-curso-ia-s1-v1.svg',
    'thumbnail-curso-ia-youtube.png',
    'youtube'
)
```

---

## üìä Componentes de Benefits Cards (Detallado)

### Estructura Completa de Card

**Basado en**: `webinar-preroll-benefits-focused.svg`

**Componentes**:
1. **Contenedor**: Rect con border acento
2. **Icono checkmark**: 3 c√≠rculos conc√©ntricos (opacidad, fondo, check)
3. **T√≠tulo**: Benefit principal (28px, peso 800)
4. **Descripci√≥n**: C√≥mo funciona (20px, peso 500)
5. **Sub-beneficio**: Extra tangible (18px, peso 400)

**Dimensiones est√°ndar**:
- Ancho: 500px (3 cards) o 380px (4 cards)
- Alto: 160px
- Radio: 20px
- Gutter entre cards: 40px (3 cards) o 32px (4 cards)

**C√≥digo completo**:
```svg
<g transform="translate(0,0)" filter="url(#sh)">
  <!-- Contenedor -->
  <rect x="0" y="0" width="500" height="160" rx="20" 
    fill="rgba(255,255,255,0.08)" 
    stroke="#34D399" stroke-width="2"/>
  
  <!-- Icono checkmark -->
  <circle cx="40" cy="80" r="24" fill="#34D399" opacity="0.2"/>
  <circle cx="40" cy="80" r="14" fill="#34D399"/>
  <circle cx="40" cy="80" r="6" fill="#FFFFFF"/>
  
  <!-- Textos -->
  <text x="80" y="50" class="benefit-title">
    [Beneficio principal]
  </text>
  <text x="80" y="85" class="benefit-desc">
    [Descripci√≥n/c√≥mo]
  </text>
  <text x="80" y="115" class="benefit-sub">
    [Extra/tangible]
  </text>
</g>
```

### Ejemplos de Benefits para Cada Producto

**Curso IA**:
1. "Prompts que reducen CPA" ‚Üí "Estrategias probadas" ‚Üí "Ejemplos + plantillas"
2. "Automatizaciones sin c√≥digo" ‚Üí "CRM y workflows" ‚Üí "Setup en 1 hora"
3. "Creatividades con IA" ‚Üí "Genera variaciones" ‚Üí "Sin habilidades dise√±o"

**SaaS Marketing**:
1. "A/B Testing autom√°tico" ‚Üí "Optimiza en tiempo real" ‚Üí "ROI +34% promedio"
2. "Segmentaci√≥n inteligente" ‚Üí "Lookalikes y audiences" ‚Üí "1 clic configuraci√≥n"
3. "Reportes claros" ‚Üí "Dashboard unificado" ‚Üí "Decisiones en minutos"

**IA Bulk**:
1. "100+ documentos con 1 consulta" ‚Üí "Brief √∫nico genera todo" ‚Üí "PDF/DOCX autom√°tico"
2. "Versionado y control" ‚Üí "Historial de cambios" ‚Üí "Auditor√≠a completa"
3. "Plantillas editables" ‚Üí "Personaliza y reutiliza" ‚Üí "Consistencia garantizada"

---

## üé¨ Optimizaci√≥n para Thumbnails de Video

### Reglas de Dise√±o para Thumbnails

**1. Legibilidad en tama√±o peque√±o**:
- Headline m√≠nimo: 72px (legible a 120√ó67px preview)
- Contraste m√≠nimo: 7:1 (WCAG AAA para texto grande)
- Espaciado: Generoso entre elementos

**2. Elementos visuales clave**:
- Play button: M√≠nimo 100px radio (visible en peque√±o)
- Headline: M√°ximo 6-8 palabras
- Persona/producto: Si incluye, que sea reconocible peque√±o

**3. Colores y contraste**:
- Fondo: Oscuro (mejor legibilidad)
- Acento: Brillante (play button, badges)
- Texto: Blanco o color acento (m√°ximo contraste)

**4. Texto optimizado**:
- Evitar: Texto muy largo (m√°ximo 40-50 caracteres)
- Usar: N√∫meros, palabras clave poderosas
- Ejemplo: "C√≥mo [Beneficio] en [Tiempo]" mejor que descripci√≥n larga

### Checklist Thumbnail

**Pre-export**:
- [ ] Headline es legible a tama√±o peque√±o (test en 120√ó67px)
- [ ] Play button es visible y prominente
- [ ] Contraste texto/fondo ‚â•7:1
- [ ] Elementos no esenciales removidos
- [ ] Dimensiones correctas (1280√ó720 YouTube, etc.)

**Post-export**:
- [ ] Verificar en preview real (YouTube, Instagram, etc.)
- [ ] Texto no se corta en previews
- [ ] Colores consistentes (sRGB)
- [ ] Tama√±o archivo < 2MB (YouTube permite hasta 2MB)

---

## üîÑ Workflow: Generar Thumbnails desde Carruseles

### Automatizaci√≥n Completa

**Makefile target**:
```makefile
# Generar thumbnails desde carruseles
thumbnails-from-carousels:
	@echo "Generando thumbnails desde carruseles..."
	python scripts/carrusel_to_thumbnail.py \
		--input source/curso_ia/carrusel-curso-ia-s1-v1.svg \
		--output exports/thumbnails/youtube/curso-ia-thumbnail.png \
		--type youtube
	python scripts/carrusel_to_thumbnail.py \
		--input source/saas_marketing/carrusel-saas-s1-v1.svg \
		--output exports/thumbnails/youtube/saas-thumbnail.png \
		--type youtube
	@echo "‚úÖ Thumbnails generados"
```

**Script completo**: `carrusel_to_thumbnail.py`
```python
#!/usr/bin/env python3
import argparse
import xml.etree.ElementTree as ET
from PIL import Image
import cairosvg

def generate_thumbnail(svg_path, output_path, video_type='youtube'):
    """Genera thumbnail optimizado desde carrusel"""
    
    # Dimensiones
    dims = {
        'youtube': (1280, 720),
        'instagram_reels': (1080, 1920),
        'linkedin': (1200, 627),
        'full_hd': (1920, 1080)
    }
    width, height = dims[video_type]
    
    # Leer SVG
    tree = ET.parse(svg_path)
    root = tree.getroot()
    
    # Actualizar dimensiones
    root.set('width', str(width))
    root.set('height', str(height))
    root.set('viewBox', f'0 0 {width} {height}')
    
    # A√±adir play button si video
    if video_type in ['youtube', 'instagram_reels']:
        add_play_button(root, width, height)
    
    # Aumentar tama√±os de texto
    scale_text_sizes(root, factor=1.3)
    
    # Simplificar elementos
    remove_non_essential(root)
    
    # Guardar SVG temporal
    temp_svg = 'temp_thumbnail.svg'
    tree.write(temp_svg, encoding='utf-8')
    
    # Exportar a PNG
    cairosvg.svg2png(
        url=temp_svg,
        write_to=output_path,
        output_width=width,
        output_height=height
    )
    
    print(f"‚úÖ Thumbnail: {output_path} ({width}√ó{height})")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', required=True)
    parser.add_argument('--output', required=True)
    parser.add_argument('--type', default='youtube')
    args = parser.parse_args()
    
    generate_thumbnail(args.input, args.output, args.type)
```

---

## üìê Especificaciones de Thumbnails por Plataforma

### YouTube

**Dimensiones**: 1280√ó720 px (16:9)  
**Tama√±o archivo**: M√°ximo 2MB  
**Formato**: JPG, PNG, GIF (animado) o WebP

**Especificaciones**:
- Safe area: 10% desde bordes (texto importante dentro)
- Texto m√≠nimo: 60px (legible en preview peque√±o)
- Play button: 120-150px radio (centrado)

**Ejemplo estructura**:
```
[Play Button Central]
[Headline 72-96px]
[Subheadline 36-42px]
[Badge opcional: "EN VIVO", "NUEVO", etc.]
```

### Instagram Reels

**Dimensiones**: 1080√ó1920 px (9:16)  
**Tama√±o**: M√°ximo 30MB  
**Formato**: MP4, MOV

**Especificaciones**:
- Safe area: 15% desde bordes (evitar cortes en preview)
- Texto: Vertical-friendly (mayor tama√±o)
- Play button: M√°s grande (150-180px)

### LinkedIn Video

**Dimensiones**: 1200√ó627 px (1.91:1)  
**Tama√±o**: M√°ximo 200MB  
**Formato**: MP4, MOV

**Especificaciones**:
- Similar a YouTube pero formato landscape
- Texto: 64-80px headline
- M√°s profesional (menos badges llamativos)

---

## üé® Play Button Styles (Variantes)

### Estilo 1: Minimalista (Circles)

```svg
<circle cx="0" cy="0" r="120" fill="url(#accent)"/>
<circle cx="0" cy="0" r="100" fill="rgba(255,255,255,0.9)"/>
<polygon points="-35,-40  -35,40  50,0" fill="url(#accent)"/>
```

### Estilo 2: Con Borde Brillante

```svg
<circle cx="0" cy="0" r="130" fill="rgba(255,255,255,0.2)"/>
<circle cx="0" cy="0" r="120" fill="url(#accent)"/>
<circle cx="0" cy="0" r="100" fill="rgba(255,255,255,0.95)"/>
<polygon points="-35,-40  -35,40  50,0" fill="url(#accent)"/>
```

### Estilo 3: Cuadrado Redondeado

```svg
<rect x="-120" y="-120" width="240" height="240" 
  rx="30" fill="url(#accent)"/>
<rect x="-100" y="-100" width="200" height="200" 
  rx="25" fill="rgba(255,255,255,0.9)"/>
<polygon points="-35,-40  -35,40  50,0" fill="url(#accent)"/>
```

### Estilo 4: Con Sombra/Glow

```svg
<circle cx="0" cy="0" r="120" fill="url(#accent)" filter="url(#glow)"/>
<circle cx="0" cy="0" r="100" fill="rgba(255,255,255,0.9)"/>
<polygon points="-35,-40  -35,40  50,0" fill="url(#accent)"/>
```

**Cu√°ndo usar cada estilo**:
- Minimalista: Contenido elegante/sophisticated
- Borde brillante: Mayor visibilidad, videos promocionales
- Cuadrado: Marca m√°s tech/moderna
- Con glow: Mayor atenci√≥n, llamativo

---

## üìã Checklist Final: Thumbnail vs Carrusel

### Diferencias Clave

| Aspecto | Carrusel | Thumbnail |
|---------|----------|-----------|
| Dimensiones | 1080√ó1080 | 1280√ó720 (YouTube) |
| Elementos | 3-5 slides | 1 imagen |
| Play button | No | S√≠ (central) |
| Texto | 64px headline | 72-96px headline |
| Info adicional | M√©tricas, testimonios | Fecha/hora, duraci√≥n |
| CTA | Prominente | Opcional |
| Legibilidad | Bueno en tama√±o normal | Cr√≠tico (preview peque√±o) |

### Decision Tree: ¬øCarrusel o Thumbnail?

```
¬øEs contenido en video?
‚îú‚îÄ S√≠ ‚Üí ¬øYouTube/Reels?
‚îÇ   ‚îú‚îÄ S√≠ ‚Üí Thumbnail
‚îÇ   ‚îî‚îÄ No ‚Üí Carrusel
‚îî‚îÄ No ‚Üí Carrusel

¬øTienes m√∫ltiples mensajes?
‚îú‚îÄ S√≠ ‚Üí Carrusel (3 slides)
‚îî‚îÄ No ‚Üí Thumbnail (1 mensaje fuerte)
```

---

## üìê Formato Square (1080√ó1080) ‚Äî Optimizaci√≥n Espec√≠fica

### Caracter√≠sticas del Formato Square

**Referencia**: `ad_curso_ia_1080x1080.svg`, `ad_ia_bulk_1080x1080.svg`

**Dimensiones**: 1080√ó1080 px (ratio 1:1)  
**Uso principal**: Instagram Feed, LinkedIn Feed, Facebook Feed

**Ventajas**:
- Vers√°til (funciona en m√∫ltiples plataformas)
- Preview completo en feed (no se corta)
- Balance visual (espacio sim√©trico)

**Desaf√≠os**:
- Menos espacio horizontal (vs 1200√ó627)
- Requiere composici√≥n m√°s vertical
- Logo y CTA compiten por espacio

### Grid System Optimizado para Square

**Basado en templates 1080√ó1080**:
- Margen exterior: 72 px (6.67%)
- Safe area interno: 84 px desde todos los bordes
- Zonas clave:
  - **Header** (top): Y = 72-240px (eyebrow + inicio headline)
  - **Contenido principal** (middle): Y = 240-540px
  - **CTA/Badge** (bottom): Y = 540-640px (m√≠nimo 72px desde borde inferior)
  - **Visual decorativo** (right): X = 820-1080px, Y = 360px (centrado vertical)

**Layout sugerido**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Logo]           [Decorativo]   ‚îÇ ‚Üê 72-240px
‚îÇ                                  ‚îÇ
‚îÇ [Eyebrow]                        ‚îÇ
‚îÇ [Headline principal]             ‚îÇ ‚Üê 240-420px
‚îÇ [Subcopy]                        ‚îÇ
‚îÇ                                  ‚îÇ
‚îÇ [M√©tricas/Testimonial]           ‚îÇ ‚Üê 420-540px
‚îÇ                                  ‚îÇ
‚îÇ [CTA Button] [Badge]            ‚îÇ ‚Üê 540-640px
‚îÇ                                  ‚îÇ
‚îÇ [Footer/Notas]                   ‚îÇ ‚Üê 980-1080px
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Ajustes Espec√≠ficos para Square

**Tipograf√≠a**:
- Headline: 68px (vs 64px en landscape, necesita m√°s presencia)
- Sub: 26px (vs 24px, mejor legibilidad)
- CTA: 26px (vs 24px)

**Espaciado vertical**:
- Entre eyebrow y headline: 72px (vs 64px)
- Entre headline y sub: 48px (vs 40px)
- Entre secciones: 56px m√≠nimo

**Componentes compactos**:
- Badge de m√©trica: 240√ó130px (vs 260√ó140px en landscape)
- Testimonial box: 480√ó95px (m√°s compacto, una l√≠nea de testimonio)
- CTA button: 280√ó68px (vs 300√ó72px)

---

## üåì Variantes Light vs Dark (Temas)

### Template Light (Fondo Claro)

**Referencia**: `webinar-square-1080x1080-light.svg`

**Caracter√≠sticas**:
- Fondo: Gradiente claro (`#F7FAFF` ‚Üí `#ECF3FF`)
- Texto principal: Oscuro (`#0B1229`)
- Acento: Azul (`#2F57E5` ‚Üí `#6A8CFF`)
- Cards: Fondo claro con borde (`#EEF4FF` + stroke azul)

**Cu√°ndo usar**:
- Audiencia profesional (LinkedIn, B2B)
- Marca premium/sofisticada
- Contenido educativo
- D√≠a/horarios de oficina

**Componentes espec√≠ficos**:
```svg
<!-- Fondo claro -->
<linearGradient id="bg" x1="0" y1="0" x2="1" y2="1">
  <stop offset="0%" stop-color="#F7FAFF"/>
  <stop offset="100%" stop-color="#ECF3FF"/>
</linearGradient>

<!-- Texto oscuro -->
.headline { fill: #0B1229; }  /* Oscuro sobre claro */
.subhead { fill: #34405B; }   /* Gris medio */

<!-- Cards claros -->
<rect fill="#EEF4FF" stroke="#2F57E5"/>
```

**Contraste requerido**:
- Texto oscuro sobre fondo claro: ‚â•4.5:1 (AA m√≠nimo)
- CTA sobre fondo claro: Usar color s√≥lido oscuro o acento brillante

### Template Dark (Fondo Oscuro)

**Referencia**: `webinar-square-1080x1080-dark.svg`

**Caracter√≠sticas**:
- Fondo: Gradiente oscuro (`#0B1229` ‚Üí `#10314A`)
- Texto principal: Claro (`#FFFFFF`, `#BFEFE8`)
- Acento: Verde/cyan (`#00E5A8` ‚Üí `#00B4D8`)
- Cards: Fondo oscuro semi-transparente (`#0E3740` + stroke cyan)

**Cu√°ndo usar**:
- Instagram, Facebook (mejor engagement)
- Audiencia m√°s joven/casual
- Contenido promocional
- Noche/horarios de ocio

**Componentes espec√≠ficos**:
```svg
<!-- Fondo oscuro -->
<linearGradient id="bg" x1="0" y1="0" x2="1" y2="1">
  <stop offset="0%" stop-color="#0B1229"/>
  <stop offset="100%" stop-color="#10314A"/>
</linearGradient>

<!-- Texto claro -->
.headline { fill: #FFFFFF; }   /* Claro sobre oscuro */
.subhead { fill: #BFEFE8; }   /* Verde claro */

<!-- Cards oscuros -->
<rect fill="#0E3740" stroke="#00C1BE"/>
```

**Contraste requerido**:
- Texto claro sobre fondo oscuro: ‚â•4.5:1 (AA)
- CTA: Usar color acento brillante (verde/cyan) para m√°ximo contraste

---

## üîÑ Conversi√≥n: Landscape ‚Üí Square

### Proceso de Adaptaci√≥n

**Desde**: 1200√ó627 (landscape LinkedIn)  
**Hacia**: 1080√ó1080 (square Instagram)

**Paso 1: Redimensionar viewBox**
```svg
<!-- Antes -->
viewBox="0 0 1200 627"

<!-- Despu√©s -->
viewBox="0 0 1080 1080"
```

**Paso 2: Reorganizar layout**
- **Landscape**: Contenido horizontal (texto izquierda, visual derecha)
- **Square**: Contenido m√°s vertical (texto arriba, m√©tricas/testimonial medio, CTA abajo)

**Paso 3: Ajustar coordenadas**

**Landscape (1200√ó627)**:
- Logo: `translate(56, 48)`
- Headline: `translate(56, 158)`
- M√©tricas: `translate(640, 158)` (derecha)
- CTA: `translate(56, 448)`

**Square (1080√ó1080)**:
- Logo: `translate(72, 72)`
- Headline: `translate(72, 240)` (m√°s abajo)
- M√©tricas: `translate(560, 240)` (derecha, menos espacio)
- CTA: `translate(72, 540)` (m√°s abajo)

**Paso 4: Compactar elementos**
- Testimonial: 2 l√≠neas ‚Üí 1 l√≠nea
- M√©tricas: Badge m√°s peque√±o (240√ó130px vs 260√ó140px)
- Visual decorativo: Escalar a 2.6√ó (vs 2.5√ó)

### Script Autom√°tico de Conversi√≥n

**Python**: `landscape_to_square.py`
```python
#!/usr/bin/env python3
"""
Convierte template landscape (1200√ó627) a square (1080√ó1080)
"""
import xml.etree.ElementTree as ET
import re

def landscape_to_square(input_path, output_path):
    """Adapta layout de landscape a square"""
    tree = ET.parse(input_path)
    root = tree.getroot()
    
    # Actualizar dimensiones
    root.set('width', '1080')
    root.set('height', '1080')
    root.set('viewBox', '0 0 1080 1080')
    
    # Ajustar coordenadas (mapping)
    coord_mapping = {
        # X coordinates
        '56': '72',   # Margen izquierdo
        '640': '560', # M√©tricas (menos espacio derecho)
        
        # Y coordinates  
        '48': '72',   # Logo top
        '158': '240', # Headline (m√°s espacio arriba)
        '318': '420', # Testimonial
        '448': '540', # CTA (m√°s espacio bottom)
    }
    
    # Aplicar transformaciones
    for elem in root.iter():
        # Transform translate
        transform = elem.get('transform', '')
        if 'translate' in transform:
            # Parse y reemplazar coordenadas
            for old, new in coord_mapping.items():
                transform = transform.replace(f'translate({old},', f'translate({new},')
                transform = transform.replace(f',{old})', f',{new})')
            elem.set('transform', transform)
        
        # Text Y positions
        if elem.tag.endswith('text'):
            y = elem.get('y')
            if y and y in coord_mapping:
                elem.set('y', coord_mapping[y])
    
    # Escalar visual decorativo
    for g in root.findall('.//{http://www.w3.org/2000/svg}g[@transform]'):
        if 'scale(2.5)' in g.get('transform', ''):
            transform = g.get('transform').replace('scale(2.5)', 'scale(2.6)')
            g.set('transform', transform)
    
    tree.write(output_path, encoding='utf-8', xml_declaration=True)
    print(f"‚úÖ Square generado: {output_path}")

if __name__ == '__main__':
    landscape_to_square(
        'ads/linkedin/ad_curso_ia_1200x627_v2.svg',
        'ads/instagram/ad_curso_ia_1080x1080.svg'
    )
```

---

## üé® Tema Light vs Dark ‚Äî Matriz de Decisi√≥n

### Cu√°ndo Usar Light

**Audiencia**:
- B2B enterprise
- Profesionales senior (40+ a√±os)
- LinkedIn (ambiente profesional)
- Horarios de oficina (9 AM - 6 PM)

**Contenido**:
- Educaci√≥n/Formaci√≥n
- Casos de estudio t√©cnicos
- Webinars profesionales
- Contenido evergreen

**M√©trica esperada**:
- Menor CTR (pero mayor calidad leads)
- Mayor tiempo en post (contenido m√°s denso)
- M√°s engagement profesional (comentarios t√©cnicos)

### Cu√°ndo Usar Dark

**Audiencia**:
- B2C o SMB
- Audiencia m√°s joven (25-40 a√±os)
- Instagram/Facebook (ambiente casual)
- Noche/horarios de ocio (6 PM - 11 PM)

**Contenido**:
- Promocional
- Ofertas/escasez
- Contenido viral
- Testimonios emocionales

**M√©trica esperada**:
- Mayor CTR (m√°s llamativo)
- Menor tiempo en post (scroll r√°pido)
- M√°s engagement social (likes, shares)

---

## üîß Generaci√≥n Autom√°tica: Light/Dark desde Base

### Script: Generar Ambos Temas

**Python**: `generate_light_dark_themes.py`
```python
#!/usr/bin/env python3
"""
Genera variantes light y dark desde template base
"""
import xml.etree.ElementTree as ET

THEMES = {
    'light': {
        'bg_start': '#F7FAFF',
        'bg_end': '#ECF3FF',
        'accent_start': '#2F57E5',
        'accent_end': '#6A8CFF',
        'headline_fill': '#0B1229',
        'sub_fill': '#34405B',
        'card_bg': '#EEF4FF',
        'card_stroke': '#2F57E5'
    },
    'dark': {
        'bg_start': '#0B1229',
        'bg_end': '#10314A',
        'accent_start': '#00E5A8',
        'accent_end': '#00B4D8',
        'headline_fill': '#FFFFFF',
        'sub_fill': '#BFEFE8',
        'card_bg': '#0E3740',
        'card_stroke': '#00C1BE'
    }
}

def apply_theme(template_path, theme_name, output_path):
    """Aplica tema light o dark a template"""
    tree = ET.parse(template_path)
    root = tree.getroot()
    theme = THEMES[theme_name]
    
    # Reemplazar gradientes
    for gradient in root.findall('.//{http://www.w3.org/2000/svg}linearGradient'):
        if gradient.get('id') == 'bg':
            stops = gradient.findall('.//{http://www.w3.org/2000/svg}stop')
            if len(stops) >= 2:
                stops[0].set('stop-color', theme['bg_start'])
                stops[1].set('stop-color', theme['bg_end'])
        
        if gradient.get('id') == 'accent':
            stops = gradient.findall('.//{http://www.w3.org/2000/svg}stop')
            if len(stops) >= 2:
                stops[0].set('stop-color', theme['accent_start'])
                stops[1].set('stop-color', theme['accent_end'])
    
    # Actualizar estilos CSS
    for style in root.findall('.//{http://www.w3.org/2000/svg}style'):
        content = style.text or ''
        # Reemplazar fills en CSS
        content = re.sub(r'\.headline.*?fill:\s*#[0-9A-Fa-f]+', 
                        f".headline {{ fill: {theme['headline_fill']} }}", content)
        content = re.sub(r'\.subhead.*?fill:\s*#[0-9A-Fa-f]+',
                        f".subhead {{ fill: {theme['sub_fill']} }}", content)
        style.text = content
    
    # Actualizar fills directos en elementos
    for text in root.findall('.//{http://www.w3.org/2000/svg}text'):
        class_attr = text.get('class', '')
        if 'headline' in class_attr:
            text.set('fill', theme['headline_fill'])
        elif 'subhead' in class_attr:
            text.set('fill', theme['sub_fill'])
    
    tree.write(output_path, encoding='utf-8', xml_declaration=True)
    print(f"‚úÖ {theme_name} generado: {output_path}")

# Generar ambos temas
for theme in ['light', 'dark']:
    apply_theme(
        'templates/webinar-square-base.svg',
        theme,
        f'webinar-square-1080x1080-{theme}.svg'
    )
```

---

## üìä Comparativa: Square vs Landscape

### Espacio Disponible

| Elemento | Landscape (1200√ó627) | Square (1080√ó1080) | Diferencia |
|----------|---------------------|-------------------|------------|
| √Årea total | 752,400 px¬≤ | 1,166,400 px¬≤ | +55% m√°s √°rea |
| Ancho √∫til | 1,088 px (margen 56px) | 936 px (margen 72px) | -14% ancho |
| Alto √∫til | 531 px (margen 48px) | 936 px (margen 72px) | +76% alto |
| Ratio | 1.91:1 (panor√°mico) | 1:1 (cuadrado) | M√°s vertical |

### Layout Strategies

**Landscape (Horizontal)**:
- **Izquierda**: Texto (headline, subcopy)
- **Derecha**: Visual decorativo o m√©tricas
- **Abajo**: CTA + badges

**Square (Vertical)**:
- **Arriba**: Header + headline
- **Medio**: M√©tricas/testimonial (horizontal compacto)
- **Abajo**: CTA prominente

### Componentes por Formato

**Landscape permite**:
- Testimonial m√°s largo (2 l√≠neas, 520√ó110px)
- M√©tricas m√°s grandes (260√ó140px)
- M√°s espacio horizontal para bullets/lista

**Square requiere**:
- Testimonial compacto (1 l√≠nea, 480√ó95px)
- M√©tricas m√°s peque√±as (240√ó130px)
- Elementos m√°s apilados verticalmente

---

## üéØ Optimizaci√≥n Square para Instagram

### Mejores Pr√°cticas Instagram Square

**1. Headline m√°s grande**:
- Instagram tiene m√°s competencia visual
- 68px m√≠nimo (vs 64px en landscape)
- M√°ximo 8-10 palabras

**2. CTA muy visible**:
- Instagram users scroll r√°pido
- Bot√≥n m√≠nimo 280√ó68px
- Color acento brillante (alto contraste)

**3. Visual decorativo estrat√©gico**:
- Posici√≥n: Esquina superior derecha o inferior derecha
- Tama√±o: 2.6√ó escala (prominente pero no dominante)
- Opacidad: 16-20% (sutil)

**4. Hashtags estrat√©gicos**:
- Usar 5-8 hashtags relevantes
- Mezclar: gen√©ricos (#Marketing) + espec√≠ficos (#IAparaMarketing)
- Colocar en primer comentario (mejor pr√°ctica)

### Timing Instagram Square

**Horarios √≥ptimos** (zona MX):
- **Lunes-Viernes**: 8-10 AM, 12-1 PM, 6-8 PM
- **S√°bado-Domingo**: 10-11 AM, 2-4 PM

**Evitar**:
- Lunes temprano (8 AM)
- Domingo noche (despu√©s 8 PM)

---

## üìã Checklist Square 1080√ó1080

### Antes de Exportar

**Layout**:
- [ ] Safe area respetada (84px desde todos los bordes)
- [ ] Headline no excede 10 palabras
- [ ] CTA est√° visible sin scroll (Y ‚â• 540px)
- [ ] Visual decorativo no interfiere con texto

**Tipograf√≠a**:
- [ ] Headline ‚â•68px (legibilidad Instagram)
- [ ] Sub ‚â•26px
- [ ] Contraste ‚â•4.5:1 (AA m√≠nimo)

**Componentes**:
- [ ] M√©tricas compactas (240√ó130px m√°ximo)
- [ ] Testimonial 1 l√≠nea o 2 muy cortas
- [ ] CTA prominente (280√ó68px m√≠nimo)
- [ ] Logo visible pero no dominante

**Tema**:
- [ ] Light o Dark elegido seg√∫n audiencia
- [ ] Colores consistentes con variante
- [ ] Cards tienen buen contraste seg√∫n tema

---

## üîÑ Workflow Completo: Generar Todos los Formatos

### Pipeline Unificado

**Makefile target**:
```makefile
# Generar todos los formatos y temas
generate-all:
	@echo "Generando variantes..."
	# Landscape 1200√ó627
	python scripts/generate_all_variants.py --format landscape
	
	# Square 1080√ó1080
	python scripts/landscape_to_square.py --input source/*/landscape/*.svg
	python scripts/generate_light_dark_themes.py --input source/*/square/*.svg
	
	# Thumbnails
	python scripts/carrusel_to_thumbnail.py --all --type youtube
	
	@echo "‚úÖ Todos los formatos generados"
```

**Output estructura**:
```
exports/
‚îú‚îÄ‚îÄ landscape_1200x627/
‚îÇ   ‚îú‚îÄ‚îÄ curso_ia_metrics.png
‚îÇ   ‚îú‚îÄ‚îÄ curso_ia_social_proof.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ square_1080x1080/
‚îÇ   ‚îú‚îÄ‚îÄ light/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ curso_ia_light.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ dark/
‚îÇ       ‚îú‚îÄ‚îÄ curso_ia_dark.png
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ thumbnails/
    ‚îú‚îÄ‚îÄ youtube/
    ‚îî‚îÄ‚îÄ instagram_reels/
```

---

## üì± Formato Vertical/Stories (1080√ó1920)

### Caracter√≠sticas del Formato Stories

**Referencia**: `ad_curso_ia_1080x1920.svg`

**Dimensiones**: 1080√ó1920 px (ratio 9:16)  
**Uso principal**: Instagram Stories, Facebook Stories, LinkedIn Stories, Reels cover

**Ventajas**:
- Optimizado para m√≥vil (pantalla vertical completa)
- Alto impacto visual (ocupa toda la pantalla)
- Mejor engagement en m√≥vil (thumb-friendly)
- Compatible con Reels (mismo ratio)

**Desaf√≠os**:
- Espacio vertical largo (requiere scroll mental)
- Safe area cr√≠tica (evitar zonas de UI)
- Texto debe ser muy grande (legibilidad m√≥vil)
- Headlines cortos (m√°ximo 5-7 palabras)

### Safe Areas y Zonas Cr√≠ticas

**Basado en template 1080√ó1920**:

**Safe Areas** (evitar contenido importante):
- **Top**: 0-140px (barra de estado, logo usuario)
- **Bottom**: 1780-1920px (swipe up prompt, barra de navegaci√≥n)
- **Centro vertical**: 240-1680px (zona segura principal)

**Zonas de contenido**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Logo/Header]   ‚îÇ ‚Üê 72-340px (Top safe)
‚îÇ                 ‚îÇ
‚îÇ [Eyebrow]       ‚îÇ
‚îÇ [Headline]      ‚îÇ ‚Üê 340-640px (Primera impresi√≥n)
‚îÇ [Subcopy]       ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ [M√©tricas]      ‚îÇ ‚Üê 440-580px (Datos clave)
‚îÇ                 ‚îÇ
‚îÇ [Testimonial]   ‚îÇ ‚Üê 610-740px (Social proof)
‚îÇ                 ‚îÇ
‚îÇ [CTA Button]    ‚îÇ ‚Üê 770-850px (Acci√≥n)
‚îÇ [Badge]         ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ [Visual]        ‚îÇ ‚Üê 520px (centro visual)
‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ [Footer]        ‚îÇ ‚Üê 1820-1920px (Notas)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Optimizaci√≥n para Stories

**1. Tipograf√≠a aumentada**:
- Headline: 86px (vs 68px square, vs 64px landscape)
- Sub: 34px (vs 26px square)
- CTA: 30px (vs 26px square)
- M√©tricas: 42px n√∫meros (vs 36px square)

**2. Espaciado generoso**:
- Entre eyebrow y headline: 100px (vertical friendly)
- Entre secciones: 70px m√≠nimo
- CTA m√°s grande: 420√ó84px (f√°cil tap en m√≥vil)

**3. Elementos verticales**:
- Testimonial: 936√ó130px (ancho completo, menos alto)
- M√©tricas: 460√ó140px (horizontal compacto, 2 columnas)
- Visual decorativo: Escala 3.4√ó (m√°s prominente)

**4. Legibilidad m√≥vil**:
- Headlines m√°ximo 6-7 palabras
- Testimonios: 2 l√≠neas m√°ximo
- CTA: Texto directo ("Ver temario", no "Descubre m√°s")

---

## üìä Variante: Numbers (Enfoque en N√∫meros Grandes)

**Referencia**: `webinar-preroll-numbers.svg`

**Caracter√≠sticas**:
- N√∫meros grandes destacados (120px, peso 900)
- Cards grandes (380√ó280px cada una)
- Layout horizontal: 3 cards lado a lado
- Formato: 1920√ó1080 (preroll) o 1080√ó1080 (square)

**Cu√°ndo usar**:
- Resultados concretos y medibles
- Comparaciones (antes/despu√©s)
- M√©tricas impactantes (2x, 3x, -50%)
- Casos de estudio con n√∫meros

**Componentes clave**:
```svg
<!-- Card n√∫mero grande -->
<rect width="380" height="280" rx="20" 
  fill="rgba(255,255,255,0.08)" 
  stroke="#20E3B2" stroke-width="2"/>

<!-- N√∫mero destacado -->
<text class="number-big" x="190" y="120" text-anchor="middle">2x</text>

<!-- Label -->
<text class="number-label" x="190" y="200" text-anchor="middle">Ventas</text>

<!-- Subtexto -->
<text x="190" y="235" fill="#9FB6FF">En promedio</text>
```

**Estructura copy**:
1. **N√∫mero** (120px): Principal, grande, color acento
2. **Label** (24px): Qu√© representa (ej: "Ventas", "CPA", "Ahorro")
3. **Subtexto** (20px): Contexto/calificaci√≥n (ej: "En promedio", "Por semana")

**Layout**:
- **3 cards**: 380px ancho cada una, gutter 20px
- **2 cards**: 500px ancho cada una, gutter 40px (si solo 2 n√∫meros)
- **4 cards**: 280px ancho cada una, 2 filas (si 4 n√∫meros)

### Ejemplos de N√∫meros por Producto

**Curso IA**:
- "2x" ‚Üí "ROI" ‚Üí "En 6 semanas"
- "-32%" ‚Üí "CPA" ‚Üí "Reducci√≥n promedio"
- "+27%" ‚Üí "Leads" ‚Üí "Incremento mensual"

**SaaS Marketing**:
- "3x" ‚Üí "Conversi√≥n" ‚Üí "Con segmentaci√≥n IA"
- "-45%" ‚Üí "Costo por lead" ‚Üí "Vs m√©todo tradicional"
- "10h" ‚Üí "Ahorro semanal" ‚Üí "Automatizaci√≥n"

**IA Bulk**:
- "100+" ‚Üí "Documentos" ‚Üí "Con 1 consulta"
- "15h" ‚Üí "Ahorro semanal" ‚Üí "Vs proceso manual"
- "5min" ‚Üí "Tiempo generaci√≥n" ‚Üí "Por documento"

---

## üì± Optimizaci√≥n Stories para Instagram

### Mejores Pr√°cticas Instagram Stories

**1. Primera impresi√≥n (0-3 segundos)**:
- Headline debe ser visible sin scroll
- Headline Y: 340-440px (centrado superior)
- M√°ximo 5-6 palabras en headline

**2. Safe area estricta**:
- Top 140px: Logo usuario + tiempo + close
- Bottom 100px: Swipe up prompt + barra navegaci√≥n
- Laterales 40px: Gestos de navegaci√≥n

**3. CTA prominente**:
- Bot√≥n m√≠nimo 400√ó80px (f√°cil tap)
- Color acento brillante (alto contraste)
- Texto directo: "Ver m√°s", "√önete", "Descargar"

**4. Visual impactante**:
- Decorativo en centro-derecha (no interfiere texto)
- Escala 3.4√ó (prominente)
- Opacidad 20% (sutil pero visible)

### Timing Instagram Stories

**Vida √∫til**: 24 horas (stories desaparecen)  
**Recomendaci√≥n**: Publicar 2-3 veces al d√≠a

**Horarios √≥ptimos** (zona MX):
- **Ma√±ana**: 8-10 AM (check matutino)
- **Mediod√≠a**: 12-1 PM (break comida)
- **Tarde**: 6-8 PM (despu√©s trabajo)

**Evitar**:
- Lunes 7-8 AM (rush matutino)
- Viernes despu√©s 9 PM (ocio)
- Domingos despu√©s 8 PM (preparaci√≥n lunes)

---

## üîÑ Conversi√≥n: Square ‚Üí Stories (Vertical)

### Proceso de Adaptaci√≥n

**Desde**: 1080√ó1080 (square)  
**Hacia**: 1080√ó1920 (stories)

**Paso 1: Expandir viewBox**
```svg
<!-- Antes -->
viewBox="0 0 1080 1080"

<!-- Despu√©s -->
viewBox="0 0 1080 1920"
```

**Paso 2: Aumentar tama√±os de texto**
- Headline: 68px ‚Üí 86px (+26%)
- Sub: 26px ‚Üí 34px (+31%)
- CTA: 26px ‚Üí 30px (+15%)
- M√©tricas: 36px ‚Üí 42px (+17%)

**Paso 3: Ajustar coordenadas Y**

**Square (1080√ó1080)**:
- Logo: Y = 72
- Headline: Y = 240
- M√©tricas: Y = 240
- Testimonial: Y = 420
- CTA: Y = 540

**Stories (1080√ó1920)**:
- Logo: Y = 84 (similar)
- Headline: Y = 340 (+100px, m√°s espacio arriba)
- M√©tricas: Y = 440 (+200px)
- Testimonial: Y = 610 (+190px)
- CTA: Y = 770 (+230px)

**Paso 4: Expandir componentes horizontales**
- M√©tricas: 240√ó130px ‚Üí 460√ó140px (m√°s ancho, aprovecha espacio)
- Testimonial: 480√ó95px ‚Üí 936√ó130px (ancho completo)
- CTA: 280√ó68px ‚Üí 420√ó84px (m√°s grande, tap-friendly)

### Script Autom√°tico: Square ‚Üí Stories

**Python**: `square_to_stories.py`
```python
#!/usr/bin/env python3
"""
Convierte template square (1080√ó1080) a stories (1080√ó1920)
"""
import xml.etree.ElementTree as ET
import re

SCALE_FACTORS = {
    'headline': 1.26,  # 68 ‚Üí 86px
    'sub': 1.31,       # 26 ‚Üí 34px
    'cta': 1.15,       # 26 ‚Üí 30px
    'metric': 1.17     # 36 ‚Üí 42px
}

Y_MAPPING = {
    '72': '84',    # Logo (similar)
    '240': '340',  # Headline (+100)
    '420': '610',  # Testimonial (+190)
    '540': '770',  # CTA (+230)
    '440': '440'   # M√©tricas (ajuste manual)
}

def square_to_stories(input_path, output_path):
    """Adapta layout de square a stories"""
    tree = ET.parse(input_path)
    root = tree.getroot()
    
    # Actualizar dimensiones
    root.set('width', '1080')
    root.set('height', '1920')
    root.set('viewBox', '0 0 1080 1920')
    
    # Aumentar tama√±os de fuente en CSS
    for style in root.findall('.//{http://www.w3.org/2000/svg}style'):
        content = style.text or ''
        # Headline
        content = re.sub(
            r'\.headline.*?font-size:\s*(\d+)px',
            lambda m: f"font-size: {int(m.group(1)) * SCALE_FACTORS['headline']:.0f}px",
            content
        )
        # Sub
        content = re.sub(
            r'\.sub.*?font-size:\s*(\d+)px',
            lambda m: f"font-size: {int(m.group(1)) * SCALE_FACTORS['sub']:.0f}px",
            content
        )
        style.text = content
    
    # Ajustar coordenadas Y
    for elem in root.iter():
        # Transform translate Y
        transform = elem.get('transform', '')
        if 'translate' in transform:
            for old_y, new_y in Y_MAPPING.items():
                transform = re.sub(
                    rf'translate\([^,]+,{old_y}\)',
                    f'translate(\\g<1>,{new_y})',
                    transform
                )
            elem.set('transform', transform)
        
        # Text Y positions
        if elem.tag.endswith('text'):
            y = elem.get('y')
            if y and y in Y_MAPPING:
                elem.set('y', Y_MAPPING[y])
    
    # Expandir componentes horizontales
    # M√©tricas: 240√ó130 ‚Üí 460√ó140
    for rect in root.findall('.//{http://www.w3.org/2000/svg}rect'):
        width = rect.get('width')
        if width == '240':
            rect.set('width', '460')
        if width == '130':
            rect.set('height', '140')
    
    # Testimonial: 480√ó95 ‚Üí 936√ó130
    for rect in root.findall('.//{http://www.w3.org/2000/svg}rect'):
        width = rect.get('width')
        if width == '480':
            rect.set('width', '936')
        if width == '95':
            rect.set('height', '130')
    
    # CTA: 280√ó68 ‚Üí 420√ó84
    for rect in root.findall('.//{http://www.w3.org/2000/svg}rect'):
        width = rect.get('width')
        if width == '280':
            rect.set('width', '420')
        if width == '68':
            rect.set('height', '84')
    
    tree.write(output_path, encoding='utf-8', xml_declaration=True)
    print(f"‚úÖ Stories generado: {output_path}")

if __name__ == '__main__':
    square_to_stories(
        'ads/instagram/ad_curso_ia_1080x1080.svg',
        'ads/stories/ad_curso_ia_1080x1920.svg'
    )
```

---

## üìä Variante Social Proof (Square)

**Referencia**: `webinar-square-1080x1080-social-proof.svg`

**Caracter√≠sticas**:
- Stats grandes centrados (52px n√∫meros)
- Grid 2 columnas (stats lado a lado)
- Testimonial mini compacto
- Headline enfocado en audiencia ("+2,500 profesionales")

**Diferencias vs Social Proof Preroll**:
- Square: Stats m√°s grandes (52px vs 48px)
- Square: Layout centrado (vs izquierda en preroll)
- Square: Testimonial m√°s compacto (720√ó80px vs m√°s grande)

**Componentes espec√≠ficos**:
```svg
<!-- Stats grid 2 columnas -->
<g transform="translate(540,330)">
  <!-- Card izquierda -->
  <g transform="translate(-200,0)">
    <rect x="-110" y="-70" width="220" height="140" rx="16" 
      fill="#0E3740" stroke="#00C1BE"/>
    <text class="metric-num">2,500+</text>
    <text class="metric-label">Inscritos</text>
    <text class="metric-sub">√∫ltimo webinar</text>
  </g>
  
  <!-- Card derecha -->
  <g transform="translate(200,0)">
    <!-- Mismo formato -->
  </g>
</g>
```

**Cu√°ndo usar**:
- Webinars/eventos
- Lanzamientos nuevos
- Necesitas construir credibilidad r√°pida
- Square format (1080√ó1080)

---

## üìê Comparativa: Todos los Formatos

### Dimensiones y Ratios

| Formato | Dimensiones | Ratio | √Årea | Uso Principal |
|---------|-------------|-------|------|--------------|
| **Landscape** | 1200√ó627 | 1.91:1 | 752,400 px¬≤ | LinkedIn Feed |
| **Square** | 1080√ó1080 | 1:1 | 1,166,400 px¬≤ | Instagram Feed |
| **Stories** | 1080√ó1920 | 9:16 | 2,073,600 px¬≤ | Instagram Stories |
| **Thumbnail** | 1280√ó720 | 16:9 | 921,600 px¬≤ | YouTube Video |
| **Preroll** | 1920√ó1080 | 16:9 | 2,073,600 px¬≤ | Webinar Preroll |

### Headline Sizes por Formato

| Formato | Headline Size | Raz√≥n |
|---------|---------------|-------|
| Landscape | 64px | Espacio horizontal generoso |
| Square | 68px | Mayor presencia visual |
| Stories | 86px | Legibilidad m√≥vil cr√≠tica |
| Thumbnail | 72-96px | Preview peque√±o |
| Preroll | 76-96px | Distancia visual (pantalla grande) |

### Safe Areas por Formato

| Formato | Top | Bottom | Left | Right |
|---------|-----|--------|------|-------|
| Landscape | 48px | 79px | 56px | 56px |
| Square | 72px | 72px | 72px | 72px |
| Stories | 140px | 100px | 72px | 72px |
| Thumbnail | 10% | 10% | 10% | 10% |
| Preroll | 80px | 100px | 120px | 120px |

---

## üéØ Decision Matrix: ¬øQu√© Formato Usar?

### Por Plataforma

| Plataforma | Formato Recomendado | Alternativas |
|-----------|-------------------|--------------|
| **LinkedIn Feed** | Landscape 1200√ó627 | Square 1080√ó1080 |
| **Instagram Feed** | Square 1080√ó1080 | Landscape 1200√ó627 |
| **Instagram Stories** | Stories 1080√ó1920 | Square (crop) |
| **Facebook Feed** | Square 1080√ó1080 | Landscape 1200√ó627 |
| **Facebook Stories** | Stories 1080√ó1920 | - |
| **YouTube** | Thumbnail 1280√ó720 | - |
| **Webinar Preroll** | Preroll 1920√ó1080 | - |

### Por Objetivo de Campa√±a

| Objetivo | Formato | Raz√≥n |
|----------|---------|-------|
| **Brand Awareness** | Square 1080√ó1080 | Vers√°til, preview completo |
| **Lead Generation** | Landscape 1200√ó627 | M√°s espacio para copy |
| **Stories/Engagement** | Stories 1080√ó1920 | Alto impacto visual |
| **Video Promo** | Thumbnail 1280√ó720 | Optimizado para preview |
| **Webinar Reg** | Preroll 1920√ó1080 | Pantalla grande, info completa |

### Por Audiencia

| Audiencia | Formato | Tema |
|-----------|---------|------|
| B2B LinkedIn | Landscape 1200√ó627 | Light |
| B2C Instagram | Square 1080√ó1080 | Dark |
| Millennials/Gen Z | Stories 1080√ó1920 | Dark |
| Enterprise/VPs | Square 1080√ó1080 | Light |
| SMB/Startups | Square 1080√ó1080 | Dark |

---

## üîß Workflow Final: Todos los Formatos y Variantes

### Pipeline Completo Unificado

**Makefile**: `generate-all-formats.mk`
```makefile
# Generar TODOS los formatos desde templates base

.PHONY: all landscape square stories thumbnails themes

all: landscape square stories thumbnails themes
	@echo "üéâ Pipeline completo: Todos los formatos generados"

# Landscape 1200√ó627
landscape:
	python scripts/generate_all_variants.py --format landscape --products curso_ia saas_marketing ia_bulk
	@echo "‚úÖ Landscape generado"

# Square 1080√ó1080
square:
	python scripts/landscape_to_square.py --input source/*/landscape/*.svg
	@echo "‚úÖ Square generado"

# Stories 1080√ó1920
stories:
	python scripts/square_to_stories.py --input source/*/square/*.svg
	@echo "‚úÖ Stories generado"

# Thumbnails
thumbnails:
	python scripts/carrusel_to_thumbnail.py --all --types youtube instagram_reels linkedin
	@echo "‚úÖ Thumbnails generados"

# Temas light/dark
themes:
	python scripts/generate_light_dark_themes.py --input source/*/square/*.svg
	python scripts/generate_light_dark_themes.py --input source/*/stories/*.svg
	@echo "‚úÖ Temas generados"

# Limpiar
clean:
	rm -rf exports/optimized/
	rm -rf exports/png/
	@echo "‚úÖ Archivos limpiados"
```

**Estructura de output final**:
```
exports/
‚îú‚îÄ‚îÄ landscape_1200x627/
‚îÇ   ‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îú‚îÄ‚îÄ social_proof/
‚îÇ   ‚îú‚îÄ‚îÄ urgency/
‚îÇ   ‚îî‚îÄ‚îÄ elegant/
‚îú‚îÄ‚îÄ square_1080x1080/
‚îÇ   ‚îú‚îÄ‚îÄ light/
‚îÇ   ‚îú‚îÄ‚îÄ dark/
‚îÇ   ‚îú‚îÄ‚îÄ social_proof/
‚îÇ   ‚îî‚îÄ‚îÄ numbers/
‚îú‚îÄ‚îÄ stories_1080x1920/
‚îÇ   ‚îú‚îÄ‚îÄ light/
‚îÇ   ‚îî‚îÄ‚îÄ dark/
‚îú‚îÄ‚îÄ thumbnails/
‚îÇ   ‚îú‚îÄ‚îÄ youtube_1280x720/
‚îÇ   ‚îú‚îÄ‚îÄ instagram_reels_1080x1920/
‚îÇ   ‚îî‚îÄ‚îÄ linkedin_1200x627/
‚îî‚îÄ‚îÄ preroll_1920x1080/
    ‚îú‚îÄ‚îÄ benefits_focused/
    ‚îú‚îÄ‚îÄ social_proof/
    ‚îú‚îÄ‚îÄ numbers/
    ‚îî‚îÄ‚îÄ elegant/
```

---

## üìã Checklist Final: Pre-Publicaci√≥n por Formato

### Landscape (1200√ó627)

- [ ] Headline ‚â§64px, m√°ximo 10 palabras
- [ ] Safe area: 48px top, 79px bottom
- [ ] M√©tricas: 260√ó140px m√°ximo
- [ ] Testimonial: 2 l√≠neas m√°ximo
- [ ] CTA: 300√ó72px m√≠nimo

### Square (1080√ó1080)

- [ ] Headline ‚â•68px, m√°ximo 10 palabras
- [ ] Safe area: 72px todos los lados
- [ ] M√©tricas: 240√ó130px (compacto)
- [ ] Testimonial: 1 l√≠nea o 2 cortas
- [ ] Tema light/dark elegido

### Stories (1080√ó1920)

- [ ] Headline ‚â•86px, m√°ximo 6-7 palabras
- [ ] Safe area: 140px top, 100px bottom
- [ ] CTA: 400√ó80px m√≠nimo (tap-friendly)
- [ ] Texto legible sin zoom
- [ ] Visual no interfiere con texto

### Thumbnail (1280√ó720)

- [ ] Headline ‚â•72px, m√°ximo 8 palabras
- [ ] Play button prominente (120px radio)
- [ ] Contraste ‚â•7:1 (legible peque√±o)
- [ ] Safe area: 10% desde bordes
- [ ] Tama√±o archivo <2MB

---

**Versi√≥n**: 10.0 Master  
**Fecha**: 2025-11  
**Referencias**: 
- Templates completos: landscape, square, stories, thumbnails, preroll (`*_1080x1920.svg`, `webinar-square-1080x1080-social-proof.svg`, `webinar-preroll-numbers.svg`)
- `TOOLS_CRM_COMPARISON.md` ‚Äî Integraciones CRM
- `UTM_GUIDE_OUTREACH.md` ‚Äî Convenciones UTMs
- `26_ADVANCED_AUTOMATION_WORKFLOWS.md` ‚Äî Workflows avanzados
- `COPY_PASTE_READY_DMS.md` ‚Äî Templates DMs

**√öltima actualizaci√≥n**: Agregado formato vertical/stories (1080√ó1920) con safe areas y optimizaci√≥n m√≥vil, variante numbers (n√∫meros grandes), variante social-proof square, scripts de conversi√≥n square‚Üístories, comparativa completa de todos los formatos, decision matrix por plataforma/objetivo/audiencia, workflow completo unificado y checklists finales por formato

---

## üîç Scripts de An√°lisis y Validaci√≥n Automatizada

### Script: An√°lisis de Performance de Carruseles

**Python**: `analyze_carousel_performance.py`
```python
#!/usr/bin/env python3
"""
Analiza performance de carruseles desde m√∫ltiples fuentes
- Meta Ads API
- Google Analytics 4
- CRM (HubSpot/Pipedrive)
- Genera reportes autom√°ticos
"""
import json
import requests
from datetime import datetime, timedelta
from collections import defaultdict

class CarouselAnalyzer:
    def __init__(self, config_path='config.json'):
        with open(config_path) as f:
            self.config = json.load(f)
        self.results = defaultdict(dict)
    
    def fetch_meta_metrics(self, carousel_id, date_range):
        """Obtiene m√©tricas de Meta Ads"""
        url = f"https://graph.facebook.com/v18.0/{carousel_id}/insights"
        params = {
            'access_token': self.config['meta']['access_token'],
            'fields': 'impressions,clicks,ctr,spend,conversions',
            'time_range': json.dumps({
                'since': date_range['start'],
                'until': date_range['end']
            }),
            'level': 'ad'
        }
        response = requests.get(url, params=params)
        return response.json()
    
    def fetch_ga4_metrics(self, utm_campaign, date_range):
        """Obtiene m√©tricas de GA4"""
        # Implementar con GA4 Data API
        # Returns: sessions, conversions, revenue
        pass
    
    def fetch_crm_leads(self, utm_campaign, date_range):
        """Obtiene leads desde CRM"""
        # Implementar seg√∫n CRM (HubSpot/Pipedrive)
        # Returns: lead_count, conversion_rate, revenue
        pass
    
    def calculate_roi(self, metrics):
        """Calcula ROI completo"""
        revenue = metrics.get('revenue', 0)
        spend = metrics.get('spend', 0)
        if spend == 0:
            return 0
        return ((revenue - spend) / spend) * 100
    
    def generate_report(self, carousel_id):
        """Genera reporte completo"""
        date_range = {
            'start': (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d'),
            'end': datetime.now().strftime('%Y-%m-%d')
        }
        
        # Recopilar m√©tricas
        meta_metrics = self.fetch_meta_metrics(carousel_id, date_range)
        ga4_metrics = self.fetch_ga4_metrics(
            meta_metrics.get('utm_campaign'), 
            date_range
        )
        crm_leads = self.fetch_crm_leads(
            meta_metrics.get('utm_campaign'),
            date_range
        )
        
        # Calcular KPIs
        ctr = (meta_metrics.get('clicks', 0) / 
               meta_metrics.get('impressions', 1)) * 100
        conversion_rate = (crm_leads.get('conversions', 0) / 
                         meta_metrics.get('clicks', 1)) * 100
        cpa = meta_metrics.get('spend', 0) / max(crm_leads.get('leads', 1), 1)
        roi = self.calculate_roi({
            'revenue': crm_leads.get('revenue', 0),
            'spend': meta_metrics.get('spend', 0)
        })
        
        report = {
            'carousel_id': carousel_id,
            'period': date_range,
            'metrics': {
                'impressions': meta_metrics.get('impressions', 0),
                'clicks': meta_metrics.get('clicks', 0),
                'ctr': round(ctr, 2),
                'spend': meta_metrics.get('spend', 0),
                'leads': crm_leads.get('leads', 0),
                'conversions': crm_leads.get('conversions', 0),
                'conversion_rate': round(conversion_rate, 2),
                'cpa': round(cpa, 2),
                'revenue': crm_leads.get('revenue', 0),
                'roi': round(roi, 2)
            },
            'benchmarks': self.get_benchmarks(),
            'recommendations': self.generate_recommendations(ctr, conversion_rate, roi)
        }
        
        return report
    
    def get_benchmarks(self):
        """Retorna benchmarks de industria"""
        return {
            'ctr': {'good': 2.0, 'excellent': 3.5},
            'conversion_rate': {'good': 15.0, 'excellent': 25.0},
            'roi': {'good': 200, 'excellent': 400}
        }
    
    def generate_recommendations(self, ctr, conversion_rate, roi):
        """Genera recomendaciones basadas en m√©tricas"""
        recommendations = []
        
        if ctr < 1.5:
            recommendations.append({
                'issue': 'CTR bajo',
                'action': 'Optimizar headline y visual (A/B test)',
                'priority': 'high'
            })
        
        if conversion_rate < 10:
            recommendations.append({
                'issue': 'Tasa conversi√≥n baja',
                'action': 'Revisar landing page y fricci√≥n del CTA',
                'priority': 'high'
            })
        
        if roi < 100:
            recommendations.append({
                'issue': 'ROI bajo',
                'action': 'Optimizar targeting y presupuesto',
                'priority': 'medium'
            })
        
        return recommendations

if __name__ == '__main__':
    analyzer = CarouselAnalyzer()
    report = analyzer.generate_report('carousel_curso_ia_v1')
    print(json.dumps(report, indent=2))
```

---

### Script: Validaci√≥n Pre-Publicaci√≥n Automatizada

**Python**: `validate_carousel_pre_launch.py`
```python
#!/usr/bin/env python3
"""
Valida carruseles antes de publicar
- Contraste WCAG
- Tama√±os de texto
- Safe areas
- UTMs v√°lidos
- Tama√±o de archivo
"""
import xml.etree.ElementTree as ET
from PIL import Image
import re

class CarouselValidator:
    def __init__(self):
        self.errors = []
        self.warnings = []
    
    def validate_svg(self, svg_path):
        """Valida SVG completo"""
        tree = ET.parse(svg_path)
        root = tree.getroot()
        
        # Validar dimensiones
        self.check_dimensions(root)
        
        # Validar safe areas
        self.check_safe_areas(root)
        
        # Validar tipograf√≠a
        self.check_typography(root)
        
        # Validar contraste
        self.check_contrast(root)
        
        return {
            'valid': len(self.errors) == 0,
            'errors': self.errors,
            'warnings': self.warnings
        }
    
    def check_dimensions(self, root):
        """Valida dimensiones correctas"""
        width = int(root.get('width', 0))
        height = int(root.get('height', 0))
        
        valid_sizes = [
            (1200, 627),   # Landscape
            (1080, 1080),  # Square
            (1080, 1920),  # Stories
            (1280, 720),   # Thumbnail
            (1920, 1080)   # Preroll
        ]
        
        if (width, height) not in valid_sizes:
            self.errors.append(
                f"Dimensiones inv√°lidas: {width}√ó{height}. "
                f"Usar: {valid_sizes}"
            )
    
    def check_safe_areas(self, root):
        """Valida que elementos importantes est√©n en safe area"""
        width = int(root.get('width', 0))
        height = int(root.get('height', 0))
        
        safe_margins = {
            (1200, 627): {'top': 48, 'bottom': 79, 'sides': 56},
            (1080, 1080): {'top': 72, 'bottom': 72, 'sides': 72},
            (1080, 1920): {'top': 140, 'bottom': 100, 'sides': 72}
        }
        
        margins = safe_margins.get((width, height), {})
        if not margins:
            return
        
        # Verificar textos importantes
        for text in root.findall('.//{http://www.w3.org/2000/svg}text'):
            if 'headline' in (text.get('class') or ''):
                y = float(text.get('y', 0))
                if y < margins['top']:
                    self.warnings.append(
                        f"Headline muy cerca del borde superior: Y={y} "
                        f"(m√≠nimo {margins['top']}px)"
                    )
    
    def check_typography(self, root):
        """Valida tama√±os de tipograf√≠a"""
        for style in root.findall('.//{http://www.w3.org/2000/svg}style'):
            content = style.text or ''
            
            # Buscar headlines
            headline_match = re.search(
                r'\.headline.*?font-size:\s*(\d+)px',
                content
            )
            if headline_match:
                size = int(headline_match.group(1))
                if size < 64:
                    self.warnings.append(
                        f"Headline muy peque√±o: {size}px "
                        "(m√≠nimo recomendado: 64px)"
                    )
    
    def check_contrast(self, root):
        """Valida contraste WCAG (requiere calcular colores)"""
        # Implementar c√°lculo de contraste real
        # Usar librer√≠a como `webcolors` o `colour`
        pass
    
    def validate_png(self, png_path):
        """Valida PNG exportado"""
        img = Image.open(png_path)
        width, height = img.size
        
        # Verificar tama√±o archivo
        file_size = os.path.getsize(png_path) / 1024  # KB
        if file_size > 1200:
            self.warnings.append(
                f"Archivo PNG muy grande: {file_size:.1f}KB "
                "(recomendado <1.2MB)"
            )
        
        # Verificar dimensiones
        valid_sizes = [
            (1200, 627),
            (1080, 1080),
            (1080, 1920),
            (1280, 720),
            (1920, 1080)
        ]
        
        if (width, height) not in valid_sizes:
            self.errors.append(
                f"Dimensiones PNG inv√°lidas: {width}√ó{height}"
            )
        
        return {
            'valid': len(self.errors) == 0,
            'errors': self.errors,
            'warnings': self.warnings
        }
    
    def validate_utms(self, url):
        """Valida formato de UTMs"""
        from urllib.parse import urlparse, parse_qs
        
        parsed = urlparse(url)
        params = parse_qs(parsed.query)
        
        required = ['utm_source', 'utm_medium', 'utm_campaign']
        for param in required:
            if param not in params:
                self.errors.append(f"UTM faltante: {param}")
        
        # Validar formato utm_campaign
        if 'utm_campaign' in params:
            campaign = params['utm_campaign'][0]
            if not re.match(r'^[a-z0-9_]+(_\d{4}-\d{2})?$', campaign):
                self.errors.append(
                    f"Formato utm_campaign inv√°lido: {campaign} "
                    "(usar: producto_tipo_YYYY-MM)"
                )

if __name__ == '__main__':
    validator = CarouselValidator()
    
    # Validar SVG
    svg_result = validator.validate_svg('carrusel-curso-ia-s1-v1.svg')
    print("SVG Validation:", json.dumps(svg_result, indent=2))
    
    # Validar PNG
    png_result = validator.validate_png('carrusel-curso-ia-s1-v1.png')
    print("PNG Validation:", json.dumps(png_result, indent=2))
    
    # Validar UTMs
    validator.validate_utms(
        'https://tusitio.com/landing?utm_source=instagram&utm_medium=carrusel&utm_campaign=curso_ia_2025-11'
    )
    print("UTM Validation:", json.dumps({
        'errors': validator.errors,
        'warnings': validator.warnings
    }, indent=2))
```

---

## üíª Templates de C√≥digo: Landing Pages React/HTML

### Template React: Landing Page Optimizada

**React Component**: `CarouselLandingPage.jsx`
```jsx
import React, { useEffect, useState } from 'react';
import { useSearchParams } from 'react-router-dom';

const CarouselLandingPage = ({ product = 'curso_ia' }) => {
  const [searchParams] = useSearchParams();
  const [utmParams, setUtmParams] = useState({});
  const [formData, setFormData] = useState({
    email: '',
    name: '',
    company: '',
    role: ''
  });

  // Capturar UTMs autom√°ticamente
  useEffect(() => {
    const utms = {
      source: searchParams.get('utm_source') || 'direct',
      medium: searchParams.get('utm_medium') || 'organic',
      campaign: searchParams.get('utm_campaign') || '',
      content: searchParams.get('utm_content') || '',
      term: searchParams.get('utm_term') || ''
    };
    setUtmParams(utms);
    
    // Enviar evento a GA4
    if (window.gtag) {
      window.gtag('event', 'carousel_landing_view', {
        carousel_name: utms.campaign,
        slide_number: utms.content,
        utm_source: utms.source
      });
    }
  }, [searchParams]);

  // Configuraci√≥n por producto
  const productConfig = {
    curso_ia: {
      headline: "Domina IA aplicada en semanas",
      subhead: "Clases pr√°cticas, webinars en vivo y casos reales de HubSpot, Make y ActiveCampaign",
      benefits: [
        { title: "Certificado oficial", desc: "V√°lido en tu perfil LinkedIn" },
        { title: "Mentor√≠a personalizada", desc: "Sesiones 1:1 con expertos" },
        { title: "Comunidad activa", desc: "Acceso permanente al grupo" }
      ],
      cta: "√önete ahora ‚Äî Cupos limitados",
      formFields: ['email', 'name', 'company', 'role']
    },
    saas_marketing: {
      headline: "Campa√±as que se optimizan solas",
      subhead: "Genera creatividades, segmenta audiencias y reporta con IA",
      benefits: [
        { title: "A/B Testing autom√°tico", desc: "Optimiza en tiempo real" },
        { title: "Segmentaci√≥n inteligente", desc: "Lookalikes y audiences" },
        { title: "Reportes claros", desc: "Dashboard unificado" }
      ],
      cta: "Pru√©balo gratis ‚Äî Demo en 3 minutos",
      formFields: ['email', 'name', 'company']
    },
    ia_bulk: {
      headline: "Crea 100+ documentos con 1 consulta",
      subhead: "Estandariza documentaci√≥n a escala. Plantillas, versionado y export PDF/DOCX",
      benefits: [
        { title: "Generaci√≥n masiva", desc: "100+ docs desde 1 brief" },
        { title: "Versionado y control", desc: "Historial de cambios" },
        { title: "Plantillas editables", desc: "Personaliza y reutiliza" }
      ],
      cta: "Solicita demo ‚Äî 15 minutos",
      formFields: ['email', 'name', 'company', 'use_case']
    }
  };

  const config = productConfig[product] || productConfig.curso_ia;

  const handleSubmit = async (e) => {
    e.preventDefault();
    
    // Preparar payload con UTMs
    const payload = {
      ...formData,
      ...utmParams,
      product,
      timestamp: new Date().toISOString(),
      referrer: document.referrer
    };

    try {
      // Enviar a API/CRM
      const response = await fetch('/api/leads', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
      });

      if (response.ok) {
        // Evento conversi√≥n GA4
        if (window.gtag) {
          window.gtag('event', 'conversion', {
            carousel_name: utmParams.campaign,
            slide_number: utmParams.content,
            value: 0,
            currency: 'USD'
          });
        }

        // Meta Pixel
        if (window.fbq) {
          window.fbq('track', 'Lead', {
            content_name: `${product}_carousel`,
            content_category: 'education',
            value: 0,
            currency: 'USD'
          });
        }

        alert('¬°Gracias! Te contactaremos pronto.');
      }
    } catch (error) {
      console.error('Error submitting form:', error);
    }
  };

  return (
    <div className="carousel-landing-page">
      {/* Hero Section */}
      <section className="hero">
        <h1>{config.headline}</h1>
        <p className="subhead">{config.subhead}</p>
      </section>

      {/* Benefits Grid */}
      <section className="benefits">
        {config.benefits.map((benefit, idx) => (
          <div key={idx} className="benefit-card">
            <h3>{benefit.title}</h3>
            <p>{benefit.desc}</p>
          </div>
        ))}
      </section>

      {/* CTA Form */}
      <section className="cta-form">
        <form onSubmit={handleSubmit}>
          {config.formFields.map(field => (
            <input
              key={field}
              type={field === 'email' ? 'email' : 'text'}
              placeholder={field === 'email' ? 'tu@email.com' : field}
              value={formData[field]}
              onChange={(e) => setFormData({
                ...formData,
                [field]: e.target.value
              })}
              required
            />
          ))}
          
          {/* Hidden UTM fields */}
          {Object.entries(utmParams).map(([key, value]) => (
            <input
              key={key}
              type="hidden"
              name={`form_${key}`}
              value={value}
            />
          ))}

          <button type="submit" className="cta-button">
            {config.cta}
          </button>
        </form>
      </section>

      {/* Trust Indicators */}
      <section className="trust">
        <p>*Resultados basados en casos de estudio. Pueden variar seg√∫n industria.</p>
      </section>
    </div>
  );
};

export default CarouselLandingPage;
```

---

### Template HTML/CSS: Landing Page Vanilla

**HTML**: `carousel-landing.html`
```html
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Domina IA Aplicada | Curso + Webinars</title>
  
  <!-- Preconnect para performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://www.google-analytics.com">
  
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700;800&display=swap" rel="stylesheet">
  
  <!-- Meta Tags -->
  <meta property="og:title" content="Domina IA Aplicada en Semanas">
  <meta property="og:description" content="Clases pr√°cticas + webinars en vivo + casos reales">
  <meta property="og:image" content="https://tusitio.com/carrusel-curso-ia-s1.png">
  
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    body {
      font-family: 'Inter', sans-serif;
      line-height: 1.6;
      color: #0B1229;
      background: linear-gradient(135deg, #F7FAFF 0%, #ECF3FF 100%);
    }
    
    .container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 24px;
    }
    
    .hero {
      text-align: center;
      padding: 80px 0 60px;
    }
    
    .hero h1 {
      font-size: 64px;
      font-weight: 800;
      line-height: 1.1;
      margin-bottom: 24px;
      letter-spacing: -0.02em;
    }
    
    .hero .subhead {
      font-size: 24px;
      color: #64748B;
      max-width: 700px;
      margin: 0 auto;
    }
    
    .benefits {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 32px;
      padding: 60px 0;
    }
    
    .benefit-card {
      background: #FFFFFF;
      padding: 32px;
      border-radius: 16px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    
    .benefit-card h3 {
      font-size: 24px;
      font-weight: 700;
      margin-bottom: 12px;
    }
    
    .benefit-card p {
      font-size: 16px;
      color: #64748B;
    }
    
    .cta-form {
      max-width: 600px;
      margin: 60px auto;
      background: #FFFFFF;
      padding: 48px;
      border-radius: 20px;
      box-shadow: 0 10px 25px rgba(0,0,0,0.1);
    }
    
    .cta-form input {
      width: 100%;
      padding: 16px;
      margin-bottom: 16px;
      border: 2px solid #E5E7EB;
      border-radius: 8px;
      font-size: 16px;
      transition: border-color 0.2s;
    }
    
    .cta-form input:focus {
      outline: none;
      border-color: #22C55E;
    }
    
    .cta-button {
      width: 100%;
      padding: 20px;
      background: linear-gradient(135deg, #22C55E 0%, #16A34A 100%);
      color: #FFFFFF;
      font-size: 20px;
      font-weight: 700;
      border: none;
      border-radius: 12px;
      cursor: pointer;
      transition: transform 0.2s, box-shadow 0.2s;
    }
    
    .cta-button:hover {
      transform: translateY(-2px);
      box-shadow: 0 8px 16px rgba(34, 197, 94, 0.3);
    }
    
    @media (max-width: 768px) {
      .hero h1 {
        font-size: 42px;
      }
      
      .benefits {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <!-- Hero -->
    <section class="hero">
      <h1>Domina IA Aplicada en Semanas</h1>
      <p class="subhead">
        Clases pr√°cticas + webinars en vivo + casos reales de HubSpot, Make y ActiveCampaign
      </p>
    </section>

    <!-- Benefits -->
    <section class="benefits">
      <div class="benefit-card">
        <h3>Certificado oficial</h3>
        <p>V√°lido en tu perfil LinkedIn</p>
      </div>
      <div class="benefit-card">
        <h3>Mentor√≠a personalizada</h3>
        <p>Sesiones 1:1 con expertos</p>
      </div>
      <div class="benefit-card">
        <h3>Comunidad activa</h3>
        <p>Acceso permanente al grupo</p>
      </div>
    </section>

    <!-- CTA Form -->
    <section class="cta-form">
      <form id="leadForm" method="POST" action="/api/leads">
        <input type="email" name="email" placeholder="tu@email.com" required>
        <input type="text" name="name" placeholder="Nombre completo" required>
        <input type="text" name="company" placeholder="Empresa (opcional)">
        <input type="text" name="role" placeholder="Rol (opcional)">
        
        <!-- Hidden UTM fields (auto-filled by JS) -->
        <input type="hidden" name="form_utm_source" id="form_utm_source">
        <input type="hidden" name="form_utm_medium" id="form_utm_medium">
        <input type="hidden" name="form_utm_campaign" id="form_utm_campaign">
        <input type="hidden" name="form_utm_content" id="form_utm_content">
        <input type="hidden" name="form_utm_term" id="form_utm_term">
        
        <button type="submit" class="cta-button">√önete ahora ‚Äî Cupos limitados</button>
      </form>
    </section>
  </div>

  <!-- Google Analytics 4 -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-XXXXXXXXXX');
  </script>

  <!-- Meta Pixel -->
  <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window, document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', 'YOUR_PIXEL_ID');
    fbq('track', 'PageView');
  </script>

  <!-- UTM Capture Script -->
  <script>
    (function() {
      const urlParams = new URLSearchParams(window.location.search);
      const utmParams = [
        'utm_source', 'utm_medium', 'utm_campaign', 
        'utm_content', 'utm_term'
      ];
      
      utmParams.forEach(param => {
        const value = urlParams.get(param) || 'direct';
        const field = document.getElementById(`form_${param}`);
        if (field) {
          field.value = value;
        }
        
        // Guardar en localStorage para persistencia
        localStorage.setItem(param, value);
      });
      
      // Enviar evento a GA4
      gtag('event', 'carousel_landing_view', {
        carousel_name: urlParams.get('utm_campaign') || 'direct',
        slide_number: urlParams.get('utm_content') || '',
        utm_source: urlParams.get('utm_source') || 'direct'
      });
    })();
  </script>

  <!-- Form Submit Handler -->
  <script>
    document.getElementById('leadForm').addEventListener('submit', async function(e) {
      e.preventDefault();
      
      const formData = new FormData(this);
      const data = Object.fromEntries(formData);
      
      try {
        const response = await fetch('/api/leads', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(data)
        });
        
        if (response.ok) {
          // Conversion tracking
          gtag('event', 'conversion', {
            carousel_name: data.form_utm_campaign,
            slide_number: data.form_utm_content
          });
          
          fbq('track', 'Lead', {
            content_name: data.form_utm_campaign,
            content_category: 'education'
          });
          
          alert('¬°Gracias! Te contactaremos pronto.');
          this.reset();
        }
      } catch (error) {
        console.error('Error:', error);
        alert('Hubo un error. Por favor intenta de nuevo.');
      }
    });
  </script>
</body>
</html>
```

---

## üé¨ Gu√≠as de Animaci√≥n SVG para Carruseles

### Animaciones CSS para SVG

**CSS**: `carousel-animations.css`
```css
/* Fade-in del carrusel */
@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(20px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.carousel-slide {
  animation: fadeIn 0.6s ease-out;
}

/* Pulse del CTA */
@keyframes pulse {
  0%, 100% {
    transform: scale(1);
    opacity: 1;
  }
  50% {
    transform: scale(1.05);
    opacity: 0.9;
  }
}

.cta-button {
  animation: pulse 2s ease-in-out infinite;
}

/* Slide-in del testimonial */
@keyframes slideInRight {
  from {
    opacity: 0;
    transform: translateX(40px);
  }
  to {
    opacity: 1;
    transform: translateX(0);
  }
}

.testimonial-card {
  animation: slideInRight 0.8s ease-out 0.3s both;
}

/* M√©tricas counter animation */
@keyframes countUp {
  from {
    opacity: 0;
    transform: translateY(10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.metric-number {
  animation: countUp 1s ease-out;
}
```

### Animaciones SVG (SMIL)

**SVG inline animations**:
```svg
<svg xmlns="http://www.w3.org/2000/svg" width="1080" height="1080">
  <!-- Headline fade-in -->
  <text class="headline" x="72" y="240">
    <animate attributeName="opacity" 
             from="0" to="1" 
             dur="0.8s" 
             begin="0s" />
    <animate attributeName="y" 
             from="220" to="240" 
             dur="0.8s" 
             begin="0s" />
    Domina IA aplicada en semanas
  </text>
  
  <!-- CTA pulse -->
  <rect class="cta-button" x="72" y="850" width="300" height="72" rx="16">
    <animate attributeName="opacity" 
             values="1;0.8;1" 
             dur="2s" 
             repeatCount="indefinite" />
  </rect>
  
  <!-- M√©tricas counter (requiere JS) -->
  <text class="metric" x="20" y="60" id="metric-value">
    0
    <animate attributeName="opacity" 
             from="0" to="1" 
             dur="1s" 
             begin="0.5s" />
  </text>
</svg>

<script>
  // Animar contador de m√©trica
  function animateCounter(element, target, duration = 1000) {
    let start = 0;
    const increment = target / (duration / 16);
    
    const timer = setInterval(() => {
      start += increment;
      if (start >= target) {
        element.textContent = target;
        clearInterval(timer);
      } else {
        element.textContent = Math.floor(start);
      }
    }, 16);
  }
  
  // Usar
  const metricEl = document.getElementById('metric-value');
  animateCounter(metricEl, 27); // Animar a 27
</script>
```

---

## üìä Dashboard Avanzado de M√©tricas

### Template: Dashboard Google Data Studio / Looker

**M√©tricas y Dimensiones**:
```sql
-- Query ejemplo para dashboard
SELECT
  utm_campaign AS carousel_name,
  utm_content AS slide_number,
  COUNT(DISTINCT session_id) AS impressions,
  COUNT(DISTINCT CASE WHEN event_name = 'click' THEN session_id END) AS clicks,
  COUNT(DISTINCT CASE WHEN event_name = 'conversion' THEN session_id END) AS conversions,
  
  -- Calculated metrics
  SAFE_DIVIDE(
    COUNT(DISTINCT CASE WHEN event_name = 'click' THEN session_id END),
    COUNT(DISTINCT session_id)
  ) * 100 AS ctr,
  
  SAFE_DIVIDE(
    COUNT(DISTINCT CASE WHEN event_name = 'conversion' THEN session_id END),
    COUNT(DISTINCT CASE WHEN event_name = 'click' THEN session_id END)
  ) * 100 AS conversion_rate,
  
  -- Revenue metrics
  SUM(revenue) AS total_revenue,
  SUM(spend) AS total_spend,
  
  -- ROI
  SAFE_DIVIDE(
    (SUM(revenue) - SUM(spend)),
    SUM(spend)
  ) * 100 AS roi
  
FROM
  `project.dataset.carousel_events`
WHERE
  date >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)
GROUP BY
  utm_campaign,
  utm_content
ORDER BY
  impressions DESC
```

### Alertas Autom√°ticas (Python)

**Script**: `carousel_alerts.py`
```python
#!/usr/bin/env python3
"""
Env√≠a alertas cuando m√©tricas est√°n fuera de rango
"""
import smtplib
from email.mime.text import MIMEText
import requests

class CarouselAlerts:
    def __init__(self, config):
        self.config = config
        self.thresholds = {
            'ctr_min': 1.5,
            'conversion_rate_min': 10.0,
            'roi_min': 100,
            'cpa_max': 5.0
        }
    
    def check_metrics(self, carousel_id):
        """Verifica m√©tricas y env√≠a alertas si necesario"""
        metrics = self.fetch_metrics(carousel_id)
        alerts = []
        
        if metrics['ctr'] < self.thresholds['ctr_min']:
            alerts.append({
                'type': 'warning',
                'metric': 'CTR',
                'value': metrics['ctr'],
                'threshold': self.thresholds['ctr_min'],
                'message': f"CTR bajo: {metrics['ctr']}% (m√≠nimo: {self.thresholds['ctr_min']}%)"
            })
        
        if metrics['conversion_rate'] < self.thresholds['conversion_rate_min']:
            alerts.append({
                'type': 'critical',
                'metric': 'Conversion Rate',
                'value': metrics['conversion_rate'],
                'threshold': self.thresholds['conversion_rate_min'],
                'message': f"Tasa conversi√≥n baja: {metrics['conversion_rate']}%"
            })
        
        if alerts:
            self.send_alerts(carousel_id, alerts)
    
    def send_slack_alert(self, message):
        """Env√≠a alerta a Slack"""
        webhook_url = self.config['slack']['webhook']
        payload = {
            'text': f"üö® Alerta Carrusel\n{message}",
            'username': 'Carousel Monitor'
        }
        requests.post(webhook_url, json=payload)
    
    def send_email_alert(self, subject, body):
        """Env√≠a alerta por email"""
        msg = MIMEText(body)
        msg['Subject'] = subject
        msg['From'] = self.config['email']['from']
        msg['To'] = self.config['email']['to']
        
        server = smtplib.SMTP(self.config['email']['smtp'], 587)
        server.starttls()
        server.login(self.config['email']['user'], self.config['email']['password'])
        server.send_message(msg)
        server.quit()
```

---

## üß™ Testing Estad√≠stico Avanzado

### A/B Testing con Significancia Estad√≠stica

**Python**: `carousel_ab_test.py`
```python
#!/usr/bin/env python3
"""
A/B Testing con c√°lculo de significancia estad√≠stica
"""
from scipy import stats
import numpy as np

class CarouselABTest:
    def __init__(self, variant_a_metrics, variant_b_metrics):
        self.variant_a = variant_a_metrics
        self.variant_b = variant_b_metrics
    
    def calculate_statistical_significance(self):
        """Calcula significancia estad√≠stica usando t-test"""
        # Extraer datos
        a_clicks = self.variant_a['clicks']
        a_impressions = self.variant_a['impressions']
        a_conversions = self.variant_a['conversions']
        
        b_clicks = self.variant_b['clicks']
        b_impressions = self.variant_b['impressions']
        b_conversions = self.variant_b['conversions']
        
        # Calcular rates
        a_ctr = a_clicks / a_impressions
        b_ctr = b_clicks / b_impressions
        
        a_conversion_rate = a_conversions / a_clicks if a_clicks > 0 else 0
        b_conversion_rate = b_conversions / b_clicks if b_clicks > 0 else 0
        
        # T-test para CTR
        a_success = a_clicks
        a_trials = a_impressions
        b_success = b_clicks
        b_trials = b_impressions
        
        # Z-test para proporciones
        p1 = a_success / a_trials
        p2 = b_success / b_trials
        p_combined = (a_success + b_success) / (a_trials + b_trials)
        
        se = np.sqrt(p_combined * (1 - p_combined) * (1/a_trials + 1/b_trials))
        z_score = (p1 - p2) / se
        p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))
        
        # Determinar winner
        if p_value < 0.05:  # 95% confidence
            if p1 > p2:
                winner = 'Variant A'
                improvement = ((p1 - p2) / p2) * 100
            else:
                winner = 'Variant B'
                improvement = ((p2 - p1) / p1) * 100
        else:
            winner = 'No significant difference'
            improvement = 0
        
        return {
            'variant_a_ctr': round(a_ctr * 100, 2),
            'variant_b_ctr': round(b_ctr * 100, 2),
            'variant_a_conversion_rate': round(a_conversion_rate * 100, 2),
            'variant_b_conversion_rate': round(b_conversion_rate * 100, 2),
            'p_value': round(p_value, 4),
            'statistically_significant': p_value < 0.05,
            'winner': winner,
            'improvement_percentage': round(improvement, 2),
            'confidence_level': '95%' if p_value < 0.05 else 'N/A'
        }
    
    def calculate_sample_size(self, baseline_rate, mde=0.2, alpha=0.05, power=0.8):
        """Calcula tama√±o de muestra necesario"""
        # MDE = Minimum Detectable Effect (20% por defecto)
        from statsmodels.stats.power import NormalIndPower
        
        effect_size = (baseline_rate * mde) / np.sqrt(
            baseline_rate * (1 - baseline_rate)
        )
        
        analysis = NormalIndPower()
        sample_size = analysis.solve_power(
            effect_size=effect_size,
            alpha=alpha,
            power=power,
            ratio=1.0
        )
        
        return {
            'required_sample_size': int(sample_size * 2),  # *2 para ambas variantes
            'per_variant': int(sample_size),
            'baseline_rate': baseline_rate,
            'mde': mde,
            'alpha': alpha,
            'power': power
        }

# Uso
ab_test = CarouselABTest(
    variant_a_metrics={'clicks': 850, 'impressions': 30000, 'conversions': 120},
    variant_b_metrics={'clicks': 920, 'impressions': 30000, 'conversions': 145}
)

results = ab_test.calculate_statistical_significance()
print(results)

# Calcular tama√±o de muestra para pr√≥ximo test
sample_calc = ab_test.calculate_sample_size(baseline_rate=0.028)  # 2.8% CTR baseline
print(sample_calc)
```

---

## üì± Estrategia de Distribuci√≥n Multi-Canal

### Calendario Automatizado Multi-Plataforma

**Python**: `multi_platform_scheduler.py`
```python
#!/usr/bin/env python3
"""
Programa carruseles en m√∫ltiples plataformas con timing optimizado
"""
from datetime import datetime, timedelta
import json

class MultiPlatformScheduler:
    def __init__(self):
        self.platform_schedules = {
            'instagram': {
                'best_times': ['08:00', '12:00', '18:00'],
                'best_days': [1, 2, 3, 4, 5],  # Lunes-Viernes
                'timezone': 'America/Mexico_City'
            },
            'linkedin': {
                'best_times': ['08:00', '12:00', '17:00'],
                'best_days': [1, 2, 3, 4],  # Lunes-Jueves
                'timezone': 'America/Mexico_City'
            },
            'facebook': {
                'best_times': ['13:00', '18:00', '20:00'],
                'best_days': [1, 2, 3, 4, 5],
                'timezone': 'America/Mexico_City'
            }
        }
    
    def schedule_carousel(self, carousel_id, platforms, start_date):
        """Programa carrusel en m√∫ltiples plataformas"""
        schedule = []
        
        for platform in platforms:
            config = self.platform_schedules[platform]
            
            for day_offset in range(7):  # Semana completa
                day = start_date + timedelta(days=day_offset)
                day_of_week = day.weekday()  # 0=Lunes, 6=Domingo
                
                if day_of_week in config['best_days']:
                    for time_str in config['best_times']:
                        schedule.append({
                            'carousel_id': carousel_id,
                            'platform': platform,
                            'datetime': f"{day.strftime('%Y-%m-%d')} {time_str}",
                            'timezone': config['timezone']
                        })
        
        return schedule
    
    def export_to_buffer(self, schedule):
        """Exporta a Buffer API"""
        # Implementar integraci√≥n con Buffer API
        pass
    
    def export_to_hootsuite(self, schedule):
        """Exporta a Hootsuite API"""
        # Implementar integraci√≥n con Hootsuite API
        pass

# Uso
scheduler = MultiPlatformScheduler()
schedule = scheduler.schedule_carousel(
    carousel_id='curso_ia_v1',
    platforms=['instagram', 'linkedin', 'facebook'],
    start_date=datetime.now() + timedelta(days=1)
)

print(json.dumps(schedule, indent=2))
```

---

## üîß Integraci√≥n con Script de An√°lisis de Assets

### Script Shell: An√°lisis Completo de Carruseles

**Referencia**: `tools/analyze_assets.sh`

**Funcionalidades integradas**:
- An√°lisis autom√°tico de todos los assets SVG
- Verificaci√≥n de cobertura por producto y formato
- Validaci√≥n de UTMs en templates
- Detecci√≥n de inconsistencias de naming
- Generaci√≥n de reportes JSON y texto

**Uso con Carruseles**:
```bash
# An√°lisis completo
./tools/analyze_assets.sh

# Con directorio espec√≠fico de carruseles
SRC_DIR=./design/instagram/carousel ./tools/analyze_assets.sh

# Output JSON para procesamiento
OUTPUT_FORMAT=json ./tools/analyze_assets.sh
```

**Integraci√≥n con Validaci√≥n Pre-Publicaci√≥n**:
```python
#!/usr/bin/env python3
"""
Integra analyze_assets.sh con validaci√≥n de carruseles
"""
import subprocess
import json
import os

def validate_carousel_assets(carousel_name):
    """Valida assets del carrusel usando analyze_assets.sh"""
    # Ejecutar script de an√°lisis
    result = subprocess.run(
        ['bash', 'tools/analyze_assets.sh'],
        capture_output=True,
        text=True,
        env={
            **os.environ,
            'SRC_DIR': f'./design/instagram/carousel/{carousel_name}',
            'OUTPUT_FORMAT': 'json'
        }
    )
    
    # Parsear JSON output
    json_report = json.loads(result.stdout)
    
    # Verificar cobertura de formato
    formats = json_report['summary']['formats']
    required_formats = {
        'square_1080x1080': 3,  # 3 slides m√≠nimo
        'vertical_1080x1920': 3  # 3 slides stories
    }
    
    issues = []
    for fmt, min_count in required_formats.items():
        actual_count = formats.get(fmt, 0)
        if actual_count < min_count:
            issues.append(
                f"‚ùå {fmt}: {actual_count} encontrados, "
                f"{min_count} requeridos"
            )
    
    # Verificar UTMs
    svgs_with_utms = json_report.get('svgs_with_utms', 0)
    svgs_with_urls = json_report.get('svgs_with_urls', 0)
    if svgs_with_urls > 0 and svgs_with_utms < svgs_with_urls:
        issues.append(
            f"‚ö†Ô∏è  {svgs_with_urls - svgs_with_utms} SVGs sin UTMs"
        )
    
    return {
        'valid': len(issues) == 0,
        'issues': issues,
        'summary': json_report['summary']
    }

# Usar
result = validate_carousel_assets('curso_ia_v1')
if not result['valid']:
    print("Issues encontrados:")
    for issue in result['issues']:
        print(f"  {issue}")
```

---

## üìä M√©tricas Automatizadas de Assets

### Dashboard de Cobertura de Assets

**Python**: `assets_coverage_dashboard.py`
```python
#!/usr/bin/env python3
"""
Genera dashboard de cobertura de assets por producto/formato/variante
Integra con analyze_assets.sh
"""
import subprocess
import json
from collections import defaultdict

class AssetsCoverageDashboard:
    def __init__(self):
        self.coverage = defaultdict(lambda: defaultdict(int))
    
    def analyze_all_assets(self):
        """Ejecuta analyze_assets.sh y parsea resultados"""
        result = subprocess.run(
            ['bash', 'tools/analyze_assets.sh'],
            capture_output=True,
            text=True,
            env={'OUTPUT_FORMAT': 'json'}
        )
        
        json_report_path = 'exports/assets_report.json'
        if os.path.exists(json_report_path):
            with open(json_report_path) as f:
                return json.load(f)
        return None
    
    def generate_coverage_matrix(self, report):
        """Genera matriz de cobertura Producto √ó Formato √ó Variante"""
        matrix = {}
        
        products = ['curso_ia', 'saas_marketing', 'ia_bulk']
        formats = ['1200x627', '1080x1080', '1080x1920']
        variants = ['metrics', 'social_proof', 'urgency', 'elegant', 'benefits', 'numbers']
        
        for product in products:
            matrix[product] = {}
            for fmt in formats:
                matrix[product][fmt] = {}
                for variant in variants:
                    # Buscar assets que coincidan
                    pattern = f"*{product}*{fmt}*{variant}*"
                    count = len(glob.glob(f"design/instagram/carousel/**/{pattern}.svg", recursive=True))
                    matrix[product][fmt][variant] = {
                        'count': count,
                        'status': 'complete' if count >= 3 else ('partial' if count > 0 else 'missing')
                    }
        
        return matrix
    
    def generate_html_report(self, matrix):
        """Genera reporte HTML visual"""
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>Cobertura de Assets - Carruseles</title>
            <style>
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: center; }
                th { background: #f2f2f2; }
                .complete { background: #d4edda; }
                .partial { background: #fff3cd; }
                .missing { background: #f8d7da; }
            </style>
        </head>
        <body>
            <h1>üìä Cobertura de Assets por Producto</h1>
        """
        
        for product, formats in matrix.items():
            html += f"<h2>{product}</h2><table>"
            html += "<tr><th>Formato</th><th>Metrics</th><th>Social Proof</th><th>Urgency</th><th>Elegant</th><th>Benefits</th><th>Numbers</th></tr>"
            
            for fmt, variants in formats.items():
                html += f"<tr><td><strong>{fmt}</strong></td>"
                for variant in ['metrics', 'social_proof', 'urgency', 'elegant', 'benefits', 'numbers']:
                    status = variants[variant]['status']
                    count = variants[variant]['count']
                    html += f'<td class="{status}">{count}</td>'
                html += "</tr>"
            
            html += "</table><br>"
        
        html += "</body></html>"
        
        with open('exports/assets_coverage_report.html', 'w') as f:
            f.write(html)
        
        print("‚úÖ Reporte HTML generado: exports/assets_coverage_report.html")

# Uso
dashboard = AssetsCoverageDashboard()
report = dashboard.analyze_all_assets()
if report:
    matrix = dashboard.generate_coverage_matrix(report)
    dashboard.generate_html_report(matrix)
```

---

## üöÄ Workflow Integrado: An√°lisis + Validaci√≥n + Export

### Makefile: Pipeline Completo de Carruseles

**`Makefile`**: `carousel-pipeline.mk`
```makefile
# Pipeline completo: An√°lisis ‚Üí Validaci√≥n ‚Üí Export ‚Üí QA

.PHONY: all analyze validate export qa report

all: analyze validate export qa report
	@echo "üéâ Pipeline completo finalizado"

# 1. An√°lisis de assets existentes
analyze:
	@echo "üìä Analizando assets existentes..."
	bash tools/analyze_assets.sh
	@echo "‚úÖ An√°lisis completado"

# 2. Validaci√≥n pre-publicaci√≥n
validate:
	@echo "üîç Validando carruseles..."
	python scripts/validate_carousel_pre_launch.py \
		--input source/*/square/*.svg \
		--input source/*/stories/*.svg
	@echo "‚úÖ Validaci√≥n completada"

# 3. Generar variantes y exportar
export:
	@echo "üé® Generando variantes..."
	make -f generate-all-formats.mk all
	@echo "‚úÖ Export completado"

# 4. QA autom√°tico
qa:
	@echo "‚úÖ Ejecutando QA..."
	python scripts/validate_carousel_pre_launch.py \
		--check-contrast \
		--check-safe-areas \
		--check-utms \
		--input exports/png/**/*.png
	@echo "‚úÖ QA completado"

# 5. Generar reporte final
report:
	@echo "üìä Generando reporte final..."
	python scripts/assets_coverage_dashboard.py
	python scripts/analyze_carousel_performance.py \
		--format html \
		--output exports/final_report.html
	@echo "‚úÖ Reporte generado: exports/final_report.html"

# Limpiar exports temporales
clean:
	rm -rf exports/temp/
	rm -rf exports/png/*.tmp
	@echo "‚úÖ Archivos temporales eliminados"
```

---

## üìã Checklist Integrado: Assets + Performance

### QA Completo Pre-Publicaci√≥n

**Checklist automatizado**:
```python
#!/usr/bin/env python3
"""
Checklist completo integrando assets y performance
"""
import subprocess
import json
from pathlib import Path

class CarouselQAChecklist:
    def __init__(self, carousel_name):
        self.carousel_name = carousel_name
        self.results = {
            'assets': {},
            'validation': {},
            'performance': {},
            'tracking': {}
        }
    
    def check_assets(self):
        """Verifica assets usando analyze_assets.sh"""
        result = subprocess.run(
            ['bash', 'tools/analyze_assets.sh'],
            capture_output=True,
            text=True,
            env={
                'SRC_DIR': f'./design/instagram/carousel/{self.carousel_name}',
                'OUTPUT_FORMAT': 'json'
            }
        )
        
        # Parsear resultados
        json_path = Path('exports/assets_report.json')
        if json_path.exists():
            with open(json_path) as f:
                report = json.load(f)
                
            self.results['assets'] = {
                'total_svgs': report['summary']['total_svgs'],
                'formats': report['summary']['formats'],
                'has_all_slides': report['summary']['formats'].get('square_1080x1080', 0) >= 3,
                'has_stories': report['summary']['formats'].get('vertical_1080x1920', 0) >= 3
            }
        
        return self.results['assets']
    
    def check_validation(self):
        """Valida SVG/PNG usando validate_carousel_pre_launch.py"""
        svg_files = list(Path(f'source/{self.carousel_name}').glob('*.svg'))
        
        issues = []
        for svg_file in svg_files:
            result = subprocess.run(
                ['python', 'scripts/validate_carousel_pre_launch.py', str(svg_file)],
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                issues.append({
                    'file': str(svg_file),
                    'errors': result.stderr
                })
        
        self.results['validation'] = {
            'valid': len(issues) == 0,
            'issues': issues,
            'checked_files': len(svg_files)
        }
        
        return self.results['validation']
    
    def check_tracking(self):
        """Verifica UTMs y tracking"""
        svg_files = list(Path(f'source/{self.carousel_name}').glob('*.svg'))
        
        utm_issues = []
        for svg_file in svg_files:
            content = svg_file.read_text()
            
            # Verificar presencia de UTMs
            if 'utm_source' not in content:
                utm_issues.append(f"{svg_file.name}: Sin utm_source")
            if 'utm_campaign' not in content:
                utm_issues.append(f"{svg_file.name}: Sin utm_campaign")
            if 'utm_content' not in content:
                utm_issues.append(f"{svg_file.name}: Sin utm_content")
        
        self.results['tracking'] = {
            'has_utms': len(utm_issues) == 0,
            'issues': utm_issues
        }
        
        return self.results['tracking']
    
    def generate_report(self):
        """Genera reporte final"""
        all_checks = [
            self.check_assets(),
            self.check_validation(),
            self.check_tracking()
        ]
        
        all_pass = all(
            check.get('valid', False) or check.get('has_all_slides', False)
            for check in all_checks
        )
        
        report = {
            'carousel': self.carousel_name,
            'timestamp': datetime.now().isoformat(),
            'all_checks_pass': all_pass,
            'results': self.results,
            'recommendations': self.generate_recommendations()
        }
        
        # Guardar reporte
        report_path = Path(f'exports/qa_report_{self.carousel_name}.json')
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        return report
    
    def generate_recommendations(self):
        """Genera recomendaciones basadas en resultados"""
        recommendations = []
        
        if not self.results['assets'].get('has_all_slides', False):
            recommendations.append({
                'priority': 'high',
                'action': 'Generar slides faltantes (m√≠nimo 3 slides por carrusel)'
            })
        
        if not self.results['assets'].get('has_stories', False):
            recommendations.append({
                'priority': 'medium',
                'action': 'Considerar generar versi√≥n stories (1080√ó1920)'
            })
        
        if not self.results['tracking'].get('has_utms', False):
            recommendations.append({
                'priority': 'high',
                'action': 'Agregar UTMs a todos los slides antes de publicar'
            })
        
        return recommendations

# Uso
qa = CarouselQAChecklist('curso_ia_v1')
report = qa.generate_report()

if report['all_checks_pass']:
    print("‚úÖ Todos los checks pasaron. Listo para publicar.")
else:
    print("‚ö†Ô∏è  Algunos checks fallaron:")
    for rec in report['recommendations']:
        print(f"  [{rec['priority']}] {rec['action']}")
```

---

---

## üîÑ CI/CD para Carruseles (GitHub Actions)

### Workflow Automatizado: Deploy en Push

**GitHub Actions**: `.github/workflows/carousel-deploy.yml`
```yaml
name: Carousel CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    paths:
      - 'design/instagram/carousel/**'
      - 'source/**/*.svg'
  pull_request:
    branches: [main]

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          npm install -g svgo
      
      - name: Analyze assets
        run: |
          bash tools/analyze_assets.sh
          OUTPUT_FORMAT=json bash tools/analyze_assets.sh > assets_report.json
      
      - name: Upload analysis report
        uses: actions/upload-artifact@v3
        with:
          name: assets-report
          path: assets_report.json

  validate:
    runs-on: ubuntu-latest
    needs: analyze
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Validate SVGs
        run: |
          python scripts/validate_carousel_pre_launch.py \
            --input source/**/*.svg \
            --check-contrast \
            --check-safe-areas \
            --check-utms
      
      - name: Validate PNGs
        if: always()
        run: |
          python scripts/validate_carousel_pre_launch.py \
            --input exports/png/**/*.png \
            --check-dimensions \
            --check-file-size

  generate:
    runs-on: ubuntu-latest
    needs: validate
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Generate all formats
        run: |
          make -f generate-all-formats.mk all
      
      - name: Upload generated assets
        uses: actions/upload-artifact@v3
        with:
          name: generated-assets
          path: exports/png/

  deploy:
    runs-on: ubuntu-latest
    needs: [analyze, validate, generate]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3
      
      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          path: artifacts/
      
      - name: Deploy to CDN
        env:
          CDN_API_KEY: ${{ secrets.CDN_API_KEY }}
        run: |
          # Subir a CDN (Cloudflare/AWS S3/etc)
          python scripts/deploy_to_cdn.py \
            --source exports/png/ \
            --cdn-path carousels/
      
      - name: Update preview site
        run: |
          python scripts/update_preview_site.py \
            --assets exports/png/
      
      - name: Notify team
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Carruseles desplegados exitosamente'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

---

## ü§ñ Automatizaci√≥n de Refresh/Republishing

### Script: Auto-Refresh de Carruseles Antiguos

**Python**: `auto_refresh_carousels.py`
```python
#!/usr/bin/env python3
"""
Refresca carruseles antiguos autom√°ticamente
- Detecta carruseles con bajo performance
- Sugiere mejoras basadas en datos
- Genera nuevas variantes autom√°ticamente
"""
from datetime import datetime, timedelta
import json
from pathlib import Path

class CarouselAutoRefresh:
    def __init__(self, threshold_days=90, ctr_threshold=1.5):
        self.threshold_days = threshold_days
        self.ctr_threshold = ctr_threshold
    
    def find_stale_carousels(self):
        """Encuentra carruseles que necesitan refresh"""
        stale = []
        
        # Leer reporte de performance
        with open('exports/carousel_performance.json') as f:
            performance = json.load(f)
        
        for carousel_id, data in performance.items():
            last_update = datetime.fromisoformat(data['last_updated'])
            days_old = (datetime.now() - last_update).days
            
            # Verificar si necesita refresh
            needs_refresh = (
                days_old > self.threshold_days or
                data.get('ctr', 0) < self.ctr_threshold or
                data.get('conversion_rate', 0) < 10
            )
            
            if needs_refresh:
                stale.append({
                    'id': carousel_id,
                    'days_old': days_old,
                    'ctr': data.get('ctr', 0),
                    'conversion_rate': data.get('conversion_rate', 0),
                    'recommendations': self.generate_refresh_recommendations(data)
                })
        
        return stale
    
    def generate_refresh_recommendations(self, performance_data):
        """Genera recomendaciones espec√≠ficas para refresh"""
        recommendations = []
        
        if performance_data.get('ctr', 0) < 1.5:
            recommendations.append({
                'action': 'update_headline',
                'reason': 'CTR bajo, probar headlines m√°s directos',
                'variants': ['metrics', 'urgency', 'benefits']
            })
        
        if performance_data.get('conversion_rate', 0) < 10:
            recommendations.append({
                'action': 'update_cta',
                'reason': 'Tasa conversi√≥n baja, probar CTAs m√°s claros',
                'variants': ['action_direct', 'urgency', 'value_prop']
            })
        
        # Analizar qu√© slide funciona mejor
        best_slide = performance_data.get('best_performing_slide', 1)
        if best_slide != 1:
            recommendations.append({
                'action': 'reorder_slides',
                'reason': f'Slide {best_slide} funciona mejor, considerar moverlo al inicio',
                'variants': ['slide_order_optimized']
            })
        
        return recommendations
    
    def auto_generate_refresh(self, carousel_id, recommendations):
        """Genera nuevas variantes autom√°ticamente"""
        from scripts.generate_all_variants import generate_variants
        
        refresh_config = {
            'carousel_id': carousel_id,
            'base_version': self.get_current_version(carousel_id),
            'new_version': f"v{self.get_next_version(carousel_id)}",
            'recommendations': recommendations
        }
        
        # Generar variantes basadas en recomendaciones
        for rec in recommendations:
            if rec['action'] == 'update_headline':
                # Generar variantes con nuevos headlines
                for variant in rec['variants']:
                    generate_variants(
                        carousel_id,
                        variant,
                        refresh_config['new_version']
                    )
        
        return refresh_config
    
    def schedule_refresh_tests(self, refresh_config):
        """Programa tests A/B de las nuevas variantes"""
        from scripts.multi_platform_scheduler import MultiPlatformScheduler
        
        scheduler = MultiPlatformScheduler()
        
        # Programar tests con split 50/50
        schedule = scheduler.schedule_carousel(
            carousel_id=f"{refresh_config['carousel_id']}_{refresh_config['new_version']}",
            platforms=['instagram', 'linkedin'],
            start_date=datetime.now() + timedelta(days=1)
        )
        
        # Configurar como test A/B
        for item in schedule:
            item['ab_test'] = True
            item['ab_variant'] = refresh_config['new_version']
            item['split'] = 50  # 50% tr√°fico
        
        return schedule

# Uso: Ejecutar semanalmente
refresh = CarouselAutoRefresh()
stale = refresh.find_stale_carousels()

for carousel in stale:
    print(f"üîÑ Refrescando: {carousel['id']}")
    refresh_config = refresh.auto_generate_refresh(
        carousel['id'],
        carousel['recommendations']
    )
    schedule = refresh.schedule_refresh_tests(refresh_config)
    print(f"‚úÖ Nuevas variantes generadas y programadas")
```

---

## üé® Integraci√≥n con Figma API

### Script: Sincronizaci√≥n Autom√°tica Figma ‚Üí SVG

**Python**: `figma_to_svg_sync.py`
```python
#!/usr/bin/env python3
"""
Sincroniza dise√±os desde Figma a SVG
- Descarga componentes desde Figma
- Convierte a SVG optimizado
- Actualiza templates autom√°ticamente
"""
import requests
import json
from pathlib import Path

class FigmaCarouselSync:
    def __init__(self, figma_token, file_key):
        self.token = figma_token
        self.file_key = file_key
        self.base_url = 'https://api.figma.com/v1'
    
    def get_carousel_frames(self):
        """Obtiene frames de carrusel desde Figma"""
        url = f"{self.base_url}/files/{self.file_key}"
        headers = {'X-Figma-Token': self.token}
        
        response = requests.get(url, headers=headers)
        data = response.json()
        
        # Buscar frames que contengan "carousel" en el nombre
        carousel_frames = []
        for node in self.traverse_nodes(data['document']):
            if node.get('type') == 'FRAME' and 'carousel' in node.get('name', '').lower():
                carousel_frames.append({
                    'id': node['id'],
                    'name': node['name'],
                    'type': self.detect_carousel_type(node['name'])
                })
        
        return carousel_frames
    
    def export_frame_as_svg(self, frame_id, output_path):
        """Exporta frame desde Figma como SVG"""
        url = f"{self.base_url}/images/{self.file_key}"
        params = {
            'ids': frame_id,
            'format': 'svg',
            'scale': 1
        }
        headers = {'X-Figma-Token': self.token}
        
        response = requests.get(url, headers=headers, params=params)
        data = response.json()
        
        # Descargar SVG
        svg_url = data['images'][frame_id]
        svg_response = requests.get(svg_url)
        
        # Optimizar SVG
        svg_content = self.optimize_svg(svg_response.text)
        
        # Guardar
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w') as f:
            f.write(svg_content)
        
        return output_path
    
    def optimize_svg(self, svg_content):
        """Optimiza SVG descargado desde Figma"""
        import subprocess
        import tempfile
        
        # Guardar temporal
        with tempfile.NamedTemporaryFile(mode='w', suffix='.svg', delete=False) as f:
            f.write(svg_content)
            temp_path = f.name
        
        # Optimizar con svgo
        try:
            result = subprocess.run(
                ['svgo', temp_path, '-o', temp_path],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                with open(temp_path) as f:
                    return f.read()
        except:
            pass
        
        return svg_content
    
    def sync_all_carousels(self, output_dir='source/figma_sync'):
        """Sincroniza todos los carruseles desde Figma"""
        frames = self.get_carousel_frames()
        
        synced = []
        for frame in frames:
            output_path = f"{output_dir}/{frame['name']}.svg"
            self.export_frame_as_svg(frame['id'], output_path)
            synced.append(output_path)
            print(f"‚úÖ Sincronizado: {frame['name']}")
        
        return synced
    
    def detect_carousel_type(self, frame_name):
        """Detecta tipo de carrusel desde nombre de frame"""
        name_lower = frame_name.lower()
        
        if 'slide1' in name_lower or 'slide-1' in name_lower:
            return 'slide_1'
        elif 'slide2' in name_lower or 'slide-2' in name_lower:
            return 'slide_2'
        elif 'slide3' in name_lower or 'slide-3' in name_lower:
            return 'slide_3'
        elif 'stories' in name_lower:
            return 'stories'
        elif 'square' in name_lower:
            return 'square'
        else:
            return 'unknown'

# Uso
if __name__ == '__main__':
    sync = FigmaCarouselSync(
        figma_token=os.environ['FIGMA_TOKEN'],
        file_key='YOUR_FIGMA_FILE_KEY'
    )
    
    # Sincronizar todos los carruseles
    synced = sync.sync_all_carousels()
    
    # Actualizar reporte
    print(f"‚úÖ {len(synced)} carruseles sincronizados desde Figma")
```

---

## üîç Optimizaci√≥n SEO y Metadata Avanzada

### Script: Generaci√≥n Autom√°tica de Metadata

**Python**: `generate_metadata.py`
```python
#!/usr/bin/env python3
"""
Genera metadata SEO optimizada para carruseles
- Open Graph tags
- Twitter Cards
- Schema.org markup
- Alt text optimizado
"""
import json
from pathlib import Path

class CarouselMetadataGenerator:
    def __init__(self):
        self.product_metadata = {
            'curso_ia': {
                'title_template': '{slide_type} - Domina IA Aplicada | Curso + Webinars',
                'description_template': '{slide_content}. Clases pr√°cticas, webinars en vivo y casos reales.',
                'keywords': ['IA', 'Inteligencia Artificial', 'Curso IA', 'Webinars', 'Automatizaci√≥n'],
                'category': 'Education',
                'schema_type': 'Course'
            },
            'saas_marketing': {
                'title_template': '{slide_type} - SaaS IA Marketing | Automatizaci√≥n de Campa√±as',
                'description_template': '{slide_content}. Genera creatividades, segmenta y reporta con IA.',
                'keywords': ['SaaS', 'Marketing IA', 'Automatizaci√≥n', 'ROI', 'Campa√±as'],
                'category': 'Software',
                'schema_type': 'SoftwareApplication'
            },
            'ia_bulk': {
                'title_template': '{slide_type} - IA Bulk Docs | Generaci√≥n Masiva de Documentos',
                'description_template': '{slide_content}. Crea 100+ documentos con 1 consulta.',
                'keywords': ['IA', 'Documentos', 'Automatizaci√≥n', 'Productividad', 'Bulk'],
                'category': 'Productivity',
                'schema_type': 'SoftwareApplication'
            }
        }
    
    def generate_open_graph(self, carousel_data):
        """Genera tags Open Graph optimizados"""
        product = carousel_data['product']
        slide = carousel_data['slide']
        slide_type = carousel_data.get('slide_type', 'Slide')
        
        meta = self.product_metadata[product]
        
        title = meta['title_template'].format(
            slide_type=slide_type,
            slide_content=slide.get('headline', '')
        )
        
        description = meta['description_template'].format(
            slide_content=slide.get('subcopy', '')
        )
        
        og_tags = {
            'og:title': title[:60],  # M√°ximo 60 caracteres
            'og:description': description[:160],  # M√°ximo 160 caracteres
            'og:image': carousel_data['image_url'],
            'og:image:width': str(carousel_data['width']),
            'og:image:height': str(carousel_data['height']),
            'og:type': 'article',
            'og:url': carousel_data['url'],
            'og:site_name': 'Tu Marca'
        }
        
        return og_tags
    
    def generate_twitter_card(self, carousel_data):
        """Genera Twitter Card tags"""
        og = self.generate_open_graph(carousel_data)
        
        twitter_tags = {
            'twitter:card': 'summary_large_image',
            'twitter:title': og['og:title'],
            'twitter:description': og['og:description'],
            'twitter:image': og['og:image'],
            'twitter:site': '@tu_marca',
            'twitter:creator': '@tu_marca'
        }
        
        return twitter_tags
    
    def generate_schema_markup(self, carousel_data):
        """Genera Schema.org JSON-LD"""
        product = carousel_data['product']
        meta = self.product_metadata[product]
        
        schema = {
            '@context': 'https://schema.org',
            '@type': meta['schema_type'],
            'name': carousel_data['headline'],
            'description': carousel_data['subcopy'],
            'image': carousel_data['image_url'],
            'url': carousel_data['url'],
            'offers': {
                '@type': 'Offer',
                'availability': 'https://schema.org/InStock'
            }
        }
        
        if meta['schema_type'] == 'Course':
            schema['courseMode'] = 'online'
            schema['provider'] = {
                '@type': 'Organization',
                'name': 'Tu Marca'
            }
        
        return schema
    
    def generate_alt_text(self, carousel_data):
        """Genera alt text optimizado para accesibilidad y SEO"""
        slide = carousel_data['slide']
        product = carousel_data['product']
        
        alt_text_parts = [
            slide.get('headline', ''),
            f"Promoci√≥n de {product.replace('_', ' ')}",
            slide.get('visual_description', ''),
            slide.get('cta', '')
        ]
        
        alt_text = '. '.join(filter(None, alt_text_parts))
        
        # Optimizar longitud (m√°ximo 125 caracteres recomendado)
        if len(alt_text) > 125:
            alt_text = alt_text[:122] + '...'
        
        return alt_text
    
    def generate_html_meta_tags(self, carousel_data):
        """Genera todos los meta tags HTML"""
        og = self.generate_open_graph(carousel_data)
        twitter = self.generate_twitter_card(carousel_data)
        schema = self.generate_schema_markup(carousel_data)
        
        meta_html = []
        
        # Basic meta
        meta_html.append(f'<meta name="description" content="{og["og:description"]}">')
        meta_html.append(f'<meta name="keywords" content="{", ".join(self.product_metadata[carousel_data["product"]]["keywords"])}">')
        
        # Open Graph
        for key, value in og.items():
            meta_html.append(f'<meta property="{key}" content="{value}">')
        
        # Twitter
        for key, value in twitter.items():
            meta_html.append(f'<meta name="{key}" content="{value}">')
        
        # Schema.org JSON-LD
        meta_html.append(f'<script type="application/ld+json">{json.dumps(schema)}</script>')
        
        return '\n'.join(meta_html)

# Uso
generator = CarouselMetadataGenerator()

carousel_data = {
    'product': 'curso_ia',
    'slide': {
        'headline': 'Domina IA aplicada en semanas',
        'subcopy': 'Clases pr√°cticas + webinars en vivo',
        'cta': '√önete ahora'
    },
    'slide_type': 'Slide 1',
    'image_url': 'https://tusitio.com/carrusel-curso-ia-s1.png',
    'width': 1080,
    'height': 1080,
    'url': 'https://tusitio.com/curso-ia'
}

meta_html = generator.generate_html_meta_tags(carousel_data)
alt_text = generator.generate_alt_text(carousel_data)

print("Meta tags HTML:")
print(meta_html)
print(f"\nAlt text: {alt_text}")
```

---

## üìù Gesti√≥n de Versiones y Changelog

### Script: Versionado Autom√°tico de Carruseles

**Python**: `carousel_versioning.py`
```python
#!/usr/bin/env python3
"""
Gestiona versionado de carruseles
- Versionado sem√°ntico (v1.0.0)
- Changelog autom√°tico
- Tracking de cambios
"""
from datetime import datetime
import json
from pathlib import Path

class CarouselVersionManager:
    def __init__(self, changelog_path='CHANGELOG.md'):
        self.changelog_path = Path(changelog_path)
        self.versions_path = Path('versions/carousels.json')
    
    def get_current_version(self, carousel_id):
        """Obtiene versi√≥n actual del carrusel"""
        if not self.versions_path.exists():
            return '0.0.0'
        
        with open(self.versions_path) as f:
            versions = json.load(f)
        
        return versions.get(carousel_id, {}).get('current', '0.0.0')
    
    def bump_version(self, carousel_id, change_type='patch'):
        """Incrementa versi√≥n seg√∫n tipo de cambio"""
        current = self.get_current_version(carousel_id)
        major, minor, patch = map(int, current.split('.'))
        
        if change_type == 'major':
            major += 1
            minor = 0
            patch = 0
        elif change_type == 'minor':
            minor += 1
            patch = 0
        else:  # patch
            patch += 1
        
        new_version = f"{major}.{minor}.{patch}"
        
        # Actualizar registro
        self.update_version(carousel_id, new_version, change_type)
        
        return new_version
    
    def update_version(self, carousel_id, new_version, change_type):
        """Actualiza registro de versiones"""
        if not self.versions_path.parent.exists():
            self.versions_path.parent.mkdir(parents=True)
        
        if self.versions_path.exists():
            with open(self.versions_path) as f:
                versions = json.load(f)
        else:
            versions = {}
        
        if carousel_id not in versions:
            versions[carousel_id] = {'history': []}
        
        versions[carousel_id]['current'] = new_version
        versions[carousel_id]['history'].append({
            'version': new_version,
            'type': change_type,
            'date': datetime.now().isoformat(),
            'previous': versions[carousel_id].get('current', '0.0.0')
        })
        
        with open(self.versions_path, 'w') as f:
            json.dump(versions, f, indent=2)
    
    def add_changelog_entry(self, carousel_id, version, changes):
        """Agrega entrada al changelog"""
        if not self.changelog_path.exists():
            self.changelog_path.write_text("# Changelog\n\n")
        
        changelog = self.changelog_path.read_text()
        
        entry = f"""
## [{carousel_id}] {version} - {datetime.now().strftime('%Y-%m-%d')}

### Cambios
{chr(10).join(f"- {change}" for change in changes)}

"""
        
        # Insertar al inicio (despu√©s del header)
        header_end = changelog.find('\n\n')
        if header_end == -1:
            changelog = changelog + entry
        else:
            changelog = changelog[:header_end+2] + entry + changelog[header_end+2:]
        
        self.changelog_path.write_text(changelog)
    
    def generate_version_report(self):
        """Genera reporte de versiones"""
        if not self.versions_path.exists():
            return "No hay versiones registradas"
        
        with open(self.versions_path) as f:
            versions = json.load(f)
        
        report = "üìä Reporte de Versiones de Carruseles\n"
        report += "=" * 50 + "\n\n"
        
        for carousel_id, data in versions.items():
            report += f"**{carousel_id}**: {data['current']}\n"
            report += f"Historial: {len(data['history'])} versiones\n"
            report += "\n"
        
        return report

# Uso
version_manager = CarouselVersionManager()

# Actualizar versi√≥n despu√©s de cambios
new_version = version_manager.bump_version('curso_ia_v1', 'minor')
version_manager.add_changelog_entry(
    'curso_ia_v1',
    new_version,
    [
        'Actualizado headline del slide 1',
        'Mejorado contraste del CTA',
        'Agregados UTMs completos'
    ]
)

print(f"‚úÖ Versi√≥n actualizada a {new_version}")
```

---

---

## üß™ Testing Automatizado de Landing Pages

### Script: Test End-to-End de Conversi√≥n

**Python**: `test_landing_page_conversion.py`
```python
#!/usr/bin/env python3
"""
Testing automatizado de landing pages generadas desde carruseles
- Verifica que formularios funcionen
- Valida tracking de conversiones
- Verifica UTMs correctos
- Test de performance (Lighthouse)
"""
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import requests
import json

class LandingPageTester:
    def __init__(self, base_url='http://localhost:3000'):
        self.base_url = base_url
        self.options = webdriver.ChromeOptions()
        self.options.add_argument('--headless')
        self.driver = webdriver.Chrome(options=self.options)
        self.results = []
    
    def test_utm_capture(self, landing_url):
        """Verifica que UTMs se capturen correctamente"""
        # Navegar con UTMs
        utm_url = f"{landing_url}?utm_source=instagram&utm_medium=carrusel&utm_campaign=curso_ia_2025-11&utm_content=slide1_v1"
        self.driver.get(utm_url)
        
        # Verificar campos hidden tienen valores
        utm_source = self.driver.find_element(By.ID, 'form_utm_source').get_attribute('value')
        utm_campaign = self.driver.find_element(By.ID, 'form_utm_campaign').get_attribute('value')
        
        assert utm_source == 'instagram', f"utm_source incorrecto: {utm_source}"
        assert utm_campaign == 'curso_ia_2025-11', f"utm_campaign incorrecto: {utm_campaign}"
        
        return {'status': 'pass', 'utms_captured': True}
    
    def test_form_submission(self, landing_url):
        """Verifica que formulario se env√≠e correctamente"""
        self.driver.get(landing_url)
        
        # Llenar formulario
        email_input = WebDriverWait(self.driver, 10).until(
            EC.presence_of_element_located((By.NAME, 'email'))
        )
        email_input.send_keys('test@example.com')
        
        name_input = self.driver.find_element(By.NAME, 'name')
        name_input.send_keys('Test User')
        
        # Submit
        submit_btn = self.driver.find_element(By.CSS_SELECTOR, 'button[type="submit"]')
        submit_btn.click()
        
        # Verificar √©xito (ajustar seg√∫n tu implementaci√≥n)
        success_message = WebDriverWait(self.driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'success-message'))
        )
        
        assert 'gracias' in success_message.text.lower()
        
        return {'status': 'pass', 'form_submitted': True}
    
    def test_conversion_tracking(self, landing_url):
        """Verifica que eventos de conversi√≥n se disparen"""
        self.driver.get(landing_url)
        
        # Verificar que gtag est√° cargado
        gtag_loaded = self.driver.execute_script('return typeof gtag !== "undefined"')
        assert gtag_loaded, "GA4 (gtag) no est√° cargado"
        
        # Verificar que fbq est√° cargado (Meta Pixel)
        fbq_loaded = self.driver.execute_script('return typeof fbq !== "undefined"')
        assert fbq_loaded, "Meta Pixel (fbq) no est√° cargado"
        
        return {'status': 'pass', 'tracking_loaded': True}
    
    def test_page_performance(self, landing_url):
        """Ejecuta Lighthouse para medir performance"""
        import subprocess
        
        result = subprocess.run(
            ['lighthouse', landing_url, '--output=json', '--quiet'],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            report = json.loads(result.stdout)
            scores = report['categories']
            
            performance_score = scores.get('performance', {}).get('score', 0) * 100
            accessibility_score = scores.get('accessibility', {}).get('score', 0) * 100
            best_practices_score = scores.get('best-practices', {}).get('score', 0) * 100
            seo_score = scores.get('seo', {}).get('score', 0) * 100
            
            return {
                'status': 'pass' if performance_score >= 80 else 'warning',
                'performance': round(performance_score, 1),
                'accessibility': round(accessibility_score, 1),
                'best_practices': round(best_practices_score, 1),
                'seo': round(seo_score, 1)
            }
        
        return {'status': 'error', 'message': 'Lighthouse failed'}
    
    def run_full_test_suite(self, landing_url):
        """Ejecuta todos los tests"""
        results = {
            'url': landing_url,
            'tests': {}
        }
        
        # Test UTMs
        try:
            results['tests']['utm_capture'] = self.test_utm_capture(landing_url)
        except Exception as e:
            results['tests']['utm_capture'] = {'status': 'fail', 'error': str(e)}
        
        # Test formulario
        try:
            results['tests']['form_submission'] = self.test_form_submission(landing_url)
        except Exception as e:
            results['tests']['form_submission'] = {'status': 'fail', 'error': str(e)}
        
        # Test tracking
        try:
            results['tests']['conversion_tracking'] = self.test_conversion_tracking(landing_url)
        except Exception as e:
            results['tests']['conversion_tracking'] = {'status': 'fail', 'error': str(e)}
        
        # Test performance
        try:
            results['tests']['performance'] = self.test_page_performance(landing_url)
        except Exception as e:
            results['tests']['performance'] = {'status': 'error', 'error': str(e)}
        
        # Resumen
        passed = sum(1 for t in results['tests'].values() if t.get('status') == 'pass')
        total = len(results['tests'])
        results['summary'] = {
            'passed': passed,
            'total': total,
            'pass_rate': round((passed / total) * 100, 1) if total > 0 else 0
        }
        
        return results
    
    def close(self):
        self.driver.quit()

# Uso
tester = LandingPageTester()
results = tester.run_full_test_suite('https://tusitio.com/curso-ia')
print(json.dumps(results, indent=2))
tester.close()
```

---

## üéØ Optimizaci√≥n de Conversi√≥n Avanzada (CRO)

### Script: Heatmap y Scroll Depth Analysis

**Python**: `cro_optimization.py`
```python
#!/usr/bin/env python3
"""
Optimizaci√≥n de conversi√≥n avanzada para landing pages
- An√°lisis de heatmaps (Hotjar/Clarity)
- Scroll depth tracking
- Click tracking
- Funnel analysis
"""
import requests
import json
from datetime import datetime, timedelta

class CROOptimizer:
    def __init__(self, hotjar_site_id=None, clarity_project_id=None):
        self.hotjar_site_id = hotjar_site_id
        self.clarity_project_id = clarity_project_id
    
    def analyze_scroll_depth(self, carousel_id):
        """Analiza profundidad de scroll por carrusel"""
        # Integraci√≥n con GA4 para scroll depth
        # O con Hotjar API
        
        scroll_data = {
            '0-25%': 0,
            '25-50%': 0,
            '50-75%': 0,
            '75-100%': 0
        }
        
        # Query a GA4 o Hotjar
        # Por ahora, estructura de ejemplo
        return {
            'carousel_id': carousel_id,
            'scroll_distribution': scroll_data,
            'average_scroll_depth': 65.5,
            'recommendations': self.generate_scroll_recommendations(scroll_data)
        }
    
    def analyze_click_heatmap(self, carousel_id):
        """Analiza clicks en landing page"""
        # Integraci√≥n con Hotjar Heatmaps API
        click_data = {
            'cta_button': {'clicks': 450, 'position': 'bottom'},
            'form_fields': {
                'email': {'clicks': 380, 'abandonment_rate': 15},
                'name': {'clicks': 320, 'abandonment_rate': 18}
            },
            'external_links': {'clicks': 120}
        }
        
        return {
            'carousel_id': carousel_id,
            'click_distribution': click_data,
            'recommendations': self.generate_click_recommendations(click_data)
        }
    
    def analyze_funnel_dropoff(self, carousel_id):
        """Analiza drop-off en funnel de conversi√≥n"""
        funnel_steps = [
            {'step': 'Carousel View', 'users': 10000, 'dropoff': 0},
            {'step': 'Landing View', 'users': 2800, 'dropoff': 72},
            {'step': 'Form Started', 'users': 850, 'dropoff': 70},
            {'step': 'Form Completed', 'users': 420, 'dropoff': 51}
        ]
        
        # Identificar steps cr√≠ticos
        critical_dropoffs = [
            step for step in funnel_steps 
            if step['dropoff'] > 50
        ]
        
        return {
            'carousel_id': carousel_id,
            'funnel_steps': funnel_steps,
            'overall_conversion_rate': 4.2,
            'critical_dropoffs': critical_dropoffs,
            'recommendations': self.generate_funnel_recommendations(funnel_steps)
        }
    
    def generate_optimization_plan(self, carousel_id):
        """Genera plan de optimizaci√≥n completo"""
        scroll_data = self.analyze_scroll_depth(carousel_id)
        click_data = self.analyze_click_heatmap(carousel_id)
        funnel_data = self.analyze_funnel_dropoff(carousel_id)
        
        plan = {
            'carousel_id': carousel_id,
            'generated_at': datetime.now().isoformat(),
            'findings': {
                'scroll_depth': scroll_data,
                'click_patterns': click_data,
                'funnel_analysis': funnel_data
            },
            'recommendations': {
                'high_priority': [],
                'medium_priority': [],
                'low_priority': []
            }
        }
        
        # Priorizar recomendaciones
        if scroll_data['average_scroll_depth'] < 50:
            plan['recommendations']['high_priority'].append({
                'action': 'Mover CTA m√°s arriba (above fold)',
                'reason': 'Usuarios no llegan al CTA inferior',
                'expected_impact': '+15-25% conversi√≥n'
            })
        
        if funnel_data['overall_conversion_rate'] < 5:
            plan['recommendations']['high_priority'].append({
                'action': 'Simplificar formulario (m√°ximo 2 campos)',
                'reason': f"Drop-off alto en form ({funnel_data['critical_dropoffs'][-1]['dropoff']}%)",
                'expected_impact': '+20-30% conversi√≥n'
            })
        
        return plan
    
    def generate_scroll_recommendations(self, scroll_data):
        """Genera recomendaciones basadas en scroll depth"""
        recommendations = []
        
        if scroll_data['75-100%'] < scroll_data['0-25%'] * 0.3:
            recommendations.append({
                'issue': 'Baja profundidad de scroll',
                'action': 'Mover contenido clave m√°s arriba',
                'priority': 'high'
            })
        
        return recommendations
    
    def generate_click_recommendations(self, click_data):
        """Genera recomendaciones basadas en heatmap"""
        recommendations = []
        
        cta_clicks = click_data['cta_button']['clicks']
        form_clicks = click_data['form_fields']['email']['clicks']
        
        if cta_clicks < form_clicks * 1.5:
            recommendations.append({
                'issue': 'Bajo CTR en CTA',
                'action': 'Mejorar visibilidad y copy del CTA',
                'priority': 'high'
            })
        
        return recommendations
    
    def generate_funnel_recommendations(self, funnel_steps):
        """Genera recomendaciones basadas en funnel"""
        recommendations = []
        
        for i, step in enumerate(funnel_steps[:-1]):
            if step['dropoff'] > 60:
                recommendations.append({
                    'issue': f"Alto drop-off en {step['step']} ({step['dropoff']}%)",
                    'action': f"Optimizar paso {i+1} ‚Üí {i+2}",
                    'priority': 'high'
                })
        
        return recommendations

# Uso
optimizer = CROOptimizer()
plan = optimizer.generate_optimization_plan('curso_ia_v1')
print(json.dumps(plan, indent=2))
```

---

## ü§ñ Personalizaci√≥n Din√°mica Basada en Audiencia

### Script: Dynamic Content Personalization

**Python**: `dynamic_personalization.py`
```python
#!/usr/bin/env python3
"""
Personalizaci√≥n din√°mica de carruseles basada en audiencia
- Segmentaci√≥n autom√°tica
- A/B testing inteligente
- Recomendaciones de contenido
"""
import json
from datetime import datetime

class DynamicCarouselPersonalizer:
    def __init__(self):
        self.audience_segments = {
            'pm': {
                'name': 'Project Managers',
                'interests': ['productivity', 'automation', 'workflow'],
                'preferred_angle': 'efficiency',
                'cta_style': 'direct'
            },
            'cmo': {
                'name': 'CMOs / Marketing Directors',
                'interests': ['roi', 'metrics', 'growth'],
                'preferred_angle': 'metrics',
                'cta_style': 'data_driven'
            },
            'founder': {
                'name': 'Founders / Entrepreneurs',
                'interests': ['scaling', 'growth', 'efficiency'],
                'preferred_angle': 'scalability',
                'cta_style': 'urgency'
            }
        }
    
    def detect_audience_segment(self, user_data):
        """Detecta segmento de audiencia del usuario"""
        # Basado en: rol, industria, comportamiento, UTM term
        utm_term = user_data.get('utm_term', '')
        role = user_data.get('role', '').lower()
        industry = user_data.get('industry', '').lower()
        
        # Detectar segmento
        if 'pm' in utm_term or 'project' in role:
            return 'pm'
        elif 'cmo' in utm_term or 'marketing' in role or 'director' in role:
            return 'cmo'
        elif 'founder' in utm_term or 'ceo' in role or 'entrepreneur' in role:
            return 'founder'
        
        return 'default'
    
    def personalize_carousel(self, carousel_base, user_data):
        """Personaliza carrusel seg√∫n audiencia"""
        segment = self.detect_audience_segment(user_data)
        segment_config = self.audience_segments.get(segment, self.audience_segments['default'])
        
        personalized = {
            'base_carousel': carousel_base,
            'segment': segment,
            'personalizations': {}
        }
        
        # Personalizar slide 1 (headline)
        if segment_config['preferred_angle'] == 'efficiency':
            personalized['personalizations']['slide_1'] = {
                'headline': f"IA que ahorra {user_data.get('hours_saved', '15')} horas semanales",
                'subcopy': 'Automatiza workflows sin c√≥digo'
            }
        elif segment_config['preferred_angle'] == 'metrics':
            personalized['personalizations']['slide_1'] = {
                'headline': '+27% ROI en promedio con IA',
                'subcopy': 'M√©tricas reales de empresas como la tuya'
            }
        
        # Personalizar CTA
        if segment_config['cta_style'] == 'direct':
            personalized['personalizations']['slide_3'] = {
                'cta': 'Ver Demo en 5 Min',
                'subtext': 'Sin compromiso'
            }
        elif segment_config['cta_style'] == 'data_driven':
            personalized['personalizations']['slide_3'] = {
                'cta': 'Descargar Caso de Estudio',
                'subtext': 'ROI real con datos'
            }
        
        return personalized
    
    def generate_personalized_variants(self, carousel_id, segments=None):
        """Genera variantes personalizadas para cada segmento"""
        if segments is None:
            segments = list(self.audience_segments.keys())
        
        variants = {}
        
        for segment in segments:
            config = self.audience_segments[segment]
            
            # Generar variante espec√≠fica del segmento
            variant = {
                'segment': segment,
                'variant_name': f"{carousel_id}_{segment}",
                'headline_style': config['preferred_angle'],
                'cta_style': config['cta_style'],
                'visual_style': 'professional' if segment == 'cmo' else 'modern'
            }
            
            variants[segment] = variant
        
        return variants

# Uso
personalizer = DynamicCarouselPersonalizer()

user_data = {
    'utm_term': 'cmo_mx',
    'role': 'Marketing Director',
    'industry': 'SaaS'
}

personalized = personalizer.personalize_carousel('curso_ia_base', user_data)
print(json.dumps(personalized, indent=2))
```

---

## üìä Machine Learning para Optimizaci√≥n

### Script: ML-Powered Optimization

**Python**: `ml_optimization.py`
```python
#!/usr/bin/env python3
"""
Optimizaci√≥n basada en Machine Learning
- Predicci√≥n de mejor variante
- Recomendaciones autom√°ticas
- Optimizaci√≥n continua
"""
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import pandas as pd
import json

class MLCarouselOptimizer:
    def __init__(self):
        self.model = None
        self.feature_importance = {}
    
    def prepare_training_data(self, historical_data):
        """Prepara datos hist√≥ricos para entrenamiento"""
        # Features: headline_type, cta_type, visual_style, platform, time_of_day
        # Target: conversion (1 o 0)
        
        features = []
        targets = []
        
        for record in historical_data:
            features.append([
                record['headline_type'],  # 0=direct, 1=metrics, 2=urgency
                record['cta_type'],        # 0=action, 1=value, 2=urgency
                record['visual_style'],    # 0=minimal, 1=detailed, 2=illustrated
                record['platform'],        # 0=instagram, 1=linkedin, 2=facebook
                record['hour_of_day'],     # 0-23
                record['day_of_week']     # 0-6
            ])
            targets.append(1 if record['converted'] else 0)
        
        return np.array(features), np.array(targets)
    
    def train_model(self, historical_data):
        """Entrena modelo de ML"""
        X, y = self.prepare_training_data(historical_data)
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.model.fit(X_train, y_train)
        
        # Calcular importancia de features
        feature_names = ['headline_type', 'cta_type', 'visual_style', 'platform', 'hour', 'day']
        self.feature_importance = dict(zip(
            feature_names,
            self.model.feature_importances_
        ))
        
        # Score
        score = self.model.score(X_test, y_test)
        
        return {
            'model_trained': True,
            'accuracy': round(score, 3),
            'feature_importance': self.feature_importance
        }
    
    def predict_best_variant(self, context):
        """Predice mejor variante para contexto dado"""
        if self.model is None:
            return {'error': 'Modelo no entrenado'}
        
        # Preparar features del contexto
        features = np.array([[
            context.get('headline_type', 0),
            context.get('cta_type', 0),
            context.get('visual_style', 0),
            context.get('platform', 0),
            context.get('hour_of_day', 12),
            context.get('day_of_week', 2)
        ]])
        
        # Predicci√≥n
        prediction = self.model.predict_proba(features)[0]
        
        # Probar diferentes combinaciones
        variants = []
        for headline in [0, 1, 2]:
            for cta in [0, 1, 2]:
                for visual in [0, 1, 2]:
                    test_features = np.array([[
                        headline, cta, visual,
                        context['platform'],
                        context['hour_of_day'],
                        context['day_of_week']
                    ]])
                    prob = self.model.predict_proba(test_features)[0][1]
                    variants.append({
                        'headline_type': headline,
                        'cta_type': cta,
                        'visual_style': visual,
                        'conversion_probability': round(prob, 3)
                    })
        
        # Mejor variante
        best = max(variants, key=lambda x: x['conversion_probability'])
        
        return {
            'recommended_variant': best,
            'predicted_conversion_rate': round(best['conversion_probability'] * 100, 1),
            'top_3_variants': sorted(variants, key=lambda x: x['conversion_probability'], reverse=True)[:3]
        }
    
    def optimize_continuously(self, current_performance, context):
        """Optimizaci√≥n continua basada en feedback"""
        if self.model is None:
            return {'error': 'Modelo no entrenado'}
        
        # Analizar performance actual
        current_ctr = current_performance.get('ctr', 0)
        current_conversion = current_performance.get('conversion_rate', 0)
        
        # Predicci√≥n para variantes alternativas
        recommendations = self.predict_best_variant(context)
        
        # Comparar con actual
        improvement_potential = (
            recommendations['predicted_conversion_rate'] - current_conversion
        )
        
        if improvement_potential > 5:  # Si mejora potencial > 5%
            return {
                'should_update': True,
                'current_performance': current_conversion,
                'predicted_improvement': round(improvement_potential, 1),
                'recommended_variant': recommendations['recommended_variant'],
                'confidence': 'high' if improvement_potential > 10 else 'medium'
            }
        
        return {
            'should_update': False,
            'reason': 'Performance actual es √≥ptima o mejora potencial < 5%'
        }

# Ejemplo de uso
optimizer = MLCarouselOptimizer()

# Datos hist√≥ricos (ejemplo)
historical_data = [
    {'headline_type': 0, 'cta_type': 0, 'visual_style': 0, 'platform': 0, 'hour_of_day': 8, 'day_of_week': 1, 'converted': True},
    {'headline_type': 1, 'cta_type': 0, 'visual_style': 1, 'platform': 1, 'hour_of_day': 12, 'day_of_week': 2, 'converted': True},
    {'headline_type': 2, 'cta_type': 1, 'visual_style': 2, 'platform': 0, 'hour_of_day': 18, 'day_of_week': 3, 'converted': False},
    # ... m√°s datos
]

# Entrenar
training_result = optimizer.train_model(historical_data)
print("Modelo entrenado:", training_result)

# Predecir mejor variante
context = {
    'platform': 0,  # Instagram
    'hour_of_day': 12,
    'day_of_week': 2
}

prediction = optimizer.predict_best_variant(context)
print("Mejor variante predicha:", prediction)
```

---

## üöÄ Integraci√≥n con Analytics Avanzados

### Script: Multi-Source Analytics Aggregation

**Python**: `advanced_analytics.py`
```python
#!/usr/bin/env python3
"""
Agrega datos de m√∫ltiples fuentes de analytics
- Google Analytics 4
- Meta Business Suite
- HubSpot Analytics
- Custom events
"""
import requests
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import RunReportRequest, DateRange
import json

class AdvancedAnalyticsAggregator:
    def __init__(self, ga4_property_id, meta_access_token, hubspot_api_key):
        self.ga4_client = BetaAnalyticsDataClient()
        self.ga4_property = ga4_property_id
        self.meta_token = meta_access_token
        self.hubspot_key = hubspot_api_key
    
    def get_ga4_carousel_metrics(self, carousel_id, date_range):
        """Obtiene m√©tricas de GA4 para carrusel espec√≠fico"""
        request = RunReportRequest(
            property=f"properties/{self.ga4_property}",
            date_ranges=[DateRange(start_date=date_range['start'], end_date=date_range['end'])],
            dimensions=[{'name': 'utm_content'}, {'name': 'utm_campaign'}],
            metrics=[
                {'name': 'sessions'},
                {'name': 'conversions'},
                {'name': 'eventCount'},
                {'name': 'totalUsers'}
            ],
            dimension_filter={
                'filter': {
                    'field_name': 'utm_campaign',
                    'string_filter': {
                        'match_type': 'CONTAINS',
                        'value': carousel_id
                    }
                }
            }
        )
        
        response = self.ga4_client.run_report(request)
        
        metrics = {}
        for row in response.rows:
            content = row.dimension_values[0].value
            campaign = row.dimension_values[1].value
            
            metrics[content] = {
                'sessions': int(row.metric_values[0].value),
                'conversions': int(row.metric_values[1].value),
                'events': int(row.metric_values[2].value),
                'users': int(row.metric_values[3].value)
            }
        
        return metrics
    
    def get_meta_carousel_metrics(self, carousel_id, date_range):
        """Obtiene m√©tricas de Meta Ads"""
        url = f"https://graph.facebook.com/v18.0/{carousel_id}/insights"
        params = {
            'access_token': self.meta_token,
            'fields': 'impressions,clicks,ctr,spend,conversions,conversion_rate',
            'time_range': json.dumps({
                'since': date_range['start'],
                'until': date_range['end']
            })
        }
        
        response = requests.get(url, params=params)
        return response.json()
    
    def get_hubspot_lead_metrics(self, carousel_id, date_range):
        """Obtiene m√©tricas de leads desde HubSpot"""
        url = 'https://api.hubapi.com/crm/v3/objects/contacts/search'
        headers = {
            'Authorization': f'Bearer {self.hubspot_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'filterGroups': [{
                'filters': [{
                    'propertyName': 'utm_campaign',
                    'operator': 'CONTAINS',
                    'value': carousel_id
                }]
            }],
            'properties': ['email', 'firstname', 'utm_campaign', 'utm_content', 'createdate']
        }
        
        response = requests.post(url, headers=headers, json=payload)
        contacts = response.json().get('results', [])
        
        return {
            'total_leads': len(contacts),
            'by_content': self.group_by_content(contacts)
        }
    
    def aggregate_all_metrics(self, carousel_id, date_range):
        """Agrega m√©tricas de todas las fuentes"""
        ga4 = self.get_ga4_carousel_metrics(carousel_id, date_range)
        meta = self.get_meta_carousel_metrics(carousel_id, date_range)
        hubspot = self.get_hubspot_lead_metrics(carousel_id, date_range)
        
        return {
            'carousel_id': carousel_id,
            'date_range': date_range,
            'ga4': ga4,
            'meta': meta,
            'hubspot': hubspot,
            'aggregated': self.calculate_aggregated_metrics(ga4, meta, hubspot)
        }
    
    def calculate_aggregated_metrics(self, ga4, meta, hubspot):
        """Calcula m√©tricas agregadas"""
        total_impressions = meta.get('impressions', 0)
        total_clicks = meta.get('clicks', 0)
        total_conversions = hubspot.get('total_leads', 0)
        
        return {
            'impressions': total_impressions,
            'clicks': total_clicks,
            'ctr': round((total_clicks / total_impressions * 100) if total_impressions > 0 else 0, 2),
            'conversions': total_conversions,
            'conversion_rate': round((total_conversions / total_clicks * 100) if total_clicks > 0 else 0, 2),
            'cpa': round(meta.get('spend', 0) / total_conversions if total_conversions > 0 else 0, 2)
        }
    
    def group_by_content(self, contacts):
        """Agrupa contactos por utm_content"""
        grouped = {}
        for contact in contacts:
            content = contact.get('properties', {}).get('utm_content', 'unknown')
            if content not in grouped:
                grouped[content] = 0
            grouped[content] += 1
        return grouped

# Uso
aggregator = AdvancedAnalyticsAggregator(
    ga4_property_id='123456789',
    meta_access_token='your_token',
    hubspot_api_key='your_key'
)

metrics = aggregator.aggregate_all_metrics(
    'curso_ia_2025-11',
    {'start': '2025-11-01', 'end': '2025-11-30'}
)

print(json.dumps(metrics, indent=2))
```

---

---

## üîÑ Batch Processing y Optimizaci√≥n Masiva

### Script: Procesamiento Masivo de Carruseles

**Python**: `batch_process_carousels.py`
```python
#!/usr/bin/env python3
"""
Procesa m√∫ltiples carruseles en batch
- Generaci√≥n masiva de variantes
- Optimizaci√≥n paralela
- Export en m√∫ltiples formatos simult√°neamente
"""
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
from pathlib import Path
import json

class BatchCarouselProcessor:
    def __init__(self, max_workers=None):
        self.max_workers = max_workers or mp.cpu_count()
        self.results = []
    
    def process_single_carousel(self, carousel_config):
        """Procesa un carrusel completo"""
        carousel_id = carousel_config['id']
        variants = carousel_config.get('variants', ['metrics', 'social_proof', 'urgency'])
        formats = carousel_config.get('formats', ['square', 'stories'])
        
        results = {
            'carousel_id': carousel_id,
            'processed': [],
            'errors': []
        }
        
        for variant in variants:
            for fmt in formats:
                try:
                    # Generar variante
                    output_path = self.generate_variant(
                        carousel_id, variant, fmt
                    )
                    results['processed'].append(output_path)
                except Exception as e:
                    results['errors'].append({
                        'variant': variant,
                        'format': fmt,
                        'error': str(e)
                    })
        
        return results
    
    def process_all_carousels(self, carousel_configs):
        """Procesa todos los carruseles en paralelo"""
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(self.process_single_carousel, config): config
                for config in carousel_configs
            }
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                    self.results.append(result)
                    print(f"‚úÖ Procesado: {result['carousel_id']}")
                except Exception as e:
                    config = futures[future]
                    print(f"‚ùå Error procesando {config['id']}: {e}")
        
        return self.generate_summary()
    
    def generate_summary(self):
        """Genera resumen del procesamiento batch"""
        total_processed = sum(len(r['processed']) for r in self.results)
        total_errors = sum(len(r['errors']) for r in self.results)
        
        return {
            'total_carousels': len(self.results),
            'total_processed': total_processed,
            'total_errors': total_errors,
            'success_rate': round((total_processed / (total_processed + total_errors)) * 100, 1) if (total_processed + total_errors) > 0 else 0,
            'details': self.results
        }

# Uso
processor = BatchCarouselProcessor(max_workers=8)

carousel_configs = [
    {'id': 'curso_ia_v1', 'variants': ['metrics', 'social_proof'], 'formats': ['square', 'stories']},
    {'id': 'saas_marketing_v1', 'variants': ['urgency', 'elegant'], 'formats': ['square']},
    {'id': 'ia_bulk_v1', 'variants': ['benefits', 'numbers'], 'formats': ['square', 'stories']}
]

summary = processor.process_all_carousels(carousel_configs)
print(json.dumps(summary, indent=2))
```

---

## üöÄ Optimizaci√≥n de Performance en Tiempo Real

### Script: Real-Time Performance Monitor

**Python**: `realtime_performance_monitor.py`
```python
#!/usr/bin/env python3
"""
Monitor de performance en tiempo real para carruseles activos
- Tracking continuo de m√©tricas
- Alertas autom√°ticas
- Auto-pausar carruseles con bajo rendimiento
"""
import time
import json
import requests
from datetime import datetime
from collections import deque

class RealTimeCarouselMonitor:
    def __init__(self, check_interval=300):  # 5 minutos
        self.check_interval = check_interval
        self.metrics_history = {}
        self.alerts = []
    
    def fetch_realtime_metrics(self, carousel_id):
        """Obtiene m√©tricas en tiempo real desde Meta/GA4"""
        # Meta Ads API (√∫ltimas 1 hora)
        meta_url = f"https://graph.facebook.com/v18.0/{carousel_id}/insights"
        params = {
            'access_token': os.environ['META_TOKEN'],
            'fields': 'impressions,clicks,ctr,spend',
            'time_range': {
                'since': int(time.time() - 3600),  # √öltima hora
                'until': int(time.time())
            }
        }
        
        response = requests.get(meta_url, params=params)
        data = response.json()
        
        return {
            'impressions': data.get('impressions', 0),
            'clicks': data.get('clicks', 0),
            'ctr': data.get('ctr', 0),
            'spend': data.get('spend', 0),
            'timestamp': datetime.now().isoformat()
        }
    
    def analyze_performance_trend(self, carousel_id):
        """Analiza tendencia de performance"""
        if carousel_id not in self.metrics_history:
            self.metrics_history[carousel_id] = deque(maxlen=12)  # √öltimas 12 mediciones (1 hora)
        
        current_metrics = self.fetch_realtime_metrics(carousel_id)
        self.metrics_history[carousel_id].append(current_metrics)
        
        # Calcular tendencia
        if len(self.metrics_history[carousel_id]) >= 3:
            recent_ctr = [m['ctr'] for m in list(self.metrics_history[carousel_id])[-3:]]
            trend = 'increasing' if recent_ctr[-1] > recent_ctr[0] else 'decreasing'
            
            return {
                'current_ctr': current_metrics['ctr'],
                'average_ctr': sum(m['ctr'] for m in self.metrics_history[carousel_id]) / len(self.metrics_history[carousel_id]),
                'trend': trend,
                'recommendation': self.generate_recommendation(current_metrics, trend)
            }
        
        return {'status': 'insufficient_data'}
    
    def auto_pause_low_performance(self, carousel_id, threshold_ctr=0.5):
        """Pausa autom√°ticamente carruseles con bajo CTR"""
        metrics = self.fetch_realtime_metrics(carousel_id)
        
        if metrics['ctr'] < threshold_ctr and metrics['impressions'] > 1000:
            # Pausar en Meta Ads
            pause_url = f"https://graph.facebook.com/v18.0/{carousel_id}"
            requests.post(pause_url, params={
                'access_token': os.environ['META_TOKEN'],
                'status': 'PAUSED'
            })
            
            return {
                'action': 'paused',
                'reason': f"CTR {metrics['ctr']}% bajo threshold {threshold_ctr}%",
                'impressions': metrics['impressions']
            }
        
        return {'action': 'none', 'reason': 'Performance within threshold'}
    
    def monitor_continuously(self, carousel_ids, duration_hours=24):
        """Monitorea carruseles continuamente"""
        end_time = time.time() + (duration_hours * 3600)
        
        while time.time() < end_time:
            for carousel_id in carousel_ids:
                try:
                    # Analizar tendencia
                    trend = self.analyze_performance_trend(carousel_id)
                    
                    # Auto-pausar si necesario
                    pause_result = self.auto_pause_low_performance(carousel_id)
                    
                    if pause_result['action'] == 'paused':
                        self.alerts.append({
                            'carousel_id': carousel_id,
                            'action': 'auto_paused',
                            'timestamp': datetime.now().isoformat(),
                            'details': pause_result
                        })
                        print(f"‚ö†Ô∏è  Carrusel {carousel_id} pausado autom√°ticamente")
                    
                except Exception as e:
                    print(f"Error monitoreando {carousel_id}: {e}")
            
            time.sleep(self.check_interval)
        
        return {
            'monitoring_duration_hours': duration_hours,
            'alerts_generated': len(self.alerts),
            'alerts': self.alerts
        }
    
    def generate_recommendation(self, metrics, trend):
        """Genera recomendaciones basadas en m√©tricas"""
        if metrics['ctr'] < 1.0:
            return {
                'priority': 'high',
                'action': 'Pausar y optimizar headline/visual',
                'reason': 'CTR muy bajo'
            }
        elif trend == 'decreasing':
            return {
                'priority': 'medium',
                'action': 'Monitorear de cerca, considerar refresh',
                'reason': 'Tendencia negativa detectada'
            }
        
        return {'priority': 'low', 'action': 'Continuar monitoreo'}

# Uso
monitor = RealTimeCarouselMonitor(check_interval=300)

carousel_ids = ['carousel_curso_ia_v1', 'carousel_saas_v1']
results = monitor.monitor_continuously(carousel_ids, duration_hours=24)
print(json.dumps(results, indent=2))
```

---

## üîê Seguridad y Compliance Avanzado

### Script: Compliance Checker Automatizado

**Python**: `compliance_checker.py`
```python
#!/usr/bin/env python3
"""
Verifica compliance autom√°ticamente
- GDPR/CCPA compliance
- Validaci√≥n de disclaimers
- Verificaci√≥n de permisos
- Auditor√≠a de datos
"""
import re
import json
from pathlib import Path

class CarouselComplianceChecker:
    def __init__(self):
        self.issues = []
        self.warnings = []
    
    def check_gdpr_compliance(self, landing_page_content):
        """Verifica compliance GDPR"""
        checks = {
            'privacy_policy_link': False,
            'consent_checkbox': False,
            'opt_out_option': False,
            'data_retention_info': False
        }
        
        # Verificar privacy policy link
        if 'privacy' in landing_page_content.lower() or 'privacidad' in landing_page_content.lower():
            checks['privacy_policy_link'] = True
        else:
            self.issues.append({
                'type': 'gdpr',
                'severity': 'high',
                'issue': 'Falta link a pol√≠tica de privacidad',
                'action': 'Agregar link visible en footer y formularios'
            })
        
        # Verificar checkbox de consentimiento
        if 'checkbox' in landing_page_content.lower() and ('consent' in landing_page_content.lower() or 'acepto' in landing_page_content.lower()):
            checks['consent_checkbox'] = True
        else:
            self.issues.append({
                'type': 'gdpr',
                'severity': 'high',
                'issue': 'Falta checkbox de consentimiento expl√≠cito',
                'action': 'Agregar checkbox requerido antes de submit'
            })
        
        return checks
    
    def check_metric_disclaimers(self, carousel_content):
        """Verifica que m√©tricas tengan disclaimers"""
        # Buscar n√∫meros con % o "x"
        metric_pattern = r'(\d+(?:\.\d+)?\s*%|\d+\s*x|\+\d+%|-\d+%)'
        metrics = re.findall(metric_pattern, carousel_content)
        
        # Verificar presencia de asterisco o disclaimer
        has_disclaimer = (
            '*' in carousel_content or
            'disclaimer' in carousel_content.lower() or
            'pueden variar' in carousel_content.lower() or
            'results may vary' in carousel_content.lower()
        )
        
        if metrics and not has_disclaimer:
            self.issues.append({
                'type': 'disclaimer',
                'severity': 'high',
                'issue': f"M√©tricas encontradas sin disclaimer: {metrics}",
                'action': "Agregar '*Resultados pueden variar seg√∫n caso'"
            })
        
        return {
            'metrics_found': len(metrics),
            'has_disclaimer': has_disclaimer,
            'metrics': metrics
        }
    
    def check_image_permissions(self, svg_files):
        """Verifica permisos de uso de im√°genes"""
        issues = []
        
        for svg_file in svg_files:
            content = Path(svg_file).read_text()
            
            # Buscar referencias a im√°genes externas
            external_images = re.findall(r'<image[^>]*href="(http[^"]+)"', content)
            
            for img_url in external_images:
                # Verificar si es stock image con licencia
                if 'unsplash.com' in img_url or 'pexels.com' in img_url:
                    # Verificar atribuci√≥n
                    if 'attribution' not in content.lower() and 'photo by' not in content.lower():
                        issues.append({
                            'file': svg_file,
                            'issue': f"Imagen de stock sin atribuci√≥n: {img_url}",
                            'action': 'Agregar atribuci√≥n seg√∫n licencia'
                        })
                elif 'placeholder' not in img_url.lower():
                    issues.append({
                        'file': svg_file,
                        'issue': f"Imagen externa sin verificar licencia: {img_url}",
                        'action': 'Verificar permisos de uso comercial'
                    })
        
        self.issues.extend(issues)
        return issues
    
    def check_testimonial_permissions(self, testimonials):
        """Verifica permisos de uso de testimonios"""
        required_fields = ['name', 'quote', 'permission_date', 'permission_type']
        
        issues = []
        for testimonial in testimonials:
            missing = [field for field in required_fields if field not in testimonial]
            if missing:
                issues.append({
                    'testimonial': testimonial.get('name', 'Unknown'),
                    'missing_fields': missing,
                    'action': 'Completar informaci√≥n de permiso'
                })
        
        self.issues.extend(issues)
        return issues
    
    def generate_compliance_report(self, carousel_id):
        """Genera reporte completo de compliance"""
        report = {
            'carousel_id': carousel_id,
            'timestamp': datetime.now().isoformat(),
            'checks': {
                'gdpr': {},
                'disclaimers': {},
                'permissions': {}
            },
            'compliance_status': 'pending',
            'issues': self.issues,
            'warnings': self.warnings
        }
        
        # Determinar status
        high_severity_issues = [i for i in self.issues if i.get('severity') == 'high']
        
        if len(high_severity_issues) == 0:
            report['compliance_status'] = 'compliant'
        elif len(high_severity_issues) <= 2:
            report['compliance_status'] = 'needs_attention'
        else:
            report['compliance_status'] = 'non_compliant'
        
        return report

# Uso
checker = CarouselComplianceChecker()

# Verificar landing page
landing_content = Path('landing_curso_ia.html').read_text()
gdpr_check = checker.check_gdpr_compliance(landing_content)

# Verificar carrusel
carousel_content = Path('carrusel-curso-ia-s1.svg').read_text()
disclaimer_check = checker.check_metric_disclaimers(carousel_content)

# Verificar im√°genes
svg_files = list(Path('source/').glob('*.svg'))
image_check = checker.check_image_permissions(svg_files)

report = checker.generate_compliance_report('curso_ia_v1')
print(json.dumps(report, indent=2))
```

---

## üé® Generaci√≥n Autom√°tica de Variantes con IA

### Script: AI-Powered Variant Generation

**Python**: `ai_variant_generator.py`
```python
#!/usr/bin/env python3
"""
Genera variantes de carruseles usando IA
- GPT-4 para generar copy variations
- DALL-E para generar visuales alternativos
- Optimizaci√≥n autom√°tica basada en audiencia
"""
import openai
import json
from pathlib import Path

class AICarouselVariantGenerator:
    def __init__(self, openai_api_key):
        openai.api_key = openai_api_key
        self.client = openai.OpenAI()
    
    def generate_headline_variations(self, base_headline, count=5):
        """Genera variaciones de headline usando GPT-4"""
        prompt = f"""
        Genera {count} variaciones del siguiente headline para un carrusel de marketing:
        
        Headline original: "{base_headline}"
        
        Requisitos:
        - M√°ximo 10 palabras cada una
        - Mantener el mensaje principal
        - Probar diferentes √°ngulos: directo, m√©tricas, urgencia, beneficio
        - Cada variaci√≥n debe ser √∫nica y poderosa
        
        Formato: Lista JSON simple
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un copywriter experto en marketing digital."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8
        )
        
        # Parsear respuesta (ajustar seg√∫n formato)
        variations = json.loads(response.choices[0].message.content)
        
        return variations
    
    def generate_cta_variations(self, base_cta, style='action'):
        """Genera variaciones de CTA"""
        prompt = f"""
        Genera 5 variaciones del siguiente CTA en estilo {style}:
        
        CTA original: "{base_cta}"
        
        Estilos disponibles:
        - action: Directo y claro ("√önete ahora", "Empieza hoy")
        - value: Enfocado en valor ("Ver demo gratis", "Descargar gu√≠a")
        - urgency: Con urgencia ("Solo hoy", "Cupos limitados")
        - data_driven: Con m√©tricas ("Ver resultados reales", "Descargar caso de estudio")
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un especialista en optimizaci√≥n de conversi√≥n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        variations = json.loads(response.choices[0].message.content)
        return variations
    
    def generate_testimonial_variations(self, base_testimonial):
        """Genera variaciones de testimonio manteniendo autenticidad"""
        prompt = f"""
        Reescribe el siguiente testimonio en 3 variaciones que mantengan el mensaje pero var√≠en el tono:
        
        Testimonio original: "{base_testimonial}"
        
        Requisitos:
        - Mantener el mensaje principal y datos espec√≠ficos
        - Variar estructura pero mantener autenticidad
        - Una versi√≥n corta (1 l√≠nea), una media (2 l√≠neas), una completa
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un editor de contenido especializado en testimonios aut√©nticos."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.6  # M√°s bajo para mantener autenticidad
        )
        
        variations = json.loads(response.choices[0].message.content)
        return variations
    
    def generate_visual_description(self, carousel_config):
        """Genera descripci√≥n para generaci√≥n de visual con DALL-E"""
        prompt = f"""
        Genera un prompt detallado para DALL-E 3 que cree una imagen para este carrusel:
        
        Producto: {carousel_config['product']}
        Headline: {carousel_config['headline']}
        Audiencia: {carousel_config['audience']}
        Estilo: {carousel_config.get('style', 'professional')}
        
        El prompt debe:
        - Ser espec√≠fico y detallado
        - Incluir estilo visual, colores, composici√≥n
        - Ser apropiado para {carousel_config.get('format', '1080x1080')} px
        - Mantener consistencia de marca
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un dise√±ador visual experto en crear prompts para generaci√≥n de im√°genes."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        visual_prompt = response.choices[0].message.content
        
        # Opcional: Generar imagen directamente con DALL-E
        image_response = self.client.images.generate(
            model="dall-e-3",
            prompt=visual_prompt,
            size="1024x1024",
            quality="standard",
            n=1
        )
        
        return {
            'prompt': visual_prompt,
            'image_url': image_response.data[0].url
        }
    
    def generate_complete_variant(self, base_carousel, target_audience):
        """Genera variante completa usando IA"""
        variant = {
            'base_carousel': base_carousel['id'],
            'target_audience': target_audience,
            'generated_at': datetime.now().isoformat()
        }
        
        # Generar headlines
        headline_variations = self.generate_headline_variations(
            base_carousel['slide_1']['headline']
        )
        variant['slide_1'] = {
            'headline_options': headline_variations,
            'recommended_headline': headline_variations[0]  # Primera opci√≥n como recomendada
        }
        
        # Generar CTAs
        cta_variations = self.generate_cta_variations(
            base_carousel['slide_3']['cta'],
            style='action'
        )
        variant['slide_3'] = {
            'cta_options': cta_variations,
            'recommended_cta': cta_variations[0]
        }
        
        # Generar visual
        visual_config = {
            'product': base_carousel['product'],
            'headline': variant['slide_1']['recommended_headline'],
            'audience': target_audience,
            'format': '1080x1080'
        }
        visual = self.generate_visual_description(visual_config)
        variant['visual'] = visual
        
        return variant

# Uso
generator = AICarouselVariantGenerator(openai_api_key=os.environ['OPENAI_API_KEY'])

base_carousel = {
    'id': 'curso_ia_v1',
    'product': 'curso_ia',
    'slide_1': {'headline': 'Domina IA aplicada en semanas'},
    'slide_3': {'cta': '√önete ahora'}
}

variant = generator.generate_complete_variant(base_carousel, 'cmo')
print(json.dumps(variant, indent=2))
```

---

## üì± Integraci√≥n con Plataformas de Programaci√≥n

### Script: Auto-Schedule Multi-Platform

**Python**: `auto_schedule_multiplatform.py`
```python
#!/usr/bin/env python3
"""
Programa autom√°ticamente carruseles en m√∫ltiples plataformas
- Buffer API
- Hootsuite API
- Meta Business Suite
- LinkedIn Creator
"""
import requests
import json
from datetime import datetime, timedelta

class MultiPlatformScheduler:
    def __init__(self):
        self.platforms = {
            'buffer': {
                'api_url': 'https://api.bufferapp.com/v1',
                'access_token': os.environ.get('BUFFER_ACCESS_TOKEN')
            },
            'hootsuite': {
                'api_url': 'https://platform.hootsuite.com/v1',
                'access_token': os.environ.get('HOOTSUITE_ACCESS_TOKEN')
            },
            'meta': {
                'api_url': 'https://graph.facebook.com/v18.0',
                'access_token': os.environ.get('META_ACCESS_TOKEN')
            }
        }
    
    def schedule_to_buffer(self, carousel_data, optimal_times):
        """Programa en Buffer"""
        buffer_url = f"{self.platforms['buffer']['api_url']}/updates/create.json"
        
        scheduled = []
        for time_slot in optimal_times:
            payload = {
                'text': carousel_data['caption'],
                'profile_ids': carousel_data['profile_ids'],  # Instagram, Facebook, etc.
                'scheduled_at': time_slot.isoformat(),
                'media': {
                    'photo': carousel_data['image_urls']  # Array de URLs de slides
                }
            }
            
            response = requests.post(
                buffer_url,
                headers={'Authorization': f"Bearer {self.platforms['buffer']['access_token']}"},
                json=payload
            )
            
            if response.status_code == 200:
                scheduled.append({
                    'platform': 'buffer',
                    'time': time_slot,
                    'status': 'scheduled',
                    'update_id': response.json().get('updates', [{}])[0].get('id')
                })
        
        return scheduled
    
    def schedule_to_hootsuite(self, carousel_data, optimal_times):
        """Programa en Hootsuite"""
        hootsuite_url = f"{self.platforms['hootsuite']['api_url']}/messages"
        
        scheduled = []
        for time_slot in optimal_times:
            payload = {
                'text': carousel_data['caption'],
                'socialProfileIds': carousel_data['profile_ids'],
                'scheduledSendTime': time_slot.isoformat(),
                'mediaUrls': carousel_data['image_urls']
            }
            
            response = requests.post(
                hootsuite_url,
                headers={'Authorization': f"Bearer {self.platforms['hootsuite']['access_token']}"},
                json=payload
            )
            
            if response.status_code == 201:
                scheduled.append({
                    'platform': 'hootsuite',
                    'time': time_slot,
                    'status': 'scheduled',
                    'message_id': response.json().get('id')
                })
        
        return scheduled
    
    def schedule_to_meta(self, carousel_data, optimal_times):
        """Programa en Meta (Instagram/Facebook)"""
        meta_url = f"{self.platforms['meta']['api_url']}/{carousel_data['page_id']}/photos"
        
        scheduled = []
        for time_slot in optimal_times:
            # Meta requiere publicaci√≥n inmediata o usar Creator Studio API
            # Para programaci√≥n real, usar Meta Business API con scheduled_publish_time
            payload = {
                'url': carousel_data['image_urls'][0],  # Primera imagen
                'caption': carousel_data['caption'],
                'published': False,
                'scheduled_publish_time': int(time_slot.timestamp())
            }
            
            response = requests.post(
                meta_url,
                params={'access_token': self.platforms['meta']['access_token']},
                json=payload
            )
            
            if response.status_code == 200:
                scheduled.append({
                    'platform': 'meta',
                    'time': time_slot,
                    'status': 'scheduled',
                    'post_id': response.json().get('id')
                })
        
        return scheduled
    
    def schedule_all_platforms(self, carousel_data, optimal_times):
        """Programa en todas las plataformas"""
        all_scheduled = {
            'buffer': [],
            'hootsuite': [],
            'meta': []
        }
        
        # Buffer
        try:
            all_scheduled['buffer'] = self.schedule_to_buffer(carousel_data, optimal_times)
        except Exception as e:
            print(f"Error en Buffer: {e}")
        
        # Hootsuite
        try:
            all_scheduled['hootsuite'] = self.schedule_to_hootsuite(carousel_data, optimal_times)
        except Exception as e:
            print(f"Error en Hootsuite: {e}")
        
        # Meta
        try:
            all_scheduled['meta'] = self.schedule_to_meta(carousel_data, optimal_times)
        except Exception as e:
            print(f"Error en Meta: {e}")
        
        return {
            'total_scheduled': sum(len(v) for v in all_scheduled.values()),
            'by_platform': all_scheduled
        }

# Uso
scheduler = MultiPlatformScheduler()

carousel_data = {
    'caption': 'Domina IA aplicada en semanas. Clases pr√°cticas + webinars en vivo.',
    'image_urls': [
        'https://cdn.tusitio.com/carrusel-curso-ia-s1.png',
        'https://cdn.tusitio.com/carrusel-curso-ia-s2.png',
        'https://cdn.tusitio.com/carrusel-curso-ia-s3.png'
    ],
    'profile_ids': ['instagram_profile_id', 'facebook_page_id'],
    'page_id': 'your_page_id'
}

# Calcular tiempos √≥ptimos (ejemplo: pr√≥ximos 3 d√≠as, 3 posts/d√≠a)
optimal_times = []
for day in range(3):
    for hour in [8, 12, 18]:
        optimal_times.append(datetime.now() + timedelta(days=day, hours=hour))

result = scheduler.schedule_all_platforms(carousel_data, optimal_times)
print(json.dumps(result, indent=2))
```

---

## üîç An√°lisis Predictivo y Forecasting Avanzado

### Script: Predictive Analytics para Carruseles

**Python**: `predictive_analytics.py`
```python
#!/usr/bin/env python3
"""
An√°lisis predictivo avanzado para carruseles
- Predicci√≥n de CTR/conversi√≥n
- Forecasting de tr√°fico
- Optimizaci√≥n predictiva de presupuesto
"""
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
import json

class PredictiveCarouselAnalytics:
    def __init__(self):
        self.ctr_model = None
        self.conversion_model = None
        self.scaler = StandardScaler()
    
    def prepare_training_data(self, historical_data):
        """Prepara datos hist√≥ricos para entrenamiento"""
        df = pd.DataFrame(historical_data)
        
        # Features
        feature_cols = [
            'headline_type', 'cta_type', 'visual_style',
            'platform', 'hour_of_day', 'day_of_week',
            'audience_size', 'budget', 'campaign_age_days'
        ]
        
        X = df[feature_cols]
        y_ctr = df['ctr']
        y_conversion = df['conversion_rate']
        
        return X, y_ctr, y_conversion
    
    def train_models(self, historical_data):
        """Entrena modelos predictivos"""
        X, y_ctr, y_conversion = self.prepare_training_data(historical_data)
        
        X_scaled = self.scaler.fit_transform(X)
        
        # Modelo para CTR
        self.ctr_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        self.ctr_model.fit(X_scaled, y_ctr)
        
        # Modelo para conversi√≥n
        self.conversion_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        self.conversion_model.fit(X_scaled, y_conversion)
        
        return {
            'ctr_model_accuracy': self.ctr_model.score(X_scaled, y_ctr),
            'conversion_model_accuracy': self.conversion_model.score(X_scaled, y_conversion)
        }
    
    def predict_performance(self, carousel_config):
        """Predice performance de un carrusel antes de lanzarlo"""
        if self.ctr_model is None:
            return {'error': 'Modelos no entrenados'}
        
        # Preparar features
        features = np.array([[
            carousel_config.get('headline_type', 0),
            carousel_config.get('cta_type', 0),
            carousel_config.get('visual_style', 0),
            carousel_config.get('platform', 0),
            carousel_config.get('hour_of_day', 12),
            carousel_config.get('day_of_week', 2),
            carousel_config.get('audience_size', 10000),
            carousel_config.get('budget', 100),
            carousel_config.get('campaign_age_days', 0)
        ]])
        
        features_scaled = self.scaler.transform(features)
        
        # Predicciones
        predicted_ctr = self.ctr_model.predict(features_scaled)[0]
        predicted_conversion = self.conversion_model.predict(features_scaled)[0]
        
        # Calcular m√©tricas derivadas
        predicted_clicks = carousel_config.get('impressions', 10000) * (predicted_ctr / 100)
        predicted_leads = predicted_clicks * (predicted_conversion / 100)
        predicted_cpa = carousel_config.get('budget', 100) / predicted_leads if predicted_leads > 0 else 0
        
        return {
            'predicted_ctr': round(predicted_ctr, 2),
            'predicted_conversion_rate': round(predicted_conversion, 2),
            'predicted_clicks': round(predicted_clicks, 0),
            'predicted_leads': round(predicted_leads, 0),
            'predicted_cpa': round(predicted_cpa, 2),
            'confidence': 'high' if predicted_ctr > 2.0 else 'medium' if predicted_ctr > 1.0 else 'low'
        }
    
    def optimize_budget_allocation(self, carousel_configs, total_budget):
        """Optimiza asignaci√≥n de presupuesto entre m√∫ltiples carruseles"""
        predictions = []
        
        for config in carousel_configs:
            pred = self.predict_performance(config)
            predictions.append({
                'carousel_id': config['id'],
                'predicted_leads': pred['predicted_leads'],
                'predicted_cpa': pred['predicted_cpa'],
                'current_budget': config.get('budget', 0)
            })
        
        # Optimizaci√≥n: Maximizar leads totales
        # Algoritmo simple: Asignar m√°s presupuesto a carruseles con mejor CPA
        predictions.sort(key=lambda x: x['predicted_cpa'])
        
        optimized_allocation = {}
        remaining_budget = total_budget
        
        for pred in predictions:
            # Asignar presupuesto proporcional a performance esperada
            allocation = min(
                remaining_budget,
                total_budget * (pred['predicted_leads'] / sum(p['predicted_leads'] for p in predictions))
            )
            
            optimized_allocation[pred['carousel_id']] = {
                'allocated_budget': round(allocation, 2),
                'expected_leads': round(pred['predicted_leads'] * (allocation / pred['current_budget']), 0) if pred['current_budget'] > 0 else 0,
                'expected_cpa': pred['predicted_cpa']
            }
            
            remaining_budget -= allocation
        
        return {
            'total_budget': total_budget,
            'allocations': optimized_allocation,
            'total_expected_leads': sum(a['expected_leads'] for a in optimized_allocation.values())
        }

# Uso
predictor = PredictiveCarouselAnalytics()

# Entrenar con datos hist√≥ricos
historical = [
    {'headline_type': 0, 'cta_type': 0, 'visual_style': 0, 'platform': 0, 
     'hour_of_day': 8, 'day_of_week': 1, 'audience_size': 10000, 'budget': 100,
     'campaign_age_days': 0, 'impressions': 50000, 'ctr': 2.5, 'conversion_rate': 18},
    # ... m√°s datos hist√≥ricos
]

training_result = predictor.train_models(historical)

# Predecir performance
config = {
    'headline_type': 1,
    'cta_type': 0,
    'visual_style': 1,
    'platform': 0,
    'hour_of_day': 12,
    'day_of_week': 2,
    'audience_size': 15000,
    'budget': 150,
    'impressions': 75000
}

prediction = predictor.predict_performance(config)
print(json.dumps(prediction, indent=2))
```

---

## üîç Lighthouse CI con Performance Budgets y Bloqueo de PRs

### Configuraci√≥n de Lighthouse CI

**GitHub Actions**: `.github/workflows/lighthouse-ci.yml`

```yaml
name: Lighthouse CI - Performance Budgets

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main]

jobs:
  lighthouse:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install Lighthouse CI
        run: |
          npm install -g @lhci/cli
      
      - name: Build landing pages
        run: |
          # Construir landing pages para testing
          make build-landing-pages
      
      - name: Run Lighthouse CI
        run: |
          lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('.lighthouseci/results.json', 'utf8'));
            
            let comment = '## üîç Lighthouse CI Results\n\n';
            
            results.forEach(result => {
              const score = result.score;
              const url = result.url;
              
              comment += `### ${url}\n\n`;
              comment += `**Performance**: ${(score.performance * 100).toFixed(0)}%\n`;
              comment += `**Accessibility**: ${(score.accessibility * 100).toFixed(0)}%\n`;
              comment += `**Best Practices**: ${(score['best-practices'] * 100).toFixed(0)}%\n`;
              comment += `**SEO**: ${(score.seo * 100).toFixed(0)}%\n\n`;
              
              // Check budgets
              if (result.budgets) {
                comment += '#### Budgets:\n';
                result.budgets.forEach(budget => {
                  const status = budget.passed ? '‚úÖ' : '‚ùå';
                  comment += `${status} ${budget.name}: ${budget.value}\n`;
                });
              }
            });
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
```

### Configuraci√≥n de Performance Budgets

**Archivo**: `.lighthouserc.js`

```javascript
module.exports = {
  ci: {
    collect: {
      url: [
        'http://localhost:3000/landing/curso-ia',
        'http://localhost:3000/landing/saas-marketing',
        'http://localhost:3000/landing/ia-bulk'
      ],
      numberOfRuns: 3,
      settings: {
        chromeFlags: '--no-sandbox --headless'
      }
    },
    assert: {
      assertions: {
        'categories:performance': ['error', { minScore: 0.85 }],
        'categories:accessibility': ['error', { minScore: 0.90 }],
        'categories:best-practices': ['error', { minScore: 0.85 }],
        'categories:seo': ['error', { minScore: 0.90 }],
        
        // Core Web Vitals
        'first-contentful-paint': ['error', { maxNumericValue: 1800 }],
        'largest-contentful-paint': ['error', { maxNumericValue: 2500 }],
        'total-blocking-time': ['error', { maxNumericValue: 200 }],
        'cumulative-layout-shift': ['error', { maxNumericValue: 0.1 }],
        'speed-index': ['error', { maxNumericValue: 3400 }],
        
        // Resource budgets
        'resource-summary:script:size': ['error', { maxNumericValue: 500000 }],
        'resource-summary:stylesheet:size': ['error', { maxNumericValue: 100000 }],
        'resource-summary:image:size': ['error', { maxNumericValue: 2000000 }],
        'resource-summary:font:size': ['error', { maxNumericValue: 200000 }],
        
        // Network requests
        'uses-optimized-images': 'error',
        'uses-text-compression': 'error',
        'uses-request-compression': 'error',
        'uses-responsive-images': 'error',
        
        // Mobile-specific
        'viewport': 'error',
        'tap-targets-size': ['error', { minScore: 0.9 }]
      }
    },
    upload: {
      target: 'temporary-public-storage',
      githubAppToken: process.env.LHCI_GITHUB_APP_TOKEN
    }
  }
};
```

### Script de Validaci√≥n Pre-Commit

**Python**: `scripts/validate_lighthouse_budgets.py`

```python
#!/usr/bin/env python3
"""
Valida que las landing pages cumplan con los budgets de Lighthouse
antes de permitir merge de PRs
"""
import subprocess
import json
import sys
from pathlib import Path

class LighthouseBudgetValidator:
    def __init__(self, config_path='.lighthouserc.js'):
        self.config_path = config_path
        self.budgets = self.load_budgets()
    
    def load_budgets(self):
        """Carga budgets desde configuraci√≥n"""
        return {
            'performance': 0.85,
            'accessibility': 0.90,
            'best-practices': 0.85,
            'seo': 0.90,
            'lcp': 2500,
            'fid': 200,
            'cls': 0.1,
            'fcp': 1800,
            'speed-index': 3400
        }
    
    def run_lighthouse(self, url):
        """Ejecuta Lighthouse en una URL"""
        cmd = [
            'lighthouse',
            url,
            '--output=json',
            '--output-path=/tmp/lighthouse-report.json',
            '--chrome-flags=--headless'
        ]
        
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            with open('/tmp/lighthouse-report.json') as f:
                return json.load(f)
        except subprocess.CalledProcessError as e:
            print(f"Error ejecutando Lighthouse: {e}")
            return None
    
    def validate_budgets(self, report):
        """Valida que los scores cumplan con los budgets"""
        errors = []
        scores = report['categories']
        
        # Validar categor√≠as principales
        for category, min_score in [
            ('performance', 0.85),
            ('accessibility', 0.90),
            ('best-practices', 0.85),
            ('seo', 0.90)
        ]:
            score = scores[category]['score']
            if score < min_score:
                errors.append(
                    f"{category}: {score:.2%} < {min_score:.2%}"
                )
        
        # Validar Core Web Vitals
        audits = report['audits']
        
        lcp = audits['largest-contentful-paint']['numericValue']
        if lcp > 2500:
            errors.append(f"LCP: {lcp}ms > 2500ms")
        
        fid = audits['max-potential-fid']['numericValue']
        if fid > 200:
            errors.append(f"FID: {fid}ms > 200ms")
        
        cls = audits['cumulative-layout-shift']['numericValue']
        if cls > 0.1:
            errors.append(f"CLS: {cls} > 0.1")
        
        fcp = audits['first-contentful-paint']['numericValue']
        if fcp > 1800:
            errors.append(f"FCP: {fcp}ms > 1800ms")
        
        return errors
    
    def validate_all_landings(self):
        """Valida todas las landing pages"""
        landings = [
            'http://localhost:3000/landing/curso-ia',
            'http://localhost:3000/landing/saas-marketing',
            'http://localhost:3000/landing/ia-bulk'
        ]
        
        all_errors = []
        
        for url in landings:
            print(f"Validando {url}...")
            report = self.run_lighthouse(url)
            
            if not report:
                all_errors.append(f"Error ejecutando Lighthouse en {url}")
                continue
            
            errors = self.validate_budgets(report)
            
            if errors:
                all_errors.append(f"\n{url}:\n" + "\n".join(f"  ‚ùå {e}" for e in errors))
            else:
                print(f"‚úÖ {url} cumple con todos los budgets")
        
        return all_errors

if __name__ == '__main__':
    validator = LighthouseBudgetValidator()
    errors = validator.validate_all_landings()
    
    if errors:
        print("\n‚ùå Errores encontrados:")
        print("\n".join(errors))
        sys.exit(1)
    else:
        print("\n‚úÖ Todas las landing pages cumplen con los budgets")
        sys.exit(0)
```

### Bloqueo de PRs con Budgets

**GitHub Actions**: Integraci√≥n en workflow principal

```yaml
# Agregar al workflow existente
  lighthouse-budgets:
    runs-on: ubuntu-latest
    needs: [generate]
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli
      
      - name: Build and serve landing pages
        run: |
          make build-landing-pages
          npm start &
          sleep 10
      
      - name: Run Lighthouse CI with budgets
        run: |
          lhci autorun --config=.lighthouserc.js
        continue-on-error: false
      
      - name: Fail PR if budgets exceeded
        if: failure() && github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '‚ùå **PR bloqueado**: Los budgets de Lighthouse no se cumplen. Revisa los resultados y optimiza antes de hacer merge.'
            });
            core.setFailed('Lighthouse budgets no cumplidos');
```

---

## üõ°Ô∏è Gobernanza UTM en CI (Validador + Autocorrecci√≥n + Reportes)

### Script de Validaci√≥n y Autocorrecci√≥n UTM

**Python**: `scripts/utm_governance.py`

```python
#!/usr/bin/env python3
"""
Gobernanza automatizada de UTMs en CI
- Valida estructura y formato
- Autocorrige errores comunes
- Genera reportes de cumplimiento
"""
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass

@dataclass
class UTMValidationResult:
    """Resultado de validaci√≥n UTM"""
    is_valid: bool
    errors: List[str]
    warnings: List[str]
    corrected_url: str = None
    original_url: str = None

class UTMGovernance:
    """Sistema de gobernanza UTM"""
    
    # Est√°ndares UTM requeridos
    REQUIRED_PARAMS = ['utm_source', 'utm_medium', 'utm_campaign', 'utm_content']
    OPTIONAL_PARAMS = ['utm_term', 'utm_id']
    
    # Validaci√≥n de valores
    SOURCES = ['instagram', 'linkedin', 'facebook', 'twitter', 'youtube']
    MEDIUMS = ['carrusel', 'stories', 'post', 'video', 'ad']
    CAMPAIGN_PATTERN = r'^(curso_ia|saas_marketing|ia_bulk)_\d{4}-\d{2}$'
    CONTENT_PATTERN = r'^slide[1-3](_[a-z]+)?$'
    
    def __init__(self, strict_mode=True):
        self.strict_mode = strict_mode
        self.corrections_made = []
        self.violations = []
    
    def parse_utm(self, url: str) -> Dict[str, str]:
        """Extrae par√°metros UTM de una URL"""
        from urllib.parse import urlparse, parse_qs
        
        parsed = urlparse(url)
        params = parse_qs(parsed.query)
        
        # Flatten single-item lists
        utm_params = {}
        for key, value in params.items():
            if key.startswith('utm_'):
                utm_params[key] = value[0] if value else ''
        
        return utm_params
    
    def validate_utm_structure(self, url: str) -> UTMValidationResult:
        """Valida estructura completa de UTM"""
        errors = []
        warnings = []
        utm_params = self.parse_utm(url)
        
        # Verificar par√°metros requeridos
        for param in self.REQUIRED_PARAMS:
            if param not in utm_params:
                errors.append(f"Par√°metro requerido faltante: {param}")
        
        # Validar valores
        if 'utm_source' in utm_params:
            if utm_params['utm_source'] not in self.SOURCES:
                errors.append(
                    f"utm_source inv√°lido: {utm_params['utm_source']}. "
                    f"Valores permitidos: {', '.join(self.SOURCES)}"
                )
        
        if 'utm_medium' in utm_params:
            if utm_params['utm_medium'] not in self.MEDIUMS:
                errors.append(
                    f"utm_medium inv√°lido: {utm_params['utm_medium']}. "
                    f"Valores permitidos: {', '.join(self.MEDIUMS)}"
                )
        
        if 'utm_campaign' in utm_params:
            if not re.match(self.CAMPAIGN_PATTERN, utm_params['utm_campaign']):
                errors.append(
                    f"utm_campaign inv√°lido: {utm_params['utm_campaign']}. "
                    f"Debe seguir formato: producto_YYYY-MM"
                )
        
        if 'utm_content' in utm_params:
            if not re.match(self.CONTENT_PATTERN, utm_params['utm_content']):
                warnings.append(
                    f"utm_content no sigue formato est√°ndar: {utm_params['utm_content']}"
                )
        
        # Verificar caracteres especiales
        for param, value in utm_params.items():
            if re.search(r'[^a-z0-9_\-]', value, re.IGNORECASE):
                warnings.append(
                    f"{param} contiene caracteres especiales: {value}"
                )
        
        is_valid = len(errors) == 0
        
        return UTMValidationResult(
            is_valid=is_valid,
            errors=errors,
            warnings=warnings,
            original_url=url
        )
    
    def auto_correct_utm(self, url: str) -> str:
        """Autocorrige errores comunes en UTMs"""
        from urllib.parse import urlparse, urlunparse, parse_qs, urlencode
        
        parsed = urlparse(url)
        params = parse_qs(parsed.query)
        
        corrections = []
        
        # Autocorregir utm_source
        if 'utm_source' in params:
            source = params['utm_source'][0].lower()
            source_mappings = {
                'ig': 'instagram',
                'li': 'linkedin',
                'fb': 'facebook',
                'yt': 'youtube',
                'tw': 'twitter'
            }
            
            if source in source_mappings:
                params['utm_source'] = [source_mappings[source]]
                corrections.append(f"utm_source corregido: {source} ‚Üí {source_mappings[source]}")
        
        # Autocorregir utm_medium
        if 'utm_carousel' in params:
            params['utm_medium'] = params.pop('utm_carousel')
            corrections.append("utm_carousel renombrado a utm_medium")
        
        # Autocorregir formato de campaign
        if 'utm_campaign' in params:
            campaign = params['utm_campaign'][0]
            # Si no tiene formato correcto, intentar inferirlo
            if not re.match(self.CAMPAIGN_PATTERN, campaign):
                # Intentar extraer producto y fecha
                for product in ['curso_ia', 'saas_marketing', 'ia_bulk']:
                    if product in campaign.lower():
                        from datetime import datetime
                        date_str = datetime.now().strftime('%Y-%m')
                        corrected = f"{product}_{date_str}"
                        params['utm_campaign'] = [corrected]
                        corrections.append(f"utm_campaign corregido: {campaign} ‚Üí {corrected}")
                        break
        
        # Autocorregir utm_content
        if 'utm_content' in params:
            content = params['utm_content'][0].lower()
            if not re.match(self.CONTENT_PATTERN, content):
                # Intentar inferir slide number
                slide_match = re.search(r'slide\s*(\d+)', content, re.IGNORECASE)
                if slide_match:
                    slide_num = slide_match.group(1)
                    params['utm_content'] = [f"slide{slide_num}"]
                    corrections.append(f"utm_content corregido: {content} ‚Üí slide{slide_num}")
        
        # Eliminar caracteres especiales
        for param in list(params.keys()):
            if param.startswith('utm_'):
                value = params[param][0]
                cleaned = re.sub(r'[^a-z0-9_\-]', '_', value.lower())
                if cleaned != value:
                    params[param] = [cleaned]
                    corrections.append(f"{param} limpiado: {value} ‚Üí {cleaned}")
        
        if corrections:
            self.corrections_made.extend(corrections)
        
        # Reconstruir URL
        new_query = urlencode(params, doseq=True)
        corrected_url = urlunparse((
            parsed.scheme,
            parsed.netloc,
            parsed.path,
            parsed.params,
            new_query,
            parsed.fragment
        ))
        
        return corrected_url
    
    def validate_file(self, file_path: Path) -> List[UTMValidationResult]:
        """Valida todos los UTMs en un archivo"""
        results = []
        
        # Buscar URLs con UTMs en el archivo
        content = file_path.read_text()
        url_pattern = r'https?://[^\s\)]+(?:\?[^\s\)]*utm_[^\s\)]+)?'
        urls = re.findall(url_pattern, content)
        
        for url in urls:
            if 'utm_' in url:
                result = self.validate_utm_structure(url)
                
                # Si hay errores y est√° en modo auto-correct
                if not result.is_valid and not self.strict_mode:
                    corrected_url = self.auto_correct_utm(url)
                    result.corrected_url = corrected_url
                    result.is_valid = True  # Asumir que correcci√≥n fue exitosa
                
                results.append(result)
        
        return results
    
    def scan_directory(self, directory: Path) -> Dict[str, List[UTMValidationResult]]:
        """Escanea directorio completo para validar UTMs"""
        findings = {}
        
        # Buscar en SVGs, HTML, JS, MD, CSV
        patterns = ['*.svg', '*.html', '*.js', '*.md', '*.csv']
        
        for pattern in patterns:
            for file_path in directory.rglob(pattern):
                results = self.validate_file(file_path)
                
                if results:
                    findings[str(file_path)] = results
        
        return findings
    
    def generate_report(self, findings: Dict[str, List[UTMValidationResult]]) -> str:
        """Genera reporte de cumplimiento UTM"""
        total_files = len(findings)
        total_urls = sum(len(results) for results in findings.values())
        
        valid_count = 0
        invalid_count = 0
        warning_count = 0
        
        report_lines = [
            "# üìä Reporte de Gobernanza UTM",
            "",
            f"**Archivos escaneados**: {total_files}",
            f"**URLs con UTM encontradas**: {total_urls}",
            "",
            "## Resultados",
            ""
        ]
        
        for file_path, results in findings.items():
            report_lines.append(f"### {file_path}")
            report_lines.append("")
            
            for i, result in enumerate(results, 1):
                status = "‚úÖ" if result.is_valid else "‚ùå"
                report_lines.append(f"{status} URL #{i}")
                
                if result.errors:
                    report_lines.append("**Errores:**")
                    for error in result.errors:
                        report_lines.append(f"  - {error}")
                
                if result.warnings:
                    report_lines.append("**Advertencias:**")
                    for warning in result.warnings:
                        report_lines.append(f"  - {warning}")
                
                if result.corrected_url:
                    report_lines.append(f"**URL corregida:**")
                    report_lines.append(f"  Original: `{result.original_url}`")
                    report_lines.append(f"  Corregida: `{result.corrected_url}`")
                
                report_lines.append("")
                
                if result.is_valid:
                    valid_count += 1
                else:
                    invalid_count += 1
                    warning_count += len(result.warnings)
        
        # Resumen
        report_lines.extend([
            "## Resumen",
            "",
            f"- ‚úÖ V√°lidos: {valid_count}",
            f"- ‚ùå Inv√°lidos: {invalid_count}",
            f"- ‚ö†Ô∏è Advertencias: {warning_count}",
            f"- üìù Correcciones aplicadas: {len(self.corrections_made)}"
        ])
        
        if self.corrections_made:
            report_lines.extend([
                "",
                "## Correcciones Aplicadas",
                ""
            ])
            for correction in self.corrections_made:
                report_lines.append(f"- {correction}")
        
        return "\n".join(report_lines)

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("Uso: utm_governance.py <directorio> [--strict|--auto-correct]")
        sys.exit(1)
    
    directory = Path(sys.argv[1])
    strict_mode = '--strict' in sys.argv or '--auto-correct' not in sys.argv
    
    governance = UTMGovernance(strict_mode=strict_mode)
    findings = governance.scan_directory(directory)
    report = governance.generate_report(findings)
    
    # Guardar reporte
    report_path = directory / 'utm_governance_report.md'
    report_path.write_text(report)
    
    print(report)
    
    # Si hay errores en modo estricto, fallar
    total_invalid = sum(
        1 for results in findings.values()
        for result in results
        if not result.is_valid
    )
    
    if strict_mode and total_invalid > 0:
        print(f"\n‚ùå {total_invalid} URLs inv√°lidas encontradas")
        sys.exit(1)
    else:
        print(f"\n‚úÖ Validaci√≥n completada")
        sys.exit(0)
```

### Integraci√≥n en CI/CD

**GitHub Actions**: `.github/workflows/utm-governance.yml`

```yaml
name: UTM Governance CI

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main]

jobs:
  utm-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Validate UTMs
        run: |
          python scripts/utm_governance.py source/ --strict
        continue-on-error: false
      
      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: utm-governance-report
          path: utm_governance_report.md
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request' && failure()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('utm_governance_report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## üõ°Ô∏è UTM Governance Check\n\n\`\`\`\n${report}\n\`\`\``
            });
      
      - name: Auto-correct UTMs (opcional)
        if: github.event_name == 'pull_request' && failure()
        run: |
          python scripts/utm_governance.py source/ --auto-correct
          
          # Si hay cambios, crear commit
          if [ -n "$(git status --porcelain)" ]; then
            git config user.name 'UTM Governance Bot'
            git config user.email 'bot@blatam.com'
            git add -A
            git commit -m 'chore: auto-correct UTM parameters'
            git push
          fi
```

### Reporte de Cumplimiento Semanal

**Python**: `scripts/utm_compliance_report.py`

```python
#!/usr/bin/env python3
"""
Genera reporte semanal de cumplimiento UTM
Env√≠a a Slack/Discord con m√©tricas de calidad
"""
from utm_governance import UTMGovernance
from pathlib import Path
import json
from datetime import datetime

def generate_compliance_report():
    """Genera reporte de cumplimiento"""
    governance = UTMGovernance(strict_mode=False)
    findings = governance.scan_directory(Path('source/'))
    
    # Calcular m√©tricas
    total_urls = sum(len(results) for results in findings.values())
    valid_urls = sum(
        1 for results in findings.values()
        for result in results
        if result.is_valid
    )
    
    compliance_rate = (valid_urls / total_urls * 100) if total_urls > 0 else 100
    
    # Generar payload para Slack
    payload = {
        'text': 'üìä Reporte Semanal de Cumplimiento UTM',
        'blocks': [
            {
                'type': 'header',
                'text': {
                    'type': 'plain_text',
                    'text': 'üìä Reporte Semanal UTM Governance'
                }
            },
            {
                'type': 'section',
                'fields': [
                    {
                        'type': 'mrkdwn',
                        'text': f'*Total URLs:*\n{total_urls}'
                    },
                    {
                        'type': 'mrkdwn',
                        'text': f'*V√°lidas:*\n{valid_urls}'
                    },
                    {
                        'type': 'mrkdwn',
                        'text': f'*Tasa de cumplimiento:*\n{compliance_rate:.1f}%'
                    },
                    {
                        'type': 'mrkdwn',
                        'text': f'*Correcciones:*\n{len(governance.corrections_made)}'
                    }
                ]
            }
        ]
    }
    
    return payload, compliance_rate

if __name__ == '__main__':
    payload, compliance = generate_compliance_report()
    
    # Guardar para env√≠o a Slack
    with open('utm_compliance_payload.json', 'w') as f:
        json.dump(payload, f, indent=2)
    
    print(f"‚úÖ Reporte generado - Cumplimiento: {compliance:.1f}%")
```

---

## üé∞ Multi-Armed Bandit (Distribuci√≥n Din√°mica de Presupuesto)

### Algoritmo Multi-Armed Bandit para Carruseles

**Python**: `scripts/multi_armed_bandit.py`

```python
#!/usr/bin/env python3
"""
Multi-Armed Bandit para distribuci√≥n din√°mica de presupuesto
entre variantes de carruseles basado en performance en tiempo real
"""
import numpy as np
import json
from typing import Dict, List, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import statistics

@dataclass
class VariantPerformance:
    """Rendimiento de una variante"""
    variant_id: str
    impressions: int = 0
    clicks: int = 0
    conversions: int = 0
    revenue: float = 0.0
    last_updated: str = None
    
    @property
    def ctr(self) -> float:
        """Click-through rate"""
        if self.impressions == 0:
            return 0.0
        return self.clicks / self.impressions
    
    @property
    def conversion_rate(self) -> float:
        """Tasa de conversi√≥n"""
        if self.clicks == 0:
            return 0.0
        return self.conversions / self.clicks
    
    @property
    def cpa(self) -> float:
        """Cost per acquisition"""
        if self.conversions == 0:
            return float('inf')
        return (self.impressions * 0.05) / self.conversions  # Asumiendo CPC
    
    @property
    def roas(self) -> float:
        """Return on ad spend"""
        spend = self.impressions * 0.05  # CPC estimado
        if spend == 0:
            return 0.0
        return self.revenue / spend

class ThompsonSamplingBandit:
    """
    Multi-Armed Bandit usando Thompson Sampling
    Optimiza distribuci√≥n de presupuesto basado en CTR y conversi√≥n
    """
    
    def __init__(self, alpha: float = 1.0, beta: float = 1.0):
        """
        Args:
            alpha: Prior de √©xito para Beta distribution
            beta: Prior de fracaso para Beta distribution
        """
        self.alpha = alpha
        self.beta = beta
        self.variants: Dict[str, VariantPerformance] = {}
        self.priors: Dict[str, Tuple[float, float]] = {}
    
    def add_variant(self, variant_id: str):
        """Agrega una nueva variante al bandit"""
        self.variants[variant_id] = VariantPerformance(
            variant_id=variant_id,
            last_updated=datetime.now().isoformat()
        )
        self.priors[variant_id] = (self.alpha, self.beta)
    
    def update_performance(self, variant_id: str, impressions: int, 
                          clicks: int, conversions: int = 0, revenue: float = 0.0):
        """Actualiza m√©tricas de performance de una variante"""
        if variant_id not in self.variants:
            self.add_variant(variant_id)
        
        variant = self.variants[variant_id]
        variant.impressions += impressions
        variant.clicks += clicks
        variant.conversions += conversions
        variant.revenue += revenue
        variant.last_updated = datetime.now().isoformat()
        
        # Actualizar priors de Beta distribution
        # alpha = √©xitos + 1, beta = fracasos + 1
        alpha_prior, beta_prior = self.priors[variant_id]
        self.priors[variant_id] = (
            alpha_prior + clicks,
            beta_prior + (impressions - clicks)
        )
    
    def sample_conversion_probability(self, variant_id: str) -> float:
        """Muestra probabilidad de conversi√≥n desde Beta distribution"""
        if variant_id not in self.priors:
            return 0.5  # Default
        
        alpha, beta = self.priors[variant_id]
        return np.random.beta(alpha, beta)
    
    def select_variant(self) -> str:
        """
        Selecciona variante usando Thompson Sampling
        Retorna el ID de la variante con mayor probabilidad muestreada
        """
        if not self.variants:
            raise ValueError("No hay variantes disponibles")
        
        samples = {}
        for variant_id in self.variants.keys():
            # Muestrear probabilidad de conversi√≥n
            conversion_prob = self.sample_conversion_probability(variant_id)
            
            # Factorizar CTR para mejor estimaci√≥n
            variant = self.variants[variant_id]
            ctr = variant.ctr if variant.impressions > 0 else 0.01
            
            # Score combinado: conversi√≥n esperada * CTR
            score = conversion_prob * ctr
            samples[variant_id] = score
        
        # Seleccionar variante con mayor score
        selected = max(samples.items(), key=lambda x: x[1])[0]
        return selected
    
    def allocate_budget(self, total_budget: float, 
                       min_allocation: float = 0.1) -> Dict[str, float]:
        """
        Asigna presupuesto a variantes basado en Thompson Sampling
        
        Args:
            total_budget: Presupuesto total a distribuir
            min_allocation: Porcentaje m√≠nimo por variante (10%)
        
        Returns:
            Dict con variant_id -> presupuesto asignado
        """
        if not self.variants:
            return {}
        
        # Calcular scores para cada variante (m√∫ltiples muestras)
        num_samples = 1000
        scores = {vid: [] for vid in self.variants.keys()}
        
        for _ in range(num_samples):
            for variant_id in self.variants.keys():
                conversion_prob = self.sample_conversion_probability(variant_id)
                variant = self.variants[variant_id]
                ctr = variant.ctr if variant.impressions > 0 else 0.01
                score = conversion_prob * ctr
                scores[variant_id].append(score)
        
        # Promedio de scores
        avg_scores = {
            vid: statistics.mean(scores[vid])
            for vid in scores.keys()
        }
        
        # Normalizar scores
        total_score = sum(avg_scores.values())
        if total_score == 0:
            # Distribuci√≥n equitativa si no hay datos
            allocation = {vid: total_budget / len(self.variants) 
                         for vid in self.variants.keys()}
        else:
            # Asignar proporcionalmente a scores
            allocation = {
                vid: max(min_allocation * total_budget,
                        (score / total_score) * total_budget)
                for vid, score in avg_scores.items()
            }
        
        # Asegurar que suma exacta
        allocated_total = sum(allocation.values())
        if allocated_total != total_budget:
            diff = total_budget - allocated_total
            # Ajustar en la variante con mayor score
            top_variant = max(avg_scores.items(), key=lambda x: x[1])[0]
            allocation[top_variant] += diff
        
        return allocation
    
    def get_recommendations(self) -> Dict[str, any]:
        """Genera recomendaciones basadas en performance"""
        recommendations = {}
        
        for variant_id, variant in self.variants.items():
            recs = []
            
            # Si CTR es bajo
            if variant.ctr < 0.01 and variant.impressions > 100:
                recs.append({
                    'type': 'low_ctr',
                    'message': 'CTR bajo, considerar actualizar headline o visual',
                    'ctr': variant.ctr
                })
            
            # Si conversi√≥n es baja pero CTR es bueno
            if variant.ctr > 0.02 and variant.conversion_rate < 0.05:
                recs.append({
                    'type': 'low_conversion',
                    'message': 'CTR bueno pero conversi√≥n baja, revisar landing page',
                    'conversion_rate': variant.conversion_rate
                })
            
            # Si tiene pocos datos
            if variant.impressions < 100:
                recs.append({
                    'type': 'insufficient_data',
                    'message': 'Datos insuficientes, continuar recolecci√≥n',
                    'impressions': variant.impressions
                })
            
            recommendations[variant_id] = recs
        
        return recommendations

# Clase para integraci√≥n con Meta Ads API
class MetaAdsBanditIntegration:
    """Integraci√≥n con Meta Ads para actualizaci√≥n autom√°tica"""
    
    def __init__(self, bandit: ThompsonSamplingBandit, 
                 access_token: str, ad_account_id: str):
        self.bandit = bandit
        self.access_token = access_token
        self.ad_account_id = ad_account_id
    
    def fetch_ad_performance(self, hours: int = 24) -> Dict[str, VariantPerformance]:
        """Obtiene performance de ads desde Meta"""
        # Aqu√≠ ir√≠a la llamada real a Meta Ads API
        # Por ahora, retorna estructura de ejemplo
        from datetime import datetime, timedelta
        
        # Simulaci√≥n de datos
        performance_data = {}
        
        # En producci√≥n, esto ser√≠a:
        # import requests
        # response = requests.get(
        #     f'https://graph.facebook.com/v18.0/{self.ad_account_id}/insights',
        #     params={
        #         'access_token': self.access_token,
        #         'fields': 'ad_name,impressions,clicks,actions',
        #         'time_range': {'since': ..., 'until': ...}
        #     }
        # )
        
        return performance_data
    
    def update_budget_allocation(self, allocation: Dict[str, float]):
        """Actualiza presupuestos en Meta Ads basado en allocation"""
        # Aqu√≠ ir√≠a la actualizaci√≥n real de presupuestos
        # Por ahora, solo log
        print(f"Actualizando presupuestos en Meta Ads:")
        for variant_id, budget in allocation.items():
            print(f"  {variant_id}: ${budget:.2f}")

# Ejemplo de uso
if __name__ == '__main__':
    # Inicializar bandit
    bandit = ThompsonSamplingBandit()
    
    # Agregar variantes
    variants = [
        'curso_ia_slide1_metrics',
        'curso_ia_slide1_urgency',
        'curso_ia_slide1_social_proof',
        'saas_marketing_slide1_benefits',
        'saas_marketing_slide1_numbers'
    ]
    
    for variant_id in variants:
        bandit.add_variant(variant_id)
    
    # Simular datos de performance
    np.random.seed(42)
    for variant_id in variants:
        impressions = np.random.randint(500, 5000)
        clicks = int(impressions * np.random.uniform(0.01, 0.05))
        conversions = int(clicks * np.random.uniform(0.05, 0.20))
        
        bandit.update_performance(
            variant_id=variant_id,
            impressions=impressions,
            clicks=clicks,
            conversions=conversions,
            revenue=conversions * 100  # $100 por conversi√≥n
        )
    
    # Asignar presupuesto
    total_budget = 1000.0  # $1000 diarios
    allocation = bandit.allocate_budget(total_budget)
    
    print("üé∞ Multi-Armed Bandit - Distribuci√≥n de Presupuesto\n")
    print(f"Presupuesto total: ${total_budget:.2f}\n")
    
    for variant_id, budget in sorted(allocation.items(), 
                                     key=lambda x: x[1], reverse=True):
        variant = bandit.variants[variant_id]
        print(f"{variant_id}:")
        print(f"  Presupuesto: ${budget:.2f} ({budget/total_budget*100:.1f}%)")
        print(f"  CTR: {variant.ctr:.2%}")
        print(f"  Conversi√≥n: {variant.conversion_rate:.2%}")
        print(f"  ROAS: {variant.roas:.2f}")
        print()
    
    # Recomendaciones
    recommendations = bandit.get_recommendations()
    print("üí° Recomendaciones:\n")
    for variant_id, recs in recommendations.items():
        if recs:
            print(f"{variant_id}:")
            for rec in recs:
                print(f"  - {rec['message']}")
    
    # Guardar configuraci√≥n
    output = {
        'allocation': allocation,
        'variants': {vid: asdict(bandit.variants[vid]) 
                    for vid in bandit.variants.keys()},
        'recommendations': recommendations,
        'timestamp': datetime.now().isoformat()
    }
    
    with open('bandit_allocation.json', 'w') as f:
        json.dump(output, f, indent=2)
    
    print("\n‚úÖ Configuraci√≥n guardada en bandit_allocation.json")
```

### Integraci√≥n con Meta Ads API

**Python**: `scripts/update_meta_budget_from_bandit.py`

```python
#!/usr/bin/env python3
"""
Actualiza presupuestos en Meta Ads basado en Multi-Armed Bandit
Se ejecuta cada hora para redistribuir presupuesto din√°micamente
"""
from multi_armed_bandit import ThompsonSamplingBandit, MetaAdsBanditIntegration
import requests
import json
from datetime import datetime, timedelta

def update_meta_ads_budgets():
    """Actualiza presupuestos en Meta Ads usando bandit"""
    # Configuraci√≥n
    ACCESS_TOKEN = os.getenv('META_ADS_ACCESS_TOKEN')
    AD_ACCOUNT_ID = os.getenv('META_ADS_ACCOUNT_ID')
    
    # Inicializar bandit
    bandit = ThompsonSamplingBandit()
    
    # Cargar variantes desde configuraci√≥n
    with open('config/variants.json') as f:
        variants_config = json.load(f)
    
    for variant in variants_config:
        bandit.add_variant(variant['id'])
    
    # Obtener performance desde Meta Ads
    integration = MetaAdsBanditIntegration(bandit, ACCESS_TOKEN, AD_ACCOUNT_ID)
    performance = integration.fetch_ad_performance(hours=24)
    
    # Actualizar bandit con datos reales
    for variant_id, perf in performance.items():
        bandit.update_performance(
            variant_id=variant_id,
            impressions=perf.impressions,
            clicks=perf.clicks,
            conversions=perf.conversions,
            revenue=perf.revenue
        )
    
    # Calcular nueva distribuci√≥n
    total_budget = float(os.getenv('TOTAL_DAILY_BUDGET', '1000'))
    allocation = bandit.allocate_budget(total_budget)
    
    # Actualizar presupuestos en Meta Ads
    integration.update_budget_allocation(allocation)
    
    # Guardar log
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'allocation': allocation,
        'total_budget': total_budget
    }
    
    with open('logs/bandit_updates.jsonl', 'a') as f:
        f.write(json.dumps(log_entry) + '\n')
    
    print(f"‚úÖ Presupuestos actualizados: {datetime.now()}")

if __name__ == '__main__':
    import os
    update_meta_ads_budgets()
```

### Cron Job para Actualizaci√≥n Autom√°tica

**GitHub Actions**: `.github/workflows/bandit-hourly.yml`

```yaml
name: Multi-Armed Bandit - Hourly Budget Update

on:
  schedule:
    - cron: '0 * * * *'  # Cada hora
  workflow_dispatch:

jobs:
  update-budgets:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Update Meta Ads budgets
        env:
          META_ADS_ACCESS_TOKEN: ${{ secrets.META_ADS_ACCESS_TOKEN }}
          META_ADS_ACCOUNT_ID: ${{ secrets.META_ADS_ACCOUNT_ID }}
          TOTAL_DAILY_BUDGET: ${{ secrets.TOTAL_DAILY_BUDGET }}
        run: |
          python scripts/update_meta_budget_from_bandit.py
      
      - name: Notify on significant changes
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            // Notificar si hay cambios significativos en allocation
            // (implementar l√≥gica de detecci√≥n de cambios)
```

---

## ‚ôø Testing Automatizado de Accesibilidad WCAG para Carruseles

### Script de Validaci√≥n WCAG 2.1 AA

**Python**: `scripts/accessibility_testing.py`

```python
#!/usr/bin/env python3
"""
Testing automatizado de accesibilidad WCAG 2.1 AA para carruseles
Valida contraste, texto alternativo, navegaci√≥n por teclado, ARIA labels
"""
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from axe_selenium_python import Axe
import json
from pathlib import Path
from typing import Dict, List
from dataclasses import dataclass

@dataclass
class AccessibilityViolation:
    """Violaci√≥n de accesibilidad encontrada"""
    rule: str
    impact: str  # minor, moderate, serious, critical
    description: str
    nodes: List[Dict]
    help_url: str

class AccessibilityTester:
    """Tester de accesibilidad WCAG para carruseles"""
    
    WCAG_LEVELS = {
        'A': 'minimum',
        'AA': 'recommended',
        'AAA': 'enhanced'
    }
    
    def __init__(self, target_level='AA'):
        self.target_level = target_level
        self.violations = []
        self.warnings = []
    
    def test_carousel_accessibility(self, svg_path: Path) -> Dict:
        """Testea accesibilidad de un carrusel SVG"""
        # Convertir SVG a HTML para testing
        html_path = self.svg_to_html(svg_path)
        
        # Inicializar navegador
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        driver = webdriver.Chrome(options=options)
        
        try:
            driver.get(f"file://{html_path.absolute()}")
            
            # Ejecutar axe-core
            axe = Axe(driver)
            axe.inject()
            results = axe.run()
            
            # Analizar resultados
            violations = self.parse_axe_results(results)
            
            return {
                'svg_path': str(svg_path),
                'total_violations': len(violations),
                'violations': violations,
                'wcag_level': self.target_level,
                'compliance': self.calculate_compliance(violations)
            }
        finally:
            driver.quit()
    
    def parse_axe_results(self, axe_results: Dict) -> List[AccessibilityViolation]:
        """Parsea resultados de axe-core"""
        violations = []
        
        for violation in axe_results.get('violations', []):
            violations.append(AccessibilityViolation(
                rule=violation['id'],
                impact=violation['impact'],
                description=violation['description'],
                nodes=violation['nodes'],
                help_url=violation['helpUrl']
            ))
        
        return violations
    
    def test_color_contrast(self, svg_path: Path) -> List[Dict]:
        """Testea contraste de colores en SVG"""
        from bs4 import BeautifulSoup
        import re
        
        violations = []
        
        with open(svg_path) as f:
            soup = BeautifulSoup(f.read(), 'xml')
        
        # Buscar elementos de texto
        text_elements = soup.find_all(['text', 'tspan', 'textPath'])
        
        for element in text_elements:
            # Extraer color y fondo
            fill = element.get('fill', '#000000')
            background = self.get_background_color(element)
            
            # Calcular contraste
            contrast = self.calculate_contrast(fill, background)
            
            # WCAG AA requiere 4.5:1 para texto normal, 3:1 para texto grande
            min_contrast = 4.5
            font_size = float(element.get('font-size', '16').replace('px', ''))
            
            if font_size >= 18:
                min_contrast = 3.0
            
            if contrast < min_contrast:
                violations.append({
                    'element': str(element),
                    'contrast_ratio': contrast,
                    'required': min_contrast,
                    'fill': fill,
                    'background': background,
                    'status': 'FAIL'
                })
        
        return violations
    
    def test_alt_text(self, svg_path: Path) -> List[Dict]:
        """Testea presencia de texto alternativo"""
        from bs4 import BeautifulSoup
        
        violations = []
        
        with open(svg_path) as f:
            soup = BeautifulSoup(f.read(), 'xml')
        
        # Buscar im√°genes e im√°genes embebidas
        images = soup.find_all(['image', 'foreignObject'])
        
        for img in images:
            alt = img.get('aria-label') or img.get('title')
            desc = soup.find('desc', {'id': img.get('aria-describedby')})
            
            if not alt and not desc:
                violations.append({
                    'element': str(img),
                    'issue': 'Missing alt text or description',
                    'status': 'FAIL'
                })
        
        return violations
    
    def test_keyboard_navigation(self, html_path: Path) -> bool:
        """Testea navegaci√≥n por teclado"""
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        driver = webdriver.Chrome(options=options)
        
        try:
            driver.get(f"file://{html_path.absolute()}")
            
            # Intentar navegar con Tab
            body = driver.find_element('tag name', 'body')
            body.send_keys(Keys.TAB)
            
            # Verificar que hay elementos enfocables
            focused = driver.switch_to.active_element
            
            return focused.tag_name != 'body'
        finally:
            driver.quit()
    
    def calculate_contrast(self, color1: str, color2: str) -> float:
        """Calcula ratio de contraste WCAG"""
        def hex_to_rgb(hex_color):
            hex_color = hex_color.lstrip('#')
            return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
        
        def relative_luminance(rgb):
            def normalize(value):
                value = value / 255.0
                if value <= 0.03928:
                    return value / 12.92
                return ((value + 0.055) / 1.055) ** 2.4
            
            r, g, b = [normalize(c) for c in rgb]
            return 0.2126 * r + 0.7152 * g + 0.0722 * b
        
        rgb1 = hex_to_rgb(color1)
        rgb2 = hex_to_rgb(color2)
        
        l1 = relative_luminance(rgb1)
        l2 = relative_luminance(rgb2)
        
        lighter = max(l1, l2)
        darker = min(l1, l2)
        
        return (lighter + 0.05) / (darker + 0.05)
    
    def get_background_color(self, element) -> str:
        """Obtiene color de fondo de un elemento"""
        # Buscar color de fondo en elemento o ancestros
        current = element
        while current:
            bg = current.get('fill') or current.get('style')
            if bg and 'fill' in bg:
                return self.extract_color(bg)
            current = current.parent
        return '#FFFFFF'  # Default white
    
    def extract_color(self, style_str: str) -> str:
        """Extrae color de un string de estilo"""
        import re
        match = re.search(r'fill:\s*([^;]+)', style_str)
        return match.group(1) if match else '#000000'
    
    def svg_to_html(self, svg_path: Path) -> Path:
        """Convierte SVG a HTML para testing"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Accessibility Test</title>
        </head>
        <body>
            <svg width="1080" height="1080" xmlns="http://www.w3.org/2000/svg">
                {svg_path.read_text()}
            </svg>
            <script src="https://cdn.jsdelivr.net/npm/axe-core@4.7.0/axe.min.js"></script>
        </body>
        </html>
        """
        
        html_path = svg_path.with_suffix('.html')
        html_path.write_text(html_content)
        
        return html_path
    
    def calculate_compliance(self, violations: List[AccessibilityViolation]) -> Dict:
        """Calcula porcentaje de cumplimiento"""
        total_rules = 50  # Aproximado para WCAG AA
        critical = sum(1 for v in violations if v.impact == 'critical')
        serious = sum(1 for v in violations if v.impact == 'serious')
        moderate = sum(1 for v in violations if v.impact == 'moderate')
        minor = sum(1 for v in violations if v.impact == 'minor')
        
        # Penalizar por impacto
        penalty = critical * 5 + serious * 3 + moderate * 2 + minor * 1
        compliance = max(0, 100 - (penalty / total_rules * 100))
        
        return {
            'percentage': compliance,
            'level': 'AA' if compliance >= 95 else 'A' if compliance >= 80 else 'Non-compliant',
            'critical': critical,
            'serious': serious,
            'moderate': moderate,
            'minor': minor
        }
    
    def generate_report(self, results: List[Dict]) -> str:
        """Genera reporte de accesibilidad"""
        report_lines = [
            "# ‚ôø Reporte de Accesibilidad WCAG 2.1 AA",
            "",
            "## Resumen General",
            ""
        ]
        
        total_files = len(results)
        total_violations = sum(r['total_violations'] for r in results)
        avg_compliance = sum(r['compliance']['percentage'] for r in results) / total_files
        
        report_lines.extend([
            f"**Archivos testeados**: {total_files}",
            f"**Violaciones totales**: {total_violations}",
            f"**Cumplimiento promedio**: {avg_compliance:.1f}%",
            ""
        ])
        
        for result in results:
            report_lines.extend([
                f"### {Path(result['svg_path']).name}",
                "",
                f"**Cumplimiento**: {result['compliance']['percentage']:.1f}% ({result['compliance']['level']})",
                f"**Violaciones**: {result['total_violations']}",
                ""
            ])
            
            if result['violations']:
                report_lines.append("#### Violaciones:")
                for violation in result['violations']:
                    report_lines.append(
                        f"- **{violation.rule}** ({violation.impact}): {violation.description}"
                    )
                    report_lines.append(f"  [Ayuda]({violation.help_url})")
            
            report_lines.append("")
        
        return "\n".join(report_lines)

if __name__ == '__main__':
    import sys
    
    tester = AccessibilityTester(target_level='AA')
    
    # Testear todos los SVGs en source/
    source_dir = Path('source')
    svg_files = list(source_dir.rglob('*.svg'))
    
    results = []
    for svg_file in svg_files:
        print(f"Testeando {svg_file}...")
        result = tester.test_carousel_accessibility(svg_file)
        results.append(result)
    
    # Generar reporte
    report = tester.generate_report(results)
    
    report_path = Path('reports/accessibility_report.md')
    report_path.parent.mkdir(exist_ok=True)
    report_path.write_text(report)
    
    print(report)
    
    # Fallar si hay violaciones cr√≠ticas
    total_critical = sum(
        sum(1 for v in r['violations'] if v.impact == 'critical')
        for r in results
    )
    
    if total_critical > 0:
        print(f"\n‚ùå {total_critical} violaciones cr√≠ticas encontradas")
        sys.exit(1)
    else:
        print("\n‚úÖ Todas las pruebas de accesibilidad pasaron")
        sys.exit(0)
```

### Integraci√≥n en CI/CD

**GitHub Actions**: `.github/workflows/accessibility.yml`

```yaml
name: Accessibility Testing

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  accessibility:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install selenium axe-selenium-python beautifulsoup4
          # Instalar ChromeDriver
          sudo apt-get update
          sudo apt-get install -y chromium-chromedriver
      
      - name: Run accessibility tests
        run: |
          python scripts/accessibility_testing.py
      
      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: accessibility-report
          path: reports/accessibility_report.md
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('reports/accessibility_report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ‚ôø Accessibility Report\n\n\`\`\`\n${report}\n\`\`\``
            });
```

---

## üí¨ An√°lisis de Sentimiento y Automatizaci√≥n de Respuestas a Comentarios

### Script de An√°lisis y Respuesta Automatizada

**Python**: `scripts/comment_sentiment_automation.py`

```python
#!/usr/bin/env python3
"""
An√°lisis de sentimiento de comentarios en carruseles
y automatizaci√≥n de respuestas inteligentes
"""
import requests
import json
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import openai

class Sentiment(Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    QUESTION = "question"

class CommentIntent(Enum):
    INTEREST = "interest"
    OBJECTION = "objection"
    QUESTION = "question"
    COMPLAINT = "complaint"
    PRAISE = "praise"
    SPAM = "spam"

@dataclass
class CommentAnalysis:
    """An√°lisis de un comentario"""
    comment_id: str
    text: str
    sentiment: Sentiment
    intent: CommentIntent
    confidence: float
    urgency: int  # 1-5
    suggested_response: Optional[str] = None
    should_escalate: bool = False
    entities: List[str] = None

class CommentSentimentAnalyzer:
    """Analizador de sentimiento y generador de respuestas"""
    
    def __init__(self, openai_api_key: str):
        self.client = openai.OpenAI(api_key=openai_api_key)
        self.response_templates = self.load_templates()
    
    def analyze_comment(self, comment_text: str, context: Dict = None) -> CommentAnalysis:
        """Analiza un comentario y determina sentimiento, intenci√≥n y respuesta"""
        
        # An√°lisis con GPT-4
        prompt = f"""
        Analiza este comentario sobre un carrusel de marketing y proporciona:
        1. Sentimiento (positive, negative, neutral, question)
        2. Intenci√≥n (interest, objection, question, complaint, praise, spam)
        3. Urgencia (1-5, donde 5 es m√°s urgente)
        4. Si requiere escalaci√≥n a humano (true/false)
        5. Entidades mencionadas (productos, precios, caracter√≠sticas)
        
        Comentario: "{comment_text}"
        
        Contexto: {json.dumps(context or {})}
        
        Responde en formato JSON:
        {{
            "sentiment": "...",
            "intent": "...",
            "confidence": 0.0-1.0,
            "urgency": 1-5,
            "should_escalate": true/false,
            "entities": ["...", "..."],
            "reasoning": "..."
        }}
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un experto en an√°lisis de sentimiento y marketing digital."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        analysis_json = json.loads(response.choices[0].message.content)
        
        return CommentAnalysis(
            comment_id=context.get('comment_id', '') if context else '',
            text=comment_text,
            sentiment=Sentiment(analysis_json['sentiment']),
            intent=CommentIntent(analysis_json['intent']),
            confidence=analysis_json['confidence'],
            urgency=analysis_json['urgency'],
            should_escalate=analysis_json['should_escalate'],
            entities=analysis_json.get('entities', [])
        )
    
    def generate_response(self, analysis: CommentAnalysis, context: Dict = None) -> str:
        """Genera respuesta apropiada basada en an√°lisis"""
        
        # Seleccionar template base
        template = self.select_template(analysis.intent, analysis.sentiment)
        
        # Personalizar con GPT-4
        personalization_prompt = f"""
        Personaliza esta respuesta de template para este comentario espec√≠fico.
        Mant√©n el tono profesional pero cercano.
        
        Template: {template}
        Comentario original: "{analysis.text}"
        Entidades detectadas: {', '.join(analysis.entities or [])}
        
        Genera una respuesta personalizada y natural que:
        1. Aborde el comentario directamente
        2. Sea apropiada para el sentimiento ({analysis.sentiment.value})
        3. Maneje la intenci√≥n ({analysis.intent.value})
        4. Sea concisa (m√°ximo 200 palabras)
        5. Incluya CTA si es apropiado
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un community manager experto en responder comentarios en redes sociales."},
                {"role": "user", "content": personalization_prompt}
            ],
            temperature=0.7
        )
        
        return response.choices[0].message.content.strip()
    
    def select_template(self, intent: CommentIntent, sentiment: Sentiment) -> str:
        """Selecciona template base seg√∫n intenci√≥n y sentimiento"""
        templates = {
            (CommentIntent.INTEREST, Sentiment.POSITIVE): """
            ¬°Genial que te interese! Te env√≠o m√°s informaci√≥n por DM.
            Mientras tanto, puedes revisar [enlace] para conocer m√°s detalles.
            ¬øTe gustar√≠a agendar una demo?
            """,
            (CommentIntent.QUESTION, Sentiment.NEUTRAL): """
            Excelente pregunta. Te explico:
            [Respuesta espec√≠fica seg√∫n pregunta]
            Si necesitas m√°s detalles, escr√≠beme por DM.
            """,
            (CommentIntent.OBJECTION, Sentiment.NEGATIVE): """
            Entiendo tu preocupaci√≥n sobre [objeci√≥n]. Muchos clientes tuvieron la misma duda inicial.
            La buena noticia es que [soluci√≥n/beneficio]. ¬øTe gustar√≠a que te cuente c√≥mo funciona?
            """,
            (CommentIntent.COMPLAINT, Sentiment.NEGATIVE): """
            Lamento la mala experiencia. Nos importa mucho tu feedback.
            Voy a escalar esto a nuestro equipo para revisarlo.
            ¬øPuedes contarme m√°s detalles por DM para poder ayudarte mejor?
            """,
            (CommentIntent.PRAISE, Sentiment.POSITIVE): """
            ¬°Muchas gracias! Nos alegra saber que te est√° funcionando.
            Si tienes sugerencias o quieres compartir tu experiencia, siempre las recibimos.
            """,
            (CommentIntent.SPAM, Sentiment.NEUTRAL): """
            [No responder - marcar como spam]
            """
        }
        
        return templates.get((intent, sentiment), """
        Gracias por tu comentario. Si necesitas ayuda, escr√≠beme por DM.
        """)
    
    def load_templates(self) -> Dict:
        """Carga templates de respuesta desde archivo"""
        template_path = Path('config/comment_response_templates.json')
        
        if template_path.exists():
            with open(template_path) as f:
                return json.load(f)
        
        return {}

class CommentAutomation:
    """Automatizaci√≥n de respuestas a comentarios"""
    
    def __init__(self, analyzer: CommentSentimentAnalyzer, 
                 meta_access_token: str):
        self.analyzer = analyzer
        self.meta_access_token = meta_access_token
        self.api_base = "https://graph.facebook.com/v18.0"
    
    def fetch_carousel_comments(self, post_id: str) -> List[Dict]:
        """Obtiene comentarios de un post de carrusel"""
        url = f"{self.api_base}/{post_id}/comments"
        params = {
            'access_token': self.meta_access_token,
            'fields': 'id,message,from,created_time,like_count'
        }
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        
        return response.json().get('data', [])
    
    def process_comments(self, post_id: str, auto_respond: bool = False):
        """Procesa todos los comentarios de un post"""
        comments = self.fetch_carousel_comments(post_id)
        
        results = []
        
        for comment in comments:
            # Analizar comentario
            analysis = self.analyzer.analyze_comment(
                comment['message'],
                context={
                    'comment_id': comment['id'],
                    'post_id': post_id,
                    'author': comment['from'].get('name', ''),
                    'created_time': comment['created_time']
                }
            )
            
            # Generar respuesta si aplica
            if auto_respond and not analysis.should_escalate:
                if analysis.intent != CommentIntent.SPAM:
                    response_text = self.analyzer.generate_response(analysis)
                    
                    # Enviar respuesta
                    if auto_respond:
                        self.post_reply(comment['id'], response_text)
            
            results.append({
                'comment': comment,
                'analysis': analysis,
                'responded': auto_respond and not analysis.should_escalate
            })
        
        return results
    
    def post_reply(self, comment_id: str, message: str):
        """Publica respuesta a un comentario"""
        url = f"{self.api_base}/{comment_id}/comments"
        data = {
            'message': message,
            'access_token': self.meta_access_token
        }
        
        response = requests.post(url, data=data)
        response.raise_for_status()
        
        return response.json()
    
    def escalate_comment(self, comment_id: str, reason: str):
        """Escala comentario para revisi√≥n manual"""
        # Crear tarea en CRM o sistema de tickets
        escalation = {
            'comment_id': comment_id,
            'reason': reason,
            'timestamp': datetime.now().isoformat(),
            'status': 'pending_review'
        }
        
        # Guardar en sistema de escalaci√≥n
        escalation_path = Path('logs/escalations.jsonl')
        escalation_path.parent.mkdir(exist_ok=True)
        
        with open(escalation_path, 'a') as f:
            f.write(json.dumps(escalation) + '\n')
        
        return escalation

if __name__ == '__main__':
    import os
    
    analyzer = CommentSentimentAnalyzer(os.getenv('OPENAI_API_KEY'))
    automation = CommentAutomation(
        analyzer,
        os.getenv('META_ACCESS_TOKEN')
    )
    
    # Procesar comentarios de un post
    post_id = os.getenv('CAROUSEL_POST_ID')
    results = automation.process_comments(post_id, auto_respond=False)
    
    # Guardar resultados
    output_path = Path('reports/comment_analysis.json')
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"‚úÖ Procesados {len(results)} comentarios")
```

### Integraci√≥n con Meta API y CRM

**Python**: `scripts/integrate_comment_automation.py`

```python
#!/usr/bin/env python3
"""
Integraci√≥n completa de automatizaci√≥n de comentarios
con Meta API, CRM y sistema de notificaciones
"""
from comment_sentiment_automation import CommentAutomation, CommentSentimentAnalyzer
import requests
import json
from datetime import datetime

class CommentAutomationPipeline:
    """Pipeline completo de automatizaci√≥n de comentarios"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.analyzer = CommentSentimentAnalyzer(config['openai_api_key'])
        self.automation = CommentAutomation(
            self.analyzer,
            config['meta_access_token']
        )
    
    def run_hourly_processing(self):
        """Ejecuta procesamiento horario de comentarios"""
        # Obtener posts de carruseles activos
        active_posts = self.get_active_carousel_posts()
        
        for post in active_posts:
            # Procesar comentarios
            results = self.automation.process_comments(
                post['id'],
                auto_respond=self.config.get('auto_respond', False)
            )
            
            # Integrar con CRM
            for result in results:
                if result['analysis'].intent.value == 'interest':
                    self.create_crm_lead(result)
                
                if result['analysis'].should_escalate:
                    self.automation.escalate_comment(
                        result['comment']['id'],
                        f"Urgencia: {result['analysis'].urgency}/5"
                    )
            
            # Enviar notificaciones si hay escalaciones
            escalations = [r for r in results if r['analysis'].should_escalate]
            if escalations:
                self.send_escalation_notification(escalations)
    
    def get_active_carousel_posts(self) -> List[Dict]:
        """Obtiene posts activos de carruseles"""
        # Consultar desde base de datos o API
        # Por ahora, retorna estructura de ejemplo
        return [
            {'id': 'post_123', 'carousel_id': 'curso_ia_slide1'},
            {'id': 'post_456', 'carousel_id': 'saas_marketing_slide2'}
        ]
    
    def create_crm_lead(self, comment_result: Dict):
        """Crea lead en CRM basado en comentario de inter√©s"""
        lead_data = {
            'first_name': comment_result['comment']['from'].get('name', '').split()[0],
            'source': 'instagram_carousel_comment',
            'lead_score': 8,  # Alto por comentario directo
            'notes': f"Comentario: {comment_result['comment']['message']}",
            'utm_content': f"comment_{comment_result['comment']['id']}"
        }
        
        # Integrar con HubSpot/Pipedrive
        # Implementaci√≥n espec√≠fica seg√∫n CRM
        print(f"Creating lead: {lead_data}")
    
    def send_escalation_notification(self, escalations: List[Dict]):
        """Env√≠a notificaci√≥n de escalaciones"""
        # Enviar a Slack/Discord/Email
        message = f"‚ö†Ô∏è {len(escalations)} comentarios requieren revisi√≥n manual"
        
        # Implementar env√≠o
        print(message)

if __name__ == '__main__':
    import os
    
    config = {
        'openai_api_key': os.getenv('OPENAI_API_KEY'),
        'meta_access_token': os.getenv('META_ACCESS_TOKEN'),
        'auto_respond': os.getenv('AUTO_RESPOND', 'false').lower() == 'true'
    }
    
    pipeline = CommentAutomationPipeline(config)
    pipeline.run_hourly_processing()
```

---

## üíæ Sistema de Backup y Versionado de Assets

### Script de Backup Automatizado

**Python**: `scripts/asset_backup_versioning.py`

```python
#!/usr/bin/env python3
"""
Sistema de backup y versionado autom√°tico de assets de carruseles
Incluye versionado sem√°ntico, snapshots, y recuperaci√≥n
"""
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import hashlib
import tarfile

class AssetVersioning:
    """Sistema de versionado de assets"""
    
    def __init__(self, source_dir: Path, backup_dir: Path):
        self.source_dir = Path(source_dir)
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.manifest_path = self.backup_dir / 'backup_manifest.json'
    
    def create_backup(self, version: str = None) -> str:
        """Crea backup completo de assets"""
        if not version:
            version = self.generate_version()
        
        backup_path = self.backup_dir / f"backup_{version}"
        backup_path.mkdir(exist_ok=True)
        
        # Copiar assets
        asset_files = list(self.source_dir.rglob('*'))
        
        for file_path in asset_files:
            if file_path.is_file():
                rel_path = file_path.relative_to(self.source_dir)
                dest_path = backup_path / rel_path
                dest_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file_path, dest_path)
        
        # Crear tarball
        tarball_path = self.backup_dir / f"backup_{version}.tar.gz"
        with tarfile.open(tarball_path, 'w:gz') as tar:
            tar.add(backup_path, arcname=backup_path.name)
        
        # Actualizar manifest
        manifest = self.load_manifest()
        manifest['backups'].append({
            'version': version,
            'timestamp': datetime.now().isoformat(),
            'path': str(backup_path),
            'tarball': str(tarball_path),
            'file_count': len(asset_files),
            'total_size': self.calculate_size(backup_path)
        })
        self.save_manifest(manifest)
        
        return version
    
    def restore_backup(self, version: str, target_dir: Path = None):
        """Restaura backup desde una versi√≥n"""
        manifest = self.load_manifest()
        
        backup_info = next(
            (b for b in manifest['backups'] if b['version'] == version),
            None
        )
        
        if not backup_info:
            raise ValueError(f"Backup {version} no encontrado")
        
        tarball_path = Path(backup_info['tarball'])
        
        if not tarball_path.exists():
            raise FileNotFoundError(f"Tarball {tarball_path} no existe")
        
        restore_dir = target_dir or self.source_dir
        restore_dir = Path(restore_dir)
        
        # Extraer tarball
        with tarfile.open(tarball_path, 'r:gz') as tar:
            tar.extractall(self.backup_dir / 'temp_restore')
        
        # Copiar archivos restaurados
        temp_restore = self.backup_dir / 'temp_restore' / f"backup_{version}"
        for file_path in temp_restore.rglob('*'):
            if file_path.is_file():
                rel_path = file_path.relative_to(temp_restore)
                dest_path = restore_dir / rel_path
                dest_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file_path, dest_path)
        
        # Limpiar temp
        shutil.rmtree(self.backup_dir / 'temp_restore')
    
    def generate_version(self) -> str:
        """Genera versi√≥n sem√°ntica basada en fecha y cambios"""
        from datetime import datetime
        date_part = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Detectar cambios significativos
        changes = self.detect_changes()
        
        if changes['major']:
            version_type = 'major'
        elif changes['minor']:
            version_type = 'minor'
        else:
            version_type = 'patch'
        
        return f"{date_part}_{version_type}"
    
    def detect_changes(self) -> Dict:
        """Detecta tipo de cambios en assets"""
        manifest = self.load_manifest()
        
        if not manifest['backups']:
            return {'major': True, 'minor': False, 'patch': False}
        
        # Comparar con √∫ltimo backup
        last_backup = manifest['backups'][-1]
        current_hash = self.calculate_directory_hash(self.source_dir)
        
        # Hash del √∫ltimo backup (si existe)
        if last_backup:
            # Simplificado: detectar cambios por conteo de archivos
            current_files = len(list(self.source_dir.rglob('*')))
            last_files = last_backup.get('file_count', 0)
            
            if abs(current_files - last_files) > 10:
                return {'major': True, 'minor': False, 'patch': False}
            elif abs(current_files - last_files) > 0:
                return {'major': False, 'minor': True, 'patch': False}
        
        return {'major': False, 'minor': False, 'patch': True}
    
    def calculate_directory_hash(self, directory: Path) -> str:
        """Calcula hash de directorio"""
        hasher = hashlib.sha256()
        
        for file_path in sorted(directory.rglob('*')):
            if file_path.is_file():
                hasher.update(str(file_path.relative_to(directory)).encode())
                hasher.update(file_path.read_bytes())
        
        return hasher.hexdigest()
    
    def calculate_size(self, directory: Path) -> int:
        """Calcula tama√±o total de directorio"""
        total = 0
        for file_path in directory.rglob('*'):
            if file_path.is_file():
                total += file_path.stat().st_size
        return total
    
    def load_manifest(self) -> Dict:
        """Carga manifest de backups"""
        if self.manifest_path.exists():
            with open(self.manifest_path) as f:
                return json.load(f)
        return {'backups': []}
    
    def save_manifest(self, manifest: Dict):
        """Guarda manifest de backups"""
        with open(self.manifest_path, 'w') as f:
            json.dump(manifest, f, indent=2)
    
    def list_backups(self) -> List[Dict]:
        """Lista todos los backups disponibles"""
        manifest = self.load_manifest()
        return manifest['backups']
    
    def cleanup_old_backups(self, keep_last_n: int = 30):
        """Limpia backups antiguos, mantiene √∫ltimos N"""
        manifest = self.load_manifest()
        backups = manifest['backups']
        
        if len(backups) <= keep_last_n:
            return
        
        # Ordenar por timestamp
        backups_sorted = sorted(backups, key=lambda x: x['timestamp'], reverse=True)
        
        # Mantener √∫ltimos N
        to_keep = backups_sorted[:keep_last_n]
        to_delete = backups_sorted[keep_last_n:]
        
        # Eliminar backups antiguos
        for backup in to_delete:
            backup_path = Path(backup['path'])
            tarball_path = Path(backup['tarball'])
            
            if backup_path.exists():
                shutil.rmtree(backup_path)
            if tarball_path.exists():
                tarball_path.unlink()
        
        # Actualizar manifest
        manifest['backups'] = to_keep
        self.save_manifest(manifest)

if __name__ == '__main__':
    import sys
    
    versioning = AssetVersioning(
        source_dir=Path('source'),
        backup_dir=Path('backups/assets')
    )
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == 'backup':
            version = versioning.create_backup()
            print(f"‚úÖ Backup creado: {version}")
        
        elif command == 'restore':
            if len(sys.argv) < 3:
                print("Uso: restore <version>")
                sys.exit(1)
            version = sys.argv[2]
            versioning.restore_backup(version)
            print(f"‚úÖ Backup restaurado: {version}")
        
        elif command == 'list':
            backups = versioning.list_backups()
            for backup in backups:
                print(f"{backup['version']}: {backup['timestamp']}")
        
        elif command == 'cleanup':
            versioning.cleanup_old_backups()
            print("‚úÖ Limpieza completada")
    else:
        print("Uso: asset_backup_versioning.py [backup|restore|list|cleanup]")
```

---

## üñºÔ∏è Optimizaci√≥n de Im√°genes con IA (Compresi√≥n Inteligente)

### Script de Optimizaci√≥n Avanzada de Im√°genes

**Python**: `scripts/ai_image_optimization.py`

```python
#!/usr/bin/env python3
"""
Optimizaci√≥n inteligente de im√°genes con IA
- Reducci√≥n de peso manteniendo calidad visual
- Conversi√≥n autom√°tica a formatos modernos (WebP, AVIF)
- Upscaling con IA cuando es necesario
- Detecci√≥n autom√°tica de elementos a optimizar
"""
from PIL import Image
import io
import os
from pathlib import Path
from typing import Dict, Tuple, Optional
import subprocess
import json

class AIImageOptimizer:
    """Optimizador de im√°genes con IA"""
    
    def __init__(self):
        self.quality_targets = {
            'jpg': {'max_size_kb': 150, 'quality': 85},
            'png': {'max_size_kb': 200, 'quality': 90},
            'webp': {'max_size_kb': 100, 'quality': 85},
            'avif': {'max_size_kb': 80, 'quality': 75}
        }
    
    def optimize_image(self, image_path: Path, target_format: str = 'webp',
                      max_size_kb: Optional[int] = None) -> Dict:
        """Optimiza una imagen con IA"""
        
        img = Image.open(image_path)
        original_size = image_path.stat().st_size / 1024  # KB
        
        # Detectar tipo de imagen
        image_type = self.detect_image_type(img)
        
        # Ajustar calidad seg√∫n tipo
        if max_size_kb is None:
            max_size_kb = self.quality_targets.get(target_format, {}).get('max_size_kb', 150)
        
        # Optimizaci√≥n iterativa
        quality = 90
        min_quality = 60
        optimized_path = image_path.with_suffix(f'.{target_format}')
        
        best_result = None
        
        while quality >= min_quality:
            # Optimizar con calidad actual
            result = self.compress_image(
                img, optimized_path, target_format, quality, max_size_kb
            )
            
            if result['success']:
                best_result = result
                if result['size_kb'] <= max_size_kb:
                    break
            
            quality -= 5
        
        if not best_result:
            # Si no se logra optimizar, mantener original
            best_result = {
                'success': False,
                'original_size_kb': original_size,
                'optimized_size_kb': original_size,
                'compression_ratio': 0
            }
        
        return {
            'original_path': str(image_path),
            'optimized_path': str(optimized_path),
            'original_size_kb': original_size,
            'optimized_size_kb': best_result.get('size_kb', original_size),
            'compression_ratio': (1 - best_result.get('size_kb', original_size) / original_size) * 100,
            'format': target_format,
            'success': best_result.get('success', False)
        }
    
    def compress_image(self, img: Image.Image, output_path: Path,
                      format: str, quality: int, max_size_kb: int) -> Dict:
        """Comprime imagen con calidad espec√≠fica"""
        
        # Convertir formato si es necesario
        if format == 'webp':
            img.save(output_path, 'WEBP', quality=quality, method=6)
        elif format == 'avif':
            # Requiere pillow-avif-plugin o usar subprocess
            try:
                img.save(output_path, 'AVIF', quality=quality)
            except:
                # Fallback a WebP si AVIF no est√° disponible
                output_path = output_path.with_suffix('.webp')
                img.save(output_path, 'WEBP', quality=quality, method=6)
        elif format == 'jpg':
            # Convertir RGBA a RGB si es necesario
            if img.mode == 'RGBA':
                background = Image.new('RGB', img.size, (255, 255, 255))
                background.paste(img, mask=img.split()[3])
                img = background
            img.save(output_path, 'JPEG', quality=quality, optimize=True)
        else:
            img.save(output_path, format.upper(), quality=quality, optimize=True)
        
        size_kb = output_path.stat().st_size / 1024
        
        return {
            'success': size_kb <= max_size_kb * 1.1,  # 10% de tolerancia
            'size_kb': size_kb,
            'quality_used': quality
        }
    
    def detect_image_type(self, img: Image.Image) -> str:
        """Detecta tipo de imagen (foto, ilustraci√≥n, texto)"""
        # An√°lisis b√°sico: transparencia, colores, etc.
        has_alpha = img.mode in ('RGBA', 'LA') or 'transparency' in img.info
        
        # Contar colores √∫nicos (simplificado)
        colors = img.getcolors(maxcolors=256)
        
        if has_alpha:
            return 'illustration'
        elif colors and len(colors) < 50:
            return 'logo_or_text'
        else:
            return 'photo'
    
    def batch_optimize(self, directory: Path, target_format: str = 'webp') -> Dict:
        """Optimiza todas las im√°genes en un directorio"""
        results = []
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}
        
        for file_path in directory.rglob('*'):
            if file_path.suffix.lower() in image_extensions:
                print(f"Optimizando {file_path}...")
                result = self.optimize_image(file_path, target_format)
                results.append(result)
        
        # Resumen
        total_original = sum(r['original_size_kb'] for r in results)
        total_optimized = sum(r['optimized_size_kb'] for r in results)
        total_saved = total_original - total_optimized
        
        return {
            'total_images': len(results),
            'total_original_size_kb': total_original,
            'total_optimized_size_kb': total_optimized,
            'total_saved_kb': total_saved,
            'compression_ratio': (total_saved / total_original * 100) if total_original > 0 else 0,
            'results': results
        }

if __name__ == '__main__':
    import sys
    
    optimizer = AIImageOptimizer()
    
    if len(sys.argv) < 2:
        print("Uso: ai_image_optimization.py <directorio|archivo> [formato]")
        sys.exit(1)
    
    target = Path(sys.argv[1])
    format = sys.argv[2] if len(sys.argv) > 2 else 'webp'
    
    if target.is_file():
        result = optimizer.optimize_image(target, format)
        print(json.dumps(result, indent=2))
    else:
        results = optimizer.batch_optimize(target, format)
        print(f"\n‚úÖ Optimizadas {results['total_images']} im√°genes")
        print(f"Tama√±o original: {results['total_original_size_kb']:.1f} KB")
        print(f"Tama√±o optimizado: {results['total_optimized_size_kb']:.1f} KB")
        print(f"Ahorro: {results['total_saved_kb']:.1f} KB ({results['compression_ratio']:.1f}%)")
```

---

## üì¢ Sistema de Notificaciones Avanzado (Multi-Canal)

### Script de Notificaciones Multi-Plataforma

**Python**: `scripts/advanced_notifications.py`

```python
#!/usr/bin/env python3
"""
Sistema de notificaciones avanzado multi-canal
- Slack, Discord, Telegram, Email, SMS
- Triage inteligente de urgencia
- Templates personalizables
- Rate limiting y deduplicaci√≥n
"""
import requests
import json
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum

class NotificationUrgency(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class NotificationChannel(Enum):
    SLACK = "slack"
    DISCORD = "discord"
    TELEGRAM = "telegram"
    EMAIL = "email"
    SMS = "sms"

@dataclass
class Notification:
    """Notificaci√≥n"""
    title: str
    message: str
    urgency: NotificationUrgency
    channels: List[NotificationChannel]
    metadata: Dict = None
    timestamp: str = None
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()

class NotificationManager:
    """Gestor de notificaciones multi-canal"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.sent_notifications = []  # Para deduplicaci√≥n
        
    def send_notification(self, notification: Notification):
        """Env√≠a notificaci√≥n a m√∫ltiples canales"""
        results = {}
        
        # Deduplicaci√≥n
        if self.is_duplicate(notification):
            return {'status': 'skipped', 'reason': 'duplicate'}
        
        for channel in notification.channels:
            try:
                result = self.send_to_channel(notification, channel)
                results[channel.value] = result
            except Exception as e:
                results[channel.value] = {'status': 'error', 'error': str(e)}
        
        # Registrar como enviada
        self.sent_notifications.append({
            'notification': notification,
            'results': results,
            'timestamp': datetime.now().isoformat()
        })
        
        return results
    
    def send_to_channel(self, notification: Notification, channel: NotificationChannel) -> Dict:
        """Env√≠a a un canal espec√≠fico"""
        if channel == NotificationChannel.SLACK:
            return self.send_slack(notification)
        elif channel == NotificationChannel.DISCORD:
            return self.send_discord(notification)
        elif channel == NotificationChannel.TELEGRAM:
            return self.send_telegram(notification)
        elif channel == NotificationChannel.EMAIL:
            return self.send_email(notification)
        elif channel == NotificationChannel.SMS:
            return self.send_sms(notification)
    
    def send_slack(self, notification: Notification) -> Dict:
        """Env√≠a notificaci√≥n a Slack"""
        webhook_url = self.config['slack']['webhook_url']
        
        # Color seg√∫n urgencia
        color_map = {
            NotificationUrgency.LOW: '#36a64f',
            NotificationUrgency.MEDIUM: '#ffaa00',
            NotificationUrgency.HIGH: '#ff6b6b',
            NotificationUrgency.CRITICAL: '#c92a2a'
        }
        
        payload = {
            'attachments': [{
                'color': color_map.get(notification.urgency, '#36a64f'),
                'title': notification.title,
                'text': notification.message,
                'footer': 'Carruseles Sociales',
                'ts': int(datetime.now().timestamp())
            }]
        }
        
        response = requests.post(webhook_url, json=payload)
        response.raise_for_status()
        
        return {'status': 'sent', 'channel': 'slack'}
    
    def send_discord(self, notification: Notification) -> Dict:
        """Env√≠a notificaci√≥n a Discord"""
        webhook_url = self.config['discord']['webhook_url']
        
        # Embed de Discord
        color_map = {
            NotificationUrgency.LOW: 3066993,  # Green
            NotificationUrgency.MEDIUM: 16776960,  # Yellow
            NotificationUrgency.HIGH: 16711680,  # Red
            NotificationUrgency.CRITICAL: 9109504  # Dark Red
        }
        
        payload = {
            'embeds': [{
                'title': notification.title,
                'description': notification.message,
                'color': color_map.get(notification.urgency, 3066993),
                'timestamp': notification.timestamp
            }]
        }
        
        response = requests.post(webhook_url, json=payload)
        response.raise_for_status()
        
        return {'status': 'sent', 'channel': 'discord'}
    
    def send_telegram(self, notification: Notification) -> Dict:
        """Env√≠a notificaci√≥n a Telegram"""
        bot_token = self.config['telegram']['bot_token']
        chat_id = self.config['telegram']['chat_id']
        
        # Emoji seg√∫n urgencia
        emoji_map = {
            NotificationUrgency.LOW: '‚ÑπÔ∏è',
            NotificationUrgency.MEDIUM: '‚ö†Ô∏è',
            NotificationUrgency.HIGH: 'üî¥',
            NotificationUrgency.CRITICAL: 'üö®'
        }
        
        message = f"{emoji_map.get(notification.urgency, '‚ÑπÔ∏è')} *{notification.title}*\n\n{notification.message}"
        
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        params = {
            'chat_id': chat_id,
            'text': message,
            'parse_mode': 'Markdown'
        }
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        
        return {'status': 'sent', 'channel': 'telegram'}
    
    def send_email(self, notification: Notification) -> Dict:
        """Env√≠a notificaci√≥n por email"""
        import smtplib
        from email.mime.text import MIMEText
        from email.mime.multipart import MIMEMultipart
        
        smtp_config = self.config['email']
        
        msg = MIMEMultipart()
        msg['From'] = smtp_config['from']
        msg['To'] = ', '.join(smtp_config['to'])
        msg['Subject'] = notification.title
        
        body = notification.message
        msg.attach(MIMEText(body, 'plain'))
        
        with smtplib.SMTP(smtp_config['smtp_server'], smtp_config['smtp_port']) as server:
            server.starttls()
            server.login(smtp_config['username'], smtp_config['password'])
            server.send_message(msg)
        
        return {'status': 'sent', 'channel': 'email'}
    
    def send_sms(self, notification: Notification) -> Dict:
        """Env√≠a notificaci√≥n por SMS (usando Twilio o similar)"""
        # Implementaci√≥n con Twilio
        from twilio.rest import Client
        
        twilio_config = self.config['sms']
        client = Client(twilio_config['account_sid'], twilio_config['auth_token'])
        
        message = client.messages.create(
            body=f"{notification.title}: {notification.message}",
            from_=twilio_config['from_number'],
            to=twilio_config['to_number']
        )
        
        return {'status': 'sent', 'channel': 'sms', 'message_sid': message.sid}
    
    def is_duplicate(self, notification: Notification, window_minutes: int = 5) -> bool:
        """Verifica si la notificaci√≥n es duplicada"""
        cutoff = datetime.now().timestamp() - (window_minutes * 60)
        
        for sent in self.sent_notifications:
            sent_time = datetime.fromisoformat(sent['timestamp']).timestamp()
            
            if sent_time > cutoff:
                if (sent['notification'].title == notification.title and
                    sent['notification'].message == notification.message):
                    return True
        
        return False

# Ejemplos de uso
if __name__ == '__main__':
    import os
    
    config = {
        'slack': {'webhook_url': os.getenv('SLACK_WEBHOOK')},
        'discord': {'webhook_url': os.getenv('DISCORD_WEBHOOK')},
        'telegram': {
            'bot_token': os.getenv('TELEGRAM_BOT_TOKEN'),
            'chat_id': os.getenv('TELEGRAM_CHAT_ID')
        },
        'email': {
            'smtp_server': os.getenv('SMTP_SERVER'),
            'smtp_port': int(os.getenv('SMTP_PORT', 587)),
            'username': os.getenv('SMTP_USERNAME'),
            'password': os.getenv('SMTP_PASSWORD'),
            'from': os.getenv('EMAIL_FROM'),
            'to': [os.getenv('EMAIL_TO')]
        }
    }
    
    manager = NotificationManager(config)
    
    # Ejemplo: Notificaci√≥n de bajo performance
    notification = Notification(
        title="‚ö†Ô∏è Bajo Performance en Carrusel",
        message="El carrusel 'curso_ia_slide1' tiene CTR < 1%. Revisar.",
        urgency=NotificationUrgency.HIGH,
        channels=[NotificationChannel.SLACK, NotificationChannel.EMAIL]
    )
    
    results = manager.send_notification(notification)
    print(json.dumps(results, indent=2))
```

---

## üîç An√°lisis de Competidores Automatizado

### Script de Monitoreo y An√°lisis de Competidores

**Python**: `scripts/competitor_analysis.py`

```python
#!/usr/bin/env python3
"""
An√°lisis automatizado de competidores
- Monitoreo de publicaciones en redes sociales
- An√°lisis de copy, visuales, hashtags
- Detecci√≥n de tendencias y gaps
- Recomendaciones de mejoras
"""
import requests
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class CompetitorPost:
    """Post de competidor"""
    id: str
    platform: str
    text: str
    hashtags: List[str]
    engagement: Dict
    timestamp: str
    image_url: Optional[str] = None

class CompetitorAnalyzer:
    """Analizador de competidores"""
    
    def __init__(self, competitors: List[Dict]):
        self.competitors = competitors
        self.api_base = "https://graph.facebook.com/v18.0"
    
    def fetch_competitor_posts(self, competitor_page_id: str, limit: int = 20) -> List[CompetitorPost]:
        """Obtiene posts recientes de un competidor"""
        url = f"{self.api_base}/{competitor_page_id}/posts"
        params = {
            'fields': 'id,message,created_time,shares,likes.summary(true),comments.summary(true)',
            'limit': limit
        }
        
        # En producci√≥n, usar access token v√°lido
        # response = requests.get(url, params=params)
        # data = response.json()
        
        # Simulaci√≥n
        posts = []
        return posts
    
    def analyze_copy(self, posts: List[CompetitorPost]) -> Dict:
        """Analiza copy de competidores"""
        all_text = ' '.join([post.text for post in posts])
        
        # Extraer palabras clave m√°s comunes
        from collections import Counter
        import re
        
        words = re.findall(r'\b\w+\b', all_text.lower())
        word_freq = Counter(words)
        
        # Filtrar palabras comunes
        stop_words = {'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'es', 'se', 'no', 'te', 'lo', 'le', 'da', 'su', 'por', 'son', 'con', 'para'}
        keywords = {word: count for word, count in word_freq.items() 
                   if word not in stop_words and len(word) > 4}
        
        return {
            'top_keywords': dict(word_freq.most_common(20)),
            'avg_post_length': sum(len(post.text) for post in posts) / len(posts) if posts else 0,
            'common_phrases': self.extract_phrases(all_text)
        }
    
    def analyze_hashtags(self, posts: List[CompetitorPost]) -> Dict:
        """Analiza hashtags de competidores"""
        all_hashtags = []
        for post in posts:
            all_hashtags.extend(post.hashtags)
        
        from collections import Counter
        hashtag_freq = Counter(all_hashtags)
        
        return {
            'most_used': dict(hashtag_freq.most_common(20)),
            'avg_per_post': len(all_hashtags) / len(posts) if posts else 0,
            'total_unique': len(set(all_hashtags))
        }
    
    def analyze_engagement(self, posts: List[CompetitorPost]) -> Dict:
        """Analiza engagement de posts"""
        if not posts:
            return {}
        
        total_likes = sum(p.engagement.get('likes', 0) for p in posts)
        total_comments = sum(p.engagement.get('comments', 0) for p in posts)
        total_shares = sum(p.engagement.get('shares', 0) for p in posts)
        
        avg_engagement = (total_likes + total_comments * 2 + total_shares * 3) / len(posts)
        
        return {
            'avg_likes': total_likes / len(posts),
            'avg_comments': total_comments / len(posts),
            'avg_shares': total_shares / len(posts),
            'avg_total_engagement': avg_engagement,
            'best_performing': max(posts, key=lambda p: sum(p.engagement.values())).id
        }
    
    def extract_phrases(self, text: str, min_words: int = 2, max_words: int = 4) -> List[str]:
        """Extrae frases comunes"""
        import re
        from collections import Counter
        
        words = re.findall(r'\b\w+\b', text.lower())
        phrases = []
        
        for i in range(len(words) - max_words + 1):
            for length in range(min_words, max_words + 1):
                phrase = ' '.join(words[i:i+length])
                phrases.append(phrase)
        
        phrase_freq = Counter(phrases)
        return [phrase for phrase, count in phrase_freq.most_common(30) if count >= 3]
    
    def generate_recommendations(self, analysis: Dict) -> List[str]:
        """Genera recomendaciones basadas en an√°lisis"""
        recommendations = []
        
        # An√°lisis de keywords
        if analysis.get('copy_analysis'):
            top_keywords = list(analysis['copy_analysis']['top_keywords'].keys())[:10]
            recommendations.append(
                f"Considerar usar estas keywords que funcionan en competencia: {', '.join(top_keywords[:5])}"
            )
        
        # An√°lisis de hashtags
        if analysis.get('hashtag_analysis'):
            most_used = list(analysis['hashtag_analysis']['most_used'].keys())[:10]
            recommendations.append(
                f"Hashtags populares en competencia: {', '.join(most_used[:5])}"
            )
        
        # Engagement
        if analysis.get('engagement_analysis'):
            avg_engagement = analysis['engagement_analysis']['avg_total_engagement']
            recommendations.append(
                f"Engagement promedio de competidores: {avg_engagement:.1f}. Objetivo: superar este n√∫mero."
            )
        
        return recommendations
    
    def run_analysis(self, competitor_id: str) -> Dict:
        """Ejecuta an√°lisis completo de un competidor"""
        posts = self.fetch_competitor_posts(competitor_id)
        
        analysis = {
            'competitor_id': competitor_id,
            'posts_analyzed': len(posts),
            'copy_analysis': self.analyze_copy(posts),
            'hashtag_analysis': self.analyze_hashtags(posts),
            'engagement_analysis': self.analyze_engagement(posts),
            'timestamp': datetime.now().isoformat()
        }
        
        analysis['recommendations'] = self.generate_recommendations(analysis)
        
        return analysis

if __name__ == '__main__':
    analyzer = CompetitorAnalyzer([
        {'id': 'competitor_1', 'name': 'Competitor A'},
        {'id': 'competitor_2', 'name': 'Competitor B'}
    ])
    
    # Analizar competidor
    result = analyzer.run_analysis('competitor_1')
    
    print(json.dumps(result, indent=2, ensure_ascii=False))
```

---

## üè∑Ô∏è Optimizaci√≥n de Hashtags con IA

### Script de An√°lisis y Sugerencia de Hashtags

**Python**: `scripts/hashtag_optimizer.py`

```python
#!/usr/bin/env python3
"""
Optimizaci√≥n de hashtags con IA
- An√°lisis de hashtags por industria/producto
- Sugerencias basadas en trending topics
- Optimizaci√≥n de volumen vs engagement
- A/B testing de combinaciones
"""
import openai
from typing import List, Dict
from dataclasses import dataclass
import json

@dataclass
class HashtagSuggestion:
    """Sugerencia de hashtag"""
    hashtag: str
    estimated_reach: int
    competition_level: str  # low, medium, high
    relevance_score: float
    category: str

class HashtagOptimizer:
    """Optimizador de hashtags con IA"""
    
    def __init__(self, openai_api_key: str):
        self.client = openai.OpenAI(api_key=openai_api_key)
        self.industry_keywords = {
            'curso_ia': ['IA', 'InteligenciaArtificial', 'AprendizajeAutomatico', 'DataScience'],
            'saas_marketing': ['MarTech', 'SaaS', 'MarketingAutomation', 'GrowthHacking'],
            'ia_bulk': ['IA', 'Automatizacion', 'Productividad', 'HerramientasIA']
        }
    
    def generate_hashtags(self, product: str, content_description: str, 
                         num_suggestions: int = 30) -> List[HashtagSuggestion]:
        """Genera hashtags optimizados con GPT-4"""
        
        prompt = f"""
        Genera {num_suggestions} hashtags optimizados para redes sociales (Instagram/LinkedIn) 
        basados en esta informaci√≥n:
        
        Producto: {product}
        Descripci√≥n del contenido: {content_description}
        Keywords de industria: {', '.join(self.industry_keywords.get(product, []))}
        
        Para cada hashtag, proporciona:
        1. El hashtag (sin #)
        2. Estimaci√≥n de alcance (bajo: <100k, medio: 100k-1M, alto: >1M)
        3. Nivel de competencia (low, medium, high)
        4. Score de relevancia (0-1)
        5. Categor√≠a (main, niche, trending, community)
        
        Responde en formato JSON:
        {{
            "hashtags": [
                {{
                    "hashtag": "...",
                    "estimated_reach": "...",
                    "competition_level": "...",
                    "relevance_score": 0.0-1.0,
                    "category": "..."
                }}
            ]
        }}
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un experto en marketing digital y optimizaci√≥n de hashtags para redes sociales."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        result_json = json.loads(response.choices[0].message.content)
        
        suggestions = []
        for item in result_json.get('hashtags', []):
            suggestions.append(HashtagSuggestion(
                hashtag=item['hashtag'],
                estimated_reach=self.parse_reach(item.get('estimated_reach', 'medio')),
                competition_level=item.get('competition_level', 'medium'),
                relevance_score=float(item.get('relevance_score', 0.5)),
                category=item.get('category', 'main')
            ))
        
        return suggestions
    
    def parse_reach(self, reach_str: str) -> int:
        """Parsea estimaci√≥n de alcance a n√∫mero"""
        reach_map = {
            'bajo': 50000,
            'medio': 500000,
            'alto': 2000000,
            'low': 50000,
            'medium': 500000,
            'high': 2000000
        }
        return reach_map.get(reach_str.lower(), 500000)
    
    def optimize_hashtag_set(self, suggestions: List[HashtagSuggestion],
                            target_count: int = 20) -> List[str]:
        """Optimiza conjunto de hashtags para mejor balance"""
        
        # Estrategia: 40% main, 30% niche, 20% trending, 10% community
        strategy = {
            'main': int(target_count * 0.4),
            'niche': int(target_count * 0.3),
            'trending': int(target_count * 0.2),
            'community': int(target_count * 0.1)
        }
        
        optimized = []
        
        # Seleccionar mejores de cada categor√≠a
        by_category = {}
        for suggestion in suggestions:
            category = suggestion.category
            if category not in by_category:
                by_category[category] = []
            by_category[category].append(suggestion)
        
        for category, count in strategy.items():
            category_hashtags = by_category.get(category, [])
            # Ordenar por relevancia * reach estimado
            category_hashtags.sort(
                key=lambda x: x.relevance_score * x.estimated_reach,
                reverse=True
            )
            
            optimized.extend([h.hashtag for h in category_hashtags[:count]])
        
        # Si no alcanzamos el target, llenar con mejores generales
        if len(optimized) < target_count:
            remaining = sorted(
                suggestions,
                key=lambda x: x.relevance_score * x.estimated_reach,
                reverse=True
            )
            
            for suggestion in remaining:
                if suggestion.hashtag not in optimized and len(optimized) < target_count:
                    optimized.append(suggestion.hashtag)
        
        return optimized[:target_count]
    
    def analyze_hashtag_performance(self, hashtags_used: List[str],
                                   engagement_data: Dict) -> Dict:
        """Analiza performance de hashtags usados"""
        
        # En producci√≥n, esto se conectar√≠a con Meta API o analytics
        # Por ahora, estructura de ejemplo
        
        return {
            'total_hashtags': len(hashtags_used),
            'top_performers': hashtags_used[:5],  # Simplificado
            'recommendations': self.generate_improvement_recommendations(hashtags_used)
        }
    
    def generate_improvement_recommendations(self, hashtags: List[str]) -> List[str]:
        """Genera recomendaciones de mejora"""
        recommendations = []
        
        if len(hashtags) > 25:
            recommendations.append("Reducir n√∫mero de hashtags. Instagram recomienda 5-15.")
        
        if len(hashtags) < 5:
            recommendations.append("Aumentar n√∫mero de hashtags para mejor descubribilidad.")
        
        # Verificar balance
        hashtag_str = ' '.join(hashtags).lower()
        if 'ia' in hashtag_str and 'inteligenciaartificial' in hashtag_str:
            recommendations.append("Evitar redundancia (IA e InteligenciaArtificial)")
        
        return recommendations

if __name__ == '__main__':
    import os
    
    optimizer = HashtagOptimizer(os.getenv('OPENAI_API_KEY'))
    
    # Generar hashtags para carrusel
    suggestions = optimizer.generate_hashtags(
        product='curso_ia',
        content_description='Carrusel sobre curso de IA aplicada con webinars',
        num_suggestions=30
    )
    
    # Optimizar conjunto
    optimized = optimizer.optimize_hashtag_set(suggestions, target_count=15)
    
    print("Hashtags optimizados:")
    print(' '.join([f"#{h}" for h in optimized]))
```

---

## üìà An√°lisis de Tendencias en Tiempo Real

### Script de Detecci√≥n y An√°lisis de Tendencias

**Python**: `scripts/trend_analysis_realtime.py`

```python
#!/usr/bin/env python3
"""
An√°lisis de tendencias en tiempo real para carruseles
- Detecci√≥n de cambios en engagement
- Identificaci√≥n de patrones estacionales
- Alertas de tendencias emergentes
- Predicci√≥n de tendencias futuras
"""
import numpy as np
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import deque
import json

@dataclass
class TrendDataPoint:
    """Punto de datos de tendencia"""
    timestamp: datetime
    metric_name: str
    value: float
    platform: str

@dataclass
class TrendAnalysis:
    """An√°lisis de tendencia"""
    metric_name: str
    direction: str  # increasing, decreasing, stable
    strength: float  # 0-1
    confidence: float  # 0-1
    change_percentage: float
    time_window: int  # d√≠as
    predictions: Dict

class RealtimeTrendAnalyzer:
    """Analizador de tendencias en tiempo real"""
    
    def __init__(self, window_size: int = 7):
        self.window_size = window_size  # d√≠as
        self.data_stream = {}  # {carousel_id: deque of TrendDataPoint}
    
    def add_data_point(self, carousel_id: str, metric_name: str, 
                       value: float, platform: str = 'all'):
        """Agrega nuevo punto de datos"""
        if carousel_id not in self.data_stream:
            self.data_stream[carousel_id] = {}
        
        if metric_name not in self.data_stream[carousel_id]:
            self.data_stream[carousel_id][metric_name] = deque(maxlen=self.window_size * 24)
        
        data_point = TrendDataPoint(
            timestamp=datetime.now(),
            metric_name=metric_name,
            value=value,
            platform=platform
        )
        
        self.data_stream[carousel_id][metric_name].append(data_point)
    
    def analyze_trend(self, carousel_id: str, metric_name: str) -> TrendAnalysis:
        """Analiza tendencia para una m√©trica espec√≠fica"""
        if carousel_id not in self.data_stream:
            return None
        
        if metric_name not in self.data_stream[carousel_id]:
            return None
        
        data_points = list(self.data_stream[carousel_id][metric_name])
        
        if len(data_points) < 3:
            return None
        
        values = [dp.value for dp in data_points]
        timestamps = [dp.timestamp for dp in data_points]
        
        # Calcular direcci√≥n de tendencia
        direction = self._calculate_direction(values)
        
        # Calcular fuerza de tendencia
        strength = self._calculate_strength(values)
        
        # Calcular cambio porcentual
        change_pct = ((values[-1] - values[0]) / values[0] * 100) if values[0] != 0 else 0
        
        # Calcular confianza
        confidence = self._calculate_confidence(values, direction)
        
        # Generar predicciones
        predictions = self._generate_predictions(values)
        
        return TrendAnalysis(
            metric_name=metric_name,
            direction=direction,
            strength=strength,
            confidence=confidence,
            change_percentage=change_pct,
            time_window=len(data_points),
            predictions=predictions
        )
    
    def _calculate_direction(self, values: List[float]) -> str:
        """Calcula direcci√≥n de tendencia"""
        if len(values) < 2:
            return 'stable'
        
        # Regresi√≥n lineal simple
        x = np.arange(len(values))
        slope = np.polyfit(x, values, 1)[0]
        
        if slope > 0.01:
            return 'increasing'
        elif slope < -0.01:
            return 'decreasing'
        else:
            return 'stable'
    
    def _calculate_strength(self, values: List[float]) -> float:
        """Calcula fuerza de tendencia (0-1)"""
        if len(values) < 2:
            return 0.0
        
        # Coeficiente de determinaci√≥n (R¬≤)
        x = np.arange(len(values))
        y = np.array(values)
        
        coeffs = np.polyfit(x, y, 1)
        y_pred = np.polyval(coeffs, x)
        
        ss_res = np.sum((y - y_pred) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        
        if ss_tot == 0:
            return 0.0
        
        r_squared = 1 - (ss_res / ss_tot)
        return max(0.0, min(1.0, r_squared))
    
    def _calculate_confidence(self, values: List[float], direction: str) -> float:
        """Calcula confianza en la tendencia"""
        if len(values) < 3:
            return 0.5
        
        # Factor 1: Consistencia de direcci√≥n
        recent_values = values[-3:]
        consistent = all(
            (recent_values[i+1] > recent_values[i] if direction == 'increasing'
             else recent_values[i+1] < recent_values[i] if direction == 'decreasing'
             else abs(recent_values[i+1] - recent_values[i]) < 0.01)
            for i in range(len(recent_values) - 1)
        )
        
        consistency_score = 1.0 if consistent else 0.5
        
        # Factor 2: Cantidad de datos
        data_amount_score = min(1.0, len(values) / 10)
        
        # Factor 3: Variabilidad (menos variabilidad = m√°s confianza)
        if len(values) > 1:
            std_dev = np.std(values)
            mean_val = np.mean(values)
            variability_score = 1.0 - min(1.0, std_dev / (mean_val + 0.001))
        else:
            variability_score = 0.5
        
        # Combinar factores
        confidence = (consistency_score * 0.4 + data_amount_score * 0.3 + variability_score * 0.3)
        
        return max(0.0, min(1.0, confidence))
    
    def _generate_predictions(self, values: List[float], periods: int = 3) -> Dict:
        """Genera predicciones futuras"""
        if len(values) < 2:
            return {'next_value': values[0] if values else 0, 'trend': 'stable'}
        
        # Regresi√≥n lineal para extrapolaci√≥n
        x = np.arange(len(values))
        coeffs = np.polyfit(x, values, 1)
        
        next_x = len(values)
        next_value = np.polyval(coeffs, next_x)
        
        # Predicci√≥n de tendencia
        direction = self._calculate_direction(values)
        
        return {
            'next_value': float(next_value),
            'trend': direction,
            'confidence': self._calculate_confidence(values, direction)
        }
    
    def detect_anomalies(self, carousel_id: str, metric_name: str) -> List[Dict]:
        """Detecta anomal√≠as en m√©tricas"""
        if carousel_id not in self.data_stream:
            return []
        
        if metric_name not in self.data_stream[carousel_id]:
            return []
        
        data_points = list(self.data_stream[carousel_id][metric_name])
        
        if len(data_points) < 5:
            return []
        
        values = [dp.value for dp in data_points]
        mean = np.mean(values)
        std = np.std(values)
        
        anomalies = []
        threshold = 2 * std  # 2 desviaciones est√°ndar
        
        for i, dp in enumerate(data_points):
            z_score = abs(dp.value - mean) / (std + 0.001)
            
            if z_score > 2:
                anomalies.append({
                    'timestamp': dp.timestamp.isoformat(),
                    'value': dp.value,
                    'z_score': z_score,
                    'severity': 'high' if z_score > 3 else 'medium'
                })
        
        return anomalies
    
    def get_trend_summary(self, carousel_id: str) -> Dict:
        """Obtiene resumen de todas las tendencias"""
        if carousel_id not in self.data_stream:
            return {}
        
        trends = {}
        
        for metric_name in self.data_stream[carousel_id].keys():
            trend = self.analyze_trend(carousel_id, metric_name)
            if trend:
                trends[metric_name] = {
                    'direction': trend.direction,
                    'strength': trend.strength,
                    'confidence': trend.confidence,
                    'change_percentage': trend.change_percentage,
                    'predictions': trend.predictions
                }
        
        return trends

if __name__ == '__main__':
    analyzer = RealtimeTrendAnalyzer(window_size=7)
    
    # Simular datos
    import random
    base_ctr = 2.5
    
    for i in range(20):
        ctr = base_ctr + random.uniform(-0.5, 0.5) + (i * 0.1)  # Tendencia creciente
        analyzer.add_data_point('curso_ia_slide1', 'ctr', ctr)
    
    # Analizar tendencia
    trend = analyzer.analyze_trend('curso_ia_slide1', 'ctr')
    
    if trend:
        print(f"Tendencia: {trend.direction}")
        print(f"Fuerza: {trend.strength:.2%}")
        print(f"Confianza: {trend.confidence:.2%}")
        print(f"Cambio: {trend.change_percentage:.1f}%")
        print(f"Predicci√≥n siguiente: {trend.predictions['next_value']:.2f}")
    
    # Detectar anomal√≠as
    anomalies = analyzer.detect_anomalies('curso_ia_slide1', 'ctr')
    if anomalies:
        print(f"\n‚ö†Ô∏è {len(anomalies)} anomal√≠as detectadas")
```

---

## üìä Generaci√≥n Autom√°tica de Reportes Ejecutivos

### Script de Generaci√≥n de Reportes

**Python**: `scripts/executive_report_generator.py`

```python
#!/usr/bin/env python3
"""
Generaci√≥n autom√°tica de reportes ejecutivos
- Dashboard ejecutivo consolidado
- Insights autom√°ticos con GPT-4
- Visualizaciones personalizadas
- Exportaci√≥n a m√∫ltiples formatos
"""
import json
from typing import Dict, List
from datetime import datetime, timedelta
from pathlib import Path
import openai

class ExecutiveReportGenerator:
    """Generador de reportes ejecutivos automatizados"""
    
    def __init__(self, openai_api_key: str):
        self.client = openai.OpenAI(api_key=openai_api_key)
        self.report_templates = self.load_templates()
    
    def generate_executive_summary(self, metrics: Dict, period: str = 'weekly') -> Dict:
        """Genera resumen ejecutivo con IA"""
        
        # Preparar prompt con m√©tricas
        metrics_summary = self.format_metrics_for_ai(metrics)
        
        prompt = f"""
        Genera un resumen ejecutivo profesional para un reporte de marketing digital.
        Analiza estas m√©tricas y proporciona:
        1. Resumen ejecutivo (2-3 p√°rrafos)
        2. Top 3 logros principales
        3. Top 3 √°reas de mejora
        4. Recomendaciones estrat√©gicas (3-5)
        5. Insights clave (2-3)
        
        M√©tricas del per√≠odo {period}:
        {metrics_summary}
        
        Responde en formato JSON:
        {{
            "executive_summary": "...",
            "key_achievements": ["...", "..."],
            "improvement_areas": ["...", "..."],
            "strategic_recommendations": ["...", "..."],
            "key_insights": ["...", "..."]
        }}
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Eres un analista de marketing digital experto en crear reportes ejecutivos."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        report_data = json.loads(response.choices[0].message.content)
        
        # Agregar m√©tricas num√©ricas
        report_data['metrics'] = metrics
        report_data['period'] = period
        report_data['generated_at'] = datetime.now().isoformat()
        
        return report_data
    
    def format_metrics_for_ai(self, metrics: Dict) -> str:
        """Formatea m√©tricas para AI"""
        lines = []
        
        if 'carousels' in metrics:
            lines.append("Carruseles:")
            for carousel, data in metrics['carousels'].items():
                lines.append(f"  - {carousel}: CTR {data.get('ctr', 0):.2f}%, "
                           f"Conversiones: {data.get('conversions', 0)}, "
                           f"ROAS: {data.get('roas', 0):.2f}")
        
        if 'totals' in metrics:
            lines.append("\nTotales:")
            totals = metrics['totals']
            lines.append(f"  - Impresiones: {totals.get('impressions', 0):,}")
            lines.append(f"  - Clics: {totals.get('clicks', 0):,}")
            lines.append(f"  - Conversiones: {totals.get('conversions', 0):,}")
            lines.append(f"  - CTR promedio: {totals.get('avg_ctr', 0):.2f}%")
            lines.append(f"  - ROAS promedio: {totals.get('avg_roas', 0):.2f}")
        
        return "\n".join(lines)
    
    def generate_pdf_report(self, report_data: Dict, output_path: Path):
        """Genera reporte en PDF"""
        from reportlab.lib.pagesizes import letter, A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib import colors
        
        doc = SimpleDocTemplate(str(output_path), pagesize=A4)
        story = []
        styles = getSampleStyleSheet()
        
        # T√≠tulo
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#1a1a1a'),
            spaceAfter=30
        )
        
        story.append(Paragraph("Reporte Ejecutivo - Carruseles Sociales", title_style))
        story.append(Spacer(1, 12))
        
        # Resumen ejecutivo
        story.append(Paragraph("Resumen Ejecutivo", styles['Heading2']))
        story.append(Paragraph(report_data['executive_summary'], styles['BodyText']))
        story.append(Spacer(1, 20))
        
        # Logros clave
        story.append(Paragraph("Logros Principales", styles['Heading2']))
        for achievement in report_data['key_achievements']:
            story.append(Paragraph(f"‚Ä¢ {achievement}", styles['BodyText']))
        story.append(Spacer(1, 20))
        
        # Recomendaciones
        story.append(Paragraph("Recomendaciones Estrat√©gicas", styles['Heading2']))
        for rec in report_data['strategic_recommendations']:
            story.append(Paragraph(f"‚Ä¢ {rec}", styles['BodyText']))
        
        # Construir PDF
        doc.build(story)
    
    def generate_html_dashboard(self, report_data: Dict, output_path: Path):
        """Genera dashboard HTML interactivo"""
        html_template = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Reporte Ejecutivo - Carruseles Sociales</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
                .container {{ background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
                h1 {{ color: #1a1a1a; border-bottom: 3px solid #22C55E; padding-bottom: 10px; }}
                h2 {{ color: #333; margin-top: 30px; }}
                .metric {{ display: inline-block; margin: 15px; padding: 20px; background: #f8f9fa; border-radius: 4px; }}
                .metric-value {{ font-size: 32px; font-weight: bold; color: #22C55E; }}
                .metric-label {{ font-size: 14px; color: #666; margin-top: 5px; }}
                .insight {{ background: #e3f2fd; padding: 15px; margin: 10px 0; border-left: 4px solid #2196F3; border-radius: 4px; }}
                .recommendation {{ background: #fff3e0; padding: 15px; margin: 10px 0; border-left: 4px solid #FF9800; border-radius: 4px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>üìä Reporte Ejecutivo - Carruseles Sociales</h1>
                <p><strong>Per√≠odo:</strong> {report_data['period']}</p>
                <p><strong>Generado:</strong> {datetime.fromisoformat(report_data['generated_at']).strftime('%Y-%m-%d %H:%M')}</p>
                
                <h2>Resumen Ejecutivo</h2>
                <p>{report_data['executive_summary']}</p>
                
                <h2>M√©tricas Clave</h2>
                <div class="metric">
                    <div class="metric-value">{report_data['metrics']['totals'].get('impressions', 0):,}</div>
                    <div class="metric-label">Impresiones</div>
                </div>
                <div class="metric">
                    <div class="metric-value">{report_data['metrics']['totals'].get('avg_ctr', 0):.2f}%</div>
                    <div class="metric-label">CTR Promedio</div>
                </div>
                <div class="metric">
                    <div class="metric-value">{report_data['metrics']['totals'].get('avg_roas', 0):.2f}</div>
                    <div class="metric-label">ROAS Promedio</div>
                </div>
                
                <h2>Logros Principales</h2>
                <ul>
                    {''.join(f'<li>{achievement}</li>' for achievement in report_data['key_achievements'])}
                </ul>
                
                <h2>Insights Clave</h2>
                {''.join(f'<div class="insight">{insight}</div>' for insight in report_data['key_insights'])}
                
                <h2>Recomendaciones Estrat√©gicas</h2>
                {''.join(f'<div class="recommendation">{rec}</div>' for rec in report_data['strategic_recommendations'])}
            </div>
        </body>
        </html>
        """
        
        output_path.write_text(html_template)
    
    def load_templates(self) -> Dict:
        """Carga templates de reporte"""
        template_path = Path('config/report_templates.json')
        if template_path.exists():
            with open(template_path) as f:
                return json.load(f)
        return {}

if __name__ == '__main__':
    import os
    
    generator = ExecutiveReportGenerator(os.getenv('OPENAI_API_KEY'))
    
    # M√©tricas de ejemplo
    metrics = {
        'totals': {
            'impressions': 125000,
            'clicks': 3250,
            'conversions': 245,
            'avg_ctr': 2.6,
            'avg_roas': 3.2
        },
        'carousels': {
            'curso_ia_slide1': {'ctr': 3.1, 'conversions': 125, 'roas': 3.5},
            'saas_marketing_slide2': {'ctr': 2.3, 'conversions': 89, 'roas': 2.9},
            'ia_bulk_slide3': {'ctr': 2.4, 'conversions': 31, 'roas': 2.7}
        }
    }
    
    # Generar reporte
    report = generator.generate_executive_summary(metrics, period='weekly')
    
    # Exportar
    output_dir = Path('reports/executive')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    generator.generate_html_dashboard(report, output_dir / 'executive_report.html')
    generator.generate_pdf_report(report, output_dir / 'executive_report.pdf')
    
    print("‚úÖ Reporte ejecutivo generado")
```

---

## üö® Sistema de Alertas Predictivas

### Script de Alertas Inteligentes

**Python**: `scripts/predictive_alerts.py`

```python
#!/usr/bin/env python3
"""
Sistema de alertas predictivas
- Predicci√≥n de problemas antes de que ocurran
- Alertas basadas en patrones hist√≥ricos
- Escalamiento inteligente de urgencia
- Integraci√≥n con sistemas de notificaci√≥n
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import numpy as np

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

@dataclass
class PredictiveAlert:
    """Alerta predictiva"""
    alert_id: str
    carousel_id: str
    metric_name: str
    predicted_value: float
    threshold: float
    severity: AlertSeverity
    confidence: float
    time_horizon: int  # horas
    recommended_action: str
    timestamp: datetime

class PredictiveAlertSystem:
    """Sistema de alertas predictivas"""
    
    def __init__(self):
        self.alert_history = []
        self.thresholds = {
            'ctr': {'warning': 1.5, 'critical': 1.0},
            'conversion_rate': {'warning': 5.0, 'critical': 3.0},
            'roas': {'warning': 2.0, 'critical': 1.5}
        }
    
    def predict_and_alert(self, carousel_id: str, metric_history: List[Dict],
                         time_horizon_hours: int = 24) -> Optional[PredictiveAlert]:
        """Predice valor futuro y genera alerta si es necesario"""
        
        if len(metric_history) < 5:
            return None  # Necesitamos m√≠nimo 5 puntos de datos
        
        # Extraer valores hist√≥ricos
        values = [m['value'] for m in metric_history]
        timestamps = [datetime.fromisoformat(m['timestamp']) for m in metric_history]
        
        # Predecir valor futuro
        predicted_value, confidence = self._predict_future_value(
            values, timestamps, time_horizon_hours
        )
        
        # Determinar m√©trica (asumir que est√° en metric_history)
        metric_name = metric_history[0].get('metric', 'unknown')
        
        # Verificar si necesita alerta
        threshold_config = self.thresholds.get(metric_name, {})
        
        if not threshold_config:
            return None
        
        # Determinar severidad
        severity = None
        if predicted_value < threshold_config.get('critical', float('inf')):
            severity = AlertSeverity.CRITICAL
        elif predicted_value < threshold_config.get('warning', float('inf')):
            severity = AlertSeverity.WARNING
        
        if not severity:
            return None
        
        # Generar alerta
        alert = PredictiveAlert(
            alert_id=f"alert_{datetime.now().timestamp()}",
            carousel_id=carousel_id,
            metric_name=metric_name,
            predicted_value=predicted_value,
            threshold=threshold_config.get(severity.value, 0),
            severity=severity,
            confidence=confidence,
            time_horizon=time_horizon_hours,
            recommended_action=self._generate_recommendation(metric_name, predicted_value, severity),
            timestamp=datetime.now()
        )
        
        # Registrar alerta
        self.alert_history.append(alert)
        
        return alert
    
    def _predict_future_value(self, values: List[float], timestamps: List[datetime],
                              hours_ahead: int) -> tuple:
        """Predice valor futuro usando regresi√≥n"""
        
        # Convertir timestamps a horas desde inicio
        hours_from_start = [(ts - timestamps[0]).total_seconds() / 3600 for ts in timestamps]
        
        # Regresi√≥n lineal
        x = np.array(hours_from_start)
        y = np.array(values)
        
        coeffs = np.polyfit(x, y, 1)
        
        # Predecir valor futuro
        future_hours = hours_from_start[-1] + hours_ahead
        predicted = np.polyval(coeffs, future_hours)
        
        # Calcular confianza (basada en R¬≤)
        y_pred = np.polyval(coeffs, x)
        ss_res = np.sum((y - y_pred) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        
        if ss_tot == 0:
            confidence = 0.5
        else:
            r_squared = 1 - (ss_res / ss_tot)
            confidence = max(0.3, min(0.95, r_squared))
        
        return float(predicted), float(confidence)
    
    def _generate_recommendation(self, metric_name: str, predicted_value: float,
                                severity: AlertSeverity) -> str:
        """Genera recomendaci√≥n basada en predicci√≥n"""
        
        recommendations = {
            'ctr': {
                AlertSeverity.WARNING: "Revisar headline y visual. Considerar variante A/B diferente.",
                AlertSeverity.CRITICAL: "CTR cayendo significativamente. Pausar y revisar estrategia inmediatamente."
            },
            'conversion_rate': {
                AlertSeverity.WARNING: "Optimizar landing page. Revisar formulario y mensaje.",
                AlertSeverity.CRITICAL: "Problema cr√≠tico en conversi√≥n. Revisar funnel completo."
            },
            'roas': {
                AlertSeverity.WARNING: "Optimizar targeting o ajustar presupuesto.",
                AlertSeverity.CRITICAL: "ROAS bajo threshold. Considerar pausar campa√±a."
            }
        }
        
        metric_recs = recommendations.get(metric_name, {})
        return metric_recs.get(severity, "Revisar m√©tricas y tomar acci√≥n correctiva.")
    
    def get_active_alerts(self, severity: Optional[AlertSeverity] = None) -> List[PredictiveAlert]:
        """Obtiene alertas activas"""
        cutoff = datetime.now() - timedelta(hours=24)
        
        active = [
            alert for alert in self.alert_history
            if alert.timestamp > cutoff
        ]
        
        if severity:
            active = [a for a in active if a.severity == severity]
        
        return sorted(active, key=lambda x: x.timestamp, reverse=True)

if __name__ == '__main__':
    system = PredictiveAlertSystem()
    
    # Simular datos hist√≥ricos
    import random
    base_ctr = 2.5
    
    metric_history = []
    for i in range(10):
        ctr = base_ctr - (i * 0.15)  # Tendencia decreciente
        metric_history.append({
            'value': ctr,
            'timestamp': (datetime.now() - timedelta(hours=10-i)).isoformat(),
            'metric': 'ctr'
        })
    
    # Predecir y alertar
    alert = system.predict_and_alert('curso_ia_slide1', metric_history, time_horizon_hours=24)
    
    if alert:
        print(f"üö® Alerta {alert.severity.value.upper()}:")
        print(f"   M√©trica: {alert.metric_name}")
        print(f"   Valor predicho: {alert.predicted_value:.2f}")
        print(f"   Confianza: {alert.confidence:.2%}")
        print(f"   Acci√≥n recomendada: {alert.recommended_action}")
```

---

## üìÖ Sistema de Calendarizaci√≥n Inteligente

### Script de Optimizaci√≥n de Timing

**Python**: `scripts/smart_scheduling.py`

```python
#!/usr/bin/env python3
"""
Sistema de calendarizaci√≥n inteligente para carruseles
- Optimizaci√≥n de timing basada en datos hist√≥ricos
- Detecci√≥n de mejores d√≠as/horas por audiencia
- Calendarizaci√≥n autom√°tica multi-plataforma
- Ajuste din√°mico seg√∫n engagement
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class OptimalTiming:
    """Timing √≥ptimo para publicaci√≥n"""
    day_of_week: int  # 0-6 (lunes-domingo)
    hour: int  # 0-23
    expected_engagement: float
    confidence: float
    timezone: str

class SmartScheduler:
    """Scheduler inteligente basado en datos"""
    
    def __init__(self):
        self.performance_history = {}  # {carousel_id: {timestamp: engagement}}
        self.audience_timezones = {}
    
    def analyze_best_times(self, carousel_id: str, platform: str = 'instagram') -> List[OptimalTiming]:
        """Analiza mejores horarios para publicaci√≥n"""
        
        if carousel_id not in self.performance_history:
            # Usar defaults si no hay datos
            return self.get_default_optimal_times(platform)
        
        history = self.performance_history[carousel_id]
        
        # Agrupar por d√≠a de semana y hora
        time_slots = {}
        for timestamp_str, engagement in history.items():
            dt = datetime.fromisoformat(timestamp_str)
            key = (dt.weekday(), dt.hour)
            
            if key not in time_slots:
                time_slots[key] = []
            time_slots[key].append(engagement)
        
        # Calcular promedio por slot
        slot_averages = {
            key: sum(values) / len(values)
            for key, values in time_slots.items()
        }
        
        # Ordenar por engagement promedio
        sorted_slots = sorted(
            slot_averages.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Generar recomendaciones
        optimal_times = []
        for (day, hour), avg_engagement in sorted_slots[:5]:
            optimal_times.append(OptimalTiming(
                day_of_week=day,
                hour=hour,
                expected_engagement=avg_engagement,
                confidence=self._calculate_confidence(time_slots[(day, hour)]),
                timezone='America/Mexico_City'  # Default
            ))
        
        return optimal_times
    
    def get_default_optimal_times(self, platform: str) -> List[OptimalTiming]:
        """Retorna horarios √≥ptimos por defecto seg√∫n plataforma"""
        
        defaults = {
            'instagram': [
                OptimalTiming(1, 11, 0.75, 0.8, 'America/Mexico_City'),  # Martes 11am
                OptimalTiming(3, 14, 0.73, 0.8, 'America/Mexico_City'),  # Jueves 2pm
                OptimalTiming(5, 10, 0.72, 0.75, 'America/Mexico_City'),  # S√°bado 10am
            ],
            'linkedin': [
                OptimalTiming(1, 9, 0.78, 0.85, 'America/Mexico_City'),  # Martes 9am
                OptimalTiming(3, 9, 0.76, 0.85, 'America/Mexico_City'),  # Jueves 9am
                OptimalTiming(2, 12, 0.74, 0.8, 'America/Mexico_City'),  # Mi√©rcoles mediod√≠a
            ],
            'facebook': [
                OptimalTiming(3, 13, 0.77, 0.8, 'America/Mexico_City'),  # Jueves 1pm
                OptimalTiming(1, 15, 0.75, 0.8, 'America/Mexico_City'),  # Martes 3pm
                OptimalTiming(6, 12, 0.74, 0.75, 'America/Mexico_City'),  # Domingo mediod√≠a
            ]
        }
        
        return defaults.get(platform, defaults['instagram'])
    
    def _calculate_confidence(self, values: List[float]) -> float:
        """Calcula confianza basada en consistencia"""
        if len(values) < 2:
            return 0.5
        
        import numpy as np
        std = np.std(values)
        mean = np.mean(values)
        
        # Menor variabilidad = mayor confianza
        cv = std / (mean + 0.001)  # Coefficient of variation
        confidence = max(0.3, min(0.95, 1 - cv))
        
        return float(confidence)
    
    def schedule_post(self, carousel_id: str, platform: str,
                     optimal_times: List[OptimalTiming]) -> List[Dict]:
        """Genera schedule de publicaciones"""
        
        schedules = []
        
        for optimal in optimal_times[:3]:  # Top 3 horarios
            # Calcular pr√≥xima fecha/hora
            next_datetime = self._calculate_next_datetime(
                optimal.day_of_week,
                optimal.hour,
                optimal.timezone
            )
            
            schedules.append({
                'carousel_id': carousel_id,
                'platform': platform,
                'scheduled_time': next_datetime.isoformat(),
                'day_of_week': optimal.day_of_week,
                'hour': optimal.hour,
                'expected_engagement': optimal.expected_engagement,
                'confidence': optimal.confidence
            })
        
        return schedules
    
    def _calculate_next_datetime(self, day_of_week: int, hour: int,
                                 timezone: str) -> datetime:
        """Calcula pr√≥xima fecha/hora para publicaci√≥n"""
        now = datetime.now()
        days_ahead = day_of_week - now.weekday()
        
        if days_ahead <= 0:  # Target day already happened this week
            days_ahead += 7
        
        target_date = now + timedelta(days=days_ahead)
        target_datetime = target_date.replace(
            hour=hour,
            minute=0,
            second=0,
            microsecond=0
        )
        
        # Si la hora ya pas√≥ hoy y es el d√≠a correcto, programar para pr√≥xima semana
        if target_datetime < now:
            target_datetime += timedelta(days=7)
        
        return target_datetime
    
    def update_performance_history(self, carousel_id: str, timestamp: datetime,
                                  engagement: float):
        """Actualiza historial de performance"""
        if carousel_id not in self.performance_history:
            self.performance_history[carousel_id] = {}
        
        self.performance_history[carousel_id][timestamp.isoformat()] = engagement

if __name__ == '__main__':
    scheduler = SmartScheduler()
    
    # Analizar mejores horarios
    optimal_times = scheduler.analyze_best_times('curso_ia_slide1', 'instagram')
    
    print("Mejores horarios para publicaci√≥n:")
    day_names = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado', 'Domingo']
    for timing in optimal_times:
        print(f"  {day_names[timing.day_of_week]} {timing.hour:02d}:00 - "
              f"Engagement: {timing.expected_engagement:.2%} "
              f"(Confianza: {timing.confidence:.2%})")
    
    # Generar schedule
    schedules = scheduler.schedule_post('curso_ia_slide1', 'instagram', optimal_times)
    print("\nPublicaciones programadas:")
    for schedule in schedules:
        print(f"  {schedule['scheduled_time']}")
```

---

## üî• An√°lisis de Contenido Viral y Replicabilidad

### Script de An√°lisis de Viralidad

**Python**: `scripts/viral_content_analyzer.py`

```python
#!/usr/bin/env python3
"""
An√°lisis de contenido viral y replicabilidad
- Identificaci√≥n de elementos que causan viralidad
- Scoring de potencial viral
- Recomendaciones para replicar √©xito
- Detecci√≥n de patrones virales
"""
from typing import Dict, List
from dataclasses import dataclass
import json

@dataclass
class ViralScore:
    """Score de potencial viral"""
    total_score: float  # 0-100
    hook_strength: float
    shareability: float
    engagement_potential: float
    timing_score: float
    visual_appeal: float

class ViralContentAnalyzer:
    """Analizador de contenido viral"""
    
    def __init__(self):
        self.viral_patterns = self.load_viral_patterns()
    
    def analyze_viral_potential(self, carousel_data: Dict) -> ViralScore:
        """Analiza potencial viral de un carrusel"""
        
        # Analizar hook (primer slide)
        hook_score = self._analyze_hook(carousel_data.get('slide_1', {}))
        
        # Analizar shareability
        shareability_score = self._analyze_shareability(carousel_data)
        
        # Analizar engagement potential
        engagement_score = self._analyze_engagement_potential(carousel_data)
        
        # Analizar timing
        timing_score = self._analyze_timing(carousel_data)
        
        # Analizar visual appeal
        visual_score = self._analyze_visual_appeal(carousel_data)
        
        # Score total (weighted)
        total = (
            hook_score * 0.3 +
            shareability_score * 0.25 +
            engagement_score * 0.25 +
            timing_score * 0.1 +
            visual_score * 0.1
        )
        
        return ViralScore(
            total_score=total,
            hook_strength=hook_score,
            shareability=shareability_score,
            engagement_potential=engagement_score,
            timing_score=timing_score,
            visual_appeal=visual_score
        )
    
    def _analyze_hook(self, slide_data: Dict) -> float:
        """Analiza fuerza del hook"""
        headline = slide_data.get('headline', '').lower()
        score = 0.0
        
        # Patrones de hook viral
        viral_hooks = [
            'descubre', 'secretos', 'nunca antes', 'la verdad sobre',
            'esto cambiar√°', 'advertencia', 'alerta', 'shocking',
            'incre√≠ble', 'revolucionario', 'revelaci√≥n'
        ]
        
        for hook in viral_hooks:
            if hook in headline:
                score += 10
        
        # Preguntas en hook (+15 puntos)
        if '?' in headline:
            score += 15
        
        # N√∫meros/concrete data (+10 puntos)
        import re
        if re.search(r'\d+', headline):
            score += 10
        
        # Emociones fuertes
        emotion_words = ['poderoso', 'transformador', 'impactante', 'sorprendente']
        for word in emotion_words:
            if word in headline:
                score += 5
        
        return min(100, score)
    
    def _analyze_shareability(self, carousel_data: Dict) -> float:
        """Analiza qu√© tan compartible es el contenido"""
        score = 0.0
        
        # Valor educativo (+20)
        educational_indicators = ['aprende', 'descubre', 'gu√≠a', 'tutorial', 'tips']
        all_text = ' '.join([
            carousel_data.get(f'slide_{i}', {}).get('headline', '')
            for i in range(1, 4)
        ]).lower()
        
        for indicator in educational_indicators:
            if indicator in all_text:
                score += 5
        
        # Controversia controlada (+15)
        if any(word in all_text for word in ['mito', 'realidad', 'verdad']):
            score += 15
        
        # Inspiraci√≥n/motivaci√≥n (+10)
        if any(word in all_text for word in ['√©xito', 'lograr', 'conseguir', 'triunfar']):
            score += 10
        
        # Humor (si aplica) (+10)
        if any(word in all_text for word in ['divertido', 'sorprendente', 'incre√≠ble']):
            score += 10
        
        return min(100, score)
    
    def _analyze_engagement_potential(self, carousel_data: Dict) -> float:
        """Analiza potencial de engagement"""
        score = 0.0
        
        # Call to action claro (+20)
        cta = carousel_data.get('slide_3', {}).get('cta', '').lower()
        strong_ctas = ['√∫nete', 'comienza', 'prueba', 'descubre', 'consigue']
        
        for strong_cta in strong_ctas:
            if strong_cta in cta:
                score += 10
        
        # Preguntas que generan comentarios (+15)
        all_text = ' '.join([
            carousel_data.get(f'slide_{i}', {}).get('headline', '')
            for i in range(1, 4)
        ]).lower()
        
        if '?' in all_text:
            score += 15
        
        # Storytelling (+10)
        if any(word in all_text for word in ['historia', 'caso', 'experiencia', 'resultado']):
            score += 10
        
        return min(100, score)
    
    def _analyze_timing(self, carousel_data: Dict) -> float:
        """Analiza timing (relevancia temporal)"""
        # Por ahora, score base
        # En producci√≥n, analizar tendencias actuales
        return 70.0
    
    def _analyze_visual_appeal(self, carousel_data: Dict) -> float:
        """Analiza atractivo visual"""
        # Por ahora, score base
        # En producci√≥n, usar an√°lisis de imagen con ML
        return 75.0
    
    def generate_viral_recommendations(self, viral_score: ViralScore) -> List[str]:
        """Genera recomendaciones para mejorar viralidad"""
        recommendations = []
        
        if viral_score.hook_strength < 60:
            recommendations.append(
                "Mejorar hook del primer slide: agregar pregunta, n√∫mero concreto, o emoci√≥n fuerte"
            )
        
        if viral_score.shareability < 60:
            recommendations.append(
                "Aumentar valor compartible: agregar tips educativos o insights sorprendentes"
            )
        
        if viral_score.engagement_potential < 60:
            recommendations.append(
                "Mejorar potencial de engagement: incluir pregunta abierta o CTA m√°s directo"
            )
        
        if viral_score.total_score >= 80:
            recommendations.append(
                "¬°Excelente potencial viral! Considerar promoci√≥n adicional para maximizar alcance"
            )
        
        return recommendations
    
    def load_viral_patterns(self) -> Dict:
        """Carga patrones de contenido viral"""
        return {
            'high_performing_hooks': [
                'descubre c√≥mo', 'la verdad sobre', 'esto cambiar√°',
                'nunca m√°s', 'advertencia importante'
            ],
            'share_triggers': [
                'tutorial', 'gu√≠a completa', 'secretos revelados',
                'caso de √©xito', 'resultados sorprendentes'
            ]
        }

if __name__ == '__main__':
    analyzer = ViralContentAnalyzer()
    
    # Analizar carrusel
    carousel_data = {
        'slide_1': {
            'headline': 'Descubre c√≥mo empresas logran 3√ó m√°s resultados con IA'
        },
        'slide_2': {
            'headline': 'La verdad sobre automatizaci√≥n: casos reales'
        },
        'slide_3': {
            'cta': '√önete al curso ahora'
        }
    }
    
    viral_score = analyzer.analyze_viral_potential(carousel_data)
    
    print(f"Score Viral: {viral_score.total_score:.1f}/100")
    print(f"  Hook: {viral_score.hook_strength:.1f}")
    print(f"  Shareability: {viral_score.shareability:.1f}")
    print(f"  Engagement: {viral_score.engagement_potential:.1f}")
    
    recommendations = analyzer.generate_viral_recommendations(viral_score)
    print("\nRecomendaciones:")
    for rec in recommendations:
        print(f"  ‚Ä¢ {rec}")
```

---

## ü§ñ Sistema de Aprendizaje Continuo y Auto-Mejora

### Script de Auto-Optimizaci√≥n

**Python**: `scripts/continuous_learning.py`

```python
#!/usr/bin/env python3
"""
Sistema de aprendizaje continuo y auto-mejora
- Aprendizaje de patrones exitosos
- Auto-generaci√≥n de variantes mejoradas
- A/B testing autom√°tico continuo
- Optimizaci√≥n iterativa basada en feedback
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class LearningPattern:
    """Patr√≥n aprendido"""
    pattern_id: str
    pattern_type: str  # headline, cta, visual, etc.
    performance_score: float
    conditions: Dict
    timestamp: datetime

class ContinuousLearningSystem:
    """Sistema de aprendizaje continuo"""
    
    def __init__(self):
        self.learned_patterns = []
        self.performance_log = {}
        self.improvements_made = []
    
    def learn_from_performance(self, carousel_id: str, variant: str,
                              performance_data: Dict):
        """Aprende de los resultados de performance"""
        
        # Extraer patrones exitosos
        patterns = self._extract_patterns(carousel_id, variant, performance_data)
        
        # Evaluar patrones
        for pattern in patterns:
            score = self._evaluate_pattern(pattern, performance_data)
            
            if score > 0.7:  # Threshold para considerar patr√≥n exitoso
                learned = LearningPattern(
                    pattern_id=f"pattern_{len(self.learned_patterns)}",
                    pattern_type=pattern['type'],
                    performance_score=score,
                    conditions=pattern['conditions'],
                    timestamp=datetime.now()
                )
                
                self.learned_patterns.append(learned)
        
        # Guardar performance
        self.performance_log[f"{carousel_id}_{variant}"] = performance_data
    
    def _extract_patterns(self, carousel_id: str, variant: str,
                         performance: Dict) -> List[Dict]:
        """Extrae patrones del carrusel"""
        patterns = []
        
        # Patr√≥n de headline (si CTR es alto)
        if performance.get('ctr', 0) > 2.5:
            patterns.append({
                'type': 'headline',
                'conditions': {
                    'contains_number': True,  # Inferido
                    'has_question': False,
                    'length': 'medium'
                }
            })
        
        # Patr√≥n de CTA (si conversi√≥n es alta)
        if performance.get('conversion_rate', 0) > 15:
            patterns.append({
                'type': 'cta',
                'conditions': {
                    'action_word': True,
                    'urgency': 'medium',
                    'length': 'short'
                }
            })
        
        return patterns
    
    def _evaluate_pattern(self, pattern: Dict, performance: Dict) -> float:
        """Eval√∫a qu√© tan exitoso es un patr√≥n"""
        score = 0.0
        
        # Factor CTR
        if 'headline' in pattern['type']:
            ctr = performance.get('ctr', 0)
            score += min(0.5, ctr / 5.0)  # Normalizar a 0-0.5
        
        # Factor conversi√≥n
        conversion_rate = performance.get('conversion_rate', 0)
        score += min(0.5, conversion_rate / 30.0)  # Normalizar a 0-0.5
        
        return min(1.0, score)
    
    def generate_improved_variant(self, base_carousel: Dict) -> Dict:
        """Genera variante mejorada basada en aprendizaje"""
        
        improved = base_carousel.copy()
        
        # Aplicar patrones aprendidos de headlines
        headline_patterns = [
            p for p in self.learned_patterns
            if p.pattern_type == 'headline' and p.performance_score > 0.7
        ]
        
        if headline_patterns:
            best_pattern = max(headline_patterns, key=lambda x: x.performance_score)
            improved['slide_1']['headline'] = self._apply_headline_pattern(
                base_carousel['slide_1'].get('headline', ''),
                best_pattern.conditions
            )
        
        # Aplicar patrones aprendidos de CTAs
        cta_patterns = [
            p for p in self.learned_patterns
            if p.pattern_type == 'cta' and p.performance_score > 0.7
        ]
        
        if cta_patterns:
            best_pattern = max(cta_patterns, key=lambda x: x.performance_score)
            improved['slide_3']['cta'] = self._apply_cta_pattern(
                base_carousel['slide_3'].get('cta', ''),
                best_pattern.conditions
            )
        
        return improved
    
    def _apply_headline_pattern(self, original: str, conditions: Dict) -> str:
        """Aplica patr√≥n aprendido a headline"""
        # Simplificado: en producci√≥n usar NLP/IA
        improved = original
        
        if conditions.get('contains_number') and not any(c.isdigit() for c in original):
            # Agregar n√∫mero
            improved = f"3√ó {improved}"
        
        return improved
    
    def _apply_cta_pattern(self, original: str, conditions: Dict) -> str:
        """Aplica patr√≥n aprendido a CTA"""
        # Simplificado
        improved = original
        
        if conditions.get('action_word') and not any(word in original.lower() for word in ['√∫nete', 'comienza', 'prueba']):
            improved = f"Comienza ahora: {improved}"
        
        return improved
    
    def get_improvement_suggestions(self, carousel_id: str) -> List[str]:
        """Obtiene sugerencias de mejora"""
        suggestions = []
        
        # Analizar performance vs benchmarks
        if carousel_id in self.performance_log:
            perf = self.performance_log[carousel_id]
            
            if perf.get('ctr', 0) < 2.0:
                suggestions.append("CTR bajo. Considerar mejorar headline o visual del primer slide")
            
            if perf.get('conversion_rate', 0) < 10:
                suggestions.append("Conversi√≥n baja. Optimizar CTA o landing page")
            
            if perf.get('engagement', 0) < 5:
                suggestions.append("Engagement bajo. Agregar pregunta o elemento interactivo")
        
        return suggestions

if __name__ == '__main__':
    learning = ContinuousLearningSystem()
    
    # Simular aprendizaje
    learning.learn_from_performance(
        'curso_ia_v1',
        'variant_a',
        {'ctr': 3.2, 'conversion_rate': 18, 'engagement': 8}
    )
    
    # Generar variante mejorada
    base = {
        'slide_1': {'headline': 'Domina IA aplicada'},
        'slide_3': {'cta': 'Ver m√°s informaci√≥n'}
    }
    
    improved = learning.generate_improved_variant(base)
    print("Variante mejorada:")
    print(f"  Headline: {improved['slide_1']['headline']}")
    print(f"  CTA: {improved['slide_3']['cta']}")
    
    # Sugerencias
    suggestions = learning.get_improvement_suggestions('curso_ia_v1')
    if suggestions:
        print("\nSugerencias de mejora:")
        for suggestion in suggestions:
            print(f"  ‚Ä¢ {suggestion}")
```

---

## üí∞ An√°lisis de ROI Avanzado y Atribuci√≥n Multi-Touch

### Script de An√°lisis de ROI

**Python**: `scripts/advanced_roi_attribution.py`

```python
#!/usr/bin/env python3
"""
An√°lisis de ROI avanzado y atribuci√≥n multi-touch
- Atribuci√≥n multi-touch (first-touch, last-touch, linear, time-decay)
- C√°lculo de ROI por canal, carrusel, variante
- LTV (Lifetime Value) de leads
- Payback period y CAC (Customer Acquisition Cost)
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum

class AttributionModel(Enum):
    FIRST_TOUCH = "first_touch"
    LAST_TOUCH = "last_touch"
    LINEAR = "linear"
    TIME_DECAY = "time_decay"
    POSITION_BASED = "position_based"

@dataclass
class TouchPoint:
    """Punto de contacto en el journey"""
    timestamp: datetime
    channel: str
    carousel_id: str
    touch_type: str  # view, click, conversion
    revenue: float = 0.0

class ROIAnalyzer:
    """Analizador de ROI y atribuci√≥n"""
    
    def __init__(self):
        self.customer_journeys = {}  # {customer_id: [TouchPoint]}
    
    def add_touchpoint(self, customer_id: str, touchpoint: TouchPoint):
        """Agrega punto de contacto al journey"""
        if customer_id not in self.customer_journeys:
            self.customer_journeys[customer_id] = []
        
        self.customer_journeys[customer_id].append(touchpoint)
        self.customer_journeys[customer_id].sort(key=lambda x: x.timestamp)
    
    def calculate_attribution(self, customer_id: str,
                             model: AttributionModel = AttributionModel.LAST_TOUCH) -> Dict:
        """Calcula atribuci√≥n seg√∫n modelo"""
        
        if customer_id not in self.customer_journeys:
            return {}
        
        journey = self.customer_journeys[customer_id]
        
        if not journey:
            return {}
        
        revenue = sum(tp.revenue for tp in journey)
        
        if model == AttributionModel.FIRST_TOUCH:
            attribution = self._first_touch(journey, revenue)
        elif model == AttributionModel.LAST_TOUCH:
            attribution = self._last_touch(journey, revenue)
        elif model == AttributionModel.LINEAR:
            attribution = self._linear(journey, revenue)
        elif model == AttributionModel.TIME_DECAY:
            attribution = self._time_decay(journey, revenue)
        elif model == AttributionModel.POSITION_BASED:
            attribution = self._position_based(journey, revenue)
        else:
            attribution = {}
        
        return attribution
    
    def _first_touch(self, journey: List[TouchPoint], revenue: float) -> Dict:
        """Primer touch recibe 100%"""
        first = journey[0]
        return {
            first.carousel_id: revenue,
            first.channel: revenue
        }
    
    def _last_touch(self, journey: List[TouchPoint], revenue: float) -> Dict:
        """√öltimo touch recibe 100%"""
        last = journey[-1]
        return {
            last.carousel_id: revenue,
            last.channel: revenue
        }
    
    def _linear(self, journey: List[TouchPoint], revenue: float) -> Dict:
        """Distribuci√≥n equitativa"""
        touchpoints = len(journey)
        attribution = {}
        
        for tp in journey:
            share = revenue / touchpoints
            attribution[tp.carousel_id] = attribution.get(tp.carousel_id, 0) + share
            attribution[tp.channel] = attribution.get(tp.channel, 0) + share
        
        return attribution
    
    def _time_decay(self, journey: List[TouchPoint], revenue: float) -> Dict:
        """M√°s peso a toques m√°s recientes"""
        if not journey:
            return {}
        
        first_time = journey[0].timestamp
        last_time = journey[-1].timestamp
        total_span = (last_time - first_time).total_seconds() + 1
        
        attribution = {}
        total_weight = 0
        
        # Calcular pesos
        weights = []
        for tp in journey:
            time_diff = (tp.timestamp - first_time).total_seconds()
            weight = (time_diff / total_span) ** 2  # Cuadr√°tico para m√°s decay
            weights.append(weight)
            total_weight += weight
        
        # Distribuir revenue
        for i, tp in enumerate(journey):
            share = revenue * (weights[i] / total_weight)
            attribution[tp.carousel_id] = attribution.get(tp.carousel_id, 0) + share
            attribution[tp.channel] = attribution.get(tp.channel, 0) + share
        
        return attribution
    
    def _position_based(self, journey: List[TouchPoint], revenue: float) -> Dict:
        """40% primero, 40% √∫ltimo, 20% medio"""
        if len(journey) == 1:
            return {journey[0].carousel_id: revenue, journey[0].channel: revenue}
        
        attribution = {}
        
        # Primer touch: 40%
        first = journey[0]
        first_share = revenue * 0.4
        attribution[first.carousel_id] = attribution.get(first.carousel_id, 0) + first_share
        attribution[first.channel] = attribution.get(first.channel, 0) + first_share
        
        # √öltimo touch: 40%
        last = journey[-1]
        last_share = revenue * 0.4
        attribution[last.carousel_id] = attribution.get(last.carousel_id, 0) + last_share
        attribution[last.channel] = attribution.get(last.channel, 0) + last_share
        
        # Tracks intermedios: 20% distribuido
        if len(journey) > 2:
            middle_share = revenue * 0.2 / (len(journey) - 2)
            for tp in journey[1:-1]:
                attribution[tp.carousel_id] = attribution.get(tp.carousel_id, 0) + middle_share
                attribution[tp.channel] = attribution.get(tp.channel, 0) + middle_share
        
        return attribution
    
    def calculate_roi(self, carousel_id: str, spend: float, 
                     attribution: Dict) -> Dict:
        """Calcula ROI de un carrusel"""
        
        revenue = attribution.get(carousel_id, 0)
        
        roi = ((revenue - spend) / spend * 100) if spend > 0 else 0
        roas = revenue / spend if spend > 0 else 0
        
        return {
            'carousel_id': carousel_id,
            'spend': spend,
            'revenue': revenue,
            'profit': revenue - spend,
            'roi': roi,
            'roas': roas,
            'cac': spend  # Simplificado
        }
    
    def calculate_ltv(self, customer_id: str, days: int = 365) -> float:
        """Calcula Lifetime Value de un customer"""
        if customer_id not in self.customer_journeys:
            return 0.0
        
        journey = self.customer_journeys[customer_id]
        total_revenue = sum(tp.revenue for tp in journey)
        
        # LTV simplificado (en producci√≥n usar modelo de churn)
        return total_revenue

if __name__ == '__main__':
    analyzer = ROIAnalyzer()
    
    # Simular journey
    customer_id = 'customer_123'
    
    analyzer.add_touchpoint(customer_id, TouchPoint(
        datetime.now() - timedelta(days=7),
        'instagram',
        'curso_ia_slide1',
        'view'
    ))
    
    analyzer.add_touchpoint(customer_id, TouchPoint(
        datetime.now() - timedelta(days=3),
        'linkedin',
        'curso_ia_slide2',
        'click'
    ))
    
    analyzer.add_touchpoint(customer_id, TouchPoint(
        datetime.now(),
        'email',
        'curso_ia_slide3',
        'conversion',
        revenue=299.0
    ))
    
    # Calcular atribuci√≥n
    attribution = analyzer.calculate_attribution(
        customer_id,
        AttributionModel.LINEAR
    )
    
    print("Atribuci√≥n (Linear):")
    for carousel, revenue in attribution.items():
        print(f"  {carousel}: ${revenue:.2f}")
    
    # Calcular ROI
    roi = analyzer.calculate_roi('curso_ia_slide1', 50.0, attribution)
    print(f"\nROI: {roi['roi']:.1f}%")
    print(f"ROAS: {roi['roas']:.2f}x")
```

---

## üê¶ Integraci√≥n Avanzada con Twitter/X y TikTok

### Script de Publicaci√≥n Multi-Plataforma

**Python**: `scripts/multi_platform_publisher.py`

```python
#!/usr/bin/env python3
"""
Integraci√≥n avanzada con Twitter/X y TikTok
- Adaptaci√≥n autom√°tica de carruseles para cada plataforma
- Publicaci√≥n simult√°nea multi-plataforma
- Optimizaci√≥n de formato por plataforma
- Tracking unificado de performance
"""
import requests
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class PlatformPost:
    """Post en una plataforma espec√≠fica"""
    platform: str
    content: str
    media_urls: List[str]
    scheduled_time: Optional[datetime] = None
    post_id: Optional[str] = None

class MultiPlatformPublisher:
    """Publicador multi-plataforma"""
    
    def __init__(self, api_keys: Dict):
        self.api_keys = api_keys
        self.platform_configs = self.load_platform_configs()
    
    def adapt_carousel_for_platform(self, carousel_data: Dict, 
                                   platform: str) -> PlatformPost:
        """Adapta carrusel para una plataforma espec√≠fica"""
        
        config = self.platform_configs.get(platform, {})
        
        if platform == 'twitter':
            return self._adapt_for_twitter(carousel_data, config)
        elif platform == 'tiktok':
            return self._adapt_for_tiktok(carousel_data, config)
        elif platform == 'linkedin':
            return self._adapt_for_linkedin(carousel_data, config)
        else:
            return self._adapt_default(carousel_data, config)
    
    def _adapt_for_twitter(self, carousel_data: Dict, config: Dict) -> PlatformPost:
        """Adapta para Twitter/X"""
        # Twitter: Primera imagen del carrusel + thread con resto
        first_slide = carousel_data.get('slide_1', {})
        
        content = f"{first_slide.get('headline', '')}\n\n{first_slide.get('subcopy', '')}"
        
        # Limitar a 280 caracteres
        if len(content) > 280:
            content = content[:277] + "..."
        
        # Hashtags (m√°ximo 2)
        hashtags = config.get('hashtags', [])[:2]
        if hashtags:
            content += "\n" + " ".join([f"#{h}" for h in hashtags])
        
        return PlatformPost(
            platform='twitter',
            content=content,
            media_urls=[first_slide.get('image_url', '')],
            scheduled_time=None
        )
    
    def _adapt_for_tiktok(self, carousel_data: Dict, config: Dict) -> PlatformPost:
        """Adapta para TikTok"""
        # TikTok: Convertir carrusel a video o usar primera imagen como thumbnail
        
        # Opci√≥n 1: Video con slides como frames
        # Opci√≥n 2: Single image post con caption
        first_slide = carousel_data.get('slide_1', {})
        
        # TikTok caption (m√°s largo que Twitter)
        caption = f"{first_slide.get('headline', '')}\n\n"
        caption += f"{carousel_data.get('slide_2', {}).get('headline', '')}\n\n"
        caption += f"{carousel_data.get('slide_3', {}).get('cta', '')}"
        
        # Hashtags (m√°s en TikTok)
        hashtags = config.get('hashtags', [])[:5]
        if hashtags:
            caption += "\n\n" + " ".join([f"#{h}" for h in hashtags])
        
        return PlatformPost(
            platform='tiktok',
            content=caption,
            media_urls=[carousel_data.get('video_url', first_slide.get('image_url', ''))],
            scheduled_time=None
        )
    
    def _adapt_for_linkedin(self, carousel_data: Dict, config: Dict) -> PlatformPost:
        """Adapta para LinkedIn"""
        # LinkedIn: Carousel nativo o document post
        content = self._build_linkedin_caption(carousel_data)
        
        return PlatformPost(
            platform='linkedin',
            content=content,
            media_urls=[slide.get('image_url', '') for slide in [
                carousel_data.get('slide_1', {}),
                carousel_data.get('slide_2', {}),
                carousel_data.get('slide_3', {})
            ]],
            scheduled_time=None
        )
    
    def _adapt_default(self, carousel_data: Dict, config: Dict) -> PlatformPost:
        """Adaptaci√≥n por defecto"""
        return PlatformPost(
            platform='default',
            content=carousel_data.get('caption', ''),
            media_urls=[],
            scheduled_time=None
        )
    
    def _build_linkedin_caption(self, carousel_data: Dict) -> str:
        """Construye caption para LinkedIn"""
        lines = []
        
        # Slide 1
        slide1 = carousel_data.get('slide_1', {})
        lines.append(slide1.get('headline', ''))
        lines.append(slide1.get('subcopy', ''))
        lines.append("")
        
        # Slide 2 (testimonio)
        slide2 = carousel_data.get('slide_2', {})
        if slide2.get('headline'):
            lines.append(f'"{slide2.get("headline", "")}"')
            lines.append(f"‚Äî {slide2.get('attribution', '')}")
            lines.append("")
        
        # Slide 3 (CTA)
        slide3 = carousel_data.get('slide_3', {})
        lines.append(slide3.get('cta', ''))
        
        return "\n".join(lines)
    
    def publish_to_twitter(self, post: PlatformPost) -> Dict:
        """Publica en Twitter/X"""
        # Twitter API v2
        url = "https://api.twitter.com/2/tweets"
        
        headers = {
            'Authorization': f"Bearer {self.api_keys['twitter_bearer_token']}",
            'Content-Type': 'application/json'
        }
        
        payload = {
            'text': post.content
        }
        
        # Si hay media, subir primero y obtener media_id
        if post.media_urls:
            media_id = self._upload_media_to_twitter(post.media_urls[0])
            payload['media'] = {'media_ids': [media_id]}
        
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        result = response.json()
        
        return {
            'platform': 'twitter',
            'post_id': result.get('data', {}).get('id'),
            'status': 'published',
            'timestamp': datetime.now().isoformat()
        }
    
    def publish_to_tiktok(self, post: PlatformPost) -> Dict:
        """Publica en TikTok"""
        # TikTok API (requiere OAuth y aprobaci√≥n)
        # Nota: API de TikTok es m√°s restrictiva
        
        url = "https://open.tiktokapis.com/v2/post/publish/inbox/video/init/"
        
        headers = {
            'Authorization': f"Bearer {self.api_keys['tiktok_access_token']}",
            'Content-Type': 'application/json'
        }
        
        # En producci√≥n, subir video primero
        payload = {
            'post_info': {
                'title': post.content[:150],  # TikTok title limit
                'privacy_level': 'PUBLIC_TO_EVERYONE',
                'disable_duet': False,
                'disable_comment': False,
                'disable_stitch': False,
                'video_cover_timestamp_ms': 1000
            },
            'source_info': {
                'source': 'FILE_UPLOAD'
            }
        }
        
        # Implementaci√≥n completa requerir√≠a upload de video
        return {
            'platform': 'tiktok',
            'status': 'pending_upload',
            'note': 'Requires video file upload first'
        }
    
    def publish_to_linkedin(self, post: PlatformPost) -> Dict:
        """Publica en LinkedIn"""
        # LinkedIn API v2
        url = "https://api.linkedin.com/v2/ugcPosts"
        
        headers = {
            'Authorization': f"Bearer {self.api_keys['linkedin_access_token']}",
            'Content-Type': 'application/json',
            'X-Restli-Protocol-Version': '2.0.0'
        }
        
        # Construir payload de LinkedIn
        author_urn = f"urn:li:person:{self.api_keys['linkedin_person_id']}"
        
        payload = {
            'author': author_urn,
            'lifecycleState': 'PUBLISHED',
            'specificContent': {
                'com.linkedin.ugc.ShareContent': {
                    'shareCommentary': {
                        'text': post.content
                    },
                    'shareMediaCategory': 'IMAGE'
                }
            },
            'visibility': {
                'com.linkedin.ugc.MemberNetworkVisibility': 'PUBLIC'
            }
        }
        
        # Si hay im√°genes, agregar URNs de media
        if post.media_urls:
            # Primero subir im√°genes y obtener URNs
            media_urns = self._upload_media_to_linkedin(post.media_urls)
            payload['specificContent']['com.linkedin.ugc.ShareContent']['media'] = [
                {'media': urn, 'status': 'READY'}
                for urn in media_urns
            ]
        
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        result = response.json()
        
        return {
            'platform': 'linkedin',
            'post_id': result.get('id'),
            'status': 'published',
            'timestamp': datetime.now().isoformat()
        }
    
    def _upload_media_to_twitter(self, media_url: str) -> str:
        """Sube media a Twitter y retorna media_id"""
        # Implementaci√≥n simplificada
        # En producci√≥n: usar Twitter Upload API
        return "media_id_123"
    
    def _upload_media_to_linkedin(self, media_urls: List[str]) -> List[str]:
        """Sube media a LinkedIn y retorna URNs"""
        # Implementaci√≥n simplificada
        # En producci√≥n: usar LinkedIn Upload API
        return [f"urn:li:digitalmediaAsset:{i}" for i in range(len(media_urls))]
    
    def publish_to_all_platforms(self, carousel_data: Dict, 
                                platforms: List[str]) -> Dict:
        """Publica en m√∫ltiples plataformas"""
        results = {}
        
        for platform in platforms:
            try:
                # Adaptar carrusel para plataforma
                post = self.adapt_carousel_for_platform(carousel_data, platform)
                
                # Publicar
                if platform == 'twitter':
                    result = self.publish_to_twitter(post)
                elif platform == 'tiktok':
                    result = self.publish_to_tiktok(post)
                elif platform == 'linkedin':
                    result = self.publish_to_linkedin(post)
                else:
                    result = {'platform': platform, 'status': 'not_supported'}
                
                results[platform] = result
                
            except Exception as e:
                results[platform] = {
                    'platform': platform,
                    'status': 'error',
                    'error': str(e)
                }
        
        return results
    
    def load_platform_configs(self) -> Dict:
        """Carga configuraciones por plataforma"""
        return {
            'twitter': {
                'hashtags': ['IA', 'MarketingDigital', 'Automatizacion'],
                'max_chars': 280
            },
            'tiktok': {
                'hashtags': ['IA', 'Marketing', 'Automatizacion', 'Tech', 'Negocios'],
                'max_caption_chars': 2200
            },
            'linkedin': {
                'hashtags': ['ArtificialIntelligence', 'Marketing', 'Automation'],
                'max_chars': 3000
            }
        }

if __name__ == '__main__':
    import os
    
    publisher = MultiPlatformPublisher({
        'twitter_bearer_token': os.getenv('TWITTER_BEARER_TOKEN'),
        'tiktok_access_token': os.getenv('TIKTOK_ACCESS_TOKEN'),
        'linkedin_access_token': os.getenv('LINKEDIN_ACCESS_TOKEN'),
        'linkedin_person_id': os.getenv('LINKEDIN_PERSON_ID')
    })
    
    # Carrusel de ejemplo
    carousel_data = {
        'slide_1': {
            'headline': 'Domina IA aplicada en semanas',
            'subcopy': 'Clases pr√°cticas + webinars en vivo',
            'image_url': 'https://example.com/slide1.jpg'
        },
        'slide_2': {
            'headline': 'Desde que uso el Curso mis entregas son 2√ó m√°s r√°pidas',
            'attribution': 'Sof√≠a, Project Manager',
            'image_url': 'https://example.com/slide2.jpg'
        },
        'slide_3': {
            'cta': '√önete ahora',
            'image_url': 'https://example.com/slide3.jpg'
        }
    }
    
    # Publicar en m√∫ltiples plataformas
    results = publisher.publish_to_all_platforms(
        carousel_data,
        ['twitter', 'linkedin']
    )
    
    print(json.dumps(results, indent=2))
```

---

## üë• Sistema de Colaboraci√≥n en Equipo

### Script de Gesti√≥n de Workflow Colaborativo

**Python**: `scripts/team_collaboration.py`

```python
#!/usr/bin/env python3
"""
Sistema de colaboraci√≥n en equipo para carruseles
- Asignaci√≥n de tareas por rol
- Revisi√≥n y aprobaci√≥n de contenido
- Comentarios y feedback estructurado
- Versionado colaborativo
- Notificaciones de cambios
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class TaskStatus(Enum):
    TODO = "todo"
    IN_PROGRESS = "in_progress"
    REVIEW = "review"
    APPROVED = "approved"
    REJECTED = "rejected"

class UserRole(Enum):
    DESIGNER = "designer"
    COPYWRITER = "copywriter"
    MANAGER = "manager"
    ANALYST = "analyst"

@dataclass
class Task:
    """Tarea en el workflow"""
    task_id: str
    carousel_id: str
    assigned_to: str
    role: UserRole
    status: TaskStatus
    description: str
    due_date: Optional[datetime] = None
    created_at: datetime = None
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now()

@dataclass
class Comment:
    """Comentario en revisi√≥n"""
    comment_id: str
    task_id: str
    author: str
    content: str
    timestamp: datetime
    resolved: bool = False

class TeamCollaborationSystem:
    """Sistema de colaboraci√≥n en equipo"""
    
    def __init__(self):
        self.tasks = {}
        self.comments = {}
        self.approvals = {}
        self.workflow_stages = [
            {'stage': 'design', 'role': UserRole.DESIGNER, 'required': True},
            {'stage': 'copy', 'role': UserRole.COPYWRITER, 'required': True},
            {'stage': 'review', 'role': UserRole.MANAGER, 'required': True},
            {'stage': 'analysis', 'role': UserRole.ANALYST, 'required': False}
        ]
    
    def create_carousel_workflow(self, carousel_id: str, 
                                assignees: Dict[str, str]) -> List[Task]:
        """Crea workflow de tareas para un carrusel"""
        
        tasks = []
        
        for stage_config in self.workflow_stages:
            role = stage_config['role']
            assignee = assignees.get(role.value)
            
            if not assignee and stage_config['required']:
                continue  # Skip si no hay asignado requerido
            
            task = Task(
                task_id=f"{carousel_id}_{stage_config['stage']}",
                carousel_id=carousel_id,
                assigned_to=assignee or 'unassigned',
                role=role,
                status=TaskStatus.TODO,
                description=f"{stage_config['stage'].capitalize()} para {carousel_id}"
            )
            
            tasks.append(task)
            self.tasks[task.task_id] = task
        
        return tasks
    
    def add_comment(self, task_id: str, author: str, content: str) -> Comment:
        """Agrega comentario a una tarea"""
        
        comment = Comment(
            comment_id=f"comment_{datetime.now().timestamp()}",
            task_id=task_id,
            author=author,
            content=content,
            timestamp=datetime.now()
        )
        
        if task_id not in self.comments:
            self.comments[task_id] = []
        
        self.comments[task_id].append(comment)
        
        return comment
    
    def update_task_status(self, task_id: str, new_status: TaskStatus,
                          user: str) -> bool:
        """Actualiza estado de tarea"""
        
        if task_id not in self.tasks:
            return False
        
        task = self.tasks[task_id]
        
        # Validar permisos (simplificado)
        if task.assigned_to != user and user != 'manager':
            return False
        
        task.status = new_status
        
        # Si se aprueba, avanzar siguiente tarea
        if new_status == TaskStatus.APPROVED:
            self._advance_workflow(task.carousel_id, task.role)
        
        return True
    
    def _advance_workflow(self, carousel_id: str, completed_role: UserRole):
        """Avanza workflow al completar una etapa"""
        
        # Encontrar siguiente etapa
        current_index = next(
            (i for i, stage in enumerate(self.workflow_stages)
             if stage['role'] == completed_role),
            -1
        )
        
        if current_index >= 0 and current_index < len(self.workflow_stages) - 1:
            next_stage = self.workflow_stages[current_index + 1]
            next_task_id = f"{carousel_id}_{next_stage['stage']}"
            
            if next_task_id in self.tasks:
                self.tasks[next_task_id].status = TaskStatus.TODO
    
    def approve_carousel(self, carousel_id: str, approver: str) -> bool:
        """Aprueba carrusel para publicaci√≥n"""
        
        # Verificar que todas las tareas requeridas est√©n aprobadas
        carousel_tasks = [
            task for task in self.tasks.values()
            if task.carousel_id == carousel_id
        ]
        
        required_tasks = [
            task for task in carousel_tasks
            if any(stage['role'] == task.role and stage['required']
                   for stage in self.workflow_stages)
        ]
        
        all_approved = all(
            task.status == TaskStatus.APPROVED
            for task in required_tasks
        )
        
        if not all_approved:
            return False
        
        # Registrar aprobaci√≥n
        self.approvals[carousel_id] = {
            'approver': approver,
            'timestamp': datetime.now().isoformat(),
            'tasks_completed': len(carousel_tasks)
        }
        
        return True
    
    def get_user_tasks(self, user: str) -> List[Task]:
        """Obtiene tareas de un usuario"""
        return [
            task for task in self.tasks.values()
            if task.assigned_to == user
        ]
    
    def get_carousel_status(self, carousel_id: str) -> Dict:
        """Obtiene estado completo del workflow de un carrusel"""
        
        tasks = [
            task for task in self.tasks.values()
            if task.carousel_id == carousel_id
        ]
        
        comments_count = sum(
            len(comments) for task_id, comments in self.comments.items()
            if any(task.task_id == task_id for task in tasks)
        )
        
        is_approved = carousel_id in self.approvals
        
        return {
            'carousel_id': carousel_id,
            'tasks': [
                {
                    'task_id': task.task_id,
                    'status': task.status.value,
                    'role': task.role.value,
                    'assigned_to': task.assigned_to
                }
                for task in tasks
            ],
            'comments_count': comments_count,
            'approved': is_approved,
            'approval_info': self.approvals.get(carousel_id)
        }

if __name__ == '__main__':
    collaboration = TeamCollaborationSystem()
    
    # Crear workflow
    tasks = collaboration.create_carousel_workflow(
        'curso_ia_slide1',
        {
            'designer': 'designer@example.com',
            'copywriter': 'copywriter@example.com',
            'manager': 'manager@example.com'
        }
    )
    
    print(f"Creadas {len(tasks)} tareas")
    
    # Agregar comentario
    comment = collaboration.add_comment(
        tasks[0].task_id,
        'manager@example.com',
        'Revisar colores de marca en slide 2'
    )
    print(f"Comentario agregado: {comment.comment_id}")
    
    # Actualizar estado
    collaboration.update_task_status(tasks[0].task_id, TaskStatus.APPROVED, tasks[0].assigned_to)
    
    # Estado del carrusel
    status = collaboration.get_carousel_status('curso_ia_slide1')
    print(json.dumps(status, indent=2, default=str))
```

---

## üéØ An√°lisis de Audiencia Avanzado con ML

### Script de Segmentaci√≥n Inteligente

**Python**: `scripts/advanced_audience_analysis.py`

```python
#!/usr/bin/env python3
"""
An√°lisis de audiencia avanzado con Machine Learning
- Segmentaci√≥n autom√°tica de audiencia
- Predicci√≥n de comportamiento
- Identificaci√≥n de buyer personas
- Optimizaci√≥n de targeting
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
import json
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np

@dataclass
class AudienceSegment:
    """Segmento de audiencia"""
    segment_id: str
    name: str
    size: int
    characteristics: Dict
    engagement_rate: float
    conversion_rate: float

@dataclass
class UserProfile:
    """Perfil de usuario"""
    user_id: str
    demographics: Dict
    behavior: Dict
    engagement_history: List[Dict]
    conversion_history: List[Dict]

class AdvancedAudienceAnalyzer:
    """Analizador avanzado de audiencia"""
    
    def __init__(self):
        self.user_profiles = {}
        self.segments = {}
    
    def add_user_profile(self, profile: UserProfile):
        """Agrega perfil de usuario"""
        self.user_profiles[profile.user_id] = profile
    
    def segment_audience(self, n_segments: int = 5) -> List[AudienceSegment]:
        """Segmenta audiencia usando K-Means"""
        
        if len(self.user_profiles) < n_segments:
            return []
        
        # Preparar features para clustering
        features = []
        user_ids = []
        
        for user_id, profile in self.user_profiles.items():
            feature_vector = self._extract_features(profile)
            features.append(feature_vector)
            user_ids.append(user_id)
        
        # Normalizar features
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        
        # K-Means clustering
        kmeans = KMeans(n_clusters=n_segments, random_state=42)
        clusters = kmeans.fit_predict(features_scaled)
        
        # Crear segmentos
        segments = []
        for i in range(n_segments):
            cluster_users = [user_ids[j] for j in range(len(user_ids)) if clusters[j] == i]
            
            if not cluster_users:
                continue
            
            # Calcular caracter√≠sticas del segmento
            segment_profiles = [self.user_profiles[uid] for uid in cluster_users]
            characteristics = self._calculate_segment_characteristics(segment_profiles)
            
            # Calcular m√©tricas
            engagement_rate = self._calculate_engagement_rate(segment_profiles)
            conversion_rate = self._calculate_conversion_rate(segment_profiles)
            
            segment = AudienceSegment(
                segment_id=f"segment_{i}",
                name=f"Segmento {i+1}",
                size=len(cluster_users),
                characteristics=characteristics,
                engagement_rate=engagement_rate,
                conversion_rate=conversion_rate
            )
            
            segments.append(segment)
            self.segments[segment.segment_id] = segment
        
        return segments
    
    def _extract_features(self, profile: UserProfile) -> List[float]:
        """Extrae features num√©ricos de un perfil"""
        features = []
        
        # Demographics
        demographics = profile.demographics
        features.append(float(demographics.get('age', 35)))
        features.append(1.0 if demographics.get('gender') == 'M' else 0.0)
        
        # Behavior
        behavior = profile.behavior
        features.append(float(behavior.get('avg_time_on_site', 0)))
        features.append(float(behavior.get('page_views', 0)))
        features.append(float(behavior.get('clicks', 0)))
        
        # Engagement
        engagement_count = len(profile.engagement_history)
        features.append(float(engagement_count))
        
        # Conversion
        conversion_count = len(profile.conversion_history)
        features.append(float(conversion_count))
        
        return features
    
    def _calculate_segment_characteristics(self, profiles: List[UserProfile]) -> Dict:
        """Calcula caracter√≠sticas promedio del segmento"""
        if not profiles:
            return {}
        
        total_age = sum(p.demographics.get('age', 35) for p in profiles)
        total_engagement = sum(len(p.engagement_history) for p in profiles)
        total_conversions = sum(len(p.conversion_history) for p in profiles)
        
        return {
            'avg_age': total_age / len(profiles),
            'avg_engagement': total_engagement / len(profiles),
            'avg_conversions': total_conversions / len(profiles),
            'gender_distribution': self._calculate_gender_dist(profiles)
        }
    
    def _calculate_gender_dist(self, profiles: List[UserProfile]) -> Dict:
        """Calcula distribuci√≥n de g√©nero"""
        genders = [p.demographics.get('gender', 'U') for p in profiles]
        total = len(genders)
        
        return {
            'male': genders.count('M') / total if total > 0 else 0,
            'female': genders.count('F') / total if total > 0 else 0,
            'other': genders.count('O') / total if total > 0 else 0
        }
    
    def _calculate_engagement_rate(self, profiles: List[UserProfile]) -> float:
        """Calcula tasa de engagement promedio"""
        if not profiles:
            return 0.0
        
        total_engagement = sum(len(p.engagement_history) for p in profiles)
        total_users = len(profiles)
        
        return total_engagement / total_users if total_users > 0 else 0.0
    
    def _calculate_conversion_rate(self, profiles: List[UserProfile]) -> float:
        """Calcula tasa de conversi√≥n promedio"""
        if not profiles:
            return 0.0
        
        total_conversions = sum(len(p.conversion_history) for p in profiles)
        total_users = len(profiles)
        
        return total_conversions / total_users if total_users > 0 else 0.0
    
    def predict_user_behavior(self, user_id: str) -> Dict:
        """Predice comportamiento de usuario"""
        
        if user_id not in self.user_profiles:
            return {}
        
        profile = self.user_profiles[user_id]
        
        # Predicciones simples (en producci√≥n usar ML m√°s sofisticado)
        predictions = {
            'likely_to_engage': self._predict_engagement(profile),
            'likely_to_convert': self._predict_conversion(profile),
            'preferred_content_type': self._predict_content_preference(profile),
            'optimal_time': self._predict_optimal_time(profile)
        }
        
        return predictions
    
    def _predict_engagement(self, profile: UserProfile) -> float:
        """Predice probabilidad de engagement"""
        # Basado en historial
        engagement_history = len(profile.engagement_history)
        
        # Score: m√°s engagement hist√≥rico = m√°s probabilidad
        base_score = min(0.9, engagement_history / 10.0)
        
        return base_score
    
    def _predict_conversion(self, profile: UserProfile) -> float:
        """Predice probabilidad de conversi√≥n"""
        conversion_history = len(profile.conversion_history)
        engagement_history = len(profile.engagement_history)
        
        if engagement_history == 0:
            return 0.1
        
        # Ratio de conversi√≥n hist√≥rica
        historical_rate = conversion_history / engagement_history
        
        return min(0.9, historical_rate * 1.2)  # Slight boost
    
    def _predict_content_preference(self, profile: UserProfile) -> str:
        """Predice tipo de contenido preferido"""
        # Simplificado: basado en comportamiento
        behavior = profile.behavior
        
        if behavior.get('clicks', 0) > 10:
            return 'interactive'
        elif behavior.get('page_views', 0) > 5:
            return 'educational'
        else:
            return 'entertainment'
    
    def _predict_optimal_time(self, profile: UserProfile) -> Dict:
        """Predice hora √≥ptima para engagement"""
        # Simplificado
        return {
            'hour': 14,  # 2 PM
            'day_of_week': 2  # Mi√©rcoles
        }
    
    def get_segment_recommendations(self, segment_id: str) -> List[str]:
        """Obtiene recomendaciones para un segmento"""
        if segment_id not in self.segments:
            return []
        
        segment = self.segments[segment_id]
        recommendations = []
        
        # Basado en caracter√≠sticas
        if segment.engagement_rate < 0.05:
            recommendations.append(
                "Engagement bajo. Considerar contenido m√°s interactivo o personalizado"
            )
        
        if segment.conversion_rate < 0.1:
            recommendations.append(
                "Conversi√≥n baja. Optimizar CTA o mejorar mensaje de valor"
            )
        
        avg_age = segment.characteristics.get('avg_age', 35)
        if avg_age > 50:
            recommendations.append(
                "Audiencia madura. Considerar tono m√°s profesional y contenido detallado"
            )
        
        return recommendations

if __name__ == '__main__':
    analyzer = AdvancedAudienceAnalyzer()
    
    # Simular perfiles
    for i in range(50):
        profile = UserProfile(
            user_id=f"user_{i}",
            demographics={'age': 25 + (i % 30), 'gender': 'M' if i % 2 == 0 else 'F'},
            behavior={
                'avg_time_on_site': 120 + (i * 5),
                'page_views': 5 + (i % 10),
                'clicks': 2 + (i % 5)
            },
            engagement_history=[{}] * (2 + i % 8),
            conversion_history=[{}] * (i % 3)
        )
        analyzer.add_user_profile(profile)
    
    # Segmentar
    segments = analyzer.segment_audience(n_segments=3)
    
    print(f"Segmentos identificados: {len(segments)}")
    for segment in segments:
        print(f"\n{segment.name}:")
        print(f"  Tama√±o: {segment.size}")
        print(f"  Engagement: {segment.engagement_rate:.2%}")
        print(f"  Conversi√≥n: {segment.conversion_rate:.2%}")
        print(f"  Edad promedio: {segment.characteristics.get('avg_age', 0):.1f}")
        
        recommendations = analyzer.get_segment_recommendations(segment.segment_id)
        if recommendations:
            print("  Recomendaciones:")
            for rec in recommendations:
                print(f"    ‚Ä¢ {rec}")
```

---

## üß™ Sistema de Testing de Creatividades Pre-Publicaci√≥n

### Script de Validaci√≥n y Testing

**Python**: `scripts/creative_testing.py`

```python
#!/usr/bin/env python3
"""
Sistema de testing de creatividades antes de publicar
- Validaci√≥n de elementos visuales
- Testing de copy con IA
- Predicci√≥n de performance
- Comparaci√≥n con benchmarks
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class CreativeTestResult:
    """Resultado de test de creatividad"""
    creative_id: str
    overall_score: float  # 0-100
    visual_score: float
    copy_score: float
    cta_score: float
    predicted_ctr: float
    predicted_engagement: float
    recommendations: List[str]

class CreativeTester:
    """Tester de creatividades"""
    
    def __init__(self):
        self.benchmarks = self.load_benchmarks()
        self.test_history = []
    
    def test_creative(self, creative_data: Dict) -> CreativeTestResult:
        """Testea una creatividad completa"""
        
        # Test visual
        visual_score = self._test_visual_elements(creative_data)
        
        # Test copy
        copy_score = self._test_copy(creative_data)
        
        # Test CTA
        cta_score = self._test_cta(creative_data)
        
        # Predicciones
        predicted_ctr = self._predict_ctr(creative_data, visual_score, copy_score)
        predicted_engagement = self._predict_engagement(creative_data, copy_score)
        
        # Score general (weighted)
        overall_score = (
            visual_score * 0.3 +
            copy_score * 0.4 +
            cta_score * 0.3
        )
        
        # Recomendaciones
        recommendations = self._generate_recommendations(
            creative_data, visual_score, copy_score, cta_score
        )
        
        result = CreativeTestResult(
            creative_id=creative_data.get('id', 'unknown'),
            overall_score=overall_score,
            visual_score=visual_score,
            copy_score=copy_score,
            cta_score=cta_score,
            predicted_ctr=predicted_ctr,
            predicted_engagement=predicted_engagement,
            recommendations=recommendations
        )
        
        self.test_history.append(result)
        
        return result
    
    def _test_visual_elements(self, creative_data: Dict) -> float:
        """Testea elementos visuales"""
        score = 100.0
        
        # Verificar contraste (si hay texto sobre imagen)
        if creative_data.get('has_text_overlay'):
            score -= 10  # Penalizar si no se valida contraste
        
        # Verificar tama√±o de fuente
        font_sizes = creative_data.get('font_sizes', [])
        if font_sizes:
            min_size = min(font_sizes)
            if min_size < 24:
                score -= 15  # Texto muy peque√±o
        
        # Verificar cantidad de elementos
        element_count = creative_data.get('element_count', 0)
        if element_count > 10:
            score -= 10  # Demasiados elementos
        
        # Verificar branding
        if not creative_data.get('has_logo'):
            score -= 5
        
        return max(0, score)
    
    def _test_copy(self, creative_data: Dict) -> float:
        """Testea copy"""
        score = 100.0
        
        headline = creative_data.get('headline', '')
        
        # Longitud
        if len(headline) < 10:
            score -= 20  # Muy corto
        elif len(headline) > 80:
            score -= 15  # Muy largo
        
        # Clarity
        if not headline:
            score -= 30
        
        # Power words
        power_words = ['descubre', 'aprende', 'consigue', 'logra', 'transforma']
        has_power_word = any(word in headline.lower() for word in power_words)
        if not has_power_word:
            score -= 10
        
        # N√∫meros (mejor performance)
        import re
        if not re.search(r'\d+', headline):
            score -= 5
        
        # Emojis (moderaci√≥n)
        emoji_count = sum(1 for c in headline if ord(c) > 127)
        if emoji_count > 3:
            score -= 5
        
        return max(0, score)
    
    def _test_cta(self, creative_data: Dict) -> float:
        """Testea CTA"""
        score = 100.0
        
        cta = creative_data.get('cta', '').lower()
        
        if not cta:
            return 0
        
        # Action words
        action_words = ['√∫nete', 'comienza', 'prueba', 'consigue', 'descubre']
        has_action = any(word in cta for word in action_words)
        if not has_action:
            score -= 20
        
        # Longitud
        if len(cta) < 5:
            score -= 15
        elif len(cta) > 30:
            score -= 10
        
        # Urgencia/Escasez (bonus)
        urgency_words = ['ahora', 'hoy', 'limitado', '√∫ltimo']
        if any(word in cta for word in urgency_words):
            score += 5
        
        return min(100, max(0, score))
    
    def _predict_ctr(self, creative_data: Dict, visual_score: float,
                    copy_score: float) -> float:
        """Predice CTR"""
        # Modelo simplificado
        base_ctr = 2.0  # CTR base
        
        # Ajustar por scores
        visual_factor = visual_score / 100
        copy_factor = copy_score / 100
        
        predicted = base_ctr * (1 + (visual_factor - 0.7) + (copy_factor - 0.7))
        
        return max(0.5, min(5.0, predicted))
    
    def _predict_engagement(self, creative_data: Dict, copy_score: float) -> float:
        """Predice engagement rate"""
        base_engagement = 3.0
        
        copy_factor = copy_score / 100
        
        predicted = base_engagement * (1 + (copy_factor - 0.7) * 0.5)
        
        return max(1.0, min(8.0, predicted))
    
    def _generate_recommendations(self, creative_data: Dict,
                                 visual_score: float, copy_score: float,
                                 cta_score: float) -> List[str]:
        """Genera recomendaciones de mejora"""
        recommendations = []
        
        if visual_score < 70:
            recommendations.append(
                "Mejorar elementos visuales: verificar contraste, tama√±o de fuente, y balance de elementos"
            )
        
        if copy_score < 70:
            recommendations.append(
                "Optimizar copy: agregar power words, n√∫meros concretos, y mantener longitud √≥ptima"
            )
        
        if cta_score < 70:
            recommendations.append(
                "Mejorar CTA: usar palabras de acci√≥n claras y mantener longitud entre 5-30 caracteres"
            )
        
        headline = creative_data.get('headline', '')
        if not any(c.isdigit() for c in headline):
            recommendations.append(
                "Agregar n√∫mero o dato concreto en headline (mejora CTR en promedio 20%)"
            )
        
        return recommendations
    
    def compare_with_benchmarks(self, result: CreativeTestResult) -> Dict:
        """Compara resultado con benchmarks"""
        benchmark_ctr = self.benchmarks.get('avg_ctr', 2.0)
        benchmark_engagement = self.benchmarks.get('avg_engagement', 3.0)
        
        ctr_vs_benchmark = (result.predicted_ctr / benchmark_ctr - 1) * 100
        engagement_vs_benchmark = (result.predicted_engagement / benchmark_engagement - 1) * 100
        
        return {
            'ctr_vs_benchmark_pct': ctr_vs_benchmark,
            'engagement_vs_benchmark_pct': engagement_vs_benchmark,
            'above_benchmark': result.predicted_ctr > benchmark_ctr
        }
    
    def load_benchmarks(self) -> Dict:
        """Carga benchmarks de performance"""
        return {
            'avg_ctr': 2.0,
            'avg_engagement': 3.0,
            'avg_conversion': 10.0
        }

if __name__ == '__main__':
    tester = CreativeTester()
    
    # Test creatividad
    creative = {
        'id': 'curso_ia_slide1',
        'headline': 'Domina IA aplicada en semanas',
        'cta': '√önete ahora',
        'has_text_overlay': True,
        'font_sizes': [68, 30, 72],
        'element_count': 5,
        'has_logo': True
    }
    
    result = tester.test_creative(creative)
    
    print(f"Score General: {result.overall_score:.1f}/100")
    print(f"  Visual: {result.visual_score:.1f}")
    print(f"  Copy: {result.copy_score:.1f}")
    print(f"  CTA: {result.cta_score:.1f}")
    print(f"\nPredicciones:")
    print(f"  CTR: {result.predicted_ctr:.2f}%")
    print(f"  Engagement: {result.predicted_engagement:.2f}%")
    
    print(f"\nRecomendaciones:")
    for rec in result.recommendations:
        print(f"  ‚Ä¢ {rec}")
```

---

## üë§ Sistema de Gesti√≥n de UGC (User-Generated Content)

### Script de Recopilaci√≥n y Curator√≠a de UGC

**Python**: `scripts/ugc_management.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de User-Generated Content
- Recopilaci√≥n autom√°tica de contenido de usuarios
- Curator√≠a y moderaci√≥n con IA
- Solicitud de permisos automatizada
- Conversi√≥n a carruseles
"""
import requests
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class UGCContent:
    """Contenido generado por usuario"""
    content_id: str
    author: str
    platform: str
    content_type: str  # image, video, text, testimonial
    content_url: str
    caption: str
    engagement: Dict
    permission_status: str  # pending, approved, denied
    created_at: datetime

class UGCManager:
    """Gestor de User-Generated Content"""
    
    def __init__(self):
        self.ugc_collection = {}
        self.permissions = {}
    
    def collect_ugc(self, hashtag: str, platform: str = 'instagram') -> List[UGCContent]:
        """Recopila UGC desde plataformas"""
        
        collected = []
        
        if platform == 'instagram':
            # Instagram Basic Display API o Graph API
            collected = self._collect_from_instagram(hashtag)
        elif platform == 'twitter':
            collected = self._collect_from_twitter(hashtag)
        elif platform == 'tiktok':
            collected = self._collect_from_tiktok(hashtag)
        
        # Guardar en colecci√≥n
        for content in collected:
            self.ugc_collection[content.content_id] = content
        
        return collected
    
    def _collect_from_instagram(self, hashtag: str) -> List[UGCContent]:
        """Recopila desde Instagram"""
        # Instagram Graph API
        # En producci√≥n, usar API real
        return []
    
    def _collect_from_twitter(self, hashtag: str) -> List[UGCContent]:
        """Recopila desde Twitter/X"""
        # Twitter API v2
        # En producci√≥n, usar API real
        return []
    
    def _collect_from_tiktok(self, hashtag: str) -> List[UGCContent]:
        """Recopila desde TikTok"""
        # TikTok API
        # En producci√≥n, usar API real
        return []
    
    def moderate_content(self, content_id: str) -> Dict:
        """Modera contenido con IA"""
        
        if content_id not in self.ugc_collection:
            return {'status': 'not_found'}
        
        content = self.ugc_collection[content_id]
        
        # An√°lisis de contenido
        moderation_score = self._analyze_content_quality(content)
        
        # Verificar branding
        has_branding = self._check_branding(content)
        
        # Verificar calidad visual
        visual_quality = self._assess_visual_quality(content)
        
        approved = (
            moderation_score > 0.7 and
            visual_quality > 0.6 and
            has_branding
        )
        
        return {
            'content_id': content_id,
            'approved': approved,
            'moderation_score': moderation_score,
            'visual_quality': visual_quality,
            'has_branding': has_branding,
            'recommendations': self._generate_moderation_recommendations(
                moderation_score, visual_quality, has_branding
            )
        }
    
    def _analyze_content_quality(self, content: UGCContent) -> float:
        """Analiza calidad del contenido"""
        score = 0.5  # Base
        
        # Engagement
        engagement = content.engagement
        if engagement.get('likes', 0) > 100:
            score += 0.2
        if engagement.get('comments', 0) > 10:
            score += 0.2
        
        # Caption quality
        if content.caption and len(content.caption) > 50:
            score += 0.1
        
        return min(1.0, score)
    
    def _check_branding(self, content: UGCContent) -> bool:
        """Verifica presencia de branding"""
        # Simplificado: en producci√≥n usar visi√≥n computacional
        caption_lower = content.caption.lower()
        
        brand_keywords = ['curso ia', 'saas', 'ia bulk', 'blatam']
        
        return any(keyword in caption_lower for keyword in brand_keywords)
    
    def _assess_visual_quality(self, content: UGCContent) -> float:
        """Eval√∫a calidad visual"""
        # Simplificado: en producci√≥n usar an√°lisis de imagen
        return 0.75
    
    def _generate_moderation_recommendations(self, moderation_score: float,
                                            visual_quality: float,
                                            has_branding: bool) -> List[str]:
        """Genera recomendaciones de moderaci√≥n"""
        recommendations = []
        
        if not has_branding:
            recommendations.append("Agregar menci√≥n de marca o hashtag")
        
        if visual_quality < 0.6:
            recommendations.append("Calidad visual baja, considerar edici√≥n")
        
        if moderation_score < 0.7:
            recommendations.append("Contenido requiere revisi√≥n manual")
        
        return recommendations
    
    def request_permission(self, content_id: str, 
                          request_message: str = None) -> Dict:
        """Solicita permiso para usar UGC"""
        
        if content_id not in self.ugc_collection:
            return {'status': 'not_found'}
        
        content = self.ugc_collection[content_id]
        
        # Generar mensaje de solicitud
        if not request_message:
            request_message = self._generate_permission_request(content)
        
        # Enviar solicitud (DM o comentario)
        if content.platform == 'instagram':
            self._send_instagram_dm(content.author, request_message)
        elif content.platform == 'twitter':
            self._send_twitter_dm(content.author, request_message)
        
        # Registrar solicitud
        self.permissions[content_id] = {
            'status': 'pending',
            'requested_at': datetime.now().isoformat(),
            'request_message': request_message
        }
        
        return {
            'content_id': content_id,
            'status': 'permission_requested',
            'author': content.author
        }
    
    def _generate_permission_request(self, content: UGCContent) -> str:
        """Genera mensaje de solicitud de permiso"""
        return f"""
        ¬°Hola! Vimos tu publicaci√≥n sobre [PRODUCTO] y nos encant√≥.
        Nos gustar√≠a compartirla en nuestros canales oficiales.
        ¬øNos dar√≠as permiso para usar tu contenido con los cr√©ditos correspondientes?
        
        Gracias! üôè
        """
    
    def _send_instagram_dm(self, username: str, message: str):
        """Env√≠a DM en Instagram"""
        # Instagram Graph API
        # En producci√≥n, implementar env√≠o real
        pass
    
    def _send_twitter_dm(self, username: str, message: str):
        """Env√≠a DM en Twitter"""
        # Twitter API
        # En producci√≥n, implementar env√≠o real
        pass
    
    def convert_ugc_to_carousel(self, content_ids: List[str]) -> Dict:
        """Convierte UGC en carrusel"""
        
        ugc_items = [
            self.ugc_collection[cid] for cid in content_ids
            if cid in self.ugc_collection and 
            self.permissions.get(cid, {}).get('status') == 'approved'
        ]
        
        if not ugc_items:
            return {'status': 'no_approved_content'}
        
        # Construir carrusel
        carousel_slides = []
        
        for i, item in enumerate(ugc_items[:3]):  # M√°ximo 3 slides
            slide = {
                'slide_number': i + 1,
                'image_url': item.content_url,
                'caption': item.caption[:100],  # Truncar
                'attribution': f"@{item.author}",
                'engagement': item.engagement
            }
            carousel_slides.append(slide)
        
        return {
            'carousel_id': f"ugc_carousel_{datetime.now().timestamp()}",
            'slides': carousel_slides,
            'total_engagement': sum(
                item.engagement.get('likes', 0) + item.engagement.get('comments', 0)
                for item in ugc_items
            ),
            'ugc_count': len(carousel_slides)
        }

if __name__ == '__main__':
    manager = UGCManager()
    
    # Recopilar UGC
    ugc_items = manager.collect_ugc('#CursoIA', 'instagram')
    print(f"Recopilados {len(ugc_items)} items de UGC")
    
    # Moderar
    if ugc_items:
        moderation = manager.moderate_content(ugc_items[0].content_id)
        print(f"Moderaci√≥n: {'Aprobado' if moderation['approved'] else 'Rechazado'}")
        
        # Solicitar permiso
        if moderation['approved']:
            permission = manager.request_permission(ugc_items[0].content_id)
            print(f"Permiso solicitado: {permission['status']}")
```

---

## üéÆ Sistema de Gamificaci√≥n para Engagement

### Script de Gamificaci√≥n y Recompensas

**Python**: `scripts/gamification_system.py`

```python
#!/usr/bin/env python3
"""
Sistema de gamificaci√≥n para engagement
- Puntos y badges por interacciones
- Leaderboards de usuarios m√°s activos
- Recompensas y reconocimientos
- Desaf√≠os y misiones
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class ActionType(Enum):
    VIEW = "view"
    LIKE = "like"
    COMMENT = "comment"
    SHARE = "share"
    SAVE = "save"
    CLICK = "click"
    CONVERSION = "conversion"

@dataclass
class UserPoints:
    """Puntos de usuario"""
    user_id: str
    total_points: int
    level: int
    badges: List[str]
    achievements: List[str]

@dataclass
class Badge:
    """Badge de gamificaci√≥n"""
    badge_id: str
    name: str
    description: str
    points_required: int
    icon: str

class GamificationSystem:
    """Sistema de gamificaci√≥n"""
    
    def __init__(self):
        self.user_points = {}
        self.badges = self.load_badges()
        self.point_values = {
            ActionType.VIEW: 1,
            ActionType.LIKE: 2,
            ActionType.COMMENT: 5,
            ActionType.SHARE: 10,
            ActionType.SAVE: 3,
            ActionType.CLICK: 4,
            ActionType.CONVERSION: 50
        }
    
    def record_action(self, user_id: str, action: ActionType, 
                     carousel_id: str = None) -> Dict:
        """Registra acci√≥n y otorga puntos"""
        
        if user_id not in self.user_points:
            self.user_points[user_id] = UserPoints(
                user_id=user_id,
                total_points=0,
                level=1,
                badges=[],
                achievements=[]
            )
        
        user = self.user_points[user_id]
        
        # Calcular puntos
        points_earned = self.point_values.get(action, 0)
        
        # Bonus por acciones consecutivas
        points_earned = self._apply_bonuses(user_id, action, points_earned)
        
        # Agregar puntos
        user.total_points += points_earned
        
        # Verificar level up
        new_level = self._calculate_level(user.total_points)
        if new_level > user.level:
            user.level = new_level
            level_up = True
        else:
            level_up = False
        
        # Verificar badges
        new_badges = self._check_badges(user)
        if new_badges:
            user.badges.extend(new_badges)
        
        # Verificar achievements
        new_achievements = self._check_achievements(user, action)
        if new_achievements:
            user.achievements.extend(new_achievements)
        
        return {
            'user_id': user_id,
            'points_earned': points_earned,
            'total_points': user.total_points,
            'level': user.level,
            'level_up': level_up,
            'new_badges': new_badges,
            'new_achievements': new_achievements
        }
    
    def _apply_bonuses(self, user_id: str, action: ActionType, 
                      base_points: int) -> int:
        """Aplica bonos por acciones consecutivas"""
        # Simplificado: en producci√≥n trackear historial
        bonus = 0
        
        # Bono por engagement m√∫ltiple
        if action in [ActionType.COMMENT, ActionType.SHARE]:
            bonus = int(base_points * 0.2)  # 20% bonus
        
        return base_points + bonus
    
    def _calculate_level(self, total_points: int) -> int:
        """Calcula level basado en puntos"""
        # Nivel = sqrt(puntos / 100)
        import math
        level = int(math.sqrt(total_points / 100)) + 1
        return max(1, min(10, level))  # Cap en nivel 10
    
    def _check_badges(self, user: UserPoints) -> List[str]:
        """Verifica si usuario gana badges"""
        new_badges = []
        
        for badge in self.badges:
            if badge.badge_id in user.badges:
                continue
            
            if user.total_points >= badge.points_required:
                new_badges.append(badge.badge_id)
        
        return new_badges
    
    def _check_achievements(self, user: UserPoints, action: ActionType) -> List[str]:
        """Verifica achievements"""
        achievements = []
        
        # Achievement: Primera interacci√≥n
        if user.total_points <= 5 and action == ActionType.LIKE:
            achievements.append('first_like')
        
        # Achievement: 100 puntos
        if 90 < user.total_points <= 100:
            achievements.append('century_club')
        
        # Achievement: Nivel 5
        if user.level == 5:
            achievements.append('level_5_master')
        
        return achievements
    
    def get_leaderboard(self, limit: int = 10) -> List[Dict]:
        """Obtiene leaderboard de usuarios"""
        
        sorted_users = sorted(
            self.user_points.values(),
            key=lambda x: x.total_points,
            reverse=True
        )
        
        leaderboard = []
        for i, user in enumerate(sorted_users[:limit], 1):
            leaderboard.append({
                'rank': i,
                'user_id': user.user_id,
                'points': user.total_points,
                'level': user.level,
                'badges_count': len(user.badges)
            })
        
        return leaderboard
    
    def create_challenge(self, challenge_name: str, description: str,
                        target_action: ActionType, target_count: int,
                        reward_points: int) -> Dict:
        """Crea desaf√≠o para usuarios"""
        
        challenge = {
            'challenge_id': f"challenge_{datetime.now().timestamp()}",
            'name': challenge_name,
            'description': description,
            'target_action': target_action.value,
            'target_count': target_count,
            'reward_points': reward_points,
            'created_at': datetime.now().isoformat(),
            'participants': []
        }
        
        return challenge
    
    def load_badges(self) -> List[Badge]:
        """Carga badges disponibles"""
        return [
            Badge('first_steps', 'Primeros Pasos', 'Gana tus primeros 10 puntos', 10, 'üåü'),
            Badge('enthusiast', 'Entusiasta', 'Alcanza 100 puntos', 100, 'üî•'),
            Badge('champion', 'Campe√≥n', 'Alcanza 500 puntos', 500, 'üèÜ'),
            Badge('legend', 'Leyenda', 'Alcanza 1000 puntos', 1000, '‚≠ê'),
            Badge('early_bird', 'Early Bird', 'Primera interacci√≥n del d√≠a', 1, 'üê¶'),
            Badge('social_butterfly', 'Mariposa Social', '10 comentarios', 20, 'üí¨'),
            Badge('sharing_is_caring', 'Compartir es Cuidar', '5 shares', 50, 'üì§')
        ]

if __name__ == '__main__':
    gamification = GamificationSystem()
    
    # Simular acciones
    result1 = gamification.record_action('user_1', ActionType.VIEW)
    result2 = gamification.record_action('user_1', ActionType.LIKE)
    result3 = gamification.record_action('user_1', ActionType.COMMENT)
    
    print(f"Usuario user_1: {result3['total_points']} puntos, Nivel {result3['level']}")
    if result3['new_badges']:
        print(f"Badges ganados: {result3['new_badges']}")
    
    # Leaderboard
    leaderboard = gamification.get_leaderboard()
    print("\nLeaderboard:")
    for entry in leaderboard:
        print(f"  {entry['rank']}. {entry['user_id']}: {entry['points']} puntos")
```

---

## üé® Integraci√≥n con Herramientas de Dise√±o (Canva API)

### Script de Integraci√≥n con Canva

**Python**: `scripts/canva_integration.py`

```python
#!/usr/bin/env python3
"""
Integraci√≥n con Canva API
- Sincronizaci√≥n de templates
- Generaci√≥n autom√°tica desde Canva
- Exportaci√≥n optimizada
- Versionado de dise√±os
"""
import requests
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class CanvaDesign:
    """Dise√±o de Canva"""
    design_id: str
    title: str
    template_id: str
    status: str
    export_url: Optional[str] = None

class CanvaIntegration:
    """Integraci√≥n con Canva API"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.api_base = "https://api.canva.com/rest/v1"
        self.headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
    
    def list_templates(self, query: str = 'carousel') -> List[Dict]:
        """Lista templates de Canva"""
        url = f"{self.api_base}/templates"
        params = {
            'query': query,
            'limit': 50
        }
        
        response = requests.get(url, headers=self.headers, params=params)
        response.raise_for_status()
        
        return response.json().get('templates', [])
    
    def create_design_from_template(self, template_id: str,
                                   variables: Dict) -> CanvaDesign:
        """Crea dise√±o desde template con variables"""
        
        url = f"{self.api_base}/templates/{template_id}/designs"
        
        payload = {
            'variables': variables
        }
        
        response = requests.post(url, headers=self.headers, json=payload)
        response.raise_for_status()
        
        result = response.json()
        
        return CanvaDesign(
            design_id=result['id'],
            title=result.get('title', 'Untitled'),
            template_id=template_id,
            status=result.get('status', 'pending'),
            export_url=None
        )
    
    def update_design_variables(self, design_id: str, variables: Dict) -> Dict:
        """Actualiza variables de un dise√±o"""
        
        url = f"{self.api_base}/designs/{design_id}"
        
        payload = {
            'variables': variables
        }
        
        response = requests.patch(url, headers=self.headers, json=payload)
        response.raise_for_status()
        
        return response.json()
    
    def export_design(self, design_id: str, format: str = 'PNG',
                     dimensions: Dict = None) -> Dict:
        """Exporta dise√±o"""
        
        url = f"{self.api_base}/designs/{design_id}/exports"
        
        payload = {
            'format': format,
            'quality': 'high'
        }
        
        if dimensions:
            payload['dimensions'] = dimensions
        
        response = requests.post(url, headers=self.headers, json=payload)
        response.raise_for_status()
        
        result = response.json()
        
        return {
            'export_id': result['id'],
            'status': result.get('status', 'processing'),
            'download_url': result.get('download_url'),
            'expires_at': result.get('expires_at')
        }
    
    def generate_carousel_from_template(self, template_id: str,
                                       carousel_data: Dict) -> List[CanvaDesign]:
        """Genera carrusel completo desde template"""
        
        designs = []
        
        # Generar cada slide
        for i in range(1, 4):
            slide_data = carousel_data.get(f'slide_{i}', {})
            
            variables = {
                'HEADLINE': slide_data.get('headline', ''),
                'SUBCOPY': slide_data.get('subcopy', ''),
                'CTA': slide_data.get('cta', '')
            }
            
            design = self.create_design_from_template(template_id, variables)
            designs.append(design)
        
        return designs
    
    def sync_template_to_repository(self, template_id: str,
                                   local_path: str) -> Dict:
        """Sincroniza template de Canva al repositorio local"""
        
        # Exportar template como SVG (si disponible)
        export_result = self.export_design(template_id, format='SVG')
        
        # Descargar y guardar localmente
        if export_result.get('download_url'):
            # En producci√≥n, descargar archivo
            pass
        
        return {
            'template_id': template_id,
            'local_path': local_path,
            'synced_at': datetime.now().isoformat()
        }

if __name__ == '__main__':
    import os
    
    integration = CanvaIntegration(os.getenv('CANVA_API_KEY'))
    
    # Buscar templates
    templates = integration.list_templates('social media carousel')
    print(f"Encontrados {len(templates)} templates")
    
    # Crear dise√±o
    if templates:
        template_id = templates[0]['id']
        
        carousel_data = {
            'slide_1': {
                'headline': 'Domina IA aplicada',
                'subcopy': 'Clases pr√°cticas + webinars',
                'cta': '√önete ahora'
            }
        }
        
        designs = integration.generate_carousel_from_template(
            template_id,
            carousel_data
        )
        
        print(f"Creados {len(designs)} dise√±os")
```

---

## ü§ñ Sistema de Recomendaciones Personalizadas con ML

### Script de Recomendaciones Inteligentes

**Python**: `scripts/personalized_recommendations.py`

```python
#!/usr/bin/env python3
"""
Sistema de recomendaciones personalizadas con ML
- Recomendaciones de contenido basadas en comportamiento
- Predicci√≥n de preferencias
- Personalizaci√≥n din√°mica
- Optimizaci√≥n de experiencia
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

@dataclass
class Recommendation:
    """Recomendaci√≥n personalizada"""
    carousel_id: str
    score: float
    reason: str
    confidence: float

@dataclass
class UserPreference:
    """Preferencias de usuario"""
    user_id: str
    preferred_topics: List[str]
    preferred_formats: List[str]
    engagement_history: List[Dict]
    conversion_history: List[Dict]

class PersonalizedRecommender:
    """Sistema de recomendaciones personalizadas"""
    
    def __init__(self):
        self.user_preferences = {}
        self.carousel_features = {}
        self.vectorizer = TfidfVectorizer(max_features=100)
    
    def add_user_preference(self, preference: UserPreference):
        """Agrega preferencias de usuario"""
        self.user_preferences[preference.user_id] = preference
    
    def add_carousel_features(self, carousel_id: str, features: Dict):
        """Agrega features de carrusel"""
        self.carousel_features[carousel_id] = features
    
    def recommend_carousels(self, user_id: str, limit: int = 5) -> List[Recommendation]:
        """Genera recomendaciones personalizadas"""
        
        if user_id not in self.user_preferences:
            # Fallback a recomendaciones populares
            return self._get_popular_recommendations(limit)
        
        user_pref = self.user_preferences[user_id]
        
        # Construir perfil de usuario
        user_profile = self._build_user_profile(user_pref)
        
        # Calcular similitud con carruseles
        recommendations = []
        
        for carousel_id, features in self.carousel_features.items():
            similarity = self._calculate_similarity(user_profile, features)
            
            # Ajustar por engagement hist√≥rico
            engagement_boost = self._calculate_engagement_boost(
                user_pref, carousel_id
            )
            
            final_score = similarity * (1 + engagement_boost)
            
            recommendations.append(Recommendation(
                carousel_id=carousel_id,
                score=final_score,
                reason=self._generate_reason(user_pref, features),
                confidence=self._calculate_confidence(user_pref, features)
            ))
        
        # Ordenar por score
        recommendations.sort(key=lambda x: x.score, reverse=True)
        
        return recommendations[:limit]
    
    def _build_user_profile(self, user_pref: UserPreference) -> Dict:
        """Construye perfil de usuario"""
        
        # Combinar preferencias y comportamiento
        topics_text = ' '.join(user_pref.preferred_topics)
        formats_text = ' '.join(user_pref.preferred_formats)
        
        # Extraer temas de engagement
        engagement_topics = []
        for engagement in user_pref.engagement_history:
            topics = engagement.get('topics', [])
            engagement_topics.extend(topics)
        
        combined_text = f"{topics_text} {formats_text} {' '.join(engagement_topics)}"
        
        return {
            'text': combined_text,
            'topics': user_pref.preferred_topics,
            'formats': user_pref.preferred_formats,
            'engagement_count': len(user_pref.engagement_history),
            'conversion_count': len(user_pref.conversion_history)
        }
    
    def _calculate_similarity(self, user_profile: Dict, 
                             carousel_features: Dict) -> float:
        """Calcula similitud entre usuario y carrusel"""
        
        # Similitud de texto (TF-IDF)
        user_text = user_profile['text']
        carousel_text = carousel_features.get('description', '') + ' ' + \
                       ' '.join(carousel_features.get('topics', []))
        
        if not user_text or not carousel_text:
            return 0.5
        
        try:
            vectors = self.vectorizer.fit_transform([user_text, carousel_text])
            similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]
        except:
            similarity = 0.5
        
        # Ajustar por formato
        format_match = any(
            f in user_profile['formats']
            for f in carousel_features.get('formats', [])
        )
        
        if format_match:
            similarity += 0.1
        
        # Ajustar por temas
        topic_overlap = len(
            set(user_profile['topics']) & set(carousel_features.get('topics', []))
        )
        
        similarity += min(0.2, topic_overlap * 0.05)
        
        return min(1.0, similarity)
    
    def _calculate_engagement_boost(self, user_pref: UserPreference,
                                   carousel_id: str) -> float:
        """Calcula boost basado en engagement hist√≥rico"""
        
        # Verificar si usuario ha interactuado con carruseles similares
        similar_interactions = sum(
            1 for eng in user_pref.engagement_history
            if eng.get('carousel_id') == carousel_id or
            eng.get('similar_carousel', False)
        )
        
        return min(0.3, similar_interactions * 0.1)
    
    def _generate_reason(self, user_pref: UserPreference,
                        carousel_features: Dict) -> str:
        """Genera raz√≥n de recomendaci√≥n"""
        
        # Encontrar temas comunes
        common_topics = set(user_pref.preferred_topics) & \
                       set(carousel_features.get('topics', []))
        
        if common_topics:
            return f"Basado en tu inter√©s en: {', '.join(list(common_topics)[:2])}"
        
        # Fallback
        return "Basado en tus interacciones anteriores"
    
    def _calculate_confidence(self, user_pref: UserPreference,
                              carousel_features: Dict) -> float:
        """Calcula confianza en recomendaci√≥n"""
        
        # M√°s datos = mayor confianza
        data_points = len(user_pref.engagement_history) + \
                     len(user_pref.conversion_history)
        
        confidence = min(0.95, 0.5 + (data_points / 20))
        
        # Ajustar por overlap de temas
        topic_overlap = len(
            set(user_pref.preferred_topics) & set(carousel_features.get('topics', []))
        )
        
        confidence += min(0.2, topic_overlap * 0.05)
        
        return min(1.0, confidence)
    
    def _get_popular_recommendations(self, limit: int) -> List[Recommendation]:
        """Recomendaciones populares (cold start)"""
        
        # Ordenar carruseles por engagement (simplificado)
        sorted_carousels = sorted(
            self.carousel_features.items(),
            key=lambda x: x[1].get('engagement_score', 0),
            reverse=True
        )
        
        return [
            Recommendation(
                carousel_id=carousel_id,
                score=0.7,
                reason="Contenido popular",
                confidence=0.8
            )
            for carousel_id, _ in sorted_carousels[:limit]
        ]

if __name__ == '__main__':
    recommender = PersonalizedRecommender()
    
    # Agregar preferencias de usuario
    user_pref = UserPreference(
        user_id='user_1',
        preferred_topics=['IA', 'Marketing', 'Automatizacion'],
        preferred_formats=['carousel', 'video'],
        engagement_history=[{'carousel_id': 'curso_ia_1', 'topics': ['IA']}],
        conversion_history=[]
    )
    
    recommender.add_user_preference(user_pref)
    
    # Agregar features de carruseles
    recommender.add_carousel_features('curso_ia_1', {
        'description': 'Curso de IA aplicada con webinars',
        'topics': ['IA', 'Educacion', 'Webinars'],
        'formats': ['carousel'],
        'engagement_score': 8.5
    })
    
    # Generar recomendaciones
    recommendations = recommender.recommend_carousels('user_1', limit=3)
    
    print("Recomendaciones personalizadas:")
    for rec in recommendations:
        print(f"  {rec.carousel_id}: {rec.score:.2f} ({rec.reason})")
```

---

## üõ°Ô∏è Sistema de Gesti√≥n de Crisis y Reputaci√≥n

### Script de Monitoreo y Respuesta a Crisis

**Python**: `scripts/crisis_management.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de crisis y reputaci√≥n
- Detecci√≥n temprana de crisis
- Escalamiento autom√°tico
- Respuestas pre-aprobadas
- Tracking de reputaci√≥n
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
import json

class CrisisSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class CrisisAlert:
    """Alerta de crisis"""
    alert_id: str
    severity: CrisisSeverity
    source: str
    content: str
    detected_at: datetime
    keywords: List[str]
    sentiment: str  # negative, very_negative
    reach_estimate: int

class CrisisManager:
    """Gestor de crisis y reputaci√≥n"""
    
    def __init__(self):
        self.crisis_keywords = [
            'problema', 'error', 'malo', 'no funciona',
            'terrible', 'p√©simo', 'decepcionado', 'estafado'
        ]
        self.active_crises = {}
        self.response_templates = self.load_response_templates()
    
    def detect_crisis(self, content: str, source: str = 'social_media',
                     engagement: Dict = None) -> Optional[CrisisAlert]:
        """Detecta posibles crisis"""
        
        content_lower = content.lower()
        
        # Detectar keywords de crisis
        detected_keywords = [
            keyword for keyword in self.crisis_keywords
            if keyword in content_lower
        ]
        
        if not detected_keywords:
            return None
        
        # Calcular severidad
        severity = self._calculate_severity(content_lower, detected_keywords)
        
        # Estimar reach
        reach = engagement.get('reach', 0) if engagement else 0
        
        # Si es alta severidad o alto reach, crear alerta
        if severity in [CrisisSeverity.HIGH, CrisisSeverity.CRITICAL] or reach > 10000:
            alert = CrisisAlert(
                alert_id=f"crisis_{datetime.now().timestamp()}",
                severity=severity,
                source=source,
                content=content,
                detected_at=datetime.now(),
                keywords=detected_keywords,
                sentiment=self._analyze_sentiment(content),
                reach_estimate=reach
            )
            
            self.active_crises[alert.alert_id] = alert
            
            return alert
        
        return None
    
    def _calculate_severity(self, content: str, keywords: List[str]) -> CrisisSeverity:
        """Calcula severidad de crisis"""
        
        # Palabras de alta severidad
        high_severity_words = ['estafado', 'demanda', 'abogado', 'terrible', 'p√©simo']
        
        if any(word in content for word in high_severity_words):
            return CrisisSeverity.CRITICAL
        
        # M√∫ltiples keywords = mayor severidad
        if len(keywords) >= 3:
            return CrisisSeverity.HIGH
        
        if len(keywords) >= 2:
            return CrisisSeverity.MEDIUM
        
        return CrisisSeverity.LOW
    
    def _analyze_sentiment(self, content: str) -> str:
        """Analiza sentimiento"""
        negative_words = ['malo', 'terrible', 'horrible', 'p√©simo', 'error']
        
        if any(word in content.lower() for word in negative_words):
            return 'very_negative'
        
        return 'negative'
    
    def generate_response(self, alert: CrisisAlert) -> str:
        """Genera respuesta a crisis"""
        
        template = self.response_templates.get(alert.severity.value, {})
        
        response = template.get('template', '').format(
            keyword=alert.keywords[0] if alert.keywords else 'situaci√≥n'
        )
        
        return response
    
    def escalate_crisis(self, alert_id: str, escalation_reason: str):
        """Escala crisis para atenci√≥n inmediata"""
        
        if alert_id not in self.active_crises:
            return
        
        alert = self.active_crises[alert_id]
        
        # Notificar equipo (en producci√≥n: Slack, email, SMS)
        escalation_notification = {
            'alert_id': alert_id,
            'severity': alert.severity.value,
            'reason': escalation_reason,
            'content': alert.content[:200],
            'reach': alert.reach_estimate,
            'timestamp': datetime.now().isoformat()
        }
        
        # Guardar escalaci√≥n
        escalation_path = Path('logs/crisis_escalations.jsonl')
        escalation_path.parent.mkdir(exist_ok=True)
        
        with open(escalation_path, 'a') as f:
            f.write(json.dumps(escalation_notification) + '\n')
        
        return escalation_notification
    
    def track_reputation(self, time_window_days: int = 7) -> Dict:
        """Tracking de reputaci√≥n"""
        
        cutoff = datetime.now() - timedelta(days=time_window_days)
        
        recent_crises = [
            alert for alert in self.active_crises.values()
            if alert.detected_at > cutoff
        ]
        
        # Calcular m√©tricas
        total_crises = len(recent_crises)
        critical_count = sum(1 for a in recent_crises if a.severity == CrisisSeverity.CRITICAL)
        total_reach = sum(a.reach_estimate for a in recent_crises)
        
        # Score de reputaci√≥n (0-100, m√°s alto = mejor)
        reputation_score = max(0, 100 - (total_crises * 10) - (critical_count * 20))
        
        return {
            'reputation_score': reputation_score,
            'total_crises': total_crises,
            'critical_crises': critical_count,
            'total_reach_affected': total_reach,
            'time_window_days': time_window_days,
            'status': 'healthy' if reputation_score > 70 else 'at_risk' if reputation_score > 40 else 'critical'
        }
    
    def load_response_templates(self) -> Dict:
        """Carga templates de respuesta"""
        return {
            'low': {
                'template': 'Hola, lamento que hayas tenido una experiencia con {keyword}. Nos gustar√≠a ayudarte. ¬øPuedes contarnos m√°s detalles por DM?'
            },
            'medium': {
                'template': 'Entendemos tu preocupaci√≥n sobre {keyword}. Queremos resolver esto lo antes posible. Nuestro equipo se pondr√° en contacto contigo inmediatamente.'
            },
            'high': {
                'template': 'Nos tomamos muy en serio tu preocupaci√≥n. Hemos escalado esto a nuestro equipo de atenci√≥n. Te contactaremos en las pr√≥ximas horas.'
            },
            'critical': {
                'template': 'Esta es una situaci√≥n prioritaria. Nuestro equipo ejecutivo est√° siendo notificado y se contactar√° contigo en menos de 1 hora. Por favor, comparte tus detalles de contacto.'
            }
        }

if __name__ == '__main__':
    manager = CrisisManager()
    
    # Simular detecci√≥n de crisis
    crisis_comment = "Este producto es terrible, no funciona nada de lo que promete"
    
    alert = manager.detect_crisis(
        crisis_comment,
        source='instagram',
        engagement={'reach': 5000}
    )
    
    if alert:
        print(f"üö® Crisis detectada: {alert.severity.value}")
        print(f"   Keywords: {alert.keywords}")
        print(f"   Reach: {alert.reach_estimate}")
        
        # Generar respuesta
        response = manager.generate_response(alert)
        print(f"\nRespuesta sugerida:\n{response}")
        
        # Escalar si es necesario
        if alert.severity in [CrisisSeverity.HIGH, CrisisSeverity.CRITICAL]:
            escalation = manager.escalate_crisis(alert.alert_id, "Alta severidad detectada")
            print(f"\n‚ö†Ô∏è Crisis escalada: {escalation['reason']}")
```

---

## üìä Sistema de A/B Testing Avanzado con An√°lisis Estad√≠stico

### Script de Testing Estad√≠stico Robusto

**Python**: `scripts/advanced_ab_testing.py`

```python
#!/usr/bin/env python3
"""
Sistema de A/B testing avanzado con an√°lisis estad√≠stico
- Power analysis y sample size calculation
- Chi-square test, t-test, Bayesian analysis
- Sequential testing (early stopping)
- Multi-armed bandit integration
- Segment analysis
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import numpy as np
from scipy import stats
from scipy.stats import chi2_contingency, ttest_ind

@dataclass
class ABTestResult:
    """Resultado de A/B test"""
    test_id: str
    variant_a_metrics: Dict
    variant_b_metrics: Dict
    lift: float
    confidence_interval: tuple
    p_value: float
    is_significant: bool
    recommended_variant: str
    power: float

class AdvancedABTester:
    """Sistema avanzado de A/B testing"""
    
    def __init__(self):
        self.active_tests = {}
        self.test_history = []
    
    def calculate_sample_size(self, baseline_rate: float, 
                            minimum_detectable_effect: float,
                            alpha: float = 0.05, power: float = 0.80) -> int:
        """Calcula tama√±o de muestra necesario"""
        
        z_alpha = stats.norm.ppf(1 - alpha/2)
        z_beta = stats.norm.ppf(power)
        
        p1 = baseline_rate
        p2 = baseline_rate * (1 + minimum_detectable_effect)
        
        p_pooled = (p1 + p2) / 2
        
        numerator = (z_alpha * np.sqrt(2 * p_pooled * (1 - p_pooled)) + 
                    z_beta * np.sqrt(p1 * (1 - p1) + p2 * (1 - p2)))**2
        denominator = (p2 - p1)**2
        
        n = numerator / denominator
        
        return int(np.ceil(n))
    
    def run_ab_test(self, test_id: str, variant_a_data: List[Dict],
                   variant_b_data: List[Dict], metric: str = 'conversion') -> ABTestResult:
        """Ejecuta A/B test con an√°lisis estad√≠stico"""
        
        # Extraer m√©tricas
        a_metrics = self._extract_metrics(variant_a_data, metric)
        b_metrics = self._extract_metrics(variant_b_data, metric)
        
        # Calcular lift
        lift = self._calculate_lift(a_metrics['rate'], b_metrics['rate'])
        
        # Chi-square test para proporciones
        contingency_table = [
            [a_metrics['conversions'], a_metrics['visitors'] - a_metrics['conversions']],
            [b_metrics['conversions'], b_metrics['visitors'] - b_metrics['conversions']]
        ]
        
        chi2, p_value, dof, expected = chi2_contingency(contingency_table)
        
        # Confidence interval
        ci = self._calculate_confidence_interval(
            a_metrics['rate'], b_metrics['rate'],
            a_metrics['visitors'], b_metrics['visitors']
        )
        
        # Statistical power
        power = self._calculate_power(
            a_metrics['rate'], b_metrics['rate'],
            a_metrics['visitors'], b_metrics['visitors']
        )
        
        # Determinar significancia (p < 0.05)
        is_significant = p_value < 0.05
        
        # Recomendar variante
        if is_significant and b_metrics['rate'] > a_metrics['rate']:
            recommended = 'B'
        elif is_significant and a_metrics['rate'] > b_metrics['rate']:
            recommended = 'A'
        else:
            recommended = 'inconclusive'
        
        result = ABTestResult(
            test_id=test_id,
            variant_a_metrics=a_metrics,
            variant_b_metrics=b_metrics,
            lift=lift,
            confidence_interval=ci,
            p_value=p_value,
            is_significant=is_significant,
            recommended_variant=recommended,
            power=power
        )
        
        self.test_history.append(result)
        
        return result
    
    def _extract_metrics(self, data: List[Dict], metric: str) -> Dict:
        """Extrae m√©tricas de los datos"""
        visitors = len(data)
        conversions = sum(1 for d in data if d.get(metric, False))
        rate = conversions / visitors if visitors > 0 else 0
        
        return {
            'visitors': visitors,
            'conversions': conversions,
            'rate': rate
        }
    
    def _calculate_lift(self, rate_a: float, rate_b: float) -> float:
        """Calcula lift porcentual"""
        if rate_a == 0:
            return float('inf') if rate_b > 0 else 0
        
        return ((rate_b - rate_a) / rate_a) * 100
    
    def _calculate_confidence_interval(self, p1: float, p2: float,
                                      n1: int, n2: int) -> tuple:
        """Calcula intervalo de confianza para diferencia"""
        se = np.sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))
        z = stats.norm.ppf(0.975)  # 95% CI
        
        diff = p2 - p1
        lower = diff - z * se
        upper = diff + z * se
        
        return (lower, upper)
    
    def _calculate_power(self, p1: float, p2: float, n1: int, n2: int) -> float:
        """Calcula poder estad√≠stico"""
        se = np.sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))
        z_alpha = stats.norm.ppf(0.975)
        
        # Efecto estandarizado
        effect_size = abs(p2 - p1) / se
        
        # Power
        z_beta = effect_size - z_alpha
        power = stats.norm.cdf(z_beta)
        
        return max(0, min(1, power))
    
    def sequential_test(self, test_id: str, variant_a_data: List[Dict],
                       variant_b_data: List[Dict], checkpoints: List[int]) -> Dict:
        """Sequential testing con early stopping"""
        
        results_at_checkpoints = []
        
        for checkpoint in checkpoints:
            if checkpoint > len(variant_a_data) or checkpoint > len(variant_b_data):
                break
            
            a_sample = variant_a_data[:checkpoint]
            b_sample = variant_b_data[:checkpoint]
            
            result = self.run_ab_test(test_id, a_sample, b_sample)
            
            results_at_checkpoints.append({
                'checkpoint': checkpoint,
                'p_value': result.p_value,
                'is_significant': result.is_significant,
                'lift': result.lift
            })
            
            # Early stopping si significativo
            if result.is_significant and result.p_value < 0.01:
                return {
                    'stopped_early': True,
                    'checkpoint': checkpoint,
                    'final_result': result
                }
        
        return {
            'stopped_early': False,
            'checkpoints': results_at_checkpoints
        }
    
    def analyze_by_segment(self, test_result: ABTestResult,
                          segment_data: Dict) -> Dict:
        """Analiza resultados por segmento"""
        
        segment_analysis = {}
        
        for segment_name, segment_info in segment_data.items():
            a_data = segment_info.get('variant_a', [])
            b_data = segment_info.get('variant_b', [])
            
            segment_result = self.run_ab_test(
                f"{test_result.test_id}_{segment_name}",
                a_data, b_data
            )
            
            segment_analysis[segment_name] = {
                'lift': segment_result.lift,
                'is_significant': segment_result.is_significant,
                'recommended_variant': segment_result.recommended_variant
            }
        
        return segment_analysis

if __name__ == '__main__':
    tester = AdvancedABTester()
    
    # Calcular sample size necesario
    sample_size = tester.calculate_sample_size(
        baseline_rate=0.02,  # 2% baseline
        minimum_detectable_effect=0.25,  # 25% improvement
        power=0.80
    )
    print(f"Sample size necesario: {sample_size} por variante")
    
    # Simular datos de test
    np.random.seed(42)
    variant_a = [{'conversion': np.random.random() < 0.02} for _ in range(5000)]
    variant_b = [{'conversion': np.random.random() < 0.025} for _ in range(5000)]
    
    # Ejecutar test
    result = tester.run_ab_test('test_1', variant_a, variant_b)
    
    print(f"\nLift: {result.lift:.2f}%")
    print(f"P-value: {result.p_value:.4f}")
    print(f"Significativo: {result.is_significant}")
    print(f"Recomendado: Variante {result.recommended_variant}")
    print(f"Power: {result.power:.2f}")
```

---

## üìß Integraci√≥n Avanzada con Email Marketing

### Script de Segmentaci√≥n y Nurturing Avanzado

**Python**: `scripts/email_marketing_integration.py`

```python
#!/usr/bin/env python3
"""
Integraci√≥n avanzada con email marketing
- Segmentaci√≥n inteligente basada en comportamiento
- Nurturing sequences personalizadas
- Trigger-based campaigns
- A/B testing de emails
- ROI tracking por campaign
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class EmailSegment:
    """Segmento de email"""
    segment_id: str
    name: str
    criteria: Dict
    size: int
    engagement_rate: float

@dataclass
class EmailCampaign:
    """Campa√±a de email"""
    campaign_id: str
    name: str
    subject: str
    content: str
    segment_ids: List[str]
    scheduled_time: datetime
    sent_count: int = 0
    open_rate: float = 0.0
    click_rate: float = 0.0

class EmailMarketingIntegration:
    """Integraci√≥n con email marketing"""
    
    def __init__(self):
        self.segments = {}
        self.campaigns = {}
        self.nurturing_sequences = {}
    
    def create_behavioral_segment(self, name: str, criteria: Dict) -> EmailSegment:
        """Crea segmento basado en comportamiento"""
        
        segment_id = f"segment_{datetime.now().timestamp()}"
        
        # Criterios comunes:
        # - viewed_carousel: bool
        # - clicked_cta: bool
        # - converted: bool
        # - days_since_last_engagement: int
        # - engagement_score: float
        
        segment = EmailSegment(
            segment_id=segment_id,
            name=name,
            criteria=criteria,
            size=0,  # Calculado despu√©s
            engagement_rate=0.0
        )
        
        self.segments[segment_id] = segment
        
        return segment
    
    def build_nurturing_sequence(self, sequence_name: str,
                               trigger_event: str,
                               emails: List[Dict]) -> Dict:
        """Construye secuencia de nurturing"""
        
        sequence = {
            'sequence_id': f"sequence_{datetime.now().timestamp()}",
            'name': sequence_name,
            'trigger_event': trigger_event,
            'emails': emails,
            'delay_days': [0, 3, 7, 14, 30],  # Default delays
            'created_at': datetime.now().isoformat()
        }
        
        self.nurturing_sequences[sequence['sequence_id']] = sequence
        
        return sequence
    
    def create_carousel_followup_sequence(self) -> Dict:
        """Crea secuencia de follow-up para clicks en carrusel"""
        
        emails = [
            {
                'subject': '¬øQuieres saber m√°s sobre [PRODUCTO]?',
                'content': 'Vimos que te interes√≥ nuestro contenido sobre [PRODUCTO]. Te compartimos m√°s informaci√≥n...',
                'delay_days': 0
            },
            {
                'subject': 'Casos de √©xito con [PRODUCTO]',
                'content': 'Estos son los resultados que nuestros clientes han logrado...',
                'delay_days': 3
            },
            {
                'subject': '√öltima oportunidad: [OFERTA]',
                'content': 'Esta semana tenemos una oferta especial para ti...',
                'delay_days': 7
            }
        ]
        
        return self.build_nurturing_sequence(
            'carousel_followup',
            'carousel_click',
            emails
        )
    
    def trigger_nurturing_sequence(self, user_id: str, trigger_event: str):
        """Activa secuencia de nurturing para usuario"""
        
        # Encontrar secuencias que coincidan con el trigger
        matching_sequences = [
            seq for seq in self.nurturing_sequences.values()
            if seq['trigger_event'] == trigger_event
        ]
        
        if not matching_sequences:
            return None
        
        # Usar primera secuencia que coincida
        sequence = matching_sequences[0]
        
        # Programar emails
        scheduled_emails = []
        
        for i, email_template in enumerate(sequence['emails']):
            delay = sequence.get('delay_days', [0, 3, 7, 14, 30])[i] if i < len(sequence.get('delay_days', [])) else 0
            
            scheduled_time = datetime.now() + timedelta(days=delay)
            
            scheduled_emails.append({
                'user_id': user_id,
                'sequence_id': sequence['sequence_id'],
                'email_index': i,
                'subject': email_template['subject'],
                'content': email_template['content'],
                'scheduled_time': scheduled_time.isoformat(),
                'status': 'scheduled'
            })
        
        return {
            'user_id': user_id,
            'sequence_id': sequence['sequence_id'],
            'emails_scheduled': len(scheduled_emails),
            'scheduled_emails': scheduled_emails
        }
    
    def track_email_performance(self, campaign_id: str, metrics: Dict):
        """Trackea performance de campa√±a de email"""
        
        if campaign_id not in self.campaigns:
            return
        
        campaign = self.campaigns[campaign_id]
        
        campaign.sent_count = metrics.get('sent', 0)
        campaign.open_rate = metrics.get('open_rate', 0.0)
        campaign.click_rate = metrics.get('click_rate', 0.0)
        
        return {
            'campaign_id': campaign_id,
            'sent': campaign.sent_count,
            'open_rate': campaign.open_rate,
            'click_rate': campaign.click_rate,
            'conversion_rate': metrics.get('conversion_rate', 0.0),
            'revenue': metrics.get('revenue', 0.0)
        }

if __name__ == '__main__':
    email_marketing = EmailMarketingIntegration()
    
    # Crear segmento
    segment = email_marketing.create_behavioral_segment(
        'Carousel Clickers',
        {
            'viewed_carousel': True,
            'clicked_cta': True,
            'days_since_last_engagement': 7
        }
    )
    
    print(f"Segmento creado: {segment.name}")
    
    # Crear secuencia de nurturing
    sequence = email_marketing.create_carousel_followup_sequence()
    print(f"Secuencia creada: {sequence['name']}")
    
    # Activar secuencia
    trigger_result = email_marketing.trigger_nurturing_sequence(
        'user_123',
        'carousel_click'
    )
    
    print(f"Emails programados: {trigger_result['emails_scheduled']}")
```

---

## ü§ù Sistema de Gesti√≥n de Influencers y Affiliates

### Script de Gesti√≥n y Tracking

**Python**: `scripts/influencer_affiliate_management.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de influencers y affiliates
- Onboarding y verificaci√≥n
- Tracking de promociones y c√≥digos √∫nicos
- C√°lculo de comisiones
- Performance dashboard
- Payout automation
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class InfluencerTier(Enum):
    MICRO = "micro"  # 1K-10K followers
    SMALL = "small"  # 10K-100K
    MID = "mid"  # 100K-500K
    MACRO = "macro"  # 500K+

class CommissionType(Enum):
    FIXED = "fixed"
    PERCENTAGE = "percentage"
    HYBRID = "hybrid"

@dataclass
class Influencer:
    """Influencer/Affiliate"""
    influencer_id: str
    name: str
    platform: str
    follower_count: int
    tier: InfluencerTier
    commission_rate: float
    commission_type: CommissionType
    promo_code: str
    status: str  # active, pending, inactive

@dataclass
class Promotion:
    """Promoci√≥n de influencer"""
    promotion_id: str
    influencer_id: str
    carousel_id: str
    promo_code: str
    clicks: int = 0
    conversions: int = 0
    revenue: float = 0.0
    commission: float = 0.0
    start_date: datetime = None
    
    def __post_init__(self):
        if not self.start_date:
            self.start_date = datetime.now()

class InfluencerAffiliateManager:
    """Gestor de influencers y affiliates"""
    
    def __init__(self):
        self.influencers = {}
        self.promotions = {}
        self.conversions = {}
    
    def onboard_influencer(self, name: str, platform: str,
                          follower_count: int, commission_rate: float = 0.10) -> Influencer:
        """Onboard de nuevo influencer"""
        
        # Determinar tier
        if follower_count < 10000:
            tier = InfluencerTier.MICRO
        elif follower_count < 100000:
            tier = InfluencerTier.SMALL
        elif follower_count < 500000:
            tier = InfluencerTier.MID
        else:
            tier = InfluencerTier.MACRO
        
        # Generar c√≥digo √∫nico
        promo_code = f"{name.upper().replace(' ', '')[:6]}{datetime.now().strftime('%m%d')}"
        
        influencer = Influencer(
            influencer_id=f"inf_{datetime.now().timestamp()}",
            name=name,
            platform=platform,
            follower_count=follower_count,
            tier=tier,
            commission_rate=commission_rate,
            commission_type=CommissionType.PERCENTAGE,
            promo_code=promo_code,
            status='active'
        )
        
        self.influencers[influencer.influencer_id] = influencer
        
        return influencer
    
    def create_promotion(self, influencer_id: str, carousel_id: str) -> Promotion:
        """Crea promoci√≥n asociada a carrusel"""
        
        if influencer_id not in self.influencers:
            raise ValueError(f"Influencer {influencer_id} no encontrado")
        
        influencer = self.influencers[influencer_id]
        
        promotion = Promotion(
            promotion_id=f"promo_{datetime.now().timestamp()}",
            influencer_id=influencer_id,
            carousel_id=carousel_id,
            promo_code=influencer.promo_code
        )
        
        self.promotions[promotion.promotion_id] = promotion
        
        return promotion
    
    def track_conversion(self, promo_code: str, order_value: float):
        """Trackea conversi√≥n con c√≥digo de promoci√≥n"""
        
        # Encontrar influencer por c√≥digo
        influencer = next(
            (inf for inf in self.influencers.values() if inf.promo_code == promo_code),
            None
        )
        
        if not influencer:
            return None
        
        # Encontrar promoci√≥n activa
        active_promotion = next(
            (p for p in self.promotions.values()
             if p.influencer_id == influencer.influencer_id and p.promo_code == promo_code),
            None
        )
        
        if not active_promotion:
            return None
        
        # Calcular comisi√≥n
        commission = self._calculate_commission(order_value, influencer)
        
        # Actualizar m√©tricas
        active_promotion.clicks += 1  # Simplificado: en producci√≥n trackear clicks separados
        active_promotion.conversions += 1
        active_promotion.revenue += order_value
        active_promotion.commission += commission
        
        conversion_record = {
            'conversion_id': f"conv_{datetime.now().timestamp()}",
            'promo_code': promo_code,
            'influencer_id': influencer.influencer_id,
            'order_value': order_value,
            'commission': commission,
            'timestamp': datetime.now().isoformat()
        }
        
        self.conversions[conversion_record['conversion_id']] = conversion_record
        
        return conversion_record
    
    def _calculate_commission(self, order_value: float, influencer: Influencer) -> float:
        """Calcula comisi√≥n"""
        
        if influencer.commission_type == CommissionType.FIXED:
            return influencer.commission_rate
        
        elif influencer.commission_type == CommissionType.PERCENTAGE:
            return order_value * influencer.commission_rate
        
        else:  # HYBRID
            base = influencer.commission_rate
            percentage = 0.05  # 5% adicional
            return base + (order_value * percentage)
    
    def get_influencer_performance(self, influencer_id: str, days: int = 30) -> Dict:
        """Obtiene performance de influencer"""
        
        cutoff = datetime.now() - timedelta(days=days)
        
        recent_promotions = [
            p for p in self.promotions.values()
            if p.influencer_id == influencer_id and p.start_date > cutoff
        ]
        
        total_clicks = sum(p.clicks for p in recent_promotions)
        total_conversions = sum(p.conversions for p in recent_promotions)
        total_revenue = sum(p.revenue for p in recent_promotions)
        total_commission = sum(p.commission for p in recent_promotions)
        
        conversion_rate = (total_conversions / total_clicks * 100) if total_clicks > 0 else 0
        
        return {
            'influencer_id': influencer_id,
            'period_days': days,
            'promotions_count': len(recent_promotions),
            'total_clicks': total_clicks,
            'total_conversions': total_conversions,
            'conversion_rate': conversion_rate,
            'total_revenue': total_revenue,
            'total_commission': total_commission,
            'roi': (total_revenue / total_commission) if total_commission > 0 else 0
        }
    
    def generate_payout_report(self, influencer_id: str, month: str) -> Dict:
        """Genera reporte de payout para mes"""
        
        # Filtrar conversiones del mes
        month_conversions = [
            conv for conv in self.conversions.values()
            if conv['influencer_id'] == influencer_id and
            conv['timestamp'].startswith(month)
        ]
        
        total_commission = sum(c['commission'] for c in month_conversions)
        
        return {
            'influencer_id': influencer_id,
            'month': month,
            'conversions_count': len(month_conversions),
            'total_commission': total_commission,
            'payout_status': 'pending',
            'conversions': month_conversions
        }

if __name__ == '__main__':
    manager = InfluencerAffiliateManager()
    
    # Onboard influencer
    influencer = manager.onboard_influencer(
        'Tech Influencer',
        'instagram',
        follower_count=50000,
        commission_rate=0.15
    )
    
    print(f"Influencer onboarded: {influencer.name}")
    print(f"Tier: {influencer.tier.value}")
    print(f"Promo code: {influencer.promo_code}")
    
    # Crear promoci√≥n
    promotion = manager.create_promotion(influencer.influencer_id, 'curso_ia_carousel_1')
    print(f"\nPromoci√≥n creada: {promotion.promotion_id}")
    
    # Trackear conversiones
    manager.track_conversion(influencer.promo_code, 299.0)
    manager.track_conversion(influencer.promo_code, 499.0)
    
    # Performance
    performance = manager.get_influencer_performance(influencer.influencer_id)
    print(f"\nPerformance:")
    print(f"  Conversiones: {performance['total_conversions']}")
    print(f"  Revenue: ${performance['total_revenue']:.2f}")
    print(f"  Comisi√≥n: ${performance['total_commission']:.2f}")
```

---

## üìà Dashboard de Performance en Tiempo Real

### Script de Dashboard Interactivo

**Python**: `scripts/realtime_dashboard.py`

```python
#!/usr/bin/env python3
"""
Dashboard de performance en tiempo real
- M√©tricas en tiempo real de m√∫ltiples fuentes
- Alertas autom√°ticas
- Visualizaci√≥n de tendencias
- Exportaci√≥n de reportes
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class MetricSnapshot:
    """Snapshot de m√©trica"""
    metric_name: str
    value: float
    previous_value: float
    change_pct: float
    timestamp: datetime
    trend: str  # up, down, stable

class RealtimeDashboard:
    """Dashboard en tiempo real"""
    
    def __init__(self):
        self.metrics_history = {}
        self.alerts = []
        self.thresholds = {
            'ctr': {'min': 2.0, 'max': 10.0},
            'engagement_rate': {'min': 3.0, 'max': 15.0},
            'conversion_rate': {'min': 10.0, 'max': 30.0}
        }
    
    def update_metric(self, metric_name: str, value: float, source: str = 'api'):
        """Actualiza m√©trica"""
        
        timestamp = datetime.now()
        
        # Obtener valor anterior
        previous_value = 0.0
        if metric_name in self.metrics_history and self.metrics_history[metric_name]:
            previous_value = self.metrics_history[metric_name][-1]['value']
        
        # Calcular cambio
        if previous_value > 0:
            change_pct = ((value - previous_value) / previous_value) * 100
        else:
            change_pct = 0.0
        
        # Determinar tendencia
        if abs(change_pct) < 2.0:
            trend = 'stable'
        elif change_pct > 0:
            trend = 'up'
        else:
            trend = 'down'
        
        snapshot = MetricSnapshot(
            metric_name=metric_name,
            value=value,
            previous_value=previous_value,
            change_pct=change_pct,
            timestamp=timestamp,
            trend=trend
        )
        
        # Guardar en historial
        if metric_name not in self.metrics_history:
            self.metrics_history[metric_name] = []
        
        self.metrics_history[metric_name].append({
            'value': value,
            'timestamp': timestamp.isoformat(),
            'source': source
        })
        
        # Mantener solo √∫ltimas 1000 entradas
        if len(self.metrics_history[metric_name]) > 1000:
            self.metrics_history[metric_name] = self.metrics_history[metric_name][-1000:]
        
        # Verificar alertas
        self._check_alerts(snapshot)
        
        return snapshot
    
    def _check_alerts(self, snapshot: MetricSnapshot):
        """Verifica si se disparan alertas"""
        
        threshold = self.thresholds.get(snapshot.metric_name)
        
        if not threshold:
            return
        
        # Alerta si est√° fuera de rango
        if snapshot.value < threshold['min']:
            alert = {
                'type': 'low',
                'metric': snapshot.metric_name,
                'value': snapshot.value,
                'threshold': threshold['min'],
                'timestamp': snapshot.timestamp.isoformat(),
                'message': f"{snapshot.metric_name} est√° por debajo del umbral ({snapshot.value:.2f} < {threshold['min']:.2f})"
            }
            self.alerts.append(alert)
        
        elif snapshot.value > threshold['max']:
            alert = {
                'type': 'high',
                'metric': snapshot.metric_name,
                'value': snapshot.value,
                'threshold': threshold['max'],
                'timestamp': snapshot.timestamp.isoformat(),
                'message': f"{snapshot.metric_name} est√° por encima del umbral ({snapshot.value:.2f} > {threshold['max']:.2f})"
            }
            self.alerts.append(alert)
        
        # Alerta si cambio significativo
        if abs(snapshot.change_pct) > 20.0:
            alert = {
                'type': 'change',
                'metric': snapshot.metric_name,
                'change_pct': snapshot.change_pct,
                'timestamp': snapshot.timestamp.isoformat(),
                'message': f"{snapshot.metric_name} cambi√≥ {snapshot.change_pct:.1f}%"
            }
            self.alerts.append(alert)
    
    def get_dashboard_summary(self, hours: int = 24) -> Dict:
        """Obtiene resumen del dashboard"""
        
        cutoff = datetime.now() - timedelta(hours=hours)
        
        # Filtrar m√©tricas recientes
        recent_metrics = {}
        
        for metric_name, history in self.metrics_history.items():
            recent = [
                m for m in history
                if datetime.fromisoformat(m['timestamp']) > cutoff
            ]
            
            if recent:
                recent_metrics[metric_name] = {
                    'current': recent[-1]['value'],
                    'average': sum(m['value'] for m in recent) / len(recent),
                    'min': min(m['value'] for m in recent),
                    'max': max(m['value'] for m in recent),
                    'data_points': len(recent)
                }
        
        # Alertas recientes
        recent_alerts = [
            a for a in self.alerts
            if datetime.fromisoformat(a['timestamp']) > cutoff
        ]
        
        return {
            'time_range_hours': hours,
            'metrics': recent_metrics,
            'alerts_count': len(recent_alerts),
            'recent_alerts': recent_alerts[-10:],  # √öltimas 10
            'timestamp': datetime.now().isoformat()
        }
    
    def export_report(self, format: str = 'json') -> str:
        """Exporta reporte"""
        
        summary = self.get_dashboard_summary(24)
        
        if format == 'json':
            return json.dumps(summary, indent=2)
        
        elif format == 'csv':
            # Implementar exportaci√≥n CSV
            lines = ['Metric,Current,Average,Min,Max']
            for metric_name, data in summary['metrics'].items():
                lines.append(f"{metric_name},{data['current']},{data['average']},{data['min']},{data['max']}")
            return '\n'.join(lines)
        
        return str(summary)

if __name__ == '__main__':
    dashboard = RealtimeDashboard()
    
    # Simular actualizaciones
    dashboard.update_metric('ctr', 2.5)
    dashboard.update_metric('engagement_rate', 4.2)
    dashboard.update_metric('conversion_rate', 12.5)
    
    # Actualizar despu√©s de un tiempo (simulado)
    dashboard.update_metric('ctr', 1.8)  # Bajo umbral, deber√≠a alertar
    
    # Obtener resumen
    summary = dashboard.get_dashboard_summary()
    print(json.dumps(summary, indent=2))
```

---

## üí∞ Sistema de Optimizaci√≥n Autom√°tica de Budget con ML

### Script de Optimizaci√≥n Inteligente de Presupuesto

**Python**: `scripts/ml_budget_optimizer.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n autom√°tica de budget con ML
- Optimizaci√≥n basada en ROI hist√≥rico
- Predicci√≥n de performance por carrusel
- Reasignaci√≥n din√°mica de budget
- Restricciones y guardrails
- Multi-objetivo optimization
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import numpy as np
from scipy.optimize import minimize

@dataclass
class BudgetAllocation:
    """Asignaci√≥n de presupuesto"""
    carousel_id: str
    allocated_budget: float
    expected_conversions: int
    expected_revenue: float
    expected_roi: float
    confidence: float

class MLBudgetOptimizer:
    """Optimizador de budget con ML"""
    
    def __init__(self):
        self.carousel_performance_history = {}
        self.allocation_history = []
    
    def optimize_budget_allocation(self, total_budget: float,
                                  carousel_configs: List[Dict],
                                  optimization_goal: str = 'maximize_roi') -> Dict:
        """Optimiza asignaci√≥n de presupuesto"""
        
        # Predecir performance para cada carrusel
        predictions = []
        for config in carousel_configs:
            prediction = self._predict_performance(config)
            predictions.append({
                'carousel_id': config['id'],
                'current_budget': config.get('budget', 0),
                **prediction
            })
        
        # Preparar optimizaci√≥n
        n_carousels = len(predictions)
        carousel_ids = [p['carousel_id'] for p in predictions]
        
        # Funci√≥n objetivo
        def objective(x):
            if optimization_goal == 'maximize_roi':
                total_roi = 0
                for i, pred in enumerate(predictions):
                    # ROI estimado basado en budget asignado
                    roi = self._estimate_roi(pred, x[i])
                    total_roi += roi
                return -total_roi  # Negativo para maximizar
        
            elif optimization_goal == 'maximize_conversions':
                total_conversions = 0
                for i, pred in enumerate(predictions):
                    conversions = self._estimate_conversions(pred, x[i])
                    total_conversions += conversions
                return -total_conversions
            
            elif optimization_goal == 'maximize_revenue':
                total_revenue = 0
                for i, pred in enumerate(predictions):
                    revenue = self._estimate_revenue(pred, x[i])
                    total_revenue += revenue
                return -total_revenue
            
            return 0
        
        # Restricciones
        constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - total_budget}  # Suma = total
        ]
        
        # L√≠mites: m√≠nimo 10% y m√°ximo 40% por carrusel
        bounds = [(total_budget * 0.10, total_budget * 0.40) for _ in range(n_carousels)]
        
        # Punto inicial (distribuci√≥n proporcional a performance)
        x0 = self._calculate_initial_allocation(predictions, total_budget)
        
        # Optimizar
        result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)
        
        # Construir asignaciones
        allocations = []
        for i, carousel_id in enumerate(carousel_ids):
            pred = predictions[i]
            allocated = result.x[i]
            
            allocation = BudgetAllocation(
                carousel_id=carousel_id,
                allocated_budget=allocated,
                expected_conversions=self._estimate_conversions(pred, allocated),
                expected_revenue=self._estimate_revenue(pred, allocated),
                expected_roi=self._estimate_roi(pred, allocated),
                confidence=pred.get('confidence', 0.7)
            )
            allocations.append(allocation)
        
        return {
            'total_budget': total_budget,
            'optimization_goal': optimization_goal,
            'allocations': allocations,
            'total_expected_conversions': sum(a.expected_conversions for a in allocations),
            'total_expected_revenue': sum(a.expected_revenue for a in allocations),
            'total_expected_roi': sum(a.expected_roi for a in allocations),
            'optimization_success': result.success
        }
    
    def _predict_performance(self, config: Dict) -> Dict:
        """Predice performance basado en historial"""
        
        carousel_id = config['id']
        historical = self.carousel_performance_history.get(carousel_id, [])
        
        if not historical:
            # Fallback a estimaciones conservadoras
            return {
                'conversion_rate': 0.02,
                'cpa': 50.0,
                'roi': 3.0,
                'confidence': 0.5
            }
        
        # Calcular promedios ponderados (m√°s peso a datos recientes)
        recent_data = historical[-30:]  # √öltimos 30 d√≠as
        
        avg_conversion_rate = np.mean([d['conversion_rate'] for d in recent_data])
        avg_cpa = np.mean([d['cpa'] for d in recent_data])
        avg_roi = np.mean([d['roi'] for d in recent_data])
        
        # Confianza basada en cantidad de datos
        confidence = min(0.95, 0.5 + len(recent_data) / 60)
        
        return {
            'conversion_rate': avg_conversion_rate,
            'cpa': avg_cpa,
            'roi': avg_roi,
            'confidence': confidence
        }
    
    def _estimate_conversions(self, prediction: Dict, budget: float) -> int:
        """Estima conversiones para un budget dado"""
        # Conversiones = Budget / CPA
        cpa = prediction.get('cpa', 50.0)
        return int(budget / cpa) if cpa > 0 else 0
    
    def _estimate_revenue(self, prediction: Dict, budget: float) -> float:
        """Estima revenue para un budget dado"""
        conversions = self._estimate_conversions(prediction, budget)
        # Asumiendo valor promedio por conversi√≥n
        avg_order_value = 300.0  # En producci√≥n, calcular desde hist√≥rico
        return conversions * avg_order_value
    
    def _estimate_roi(self, prediction: Dict, budget: float) -> float:
        """Estima ROI para un budget dado"""
        revenue = self._estimate_revenue(prediction, budget)
        if budget > 0:
            return (revenue - budget) / budget
        return 0
    
    def _calculate_initial_allocation(self, predictions: List[Dict], total_budget: float) -> np.ndarray:
        """Calcula asignaci√≥n inicial basada en performance"""
        
        # Asignar proporcional a ROI esperado
        rois = [p.get('roi', 1.0) for p in predictions]
        total_roi = sum(rois)
        
        if total_roi == 0:
            # Distribuci√≥n uniforme
            return np.ones(len(predictions)) * (total_budget / len(predictions))
        
        # Distribuci√≥n proporcional
        weights = [roi / total_roi for roi in rois]
        return np.array([w * total_budget for w in weights])
    
    def update_performance_history(self, carousel_id: str, metrics: Dict):
        """Actualiza historial de performance"""
        
        if carousel_id not in self.carousel_performance_history:
            self.carousel_performance_history[carousel_id] = []
        
        self.carousel_performance_history[carousel_id].append({
            'date': datetime.now().isoformat(),
            'conversion_rate': metrics.get('conversion_rate', 0),
            'cpa': metrics.get('cpa', 0),
            'roi': metrics.get('roi', 0),
            'revenue': metrics.get('revenue', 0)
        })
        
        # Mantener solo √∫ltimos 90 d√≠as
        if len(self.carousel_performance_history[carousel_id]) > 90:
            self.carousel_performance_history[carousel_id] = \
                self.carousel_performance_history[carousel_id][-90:]

if __name__ == '__main__':
    optimizer = MLBudgetOptimizer()
    
    # Configurar carruseles
    carousels = [
        {'id': 'curso_ia_1', 'budget': 500},
        {'id': 'saas_marketing_1', 'budget': 300},
        {'id': 'ia_bulk_1', 'budget': 200}
    ]
    
    # Simular historial de performance
    optimizer.update_performance_history('curso_ia_1', {
        'conversion_rate': 0.025,
        'cpa': 40.0,
        'roi': 4.5,
        'revenue': 5000
    })
    
    # Optimizar
    result = optimizer.optimize_budget_allocation(
        total_budget=1000,
        carousel_configs=carousels,
        optimization_goal='maximize_roi'
    )
    
    print(f"Optimizaci√≥n completada:")
    print(f"  Conversiones esperadas: {result['total_expected_conversions']}")
    print(f"  Revenue esperado: ${result['total_expected_revenue']:.2f}")
    print(f"  ROI esperado: {result['total_expected_roi']:.2%}")
```

---

## üìä Sistema de An√°lisis de Cohortes

### Script de An√°lisis Cohort Avanzado

**Python**: `scripts/cohort_analysis.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis de cohortes
- Segmentaci√≥n por fecha de adquisici√≥n
- M√©tricas de retenci√≥n
- An√°lisis de lifetime value
- Comparaci√≥n entre cohortes
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
from collections import defaultdict

@dataclass
class CohortMetrics:
    """M√©tricas de cohorte"""
    cohort_id: str
    acquisition_date: datetime
    size: int
    retention_by_period: Dict[int, float]  # period -> retention rate
    ltv: float
    revenue_by_period: Dict[int, float]

class CohortAnalyzer:
    """Analizador de cohortes"""
    
    def __init__(self):
        self.cohorts = {}
        self.user_data = {}
    
    def create_cohort(self, cohort_id: str, acquisition_date: datetime,
                    user_ids: List[str]) -> CohortMetrics:
        """Crea cohorte"""
        
        cohort = CohortMetrics(
            cohort_id=cohort_id,
            acquisition_date=acquisition_date,
            size=len(user_ids),
            retention_by_period={},
            ltv=0.0,
            revenue_by_period={}
        )
        
        self.cohorts[cohort_id] = cohort
        
        # Registrar usuarios en cohorte
        for user_id in user_ids:
            if user_id not in self.user_data:
                self.user_data[user_id] = {
                    'cohort_id': cohort_id,
                    'acquisition_date': acquisition_date,
                    'activity_by_period': {}
                }
        
        return cohort
    
    def calculate_retention(self, cohort_id: str, periods: List[int]) -> Dict:
        """Calcula retenci√≥n por per√≠odos"""
        
        if cohort_id not in self.cohorts:
            return {}
        
        cohort = self.cohorts[cohort_id]
        users_in_cohort = [
            uid for uid, data in self.user_data.items()
            if data['cohort_id'] == cohort_id
        ]
        
        retention_by_period = {}
        
        for period in periods:
            # Usuarios activos en este per√≠odo
            active_users = sum(
                1 for uid in users_in_cohort
                if self._is_user_active(uid, cohort.acquisition_date, period)
            )
            
            retention_rate = active_users / len(users_in_cohort) if users_in_cohort else 0
            retention_by_period[period] = retention_rate
        
        cohort.retention_by_period = retention_by_period
        
        return retention_by_period
    
    def calculate_ltv(self, cohort_id: str, periods: int = 12) -> float:
        """Calcula Lifetime Value"""
        
        if cohort_id not in self.cohorts:
            return 0.0
        
        cohort = self.cohorts[cohort_id]
        users_in_cohort = [
            uid for uid, data in self.user_data.items()
            if data['cohort_id'] == cohort_id
        ]
        
        total_revenue = 0.0
        
        for period in range(periods):
            period_revenue = sum(
                self._get_user_revenue(uid, cohort.acquisition_date, period)
                for uid in users_in_cohort
            )
            total_revenue += period_revenue
            cohort.revenue_by_period[period] = period_revenue
        
        ltv = total_revenue / len(users_in_cohort) if users_in_cohort else 0.0
        cohort.ltv = ltv
        
        return ltv
    
    def compare_cohorts(self, cohort_ids: List[str]) -> Dict:
        """Compara m√∫ltiples cohortes"""
        
        comparison = {}
        
        for cohort_id in cohort_ids:
            if cohort_id not in self.cohorts:
                continue
            
            cohort = self.cohorts[cohort_id]
            
            comparison[cohort_id] = {
                'size': cohort.size,
                'acquisition_date': cohort.acquisition_date.isoformat(),
                'retention_30d': cohort.retention_by_period.get(30, 0),
                'retention_90d': cohort.retention_by_period.get(90, 0),
                'ltv': cohort.ltv,
                'revenue_30d': cohort.revenue_by_period.get(0, 0)
            }
        
        return comparison
    
    def _is_user_active(self, user_id: str, cohort_date: datetime, period: int) -> bool:
        """Verifica si usuario est√° activo en per√≠odo"""
        # Simplificado: en producci√≥n verificar actividad real
        return True
    
    def _get_user_revenue(self, user_id: str, cohort_date: datetime, period: int) -> float:
        """Obtiene revenue de usuario en per√≠odo"""
        # Simplificado: en producci√≥n obtener de base de datos
        return 25.0  # Revenue promedio por per√≠odo

if __name__ == '__main__':
    analyzer = CohortAnalyzer()
    
    # Crear cohortes
    cohort1 = analyzer.create_cohort(
        'january_2024',
        datetime(2024, 1, 1),
        ['user_1', 'user_2', 'user_3']
    )
    
    cohort2 = analyzer.create_cohort(
        'february_2024',
        datetime(2024, 2, 1),
        ['user_4', 'user_5']
    )
    
    # Calcular retenci√≥n
    retention1 = analyzer.calculate_retention('january_2024', [7, 30, 90])
    print(f"Retenci√≥n cohort enero: {retention1}")
    
    # Calcular LTV
    ltv1 = analyzer.calculate_ltv('january_2024', periods=12)
    print(f"LTV cohort enero: ${ltv1:.2f}")
    
    # Comparar
    comparison = analyzer.compare_cohorts(['january_2024', 'february_2024'])
    print(f"\nComparaci√≥n: {json.dumps(comparison, indent=2, default=str)}")
```

---

## üåç Sistema de Localizaci√≥n Multiling√ºe

### Script de Gesti√≥n Multi-Idioma

**Python**: `scripts/multilingual_localization.py`

```python
#!/usr/bin/env python3
"""
Sistema de localizaci√≥n multiling√ºe
- Traducci√≥n autom√°tica de carruseles
- Adaptaci√≥n cultural de copy
- Gesti√≥n de assets por idioma
- Testing de performance por mercado
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class LocalizedContent:
    """Contenido localizado"""
    carousel_id: str
    language: str
    locale: str  # es-ES, es-MX, en-US, etc.
    headline: str
    subcopy: str
    cta: str
    hashtags: List[str]
    status: str  # draft, approved, published

class MultilingualLocalization:
    """Sistema de localizaci√≥n"""
    
    def __init__(self):
        self.localized_content = {}
        self.supported_languages = ['es', 'en', 'pt', 'fr']
        self.locale_configs = {
            'es-ES': {'currency': 'EUR', 'date_format': 'DD/MM/YYYY'},
            'es-MX': {'currency': 'MXN', 'date_format': 'DD/MM/YYYY'},
            'en-US': {'currency': 'USD', 'date_format': 'MM/DD/YYYY'},
            'pt-BR': {'currency': 'BRL', 'date_format': 'DD/MM/YYYY'}
        }
    
    def translate_carousel(self, source_carousel: Dict, target_language: str,
                          target_locale: str, translation_service: str = 'auto') -> LocalizedContent:
        """Traduce carrusel a idioma objetivo"""
        
        # En producci√≥n, integrar con servicio de traducci√≥n (Google Translate, DeepL)
        translated = self._translate_content(
            source_carousel,
            target_language,
            target_locale
        )
        
        localized = LocalizedContent(
            carousel_id=f"{source_carousel['id']}_{target_locale}",
            language=target_language,
            locale=target_locale,
            headline=translated['headline'],
            subcopy=translated['subcopy'],
            cta=translated['cta'],
            hashtags=translated['hashtags'],
            status='draft'
        )
        
        self.localized_content[localized.carousel_id] = localized
        
        return localized
    
    def _translate_content(self, source: Dict, language: str, locale: str) -> Dict:
        """Traduce contenido (simplificado)"""
        
        # Mapeo de traducciones simples (en producci√≥n usar API real)
        translations = {
            'es': {
                'headline': source.get('headline', '').replace('Domina', 'Master'),
                'subcopy': source.get('subcopy', ''),
                'cta': source.get('cta', '').replace('√önete', 'Join'),
                'hashtags': source.get('hashtags', [])
            },
            'en': {
                'headline': source.get('headline', ''),
                'subcopy': source.get('subcopy', ''),
                'cta': source.get('cta', ''),
                'hashtags': source.get('hashtags', [])
            }
        }
        
        return translations.get(language, translations['en'])
    
    def adapt_culturally(self, localized: LocalizedContent) -> LocalizedContent:
        """Adapta contenido culturalmente"""
        
        locale_config = self.locale_configs.get(localized.locale, {})
        
        # Adaptar formato de moneda
        if 'price' in localized.headline:
            currency_symbol = self._get_currency_symbol(locale_config.get('currency', 'USD'))
            localized.headline = localized.headline.replace('$', currency_symbol)
        
        # Adaptar formato de fecha
        # Adaptar referencias culturales
        if localized.locale == 'es-MX':
            # Usar "ustedes" en lugar de "vosotros"
            localized.subcopy = localized.subcopy.replace('vosotros', 'ustedes')
        
        return localized
    
    def _get_currency_symbol(self, currency: str) -> str:
        """Obtiene s√≠mbolo de moneda"""
        symbols = {
            'USD': '$',
            'EUR': '‚Ç¨',
            'MXN': '$',
            'BRL': 'R$'
        }
        return symbols.get(currency, '$')
    
    def get_localized_carousel(self, original_id: str, locale: str) -> Optional[LocalizedContent]:
        """Obtiene carrusel localizado"""
        localized_id = f"{original_id}_{locale}"
        return self.localized_content.get(localized_id)
    
    def compare_performance_by_locale(self, original_id: str, locales: List[str]) -> Dict:
        """Compara performance por locale"""
        
        performance = {}
        
        for locale in locales:
            localized = self.get_localized_carousel(original_id, locale)
            
            if localized:
                # En producci√≥n, obtener m√©tricas reales
                performance[locale] = {
                    'ctr': 2.5,
                    'conversion_rate': 12.0,
                    'engagement_rate': 4.2,
                    'status': localized.status
                }
        
        return performance

if __name__ == '__main__':
    localization = MultilingualLocalization()
    
    # Carrusel original
    original = {
        'id': 'curso_ia_1',
        'headline': 'Domina IA aplicada en semanas',
        'subcopy': 'Clases pr√°cticas + webinars en vivo',
        'cta': '√önete ahora',
        'hashtags': ['IA', 'Marketing', 'Automatizacion']
    }
    
    # Traducir
    localized = localization.translate_carousel(original, 'en', 'en-US')
    print(f"Carrusel traducido: {localized.headline}")
    
    # Adaptar culturalmente
    adapted = localization.adapt_culturally(localized)
    print(f"Adaptado: {adapted.headline}")
```

---

## üìÖ Sistema de Predicci√≥n de Demanda Estacional

### Script de Forecasting Estacional

**Python**: `scripts/seasonal_demand_forecasting.py`

```python
#!/usr/bin/env python3
"""
Sistema de predicci√≥n de demanda estacional
- Detecci√≥n de patrones estacionales
- Forecasting de demanda
- Optimizaci√≥n de inventario/contenido
- Alertas de picos esperados
"""
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import defaultdict
import json
import numpy as np

@dataclass
class SeasonalPattern:
    """Patr√≥n estacional"""
    pattern_id: str
    name: str
    period_type: str  # daily, weekly, monthly, yearly
    peaks: List[int]  # D√≠as/meses de picos
    troughs: List[int]
    amplitude: float
    confidence: float

@dataclass
class DemandForecast:
    """Pron√≥stico de demanda"""
    date: datetime
    predicted_demand: float
    confidence_interval: tuple
    seasonal_factor: float
    trend: str  # increasing, decreasing, stable

class SeasonalDemandForecaster:
    """Pronosticador de demanda estacional"""
    
    def __init__(self):
        self.historical_data = {}
        self.seasonal_patterns = {}
        self.forecasts = {}
    
    def add_historical_data(self, product_id: str, data: List[Dict]):
        """Agrega datos hist√≥ricos"""
        self.historical_data[product_id] = data
    
    def detect_seasonal_pattern(self, product_id: str) -> SeasonalPattern:
        """Detecta patr√≥n estacional"""
        
        if product_id not in self.historical_data:
            return None
        
        data = self.historical_data[product_id]
        
        # Extraer valores por d√≠a/mes
        values_by_date = {}
        for entry in data:
            date = datetime.fromisoformat(entry['date'])
            values_by_date[date] = entry.get('demand', 0)
        
        # Calcular promedios por mes
        monthly_averages = defaultdict(list)
        for date, value in values_by_date.items():
            month = date.month
            monthly_averages[month].append(value)
        
        monthly_means = {m: np.mean(vals) for m, vals in monthly_averages.items()}
        
        # Identificar picos y valles
        peak_months = sorted(monthly_means.items(), key=lambda x: x[1], reverse=True)[:3]
        trough_months = sorted(monthly_means.items(), key=lambda x: x[1])[:3]
        
        # Calcular amplitud
        max_val = max(monthly_means.values())
        min_val = min(monthly_means.values())
        amplitude = (max_val - min_val) / max_val if max_val > 0 else 0
        
        pattern = SeasonalPattern(
            pattern_id=f"pattern_{product_id}",
            name=f"Seasonal Pattern for {product_id}",
            period_type='monthly',
            peaks=[m[0] for m in peak_months],
            troughs=[m[0] for m in trough_months],
            amplitude=amplitude,
            confidence=min(0.95, len(data) / 100)
        )
        
        self.seasonal_patterns[product_id] = pattern
        
        return pattern
    
    def forecast_demand(self, product_id: str, forecast_date: datetime) -> DemandForecast:
        """Pronostica demanda para fecha espec√≠fica"""
        
        if product_id not in self.seasonal_patterns:
            self.detect_seasonal_pattern(product_id)
        
        pattern = self.seasonal_patterns.get(product_id)
        historical = self.historical_data.get(product_id, [])
        
        if not pattern or not historical:
            return None
        
        # Calcular factor estacional
        month = forecast_date.month
        seasonal_factor = self._calculate_seasonal_factor(pattern, month, historical)
        
        # Tendencia base (promedio reciente)
        recent_avg = np.mean([d.get('demand', 0) for d in historical[-30:]])
        
        # Predicci√≥n
        predicted_demand = recent_avg * seasonal_factor
        
        # Intervalo de confianza (simplificado)
        std_dev = np.std([d.get('demand', 0) for d in historical[-30:]])
        confidence_interval = (
            predicted_demand - 1.96 * std_dev,
            predicted_demand + 1.96 * std_dev
        )
        
        # Determinar tendencia
        recent_trend = self._calculate_trend(historical[-30:])
        
        forecast = DemandForecast(
            date=forecast_date,
            predicted_demand=predicted_demand,
            confidence_interval=confidence_interval,
            seasonal_factor=seasonal_factor,
            trend=recent_trend
        )
        
        self.forecasts[f"{product_id}_{forecast_date.isoformat()}"] = forecast
        
        return forecast
    
    def _calculate_seasonal_factor(self, pattern: SeasonalPattern, month: int,
                                  historical: List[Dict]) -> float:
        """Calcula factor estacional"""
        
        # Obtener demanda promedio del mes en hist√≥rico
        month_data = [
            d.get('demand', 0) for d in historical
            if datetime.fromisoformat(d['date']).month == month
        ]
        
        if not month_data:
            return 1.0
        
        month_avg = np.mean(month_data)
        overall_avg = np.mean([d.get('demand', 0) for d in historical])
        
        return month_avg / overall_avg if overall_avg > 0 else 1.0
    
    def _calculate_trend(self, recent_data: List[Dict]) -> str:
        """Calcula tendencia"""
        if len(recent_data) < 2:
            return 'stable'
        
        demands = [d.get('demand', 0) for d in recent_data]
        
        # Regresi√≥n simple
        x = np.arange(len(demands))
        slope = np.polyfit(x, demands, 1)[0]
        
        if slope > 0.1:
            return 'increasing'
        elif slope < -0.1:
            return 'decreasing'
        else:
            return 'stable'
    
    def get_peak_periods(self, product_id: str, months_ahead: int = 6) -> List[datetime]:
        """Obtiene per√≠odos de pico esperados"""
        
        if product_id not in self.seasonal_patterns:
            return []
        
        pattern = self.seasonal_patterns[product_id]
        current_date = datetime.now()
        peak_periods = []
        
        for month_offset in range(months_ahead):
            check_date = current_date + timedelta(days=30 * month_offset)
            check_month = check_date.month
            
            if check_month in pattern.peaks:
                peak_periods.append(check_date)
        
        return peak_periods

if __name__ == '__main__':
    forecaster = SeasonalDemandForecaster()
    
    # Simular datos hist√≥ricos
    historical_data = []
    for month in range(1, 13):
        for day in range(1, 29):
            date = datetime(2024, month, day)
            # Simular demanda con patr√≥n estacional (m√°s alta en meses 3, 6, 9)
            base_demand = 100
            seasonal_factor = 1.5 if month in [3, 6, 9] else 0.8
            demand = base_demand * seasonal_factor + np.random.normal(0, 10)
            
            historical_data.append({
                'date': date.isoformat(),
                'demand': max(0, demand)
            })
    
    forecaster.add_historical_data('curso_ia', historical_data)
    
    # Detectar patr√≥n
    pattern = forecaster.detect_seasonal_pattern('curso_ia')
    print(f"Patr√≥n detectado:")
    print(f"  Picos en meses: {pattern.peaks}")
    print(f"  Amplitud: {pattern.amplitude:.2%}")
    
    # Pronosticar
    forecast_date = datetime(2025, 3, 15)
    forecast = forecaster.forecast_demand('curso_ia', forecast_date)
    print(f"\nPron√≥stico para {forecast_date.strftime('%Y-%m-%d')}:")
    print(f"  Demanda esperada: {forecast.predicted_demand:.1f}")
    print(f"  Factor estacional: {forecast.seasonal_factor:.2f}")
    print(f"  Tendencia: {forecast.trend}")
```

---

## üîå Integraci√≥n Avanzada con Herramientas de BI

### Script de Integraci√≥n con Tableau, Power BI y Looker

**Python**: `scripts/bi_tools_integration.py`

```python
#!/usr/bin/env python3
"""
Integraci√≥n avanzada con herramientas de BI
- Exportaci√≥n de datos a Tableau, Power BI, Looker
- Sincronizaci√≥n autom√°tica de m√©tricas
- Dashboards pre-configurados
- Reportes automatizados
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import pandas as pd

@dataclass
class BIDashboard:
    """Dashboard de BI"""
    dashboard_id: str
    name: str
    tool: str  # tableau, powerbi, looker
    metrics: List[str]
    update_frequency: str  # hourly, daily, weekly
    last_updated: datetime

class BIToolsIntegration:
    """Integraci√≥n con herramientas de BI"""
    
    def __init__(self):
        self.dashboards = {}
        self.data_warehouse = {}
    
    def export_to_tableau(self, carousel_data: List[Dict], 
                         dashboard_name: str) -> Dict:
        """Exporta datos a Tableau"""
        
        # Preparar datos para Tableau
        df = pd.DataFrame(carousel_data)
        
        # Transformar datos
        tableau_data = self._transform_for_tableau(df)
        
        # Generar archivo .hyper o .csv
        file_path = f"exports/tableau_{dashboard_name}_{datetime.now().strftime('%Y%m%d')}.csv"
        tableau_data.to_csv(file_path, index=False)
        
        dashboard = BIDashboard(
            dashboard_id=f"tableau_{dashboard_name}",
            name=dashboard_name,
            tool='tableau',
            metrics=['ctr', 'conversion_rate', 'roi', 'engagement_rate'],
            update_frequency='daily',
            last_updated=datetime.now()
        )
        
        self.dashboards[dashboard.dashboard_id] = dashboard
        
        return {
            'tool': 'tableau',
            'file_path': file_path,
            'rows': len(tableau_data),
            'columns': list(tableau_data.columns),
            'dashboard_id': dashboard.dashboard_id
        }
    
    def export_to_powerbi(self, carousel_data: List[Dict],
                         dataset_name: str) -> Dict:
        """Exporta datos a Power BI"""
        
        # Preparar datos
        df = pd.DataFrame(carousel_data)
        
        # Transformar para Power BI
        powerbi_data = self._transform_for_powerbi(df)
        
        # Generar JSON (Power BI puede importar JSON)
        file_path = f"exports/powerbi_{dataset_name}_{datetime.now().strftime('%Y%m%d')}.json"
        
        with open(file_path, 'w') as f:
            json.dump(powerbi_data.to_dict('records'), f, default=str)
        
        return {
            'tool': 'powerbi',
            'file_path': file_path,
            'dataset_name': dataset_name,
            'rows': len(powerbi_data),
            'update_url': f"https://api.powerbi.com/datasets/{dataset_name}"
        }
    
    def export_to_looker(self, carousel_data: List[Dict],
                        view_name: str) -> Dict:
        """Exporta datos a Looker"""
        
        # Looker usa LookML para definir modelos
        lookml_model = self._generate_lookml_model(view_name, carousel_data)
        
        file_path = f"exports/looker_{view_name}.model.lkml"
        
        with open(file_path, 'w') as f:
            f.write(lookml_model)
        
        return {
            'tool': 'looker',
            'file_path': file_path,
            'view_name': view_name,
            'lookml_model': lookml_model[:500]  # Preview
        }
    
    def _transform_for_tableau(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transforma datos para Tableau"""
        # Agregar columnas calculadas
        df['ctr_pct'] = df['clicks'] / df['impressions'] * 100
        df['conversion_rate_pct'] = df['conversions'] / df['clicks'] * 100
        df['roi_multiplier'] = df['revenue'] / df['spend']
        
        # Formatear fechas
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
        
        return df
    
    def _transform_for_powerbi(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transforma datos para Power BI"""
        # Power BI prefiere formato espec√≠fico
        df['Date'] = pd.to_datetime(df.get('date', datetime.now()))
        
        # M√©tricas calculadas
        df['CTR'] = (df['clicks'] / df['impressions'] * 100).round(2)
        df['ConversionRate'] = (df['conversions'] / df['clicks'] * 100).round(2)
        
        return df
    
    def _generate_lookml_model(self, view_name: str, data: List[Dict]) -> str:
        """Genera modelo LookML"""
        
        # Obtener columnas del primer registro
        if not data:
            return ""
        
        columns = list(data[0].keys())
        
        lookml = f"""
view: {view_name} {{
  sql_table_name: `carousel_metrics` ;;
  
"""
        
        for col in columns:
            lookml_type = self._map_to_lookml_type(col, data[0].get(col))
            lookml += f"  dimension: {col} {{\n"
            lookml += f"    type: {lookml_type}\n"
            lookml += f"    sql: ${{TABLE}}.{col} ;;\n"
            lookml += f"  }}\n\n"
        
        # Agregar medidas
        lookml += "  measure: total_clicks {\n"
        lookml += "    type: sum\n"
        lookml += "    sql: ${TABLE}.clicks ;;\n"
        lookml += "  }\n\n"
        
        lookml += "  measure: total_conversions {\n"
        lookml += "    type: sum\n"
        lookml += "    sql: ${TABLE}.conversions ;;\n"
        lookml += "  }\n\n"
        
        lookml += "}\n"
        
        return lookml
    
    def _map_to_lookml_type(self, column_name: str, sample_value) -> str:
        """Mapea columna a tipo LookML"""
        if isinstance(sample_value, (int, float)):
            return 'number'
        elif isinstance(sample_value, datetime):
            return 'date'
        else:
            return 'string'
    
    def sync_metrics_to_bi(self, dashboard_id: str, metrics: Dict):
        """Sincroniza m√©tricas con herramienta de BI"""
        
        if dashboard_id not in self.dashboards:
            return None
        
        dashboard = self.dashboards[dashboard_id]
        dashboard.last_updated = datetime.now()
        
        # Actualizar data warehouse
        self.data_warehouse[dashboard_id] = {
            'metrics': metrics,
            'updated_at': datetime.now().isoformat()
        }
        
        return {
            'dashboard_id': dashboard_id,
            'status': 'synced',
            'metrics_count': len(metrics),
            'last_updated': dashboard.last_updated.isoformat()
        }

if __name__ == '__main__':
    bi = BIToolsIntegration()
    
    # Datos de ejemplo
    carousel_data = [
        {
            'carousel_id': 'curso_ia_1',
            'date': '2024-11-01',
            'impressions': 10000,
            'clicks': 250,
            'conversions': 30,
            'spend': 100,
            'revenue': 9000
        }
    ]
    
    # Exportar a Tableau
    tableau_result = bi.export_to_tableau(carousel_data, 'Carousel Performance')
    print(f"Exportado a Tableau: {tableau_result['file_path']}")
    
    # Exportar a Power BI
    powerbi_result = bi.export_to_powerbi(carousel_data, 'carousel_metrics')
    print(f"Exportado a Power BI: {powerbi_result['file_path']}")
```

---

## üö® Sistema de Detecci√≥n de Anomal√≠as

### Script de Detecci√≥n Autom√°tica de Anomal√≠as

**Python**: `scripts/anomaly_detection.py`

```python
#!/usr/bin/env python3
"""
Sistema de detecci√≥n de anomal√≠as
- Detecci√≥n estad√≠stica de outliers
- Alertas autom√°ticas
- An√°lisis de causas ra√≠z
- Patrones an√≥malos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import numpy as np
from scipy import stats

@dataclass
class AnomalyAlert:
    """Alerta de anomal√≠a"""
    alert_id: str
    metric_name: str
    detected_value: float
    expected_value: float
    deviation: float
    severity: str  # low, medium, high, critical
    timestamp: datetime
    possible_causes: List[str]

class AnomalyDetector:
    """Detector de anomal√≠as"""
    
    def __init__(self):
        self.metric_history = {}
        self.alerts = []
        self.threshold_multiplier = 2.0  # Desviaciones est√°ndar
    
    def detect_anomalies(self, metric_name: str, current_value: float,
                        historical_data: List[float]) -> Optional[AnomalyAlert]:
        """Detecta anomal√≠as en m√©trica"""
        
        if len(historical_data) < 10:
            return None  # No hay suficientes datos
        
        # Calcular estad√≠sticas
        mean = np.mean(historical_data)
        std = np.std(historical_data)
        z_score = (current_value - mean) / std if std > 0 else 0
        
        # Detectar si es anomal√≠a (z-score > threshold)
        if abs(z_score) > self.threshold_multiplier:
            severity = self._calculate_severity(z_score)
            possible_causes = self._suggest_causes(metric_name, current_value, mean)
            
            alert = AnomalyAlert(
                alert_id=f"anomaly_{datetime.now().timestamp()}",
                metric_name=metric_name,
                detected_value=current_value,
                expected_value=mean,
                deviation=abs(current_value - mean),
                severity=severity,
                timestamp=datetime.now(),
                possible_causes=possible_causes
            )
            
            self.alerts.append(alert)
            return alert
        
        return None
    
    def detect_multiple_metric_anomalies(self, metrics: Dict[str, float],
                                        historical_data: Dict[str, List[float]]) -> List[AnomalyAlert]:
        """Detecta anomal√≠as en m√∫ltiples m√©tricas"""
        
        alerts = []
        
        for metric_name, current_value in metrics.items():
            if metric_name in historical_data:
                alert = self.detect_anomalies(
                    metric_name,
                    current_value,
                    historical_data[metric_name]
                )
                if alert:
                    alerts.append(alert)
        
        return alerts
    
    def _calculate_severity(self, z_score: float) -> str:
        """Calcula severidad basada en z-score"""
        abs_z = abs(z_score)
        
        if abs_z > 4.0:
            return 'critical'
        elif abs_z > 3.0:
            return 'high'
        elif abs_z > 2.5:
            return 'medium'
        else:
            return 'low'
    
    def _suggest_causes(self, metric_name: str, current_value: float,
                       expected_value: float) -> List[str]:
        """Sugiere posibles causas de anomal√≠a"""
        
        causes = []
        is_higher = current_value > expected_value
        
        if metric_name == 'ctr':
            if is_higher:
                causes.append("Posible error en tracking o bot traffic")
                causes.append("Cambio en targeting o audiencia")
            else:
                causes.append("Carrusel puede estar mostr√°ndose a audiencia incorrecta")
                causes.append("Posible problema t√©cnico en visualizaci√≥n")
        
        elif metric_name == 'conversion_rate':
            if is_higher:
                causes.append("Mejora en landing page o CTA")
                causes.append("Cambio positivo en audiencia")
            else:
                causes.append("Problema en landing page o checkout")
                causes.append("Cambio negativo en audiencia o competencia")
        
        elif metric_name == 'spend':
            if is_higher:
                causes.append("Aumento en CPC o presupuesto")
                causes.append("M√°s impresiones de lo esperado")
            else:
                causes.append("Reducci√≥n en presupuesto o pausa de campa√±a")
                causes.append("Menor competencia en subasta")
        
        return causes
    
    def analyze_trend_anomalies(self, time_series: List[float], window: int = 7) -> List[Dict]:
        """Analiza anomal√≠as en tendencias"""
        
        if len(time_series) < window * 2:
            return []
        
        anomalies = []
        
        for i in range(window, len(time_series)):
            window_data = time_series[i-window:i]
            current_value = time_series[i]
            
            window_mean = np.mean(window_data)
            window_std = np.std(window_data)
            
            if window_std > 0:
                z_score = (current_value - window_mean) / window_std
                
                if abs(z_score) > 2.0:
                    anomalies.append({
                        'index': i,
                        'value': current_value,
                        'z_score': z_score,
                        'window_mean': window_mean
                    })
        
        return anomalies

if __name__ == '__main__':
    detector = AnomalyDetector()
    
    # Datos hist√≥ricos
    historical_ctr = [2.1, 2.3, 2.0, 2.2, 2.4, 2.1, 2.3, 2.2, 2.1, 2.4]
    
    # Valor actual an√≥malo
    current_ctr = 5.5  # Muy alto
    
    alert = detector.detect_anomalies('ctr', current_ctr, historical_ctr)
    
    if alert:
        print(f"üö® Anomal√≠a detectada:")
        print(f"   M√©trica: {alert.metric_name}")
        print(f"   Valor: {alert.detected_value:.2f} (esperado: {alert.expected_value:.2f})")
        print(f"   Severidad: {alert.severity}")
        print(f"   Posibles causas:")
        for cause in alert.possible_causes:
            print(f"     ‚Ä¢ {cause}")
```

---

## ‚ö° Sistema de Auto-Scaling de Campa√±as

### Script de Escalamiento Autom√°tico

**Python**: `scripts/auto_scaling_campaigns.py`

```python
#!/usr/bin/env python3
"""
Sistema de auto-scaling de campa√±as
- Escalamiento autom√°tico basado en performance
- Reducci√≥n de budget para bajo performance
- Aumento de budget para alto performance
- Guardrails y l√≠mites
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class ScalingDecision:
    """Decisi√≥n de escalamiento"""
    carousel_id: str
    current_budget: float
    recommended_budget: float
    scaling_factor: float
    reason: str
    confidence: float

class AutoScalingManager:
    """Gestor de auto-scaling"""
    
    def __init__(self):
        self.scaling_history = []
        self.min_budget_multiplier = 0.5  # Reducir m√°ximo 50%
        self.max_budget_multiplier = 2.0  # Aumentar m√°ximo 2x
        self.performance_thresholds = {
            'good': {'roi': 3.0, 'ctr': 2.5, 'conversion_rate': 15.0},
            'excellent': {'roi': 5.0, 'ctr': 3.5, 'conversion_rate': 20.0}
        }
    
    def evaluate_scaling_opportunity(self, carousel_id: str,
                                    current_metrics: Dict,
                                    current_budget: float) -> Optional[ScalingDecision]:
        """Eval√∫a oportunidad de escalamiento"""
        
        # Calcular performance score
        performance_score = self._calculate_performance_score(current_metrics)
        
        # Determinar si escalar
        if performance_score >= 0.8:
            # Excelente performance: aumentar budget
            scaling_factor = min(self.max_budget_multiplier, 1.0 + (performance_score - 0.8) * 2)
            recommended_budget = current_budget * scaling_factor
            reason = "Excelente performance: aumentar inversi√≥n"
        
        elif performance_score <= 0.3:
            # Bajo performance: reducir budget
            scaling_factor = max(self.min_budget_multiplier, performance_score)
            recommended_budget = current_budget * scaling_factor
            reason = "Bajo performance: reducir inversi√≥n"
        
        else:
            # Performance estable: mantener
            return None
        
        decision = ScalingDecision(
            carousel_id=carousel_id,
            current_budget=current_budget,
            recommended_budget=recommended_budget,
            scaling_factor=scaling_factor,
            reason=reason,
            confidence=self._calculate_confidence(current_metrics)
        )
        
        self.scaling_history.append(decision)
        
        return decision
    
    def _calculate_performance_score(self, metrics: Dict) -> float:
        """Calcula score de performance (0-1)"""
        
        roi = metrics.get('roi', 1.0)
        ctr = metrics.get('ctr', 0.0)
        conversion_rate = metrics.get('conversion_rate', 0.0)
        
        # Normalizar m√©tricas
        roi_score = min(1.0, roi / 5.0)  # ROI de 5 = score 1.0
        ctr_score = min(1.0, ctr / 5.0)  # CTR de 5% = score 1.0
        conversion_score = min(1.0, conversion_rate / 25.0)  # CR de 25% = score 1.0
        
        # Weighted average
        overall_score = (roi_score * 0.5 + ctr_score * 0.3 + conversion_score * 0.2)
        
        return overall_score
    
    def _calculate_confidence(self, metrics: Dict) -> float:
        """Calcula confianza en decisi√≥n"""
        
        # M√°s datos = mayor confianza
        data_points = metrics.get('sample_size', 100)
        confidence = min(0.95, 0.5 + (data_points / 500))
        
        # Ajustar por consistencia
        if metrics.get('consistency', 0) > 0.8:
            confidence += 0.1
        
        return min(1.0, confidence)
    
    def apply_scaling(self, decision: ScalingDecision) -> Dict:
        """Aplica escalamiento"""
        
        return {
            'carousel_id': decision.carousel_id,
            'previous_budget': decision.current_budget,
            'new_budget': decision.recommended_budget,
            'change_pct': ((decision.recommended_budget - decision.current_budget) / decision.current_budget) * 100,
            'applied_at': datetime.now().isoformat(),
            'reason': decision.reason
        }

if __name__ == '__main__':
    scaler = AutoScalingManager()
    
    # M√©tricas de ejemplo
    metrics = {
        'roi': 6.5,
        'ctr': 4.2,
        'conversion_rate': 22.0,
        'sample_size': 500
    }
    
    decision = scaler.evaluate_scaling_opportunity(
        'curso_ia_1',
        metrics,
        current_budget=500.0
    )
    
    if decision:
        print(f"Decision de escalamiento:")
        print(f"  Budget actual: ${decision.current_budget:.2f}")
        print(f"  Budget recomendado: ${decision.recommended_budget:.2f}")
        print(f"  Factor: {decision.scaling_factor:.2f}x")
        print(f"  Raz√≥n: {decision.reason}")
        
        # Aplicar
        result = scaler.apply_scaling(decision)
        print(f"\nEscalamiento aplicado: {result['change_pct']:.1f}%")
```

---

## üéØ Sistema de Gesti√≥n de Contenido por Funnel Stage

### Script de Contenido Segmentado por Etapa

**Python**: `scripts/funnel_stage_content_manager.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de contenido por funnel stage
- TOFU (Top of Funnel): Awareness
- MOFU (Middle of Funnel): Consideration
- BOFU (Bottom of Funnel): Conversion
- Personalizaci√≥n por etapa
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class FunnelStage(Enum):
    TOFU = "tofu"  # Top of Funnel - Awareness
    MOFU = "mofu"  # Middle of Funnel - Consideration
    BOFU = "bofu"  # Bottom of Funnel - Conversion

@dataclass
class FunnelContent:
    """Contenido por etapa de funnel"""
    content_id: str
    stage: FunnelStage
    headline: str
    subcopy: str
    cta: str
    objective: str
    target_metrics: Dict

class FunnelContentManager:
    """Gestor de contenido por funnel"""
    
    def __init__(self):
        self.content_by_stage = {
            FunnelStage.TOFU: [],
            FunnelStage.MOFU: [],
            FunnelStage.BOFU: []
        }
    
    def create_tofu_content(self, headline: str, subcopy: str) -> FunnelContent:
        """Crea contenido TOFU (Awareness)"""
        
        content = FunnelContent(
            content_id=f"tofu_{datetime.now().timestamp()}",
            stage=FunnelStage.TOFU,
            headline=headline,
            subcopy=subcopy,
            cta="Descubre m√°s",
            objective="Awareness y Education",
            target_metrics={
                'ctr': 2.0,
                'engagement_rate': 4.0,
                'reach': 10000
            }
        )
        
        self.content_by_stage[FunnelStage.TOFU].append(content)
        
        return content
    
    def create_mofu_content(self, headline: str, subcopy: str) -> FunnelContent:
        """Crea contenido MOFU (Consideration)"""
        
        content = FunnelContent(
            content_id=f"mofu_{datetime.now().timestamp()}",
            stage=FunnelStage.MOFU,
            headline=headline,
            subcopy=subcopy,
            cta="Ver demo",
            objective="Consideration y Interest",
            target_metrics={
                'ctr': 2.5,
                'conversion_rate': 10.0,
                'demo_bookings': 5
            }
        )
        
        self.content_by_stage[FunnelStage.MOFU].append(content)
        
        return content
    
    def create_bofu_content(self, headline: str, subcopy: str) -> FunnelContent:
        """Crea contenido BOFU (Conversion)"""
        
        content = FunnelContent(
            content_id=f"bofu_{datetime.now().timestamp()}",
            stage=FunnelStage.BOFU,
            headline=headline,
            subcopy=subcopy,
            cta="Comprar ahora",
            objective="Conversion y Purchase",
            target_metrics={
                'conversion_rate': 15.0,
                'roi': 3.0,
                'revenue': 5000
            }
        )
        
        self.content_by_stage[FunnelStage.BOFU].append(content)
        
        return content
    
    def recommend_content_for_user(self, user_journey: Dict) -> List[FunnelContent]:
        """Recomienda contenido basado en journey de usuario"""
        
        stage = self._determine_user_stage(user_journey)
        
        # Recomendar contenido de la etapa actual y siguiente
        recommendations = []
        
        if stage == FunnelStage.TOFU:
            recommendations.extend(self.content_by_stage[FunnelStage.TOFU][:3])
            recommendations.extend(self.content_by_stage[FunnelStage.MOFU][:1])
        
        elif stage == FunnelStage.MOFU:
            recommendations.extend(self.content_by_stage[FunnelStage.MOFU][:3])
            recommendations.extend(self.content_by_stage[FunnelStage.BOFU][:1])
        
        else:  # BOFU
            recommendations.extend(self.content_by_stage[FunnelStage.BOFU])
        
        return recommendations
    
    def _determine_user_stage(self, user_journey: Dict) -> FunnelStage:
        """Determina etapa del funnel para usuario"""
        
        page_views = user_journey.get('page_views', 0)
        time_on_site = user_journey.get('time_on_site', 0)
        form_submissions = user_journey.get('form_submissions', 0)
        product_views = user_journey.get('product_views', 0)
        
        # L√≥gica simplificada
        if form_submissions > 0 or product_views > 2:
            return FunnelStage.BOFU
        elif page_views > 3 or time_on_site > 300:
            return FunnelStage.MOFU
        else:
            return FunnelStage.TOFU
    
    def get_stage_performance(self, stage: FunnelStage) -> Dict:
        """Obtiene performance por etapa"""
        
        content_list = self.content_by_stage.get(stage, [])
        
        # En producci√≥n, obtener m√©tricas reales
        total_content = len(content_list)
        avg_ctr = 2.5
        avg_conversion = 10.0
        
        return {
            'stage': stage.value,
            'total_content': total_content,
            'avg_ctr': avg_ctr,
            'avg_conversion_rate': avg_conversion
        }

if __name__ == '__main__':
    manager = FunnelContentManager()
    
    # Crear contenido por etapa
    tofu = manager.create_tofu_content(
        '¬øQuieres dominar IA aplicada?',
        'Aprende de los mejores sin experiencia previa'
    )
    
    mofu = manager.create_mofu_content(
        'C√≥mo nuestros alumnos logran resultados',
        'Casos de √©xito reales con m√©tricas verificables'
    )
    
    bofu = manager.create_bofu_content(
        '√önete ahora con 30% de descuento',
        'Oferta limitada: solo hoy'
    )
    
    print(f"Contenido creado:")
    print(f"  TOFU: {tofu.content_id}")
    print(f"  MOFU: {mofu.content_id}")
    print(f"  BOFU: {bofu.content_id}")
    
    # Recomendar para usuario
    user_journey = {
        'page_views': 5,
        'time_on_site': 450,
        'form_submissions': 0
    }
    
    recommendations = manager.recommend_content_for_user(user_journey)
    print(f"\nRecomendaciones: {len(recommendations)} contenidos")
```

---

## üìã Integraci√≥n con Herramientas de Gesti√≥n de Proyectos

### Script de Integraci√≥n con Asana, Jira y Monday.com

**Python**: `scripts/project_management_integration.py`

```python
#!/usr/bin/env python3
"""
Integraci√≥n con herramientas de gesti√≥n de proyectos
- Creaci√≥n autom√°tica de tareas desde carruseles
- Sincronizaci√≥n de estados
- Asignaci√≥n de responsables
- Tracking de progreso
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class ProjectTask:
    """Tarea de proyecto"""
    task_id: str
    title: str
    description: str
    assignee: str
    due_date: datetime
    status: str
    carousel_id: str
    priority: str  # low, medium, high, urgent

class ProjectManagementIntegration:
    """Integraci√≥n con PM tools"""
    
    def __init__(self):
        self.tasks = {}
        self.workflows = {}
    
    def create_carousel_workflow_tasks(self, carousel_id: str,
                                      workflow_stages: List[Dict],
                                      project_tool: str = 'asana') -> List[ProjectTask]:
        """Crea tareas de workflow para carrusel"""
        
        tasks = []
        
        for i, stage in enumerate(workflow_stages):
            due_date = datetime.now() + timedelta(days=stage.get('days_due', 1))
            
            task = ProjectTask(
                task_id=f"{carousel_id}_{stage['name']}_{datetime.now().timestamp()}",
                title=f"[{carousel_id}] {stage['name']}",
                description=stage.get('description', ''),
                assignee=stage.get('assignee', 'unassigned'),
                due_date=due_date,
                status='todo',
                carousel_id=carousel_id,
                priority=stage.get('priority', 'medium')
            )
            
            tasks.append(task)
            self.tasks[task.task_id] = task
        
        # Exportar seg√∫n herramienta
        if project_tool == 'asana':
            return self._export_to_asana(tasks)
        elif project_tool == 'jira':
            return self._export_to_jira(tasks)
        elif project_tool == 'monday':
            return self._export_to_monday(tasks)
        
        return tasks
    
    def _export_to_asana(self, tasks: List[ProjectTask]) -> List[Dict]:
        """Exporta tareas a Asana"""
        
        asana_tasks = []
        
        for task in tasks:
            asana_task = {
                'name': task.title,
                'notes': task.description,
                'assignee': task.assignee,
                'due_on': task.due_date.strftime('%Y-%m-%d'),
                'tags': ['carousel', task.carousel_id],
                'custom_fields': {
                    'carousel_id': task.carousel_id,
                    'priority': task.priority
                }
            }
            asana_tasks.append(asana_task)
        
        return asana_tasks
    
    def _export_to_jira(self, tasks: List[ProjectTask]) -> List[Dict]:
        """Exporta tareas a Jira"""
        
        jira_issues = []
        
        for task in tasks:
            jira_issue = {
                'fields': {
                    'summary': task.title,
                    'description': task.description,
                    'assignee': {'name': task.assignee},
                    'duedate': task.due_date.strftime('%Y-%m-%d'),
                    'labels': ['carousel', task.carousel_id],
                    'priority': {'name': task.priority.capitalize()},
                    'issuetype': {'name': 'Task'}
                }
            }
            jira_issues.append(jira_issue)
        
        return jira_issues
    
    def _export_to_monday(self, tasks: List[ProjectTask]) -> List[Dict]:
        """Exporta tareas a Monday.com"""
        
        monday_items = []
        
        for task in tasks:
            monday_item = {
                'name': task.title,
                'column_values': {
                    'text': task.description,
                    'person': task.assignee,
                    'date': {
                        'date': task.due_date.strftime('%Y-%m-%d')
                    },
                    'status': task.status,
                    'text8': task.carousel_id  # Custom field
                }
            }
            monday_items.append(monday_item)
        
        return monday_items
    
    def sync_task_status(self, task_id: str, new_status: str, tool: str):
        """Sincroniza estado de tarea"""
        
        if task_id not in self.tasks:
            return None
        
        task = self.tasks[task_id]
        task.status = new_status
        
        # Actualizar en herramienta externa
        sync_data = {
            'task_id': task_id,
            'new_status': new_status,
            'tool': tool,
            'updated_at': datetime.now().isoformat()
        }
        
        return sync_data

if __name__ == '__main__':
    pm = ProjectManagementIntegration()
    
    # Crear workflow de tareas
    workflow = [
        {'name': 'Design', 'days_due': 2, 'assignee': 'designer@example.com', 'priority': 'high'},
        {'name': 'Copy Review', 'days_due': 3, 'assignee': 'copywriter@example.com', 'priority': 'medium'},
        {'name': 'Approval', 'days_due': 4, 'assignee': 'manager@example.com', 'priority': 'urgent'}
    ]
    
    tasks = pm.create_carousel_workflow_tasks('curso_ia_1', workflow, 'asana')
    print(f"Tareas creadas: {len(tasks)}")
```

---

## üí¨ Sistema de An√°lisis de Sentimiento Avanzado en Tiempo Real

### Script de An√°lisis de Sentimiento con IA

**Python**: `scripts/advanced_sentiment_analysis.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis de sentimiento avanzado en tiempo real
- An√°lisis de comentarios y menciones
- Detecci√≥n de emociones espec√≠ficas
- Alertas de sentimiento negativo
- Tracking de tendencias de sentimiento
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class SentimentLabel(Enum):
    VERY_POSITIVE = "very_positive"
    POSITIVE = "positive"
    NEUTRAL = "neutral"
    NEGATIVE = "negative"
    VERY_NEGATIVE = "very_negative"

class EmotionType(Enum):
    JOY = "joy"
    ANGER = "anger"
    FEAR = "fear"
    SADNESS = "sadness"
    SURPRISE = "surprise"
    TRUST = "trust"

@dataclass
class SentimentAnalysis:
    """An√°lisis de sentimiento"""
    text: str
    sentiment: SentimentLabel
    score: float  # -1 a 1
    emotions: Dict[EmotionType, float]
    keywords: List[str]
    timestamp: datetime

class AdvancedSentimentAnalyzer:
    """Analizador avanzado de sentimiento"""
    
    def __init__(self):
        self.analysis_history = []
        self.sentiment_trends = {}
    
    def analyze_text(self, text: str, source: str = 'comment') -> SentimentAnalysis:
        """Analiza sentimiento de texto"""
        
        # En producci√≥n, usar modelo de NLP (BERT, RoBERTa, etc.)
        # Aqu√≠ simplificado con reglas
        
        sentiment_score = self._calculate_sentiment_score(text)
        sentiment_label = self._classify_sentiment(sentiment_score)
        emotions = self._detect_emotions(text)
        keywords = self._extract_keywords(text)
        
        analysis = SentimentAnalysis(
            text=text,
            sentiment=sentiment_label,
            score=sentiment_score,
            emotions=emotions,
            keywords=keywords,
            timestamp=datetime.now()
        )
        
        self.analysis_history.append(analysis)
        
        # Verificar si requiere alerta
        if sentiment_label in [SentimentLabel.NEGATIVE, SentimentLabel.VERY_NEGATIVE]:
            self._trigger_negative_sentiment_alert(analysis)
        
        return analysis
    
    def _calculate_sentiment_score(self, text: str) -> float:
        """Calcula score de sentimiento (-1 a 1)"""
        
        positive_words = ['excelente', 'genial', 'me encanta', 'perfecto', 'incre√≠ble', 'fant√°stico']
        negative_words = ['malo', 'terrible', 'horrible', 'no funciona', 'decepcionado', 'estafado']
        
        text_lower = text.lower()
        
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            score = min(1.0, 0.5 + (positive_count * 0.2))
        elif negative_count > positive_count:
            score = max(-1.0, -0.5 - (negative_count * 0.2))
        else:
            score = 0.0
        
        return score
    
    def _classify_sentiment(self, score: float) -> SentimentLabel:
        """Clasifica sentimiento"""
        if score >= 0.6:
            return SentimentLabel.VERY_POSITIVE
        elif score >= 0.2:
            return SentimentLabel.POSITIVE
        elif score <= -0.6:
            return SentimentLabel.VERY_NEGATIVE
        elif score <= -0.2:
            return SentimentLabel.NEGATIVE
        else:
            return SentimentLabel.NEUTRAL
    
    def _detect_emotions(self, text: str) -> Dict[EmotionType, float]:
        """Detecta emociones en texto"""
        
        emotions = {emotion: 0.0 for emotion in EmotionType}
        
        text_lower = text.lower()
        
        # Mapeo simplificado (en producci√≥n usar modelo de emociones)
        emotion_keywords = {
            EmotionType.JOY: ['feliz', 'contento', 'alegre', 'emocionado'],
            EmotionType.ANGER: ['molesto', 'enfadado', 'furioso', 'ira'],
            EmotionType.FEAR: ['preocupado', 'ansioso', 'miedo', 'nervioso'],
            EmotionType.SADNESS: ['triste', 'decepcionado', 'deprimido'],
            EmotionType.SURPRISE: ['sorprendido', 'incre√≠ble', 'wow'],
            EmotionType.TRUST: ['conf√≠o', 'seguro', 'recomendado', 'confiable']
        }
        
        for emotion, keywords in emotion_keywords.items():
            count = sum(1 for kw in keywords if kw in text_lower)
            if count > 0:
                emotions[emotion] = min(1.0, count * 0.3)
        
        return emotions
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extrae keywords importantes"""
        
        # Simplificado: en producci√≥n usar NLP avanzado
        important_words = ['curso', 'ia', 'producto', 'servicio', 'resultado', 'problema']
        
        text_lower = text.lower()
        found_keywords = [word for word in important_words if word in text_lower]
        
        return found_keywords
    
    def _trigger_negative_sentiment_alert(self, analysis: SentimentAnalysis):
        """Dispara alerta por sentimiento negativo"""
        
        alert = {
            'type': 'negative_sentiment',
            'text': analysis.text[:200],
            'sentiment': analysis.sentiment.value,
            'score': analysis.score,
            'timestamp': analysis.timestamp.isoformat(),
            'keywords': analysis.keywords
        }
        
        # En producci√≥n, enviar a sistema de alertas
        print(f"‚ö†Ô∏è Alerta de sentimiento negativo detectado: {alert['sentiment']}")
    
    def analyze_sentiment_trend(self, time_window_hours: int = 24) -> Dict:
        """Analiza tendencia de sentimiento"""
        
        cutoff = datetime.now() - timedelta(hours=time_window_hours)
        
        recent_analyses = [
            a for a in self.analysis_history
            if a.timestamp > cutoff
        ]
        
        if not recent_analyses:
            return {}
        
        avg_score = sum(a.score for a in recent_analyses) / len(recent_analyses)
        
        sentiment_distribution = {}
        for label in SentimentLabel:
            count = sum(1 for a in recent_analyses if a.sentiment == label)
            sentiment_distribution[label.value] = count / len(recent_analyses) * 100
        
        return {
            'avg_sentiment_score': avg_score,
            'total_analyses': len(recent_analyses),
            'sentiment_distribution': sentiment_distribution,
            'trend': 'improving' if avg_score > 0.2 else 'declining' if avg_score < -0.2 else 'stable'
        }

if __name__ == '__main__':
    analyzer = AdvancedSentimentAnalyzer()
    
    # Analizar comentarios
    comments = [
        "Este curso es excelente, me encant√≥!",
        "No funciona nada, estoy muy decepcionado",
        "Interesante, voy a probarlo"
    ]
    
    for comment in comments:
        analysis = analyzer.analyze_text(comment)
        print(f"\nComentario: {comment[:50]}...")
        print(f"  Sentimiento: {analysis.sentiment.value} ({analysis.score:.2f})")
        print(f"  Emociones: {[e.value for e, v in analysis.emotions.items() if v > 0]}")
    
    # Tendencias
    trend = analyzer.analyze_sentiment_trend()
    print(f"\nTendencia: {trend.get('trend', 'unknown')}")
```

---

## üéØ Sistema de Optimizaci√≥n de Bidding Autom√°tico

### Script de Optimizaci√≥n de Pujas

**Python**: `scripts/auto_bidding_optimizer.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n de bidding autom√°tico
- Ajuste din√°mico de pujas basado en performance
- Optimizaci√≥n de CPC/CPM
- Maximizaci√≥n de ROI
- Guardrails y l√≠mites
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class BiddingStrategy:
    """Estrategia de bidding"""
    strategy_id: str
    name: str
    bid_type: str  # cpc, cpm, cpa
    base_bid: float
    current_bid: float
    optimization_goal: str  # maximize_roi, minimize_cpa, maximize_conversions

class AutoBiddingOptimizer:
    """Optimizador de bidding autom√°tico"""
    
    def __init__(self):
        self.strategies = {}
        self.bid_history = {}
        self.min_bid_multiplier = 0.5
        self.max_bid_multiplier = 3.0
    
    def optimize_bid(self, strategy_id: str, current_metrics: Dict) -> Dict:
        """Optimiza puja basado en m√©tricas"""
        
        if strategy_id not in self.strategies:
            return None
        
        strategy = self.strategies[strategy_id]
        
        # Calcular ajuste de bid
        bid_adjustment = self._calculate_bid_adjustment(strategy, current_metrics)
        
        new_bid = strategy.current_bid * bid_adjustment
        
        # Aplicar l√≠mites
        new_bid = max(
            strategy.base_bid * self.min_bid_multiplier,
            min(new_bid, strategy.base_bid * self.max_bid_multiplier)
        )
        
        # Actualizar bid
        previous_bid = strategy.current_bid
        strategy.current_bid = new_bid
        
        # Registrar cambio
        self.bid_history[strategy_id] = {
            'previous_bid': previous_bid,
            'new_bid': new_bid,
            'adjustment': bid_adjustment,
            'timestamp': datetime.now().isoformat(),
            'metrics': current_metrics
        }
        
        return {
            'strategy_id': strategy_id,
            'previous_bid': previous_bid,
            'new_bid': new_bid,
            'change_pct': ((new_bid - previous_bid) / previous_bid) * 100,
            'reason': self._get_bid_change_reason(current_metrics)
        }
    
    def _calculate_bid_adjustment(self, strategy: BiddingStrategy,
                                 metrics: Dict) -> float:
        """Calcula ajuste de bid"""
        
        if strategy.optimization_goal == 'maximize_roi':
            return self._optimize_for_roi(metrics)
        elif strategy.optimization_goal == 'minimize_cpa':
            return self._optimize_for_cpa(metrics)
        elif strategy.optimization_goal == 'maximize_conversions':
            return self._optimize_for_conversions(metrics)
        
        return 1.0
    
    def _optimize_for_roi(self, metrics: Dict) -> float:
        """Optimiza para ROI"""
        roi = metrics.get('roi', 1.0)
        
        # Si ROI > 4.0: aumentar bid
        if roi > 4.0:
            return 1.2
        # Si ROI < 2.0: reducir bid
        elif roi < 2.0:
            return 0.8
        else:
            return 1.0
    
    def _optimize_for_cpa(self, metrics: Dict) -> float:
        """Optimiza para CPA"""
        current_cpa = metrics.get('cpa', 50.0)
        target_cpa = metrics.get('target_cpa', 40.0)
        
        if current_cpa > target_cpa * 1.2:
            return 0.9  # Reducir bid si CPA muy alto
        elif current_cpa < target_cpa * 0.8:
            return 1.1  # Aumentar bid si CPA bajo
        else:
            return 1.0
    
    def _optimize_for_conversions(self, metrics: Dict) -> float:
        """Optimiza para conversiones"""
        conversion_rate = metrics.get('conversion_rate', 0.0)
        
        if conversion_rate > 15.0:
            return 1.15  # Aumentar bid
        elif conversion_rate < 5.0:
            return 0.85  # Reducir bid
        else:
            return 1.0
    
    def _get_bid_change_reason(self, metrics: Dict) -> str:
        """Obtiene raz√≥n del cambio de bid"""
        roi = metrics.get('roi', 1.0)
        cpa = metrics.get('cpa', 50.0)
        
        if roi > 4.0:
            return "ROI alto, aumentando inversi√≥n"
        elif roi < 2.0:
            return "ROI bajo, reduciendo inversi√≥n"
        elif cpa > 60.0:
            return "CPA alto, ajustando bid"
        else:
            return "Ajuste basado en performance"

if __name__ == '__main__':
    optimizer = AutoBiddingOptimizer()
    
    # Crear estrategia
    strategy = BiddingStrategy(
        strategy_id='curso_ia_strategy',
        name='Curso IA Bidding',
        bid_type='cpc',
        base_bid=1.0,
        current_bid=1.0,
        optimization_goal='maximize_roi'
    )
    
    optimizer.strategies[strategy.strategy_id] = strategy
    
    # Optimizar
    metrics = {
        'roi': 5.5,
        'cpa': 35.0,
        'conversion_rate': 18.0
    }
    
    result = optimizer.optimize_bid(strategy.strategy_id, metrics)
    
    if result:
        print(f"Bid optimizado:")
        print(f"  Bid anterior: ${result['previous_bid']:.2f}")
        print(f"  Bid nuevo: ${result['new_bid']:.2f}")
        print(f"  Cambio: {result['change_pct']:.1f}%")
        print(f"  Raz√≥n: {result['reason']}")
```

---

## üß™ Sistema de Testing Multivariado Avanzado

### Script de Testing MVT

**Python**: `scripts/multivariate_testing.py`

```python
#!/usr/bin/env python3
"""
Sistema de testing multivariado avanzado
- Testing de m√∫ltiples variables simult√°neamente
- An√°lisis factorial
- Optimizaci√≥n de combinaciones
- Statistical significance por combinaci√≥n
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from itertools import product
import json
import numpy as np

@dataclass
class Variant:
    """Variante en test multivariado"""
    variant_id: str
    variables: Dict[str, str]  # variable_name -> value
    metrics: Dict
    sample_size: int

class MultivariateTester:
    """Tester multivariado"""
    
    def __init__(self):
        self.tests = {}
        self.variants = {}
    
    def create_mvt(self, test_name: str, variables: Dict[str, List[str]]) -> Dict:
        """Crea test multivariado"""
        
        # Generar todas las combinaciones
        variable_names = list(variables.keys())
        variable_values = list(variables.values())
        
        combinations = list(product(*variable_values))
        
        variants = []
        for i, combo in enumerate(combinations):
            variant_vars = dict(zip(variable_names, combo))
            
            variant = Variant(
                variant_id=f"{test_name}_variant_{i}",
                variables=variant_vars,
                metrics={},
                sample_size=0
            )
            
            variants.append(variant)
            self.variants[variant.variant_id] = variant
        
        test_config = {
            'test_id': f"mvt_{datetime.now().timestamp()}",
            'name': test_name,
            'variables': variables,
            'total_variants': len(variants),
            'variants': [v.variant_id for v in variants],
            'created_at': datetime.now().isoformat()
        }
        
        self.tests[test_config['test_id']] = test_config
        
        return test_config
    
    def analyze_mvt_results(self, test_id: str, variant_results: Dict[str, Dict]) -> Dict:
        """Analiza resultados de MVT"""
        
        if test_id not in self.tests:
            return None
        
        # Calcular m√©tricas por variante
        variant_performance = {}
        
        for variant_id, results in variant_results.items():
            if variant_id in self.variants:
                variant = self.variants[variant_id]
                variant.metrics = results
                variant.sample_size = results.get('sample_size', 0)
                
                variant_performance[variant_id] = {
                    'conversion_rate': results.get('conversion_rate', 0),
                    'ctr': results.get('ctr', 0),
                    'roi': results.get('roi', 0),
                    'variables': variant.variables
                }
        
        # Encontrar mejor combinaci√≥n
        best_variant = max(
            variant_performance.items(),
            key=lambda x: x[1].get('conversion_rate', 0)
        )
        
        # An√°lisis factorial (qu√© variables importan m√°s)
        factor_analysis = self._perform_factor_analysis(variant_performance)
        
        return {
            'test_id': test_id,
            'total_variants': len(variant_performance),
            'best_variant': {
                'variant_id': best_variant[0],
                'variables': best_variant[1]['variables'],
                'performance': best_variant[1]
            },
            'factor_analysis': factor_analysis,
            'all_variants': variant_performance
        }
    
    def _perform_factor_analysis(self, variant_performance: Dict) -> Dict:
        """Realiza an√°lisis factorial"""
        
        # Agrupar por variable y calcular impacto
        variable_impact = {}
        
        # Simplificado: en producci√≥n usar ANOVA o regression
        for variant_id, performance in variant_performance.items():
            variables = performance['variables']
            conversion_rate = performance.get('conversion_rate', 0)
            
            for var_name, var_value in variables.items():
                if var_name not in variable_impact:
                    variable_impact[var_name] = {}
                
                if var_value not in variable_impact[var_name]:
                    variable_impact[var_name][var_value] = []
                
                variable_impact[var_name][var_value].append(conversion_rate)
        
        # Calcular impacto promedio por valor
        factor_analysis = {}
        for var_name, values in variable_impact.items():
            factor_analysis[var_name] = {}
            for var_value, rates in values.items():
                avg_rate = np.mean(rates) if rates else 0
                factor_analysis[var_name][var_value] = avg_rate
        
        return factor_analysis

if __name__ == '__main__':
    tester = MultivariateTester()
    
    # Crear MVT con m√∫ltiples variables
    variables = {
        'headline': ['Opci√≥n A', 'Opci√≥n B'],
        'cta': ['√önete', 'Comienza'],
        'color': ['Azul', 'Rojo']
    }
    
    mvt = tester.create_mvt('headline_cta_color_test', variables)
    print(f"MVT creado: {mvt['total_variants']} variantes")
    
    # Simular resultados
    variant_results = {}
    for variant_id in mvt['variants']:
        variant_results[variant_id] = {
            'conversion_rate': np.random.uniform(8, 15),
            'ctr': np.random.uniform(2, 4),
            'sample_size': 1000
        }
    
    # Analizar
    analysis = tester.analyze_mvt_results(mvt['test_id'], variant_results)
    print(f"\nMejor variante: {analysis['best_variant']['variant_id']}")
    print(f"An√°lisis factorial: {json.dumps(analysis['factor_analysis'], indent=2)}")
```

---

## üé® Sistema de Personalizaci√≥n Contextual Avanzada

### Script de Personalizaci√≥n Inteligente

**Python**: `scripts/contextual_personalization.py`

```python
#!/usr/bin/env python3
"""
Sistema de personalizaci√≥n contextual avanzada
- Personalizaci√≥n basada en contexto (hora, d√≠a, clima, ubicaci√≥n)
- Personalizaci√≥n basada en dispositivo
- Personalizaci√≥n basada en comportamiento
- A/B testing de personalizaci√≥n
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class ContextType(Enum):
    TEMPORAL = "temporal"
    LOCATION = "location"
    DEVICE = "device"
    BEHAVIORAL = "behavioral"
    WEATHER = "weather"

@dataclass
class PersonalizedContent:
    """Contenido personalizado"""
    content_id: str
    base_content_id: str
    personalizations: Dict[str, str]  # variable -> personalized_value
    context: Dict
    performance: Dict

class ContextualPersonalizer:
    """Personalizador contextual"""
    
    def __init__(self):
        self.personalization_rules = {}
        self.personalized_content = {}
    
    def personalize_carousel(self, carousel_id: str, context: Dict) -> PersonalizedContent:
        """Personaliza carrusel basado en contexto"""
        
        personalizations = {}
        
        # Personalizaci√≥n temporal
        if 'time' in context:
            hour = context['time'].hour
            if 6 <= hour < 12:
                personalizations['greeting'] = 'Buenos d√≠as'
            elif 12 <= hour < 18:
                personalizations['greeting'] = 'Buenas tardes'
            else:
                personalizations['greeting'] = 'Buenas noches'
        
        # Personalizaci√≥n por d√≠a
        if 'time' in context:
            day_of_week = context['time'].weekday()
            if day_of_week < 5:  # Lunes-Viernes
                personalizations['urgency'] = '√önete esta semana'
            else:  # Fin de semana
                personalizations['urgency'] = 'Oferta de fin de semana'
        
        # Personalizaci√≥n por ubicaci√≥n
        if 'location' in context:
            country = context['location'].get('country', '')
            if country == 'MX':
                personalizations['currency'] = 'MXN'
                personalizations['price_format'] = '$MX'
            elif country == 'ES':
                personalizations['currency'] = 'EUR'
                personalizations['price_format'] = '‚Ç¨'
        
        # Personalizaci√≥n por dispositivo
        if 'device' in context:
            device_type = context['device'].get('type', 'desktop')
            if device_type == 'mobile':
                personalizations['headline_length'] = 'short'
            else:
                personalizations['headline_length'] = 'long'
        
        # Personalizaci√≥n por clima
        if 'weather' in context:
            weather = context['weather'].get('condition', '')
            if weather == 'rainy':
                personalizations['mood'] = 'cozy_indoor'
            elif weather == 'sunny':
                personalizations['mood'] = 'energetic'
        
        personalized = PersonalizedContent(
            content_id=f"{carousel_id}_personalized_{datetime.now().timestamp()}",
            base_content_id=carousel_id,
            personalizations=personalizations,
            context=context,
            performance={}
        )
        
        self.personalized_content[personalized.content_id] = personalized
        
        return personalized
    
    def get_personalization_rules(self, context_type: ContextType) -> List[Dict]:
        """Obtiene reglas de personalizaci√≥n"""
        
        if context_type not in self.personalization_rules:
            return []
        
        return self.personalization_rules[context_type]
    
    def add_personalization_rule(self, context_type: ContextType, rule: Dict):
        """Agrega regla de personalizaci√≥n"""
        
        if context_type not in self.personalization_rules:
            self.personalization_rules[context_type] = []
        
        self.personalization_rules[context_type].append(rule)

if __name__ == '__main__':
    personalizer = ContextualPersonalizer()
    
    # Contexto de ejemplo
    context = {
        'time': datetime.now(),
        'location': {'country': 'MX', 'city': 'CDMX'},
        'device': {'type': 'mobile', 'os': 'iOS'},
        'weather': {'condition': 'sunny', 'temperature': 25}
    }
    
    # Personalizar
    personalized = personalizer.personalize_carousel('curso_ia_1', context)
    
    print(f"Contenido personalizado:")
    print(f"  ID: {personalized.content_id}")
    print(f"  Personalizaciones: {json.dumps(personalized.personalizations, indent=2)}")
```

---

## üí≥ Integraci√≥n con Sistemas de Pago (Stripe, PayPal)

### Script de Tracking de Conversiones y Revenue

**Python**: `scripts/payment_systems_integration.py`

```python
#!/usr/bin/env python3
"""
Integraci√≥n con sistemas de pago
- Tracking de conversiones desde carruseles
- Asociaci√≥n de revenue con campa√±as
- Webhook handling para pagos
- Revenue attribution
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import requests

@dataclass
class PaymentTransaction:
    """Transacci√≥n de pago"""
    transaction_id: str
    amount: float
    currency: str
    status: str
    carousel_id: str
    utm_source: str
    utm_campaign: str
    customer_id: str
    timestamp: datetime

class PaymentSystemsIntegration:
    """Integraci√≥n con sistemas de pago"""
    
    def __init__(self):
        self.transactions = {}
        self.webhook_handlers = {}
    
    def track_stripe_payment(self, payment_intent: Dict, carousel_data: Dict) -> PaymentTransaction:
        """Trackea pago de Stripe"""
        
        transaction = PaymentTransaction(
            transaction_id=payment_intent['id'],
            amount=payment_intent['amount'] / 100,  # Convertir de centavos
            currency=payment_intent['currency'],
            status=payment_intent['status'],
            carousel_id=carousel_data.get('carousel_id', 'unknown'),
            utm_source=payment_intent.get('metadata', {}).get('utm_source', ''),
            utm_campaign=payment_intent.get('metadata', {}).get('utm_campaign', ''),
            customer_id=payment_intent.get('customer', ''),
            timestamp=datetime.fromtimestamp(payment_intent['created'])
        )
        
        self.transactions[transaction.transaction_id] = transaction
        
        return transaction
    
    def track_paypal_payment(self, payment_data: Dict, carousel_data: Dict) -> PaymentTransaction:
        """Trackea pago de PayPal"""
        
        transaction = PaymentTransaction(
            transaction_id=payment_data['id'],
            amount=float(payment_data['amount']['total']),
            currency=payment_data['amount']['currency'],
            status=payment_data['state'],
            carousel_id=carousel_data.get('carousel_id', 'unknown'),
            utm_source=payment_data.get('custom', {}).get('utm_source', ''),
            utm_campaign=payment_data.get('custom', {}).get('utm_campaign', ''),
            customer_id=payment_data.get('payer', {}).get('payer_info', {}).get('payer_id', ''),
            timestamp=datetime.fromisoformat(payment_data['create_time'].replace('Z', '+00:00'))
        )
        
        self.transactions[transaction.transaction_id] = transaction
        
        return transaction
    
    def calculate_revenue_by_carousel(self, carousel_id: str, days: int = 30) -> Dict:
        """Calcula revenue por carrusel"""
        
        cutoff = datetime.now() - timedelta(days=days)
        
        carousel_transactions = [
            t for t in self.transactions.values()
            if t.carousel_id == carousel_id and t.timestamp > cutoff and t.status == 'succeeded'
        ]
        
        total_revenue = sum(t.amount for t in carousel_transactions)
        
        # Convertir a moneda base (simplificado)
        revenue_by_currency = {}
        for t in carousel_transactions:
            if t.currency not in revenue_by_currency:
                revenue_by_currency[t.currency] = 0
            revenue_by_currency[t.currency] += t.amount
        
        return {
            'carousel_id': carousel_id,
            'total_revenue': total_revenue,
            'transaction_count': len(carousel_transactions),
            'revenue_by_currency': revenue_by_currency,
            'period_days': days
        }
    
    def handle_stripe_webhook(self, event: Dict) -> Dict:
        """Maneja webhook de Stripe"""
        
        event_type = event['type']
        data = event['data']['object']
        
        if event_type == 'payment_intent.succeeded':
            # Extraer metadata para asociar con carrusel
            metadata = data.get('metadata', {})
            carousel_data = {
                'carousel_id': metadata.get('carousel_id', 'unknown'),
                'utm_source': metadata.get('utm_source', ''),
                'utm_campaign': metadata.get('utm_campaign', '')
            }
            
            transaction = self.track_stripe_payment(data, carousel_data)
            
            return {
                'event_type': event_type,
                'transaction_id': transaction.transaction_id,
                'amount': transaction.amount,
                'status': 'processed'
            }
        
        return {'event_type': event_type, 'status': 'ignored'}

if __name__ == '__main__':
    from datetime import timedelta
    
    payment = PaymentSystemsIntegration()
    
    # Simular pago de Stripe
    stripe_payment = {
        'id': 'pi_1234567890',
        'amount': 29900,  # $299.00 en centavos
        'currency': 'usd',
        'status': 'succeeded',
        'created': datetime.now().timestamp(),
        'metadata': {
            'carousel_id': 'curso_ia_1',
            'utm_source': 'instagram',
            'utm_campaign': 'curso_ia_q4'
        }
    }
    
    transaction = payment.track_stripe_payment(stripe_payment, {'carousel_id': 'curso_ia_1'})
    print(f"Transacci√≥n trackeada: ${transaction.amount} {transaction.currency}")
    
    # Calcular revenue
    revenue = payment.calculate_revenue_by_carousel('curso_ia_1')
    print(f"Revenue total: ${revenue['total_revenue']:.2f}")
```

---

## ‚öñÔ∏è Sistema de Gesti√≥n de Permisos y Derechos de Autor

### Script de Gesti√≥n de Derechos

**Python**: `scripts/content_rights_management.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de permisos y derechos de autor
- Tracking de permisos de uso de contenido
- Gesti√≥n de derechos de im√°genes/testimonios
- Verificaci√≥n de permisos antes de publicaci√≥n
- Expiraci√≥n de permisos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class PermissionStatus(Enum):
    PENDING = "pending"
    APPROVED = "approved"
    DENIED = "denied"
    EXPIRED = "expired"
    REVOKED = "revoked"

@dataclass
class ContentPermission:
    """Permiso de uso de contenido"""
    permission_id: str
    content_id: str
    content_type: str  # image, testimonial, video, text
    owner: str
    status: PermissionStatus
    granted_date: datetime
    expiry_date: Optional[datetime]
    usage_terms: str
    attribution_required: bool

class ContentRightsManager:
    """Gestor de derechos de contenido"""
    
    def __init__(self):
        self.permissions = {}
        self.usage_tracking = {}
    
    def request_permission(self, content_id: str, content_type: str,
                          owner: str, usage_terms: str = 'commercial') -> ContentPermission:
        """Solicita permiso de uso"""
        
        permission = ContentPermission(
            permission_id=f"perm_{datetime.now().timestamp()}",
            content_id=content_id,
            content_type=content_type,
            owner=owner,
            status=PermissionStatus.PENDING,
            granted_date=datetime.now(),
            expiry_date=None,
            usage_terms=usage_terms,
            attribution_required=True
        )
        
        self.permissions[permission.permission_id] = permission
        
        return permission
    
    def approve_permission(self, permission_id: str, expiry_days: Optional[int] = None):
        """Aprueba permiso"""
        
        if permission_id not in self.permissions:
            return False
        
        permission = self.permissions[permission_id]
        permission.status = PermissionStatus.APPROVED
        
        if expiry_days:
            permission.expiry_date = datetime.now() + timedelta(days=expiry_days)
        
        return True
    
    def check_permission_valid(self, content_id: str) -> bool:
        """Verifica si hay permiso v√°lido para contenido"""
        
        # Buscar permisos aprobados para este contenido
        valid_permissions = [
            p for p in self.permissions.values()
            if p.content_id == content_id and
            p.status == PermissionStatus.APPROVED
        ]
        
        if not valid_permissions:
            return False
        
        # Verificar expiraci√≥n
        now = datetime.now()
        for perm in valid_permissions:
            if perm.expiry_date is None or perm.expiry_date > now:
                return True
        
        # Si todos expiraron, marcar como expirados
        for perm in valid_permissions:
            if perm.expiry_date and perm.expiry_date <= now:
                perm.status = PermissionStatus.EXPIRED
        
        return False
    
    def track_content_usage(self, content_id: str, carousel_id: str, platform: str):
        """Trackea uso de contenido"""
        
        usage_key = f"{content_id}_{carousel_id}"
        
        if usage_key not in self.usage_tracking:
            self.usage_tracking[usage_key] = []
        
        self.usage_tracking[usage_key].append({
            'platform': platform,
            'timestamp': datetime.now().isoformat(),
            'carousel_id': carousel_id
        })
    
    def get_permission_report(self, content_id: str) -> Dict:
        """Obtiene reporte de permisos para contenido"""
        
        related_permissions = [
            p for p in self.permissions.values()
            if p.content_id == content_id
        ]
        
        usage_count = sum(
            len(usages) for key, usages in self.usage_tracking.items()
            if key.startswith(content_id)
        )
        
        return {
            'content_id': content_id,
            'permissions_count': len(related_permissions),
            'current_status': related_permissions[0].status.value if related_permissions else 'none',
            'usage_count': usage_count,
            'attribution_required': related_permissions[0].attribution_required if related_permissions else False
        }

if __name__ == '__main__':
    from datetime import timedelta
    
    rights = ContentRightsManager()
    
    # Solicitar permiso
    permission = rights.request_permission(
        'testimonial_sofia',
        'testimonial',
        'sofia@example.com'
    )
    
    print(f"Permiso solicitado: {permission.permission_id}")
    
    # Aprobar
    rights.approve_permission(permission.permission_id, expiry_days=365)
    print(f"Permiso aprobado: {permission.status.value}")
    
    # Verificar
    is_valid = rights.check_permission_valid('testimonial_sofia')
    print(f"Permiso v√°lido: {is_valid}")
```

---

## üîç Sistema de An√°lisis de Competidores en Tiempo Real

### Script de Monitoreo Competitivo

**Python**: `scripts/realtime_competitor_analysis.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis de competidores en tiempo real
- Monitoreo de publicaciones de competidores
- An√°lisis de copy y hashtags
- Detecci√≥n de nuevas campa√±as
- Comparaci√≥n de engagement
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class CompetitorPost:
    """Post de competidor"""
    post_id: str
    competitor_name: str
    platform: str
    content: str
    hashtags: List[str]
    engagement: Dict
    posted_at: datetime
    detected_at: datetime

class RealtimeCompetitorAnalyzer:
    """Analizador de competidores en tiempo real"""
    
    def __init__(self):
        self.competitor_posts = {}
        self.competitor_profiles = {}
        self.monitoring_keywords = []
    
    def monitor_competitor(self, competitor_name: str, platform: str,
                          keywords: List[str]):
        """Configura monitoreo de competidor"""
        
        profile_id = f"{competitor_name}_{platform}"
        
        self.competitor_profiles[profile_id] = {
            'competitor_name': competitor_name,
            'platform': platform,
            'keywords': keywords,
            'monitoring_active': True,
            'last_checked': datetime.now().isoformat()
        }
        
        self.monitoring_keywords.extend(keywords)
    
    def detect_competitor_post(self, post_data: Dict) -> Optional[CompetitorPost]:
        """Detecta nuevo post de competidor"""
        
        content = post_data.get('content', '').lower()
        
        # Verificar si contiene keywords monitoreadas
        matches_keyword = any(
            keyword.lower() in content
            for keyword in self.monitoring_keywords
        )
        
        if not matches_keyword:
            return None
        
        # Identificar competidor
        competitor_name = self._identify_competitor(post_data)
        
        if not competitor_name:
            return None
        
        post = CompetitorPost(
            post_id=post_data.get('id', f"post_{datetime.now().timestamp()}"),
            competitor_name=competitor_name,
            platform=post_data.get('platform', 'unknown'),
            content=post_data.get('content', ''),
            hashtags=post_data.get('hashtags', []),
            engagement=post_data.get('engagement', {}),
            posted_at=datetime.fromisoformat(post_data.get('posted_at', datetime.now().isoformat())),
            detected_at=datetime.now()
        )
        
        self.competitor_posts[post.post_id] = post
        
        return post
    
    def _identify_competitor(self, post_data: Dict) -> Optional[str]:
        """Identifica competidor desde post"""
        
        # Buscar en perfiles monitoreados
        author = post_data.get('author', '').lower()
        
        for profile_id, profile in self.competitor_profiles.items():
            if profile['competitor_name'].lower() in author:
                return profile['competitor_name']
        
        return None
    
    def analyze_competitor_trends(self, competitor_name: str, days: int = 7) -> Dict:
        """Analiza tendencias de competidor"""
        
        cutoff = datetime.now() - timedelta(days=days)
        
        competitor_posts = [
            p for p in self.competitor_posts.values()
            if p.competitor_name == competitor_name and p.posted_at > cutoff
        ]
        
        if not competitor_posts:
            return {}
        
        # Calcular m√©tricas promedio
        avg_likes = sum(p.engagement.get('likes', 0) for p in competitor_posts) / len(competitor_posts)
        avg_comments = sum(p.engagement.get('comments', 0) for p in competitor_posts) / len(competitor_posts)
        
        # Hashtags m√°s usados
        all_hashtags = []
        for post in competitor_posts:
            all_hashtags.extend(post.hashtags)
        
        hashtag_counts = {}
        for tag in all_hashtags:
            hashtag_counts[tag] = hashtag_counts.get(tag, 0) + 1
        
        top_hashtags = sorted(hashtag_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            'competitor_name': competitor_name,
            'posts_count': len(competitor_posts),
            'avg_likes': avg_likes,
            'avg_comments': avg_comments,
            'top_hashtags': [{'tag': tag, 'count': count} for tag, count in top_hashtags],
            'posting_frequency': len(competitor_posts) / days  # posts por d√≠a
        }
    
    def compare_with_competitors(self, own_metrics: Dict, competitor_names: List[str]) -> Dict:
        """Compara m√©tricas propias con competidores"""
        
        comparison = {
            'own_metrics': own_metrics,
            'competitors': {}
        }
        
        for competitor_name in competitor_names:
            trends = self.analyze_competitor_trends(competitor_name)
            
            if trends:
                comparison['competitors'][competitor_name] = {
                    'avg_likes': trends['avg_likes'],
                    'avg_comments': trends['avg_comments'],
                    'posting_frequency': trends['posting_frequency']
                }
        
        # Calcular diferencias
        if comparison['competitors']:
            avg_competitor_likes = sum(
                c['avg_likes'] for c in comparison['competitors'].values()
            ) / len(comparison['competitors'])
            
            comparison['vs_competitors'] = {
                'likes_difference_pct': ((own_metrics.get('avg_likes', 0) - avg_competitor_likes) / avg_competitor_likes * 100) if avg_competitor_likes > 0 else 0,
                'above_average': own_metrics.get('avg_likes', 0) > avg_competitor_likes
            }
        
        return comparison

if __name__ == '__main__':
    from datetime import timedelta
    
    analyzer = RealtimeCompetitorAnalyzer()
    
    # Configurar monitoreo
    analyzer.monitor_competitor('Competitor A', 'instagram', ['IA', 'curso', 'marketing'])
    
    # Detectar post
    post_data = {
        'id': 'post_123',
        'author': 'competitor_a',
        'platform': 'instagram',
        'content': 'Nuevo curso de IA aplicada, aprende en semanas',
        'hashtags': ['IA', 'curso', 'marketing'],
        'engagement': {'likes': 500, 'comments': 30},
        'posted_at': datetime.now().isoformat()
    }
    
    post = analyzer.detect_competitor_post(post_data)
    if post:
        print(f"Post detectado: {post.competitor_name}")
        
        # Analizar tendencias
        trends = analyzer.analyze_competitor_trends('Competitor A')
        print(f"Posts en √∫ltima semana: {trends.get('posts_count', 0)}")
```

---

## üìâ Sistema de Predicci√≥n de Churn

### Script de Predicci√≥n de Abandono

**Python**: `scripts/churn_prediction.py`

```python
#!/usr/bin/env python3
"""
Sistema de predicci√≥n de churn
- Predicci√≥n de probabilidad de churn
- Segmentaci√≥n de usuarios en riesgo
- Recomendaciones de retenci√≥n
- An√°lisis de factores de churn
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import numpy as np

@dataclass
class ChurnPrediction:
    """Predicci√≥n de churn"""
    user_id: str
    churn_probability: float  # 0-1
    risk_level: str  # low, medium, high, critical
    factors: List[str]
    days_to_churn: Optional[int]
    recommendations: List[str]

class ChurnPredictor:
    """Predictor de churn"""
    
    def __init__(self):
        self.user_data = {}
        self.predictions = {}
    
    def predict_churn(self, user_id: str, user_behavior: Dict) -> ChurnPrediction:
        """Predice probabilidad de churn"""
        
        # Calcular features
        days_since_last_activity = user_behavior.get('days_since_last_activity', 0)
        engagement_frequency = user_behavior.get('engagement_frequency', 0)
        content_interactions = user_behavior.get('content_interactions', 0)
        conversion_rate = user_behavior.get('conversion_rate', 0)
        
        # Modelo simplificado de predicci√≥n
        churn_probability = self._calculate_churn_probability(
            days_since_last_activity,
            engagement_frequency,
            content_interactions,
            conversion_rate
        )
        
        # Determinar nivel de riesgo
        if churn_probability >= 0.75:
            risk_level = 'critical'
        elif churn_probability >= 0.5:
            risk_level = 'high'
        elif churn_probability >= 0.25:
            risk_level = 'medium'
        else:
            risk_level = 'low'
        
        # Identificar factores
        factors = self._identify_churn_factors(user_behavior)
        
        # Estimaci√≥n de d√≠as hasta churn (simplificado)
        days_to_churn = self._estimate_days_to_churn(churn_probability, days_since_last_activity)
        
        # Recomendaciones
        recommendations = self._generate_retention_recommendations(risk_level, factors)
        
        prediction = ChurnPrediction(
            user_id=user_id,
            churn_probability=churn_probability,
            risk_level=risk_level,
            factors=factors,
            days_to_churn=days_to_churn,
            recommendations=recommendations
        )
        
        self.predictions[user_id] = prediction
        
        return prediction
    
    def _calculate_churn_probability(self, days_inactive: int, engagement_freq: float,
                                    interactions: int, conversion_rate: float) -> float:
        """Calcula probabilidad de churn"""
        
        probability = 0.0
        
        # Factor: d√≠as sin actividad
        if days_inactive > 30:
            probability += 0.4
        elif days_inactive > 14:
            probability += 0.25
        elif days_inactive > 7:
            probability += 0.15
        
        # Factor: frecuencia de engagement
        if engagement_freq < 0.1:
            probability += 0.3
        elif engagement_freq < 0.3:
            probability += 0.15
        
        # Factor: interacciones
        if interactions == 0:
            probability += 0.2
        elif interactions < 3:
            probability += 0.1
        
        # Factor: conversi√≥n
        if conversion_rate == 0:
            probability += 0.1
        
        return min(1.0, probability)
    
    def _identify_churn_factors(self, behavior: Dict) -> List[str]:
        """Identifica factores de churn"""
        
        factors = []
        
        if behavior.get('days_since_last_activity', 0) > 14:
            factors.append('Inactividad prolongada')
        
        if behavior.get('engagement_frequency', 1) < 0.2:
            factors.append('Baja frecuencia de engagement')
        
        if behavior.get('content_interactions', 0) == 0:
            factors.append('Sin interacciones con contenido')
        
        if behavior.get('conversion_rate', 0) == 0:
            factors.append('Sin conversiones')
        
        return factors
    
    def _estimate_days_to_churn(self, probability: float, days_inactive: int) -> Optional[int]:
        """Estima d√≠as hasta churn potencial"""
        
        if probability < 0.3:
            return None  # Riesgo bajo, no estimar
        
        # Estimaci√≥n basada en probabilidad e inactividad
        base_days = 30
        adjusted = base_days * (1 - probability) + days_inactive
        
        return int(adjusted)
    
    def _generate_retention_recommendations(self, risk_level: str, factors: List[str]) -> List[str]:
        """Genera recomendaciones de retenci√≥n"""
        
        recommendations = []
        
        if risk_level in ['high', 'critical']:
            recommendations.append("Enviar campa√±a de reactivaci√≥n inmediata")
            recommendations.append("Ofrecer descuento o contenido exclusivo")
        
        if 'Inactividad prolongada' in factors:
            recommendations.append("Re-engagement campaign con contenido nuevo")
        
        if 'Baja frecuencia de engagement' in factors:
            recommendations.append("Personalizar contenido seg√∫n intereses previos")
        
        if 'Sin conversiones' in factors:
            recommendations.append("Revisar funnel y optimizar CTA")
        
        return recommendations
    
    def get_at_risk_users(self, min_probability: float = 0.5) -> List[ChurnPrediction]:
        """Obtiene usuarios en riesgo"""
        
        return [
            pred for pred in self.predictions.values()
            if pred.churn_probability >= min_probability
        ]

if __name__ == '__main__':
    predictor = ChurnPredictor()
    
    # Simular comportamiento de usuario
    user_behavior = {
        'days_since_last_activity': 20,
        'engagement_frequency': 0.15,
        'content_interactions': 2,
        'conversion_rate': 0.0
    }
    
    prediction = predictor.predict_churn('user_123', user_behavior)
    
    print(f"Predicci√≥n de churn:")
    print(f"  Probabilidad: {prediction.churn_probability:.2%}")
    print(f"  Nivel de riesgo: {prediction.risk_level}")
    print(f"  Factores: {', '.join(prediction.factors)}")
    print(f"  Recomendaciones:")
    for rec in prediction.recommendations:
        print(f"    ‚Ä¢ {rec}")
```

---

## üé™ Sistema de Gesti√≥n de Eventos y Webhooks

### Script de Gesti√≥n de Webhooks Avanzada

**Python**: `scripts/event_webhook_management.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de eventos y webhooks
- Recepci√≥n y procesamiento de webhooks
- Routing de eventos a handlers
- Retry logic y error handling
- Event logging y audit trail
"""
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json
import hashlib
import hmac

class EventType(Enum):
    CAROUSEL_VIEW = "carousel.view"
    CAROUSEL_CLICK = "carousel.click"
    CONVERSION = "conversion"
    PAYMENT = "payment.succeeded"
    COMMENT = "comment.created"

@dataclass
class WebhookEvent:
    """Evento de webhook"""
    event_id: str
    event_type: EventType
    payload: Dict
    source: str
    timestamp: datetime
    signature: Optional[str] = None
    processed: bool = False

class WebhookManager:
    """Gestor de webhooks"""
    
    def __init__(self):
        self.handlers = {}
        self.event_log = []
        self.webhook_secrets = {}
    
    def register_handler(self, event_type: EventType, handler: Callable):
        """Registra handler para tipo de evento"""
        
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        
        self.handlers[event_type].append(handler)
    
    def process_webhook(self, event_type: str, payload: Dict,
                       source: str, signature: Optional[str] = None) -> Dict:
        """Procesa webhook recibido"""
        
        # Verificar firma si existe
        if signature and source in self.webhook_secrets:
            if not self._verify_signature(payload, signature, source):
                return {'status': 'error', 'message': 'Invalid signature'}
        
        # Crear evento
        try:
            event_enum = EventType(event_type)
        except ValueError:
            return {'status': 'error', 'message': f'Unknown event type: {event_type}'}
        
        event = WebhookEvent(
            event_id=f"event_{datetime.now().timestamp()}",
            event_type=event_enum,
            payload=payload,
            source=source,
            timestamp=datetime.now(),
            signature=signature
        )
        
        # Log evento
        self.event_log.append(event)
        
        # Procesar con handlers
        try:
            result = self._process_event(event)
            event.processed = True
            
            return {
                'status': 'success',
                'event_id': event.event_id,
                'handlers_executed': result['handlers_count']
            }
        
        except Exception as e:
            return {
                'status': 'error',
                'event_id': event.event_id,
                'error': str(e)
            }
    
    def _process_event(self, event: WebhookEvent) -> Dict:
        """Procesa evento con handlers registrados"""
        
        handlers = self.handlers.get(event.event_type, [])
        
        results = []
        for handler in handlers:
            try:
                result = handler(event.payload)
                results.append(result)
            except Exception as e:
                # Log error pero continuar con otros handlers
                print(f"Handler error: {e}")
        
        return {
            'handlers_count': len(results),
            'results': results
        }
    
    def _verify_signature(self, payload: Dict, signature: str, source: str) -> bool:
        """Verifica firma de webhook"""
        
        secret = self.webhook_secrets.get(source)
        if not secret:
            return False
        
        # Convertir payload a string
        payload_str = json.dumps(payload, sort_keys=True)
        
        # Calcular HMAC
        expected_signature = hmac.new(
            secret.encode(),
            payload_str.encode(),
            hashlib.sha256
        ).hexdigest()
        
        return hmac.compare_digest(signature, expected_signature)
    
    def get_event_history(self, event_type: Optional[EventType] = None,
                         hours: int = 24) -> List[WebhookEvent]:
        """Obtiene historial de eventos"""
        
        cutoff = datetime.now() - timedelta(hours=hours)
        
        filtered_events = [
            e for e in self.event_log
            if e.timestamp > cutoff
        ]
        
        if event_type:
            filtered_events = [
                e for e in filtered_events
                if e.event_type == event_type
            ]
        
        return sorted(filtered_events, key=lambda x: x.timestamp, reverse=True)

if __name__ == '__main__':
    from datetime import timedelta
    
    manager = WebhookManager()
    
    # Registrar handler
    def handle_carousel_click(payload):
        print(f"Carousel click: {payload.get('carousel_id')}")
        return {'status': 'processed'}
    
    manager.register_handler(EventType.CAROUSEL_CLICK, handle_carousel_click)
    
    # Procesar webhook
    payload = {
        'carousel_id': 'curso_ia_1',
        'user_id': 'user_123',
        'timestamp': datetime.now().isoformat()
    }
    
    result = manager.process_webhook(
        'carousel.click',
        payload,
        source='instagram'
    )
    
    print(f"Webhook procesado: {result['status']}")
```

---

## üöÄ Sistema de Optimizaci√≥n de CDN y Delivery

### Script de Optimizaci√≥n de Assets

**Python**: `scripts/cdn_optimization.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n de CDN y delivery
- Distribuci√≥n autom√°tica a CDN
- Invalidaci√≥n de cache
- Optimizaci√≥n de im√°genes
- Compresi√≥n y minificaci√≥n
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import requests

@dataclass
class CDNAsset:
    """Asset en CDN"""
    asset_id: str
    local_path: str
    cdn_url: str
    cdn_provider: str
    size_bytes: int
    upload_date: datetime
    cache_headers: Dict

class CDNOptimizer:
    """Optimizador de CDN"""
    
    def __init__(self):
        self.assets = {}
        self.cdn_config = {
            'cloudflare': {'api_key': '', 'zone_id': ''},
            'cloudfront': {'distribution_id': '', 'access_key': ''}
        }
    
    def upload_to_cdn(self, local_path: str, cdn_provider: str = 'cloudflare') -> CDNAsset:
        """Sube asset a CDN"""
        
        # En producci√≥n, usar SDK real del CDN
        asset_id = f"asset_{datetime.now().timestamp()}"
        cdn_url = f"https://cdn.example.com/{asset_id}"
        
        asset = CDNAsset(
            asset_id=asset_id,
            local_path=local_path,
            cdn_url=cdn_url,
            cdn_provider=cdn_provider,
            size_bytes=102400,  # En producci√≥n, obtener tama√±o real
            upload_date=datetime.now(),
            cache_headers={
                'Cache-Control': 'public, max-age=31536000',
                'ETag': asset_id
            }
        )
        
        self.assets[asset.asset_id] = asset
        
        return asset
    
    def invalidate_cache(self, asset_id: str, cdn_provider: str = 'cloudflare') -> Dict:
        """Invalida cache de asset"""
        
        if asset_id not in self.assets:
            return {'status': 'error', 'message': 'Asset not found'}
        
        asset = self.assets[asset_id]
        
        # En producci√≥n, usar API del CDN para invalidar
        return {
            'status': 'success',
            'asset_id': asset_id,
            'cdn_url': asset.cdn_url,
            'invalidated_at': datetime.now().isoformat()
        }
    
    def optimize_image_for_cdn(self, image_path: str, formats: List[str] = ['webp', 'avif']) -> Dict:
        """Optimiza imagen para CDN"""
        
        # En producci√≥n, usar biblioteca de procesamiento de im√°genes
        optimized_versions = {}
        
        for format in formats:
            # Simular optimizaci√≥n
            optimized_path = f"{image_path}.{format}"
            optimized_url = f"https://cdn.example.com/{optimized_path}"
            
            optimized_versions[format] = {
                'path': optimized_path,
                'url': optimized_url,
                'size_reduction_pct': 30.0  # Simulado
            }
        
        return {
            'original_path': image_path,
            'optimized_versions': optimized_versions
        }
    
    def get_cdn_performance(self, asset_id: str) -> Dict:
        """Obtiene m√©tricas de performance de CDN"""
        
        if asset_id not in self.assets:
            return {}
        
        asset = self.assets[asset_id]
        
        # En producci√≥n, obtener m√©tricas reales del CDN
        return {
            'asset_id': asset_id,
            'cdn_url': asset.cdn_url,
            'cache_hit_rate': 0.95,
            'avg_response_time_ms': 45,
            'requests_24h': 10000,
            'bandwidth_saved_mb': 500
        }

if __name__ == '__main__':
    cdn = CDNOptimizer()
    
    # Subir a CDN
    asset = cdn.upload_to_cdn('carousels/curso_ia_slide1.png')
    print(f"Asset subido: {asset.cdn_url}")
    
    # Optimizar imagen
    optimized = cdn.optimize_image_for_cdn('carousels/curso_ia_slide1.png')
    print(f"Versiones optimizadas: {len(optimized['optimized_versions'])}")
```

---

## üìä Sistema de Generaci√≥n Autom√°tica de Reportes con Visualizaciones

### Script de Reportes Avanzados

**Python**: `scripts/automated_reporting_with_viz.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de reportes con visualizaciones
- Generaci√≥n de reportes PDF/HTML
- Gr√°ficos interactivos (Chart.js, Plotly)
- Dashboards personalizables
- Exportaci√≥n a m√∫ltiples formatos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import base64
from pathlib import Path

@dataclass
class ReportConfig:
    """Configuraci√≥n de reporte"""
    report_id: str
    report_type: str  # weekly, monthly, executive, custom
    metrics: List[str]
    format: str  # pdf, html, excel
    recipients: List[str]
    schedule: Optional[str] = None

class AutomatedReporter:
    """Generador autom√°tico de reportes"""
    
    def __init__(self):
        self.reports = {}
        self.templates = {}
    
    def generate_carousel_performance_report(self, carousel_id: str,
                                           date_range: Dict) -> Dict:
        """Genera reporte de performance de carrusel"""
        
        # Simular datos (en producci√≥n obtener de analytics)
        report_data = {
            'carousel_id': carousel_id,
            'period': date_range,
            'metrics': {
                'impressions': 50000,
                'clicks': 2500,
                'ctr': 5.0,
                'engagement_rate': 12.5,
                'conversions': 150,
                'conversion_rate': 6.0,
                'revenue': 44950.0
            },
            'trends': {
                'ctr_trend': '+15%',
                'conversion_trend': '+8%',
                'revenue_trend': '+22%'
            },
            'top_slides': [
                {'slide': 1, 'views': 50000, 'clicks': 3000},
                {'slide': 2, 'views': 45000, 'clicks': 2000},
                {'slide': 3, 'views': 40000, 'clicks': 1500}
            ]
        }
        
        return report_data
    
    def generate_html_dashboard(self, report_data: Dict) -> str:
        """Genera dashboard HTML interactivo"""
        
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>Carousel Performance Dashboard</title>
            <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .metric-card { border: 1px solid #ddd; padding: 15px; margin: 10px; 
                              border-radius: 8px; display: inline-block; width: 200px; }
                .metric-value { font-size: 32px; font-weight: bold; color: #2c3e50; }
                .metric-label { color: #7f8c8d; margin-top: 5px; }
                .chart-container { width: 400px; height: 300px; margin: 20px; }
                .trend-up { color: #27ae60; }
                .trend-down { color: #e74c3c; }
            </style>
        </head>
        <body>
            <h1>Carousel Performance: {carousel_id}</h1>
            <div class="metrics">
                <div class="metric-card">
                    <div class="metric-value">{ctr}%</div>
                    <div class="metric-label">CTR</div>
                    <div class="trend-up">{ctr_trend}</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{conversions}</div>
                    <div class="metric-label">Conversions</div>
                    <div class="trend-up">{conversion_trend}</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">${revenue:,.0f}</div>
                    <div class="metric-label">Revenue</div>
                    <div class="trend-up">{revenue_trend}</div>
                </div>
            </div>
            <canvas id="performanceChart" class="chart-container"></canvas>
            <script>
                const ctx = document.getElementById('performanceChart').getContext('2d');
                new Chart(ctx, {{
                    type: 'line',
                    data: {{
                        labels: ['Slide 1', 'Slide 2', 'Slide 3'],
                        datasets: [{{
                            label: 'Views',
                            data: {slide_views},
                            borderColor: 'rgb(75, 192, 192)',
                            tension: 0.1
                        }}]
                    }}
                }});
            </script>
        </body>
        </html>
        """
        
        # Formatear datos
        formatted_html = html_template.format(
            carousel_id=report_data['carousel_id'],
            ctr=report_data['metrics']['ctr'],
            ctr_trend=report_data['trends']['ctr_trend'],
            conversions=report_data['metrics']['conversions'],
            conversion_trend=report_data['trends']['conversion_trend'],
            revenue=report_data['metrics']['revenue'],
            revenue_trend=report_data['trends']['revenue_trend'],
            slide_views=[s['views'] for s in report_data['top_slides']]
        )
        
        return formatted_html
    
    def generate_executive_summary(self, date_range: Dict) -> Dict:
        """Genera resumen ejecutivo"""
        
        # Simular datos agregados
        summary = {
            'period': date_range,
            'total_carousels': 15,
            'total_impressions': 750000,
            'total_clicks': 37500,
            'avg_ctr': 5.0,
            'total_conversions': 2250,
            'total_revenue': 674250.0,
            'roi': 4.5,
            'top_performer': {
                'carousel_id': 'curso_ia_1',
                'ctr': 7.2,
                'conversions': 320,
                'revenue': 95880.0
            },
            'insights': [
                'CTR aument√≥ 15% vs per√≠odo anterior',
                'Conversions mejoraron en 8%',
                'Revenue creci√≥ 22%'
            ],
            'recommendations': [
                'Escalar budget para carruseles con CTR > 6%',
                'Aplicar learnings de top performer a otros carruseles',
                'Testear variantes en carruseles bajo promedio'
            ]
        }
        
        return summary

if __name__ == '__main__':
    reporter = AutomatedReporter()
    
    # Generar reporte
    date_range = {
        'start': (datetime.now() - timedelta(days=30)).isoformat(),
        'end': datetime.now().isoformat()
    }
    
    report_data = reporter.generate_carousel_performance_report('curso_ia_1', date_range)
    print(f"Reporte generado para: {report_data['carousel_id']}")
    
    # Generar dashboard HTML
    html = reporter.generate_html_dashboard(report_data)
    print(f"Dashboard HTML generado ({len(html)} caracteres)")
```

---

## üé® Sistema de Optimizaci√≥n de Creatividades con IA

### Script de Optimizaci√≥n Inteligente

**Python**: `scripts/ai_creative_optimization.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n de creatividades con IA
- An√°lisis de elementos visuales
- Recomendaciones de mejoras
- Generaci√≥n de variantes autom√°ticas
- Predicci√≥n de performance
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class CreativeAnalysis:
    """An√°lisis de creatividad"""
    creative_id: str
    visual_score: float
    copy_score: float
    overall_score: float
    recommendations: List[str]
    predicted_ctr: float

class AICreativeOptimizer:
    """Optimizador de creatividades con IA"""
    
    def __init__(self):
        self.analyses = {}
        self.optimization_rules = {}
    
    def analyze_creative(self, creative_data: Dict) -> CreativeAnalysis:
        """Analiza creatividad"""
        
        # An√°lisis visual
        visual_score = self._analyze_visual_elements(creative_data)
        
        # An√°lisis de copy
        copy_score = self._analyze_copy(creative_data)
        
        # Score general
        overall_score = (visual_score * 0.6 + copy_score * 0.4)
        
        # Recomendaciones
        recommendations = self._generate_recommendations(creative_data, visual_score, copy_score)
        
        # Predicci√≥n de CTR
        predicted_ctr = self._predict_ctr(visual_score, copy_score)
        
        analysis = CreativeAnalysis(
            creative_id=creative_data.get('id', 'unknown'),
            visual_score=visual_score,
            copy_score=copy_score,
            overall_score=overall_score,
            recommendations=recommendations,
            predicted_ctr=predicted_ctr
        )
        
        self.analyses[analysis.creative_id] = analysis
        
        return analysis
    
    def _analyze_visual_elements(self, creative: Dict) -> float:
        """Analiza elementos visuales"""
        
        score = 0.5  # Base
        
        # Factor: contraste de colores
        if creative.get('has_high_contrast', False):
            score += 0.15
        
        # Factor: claridad del CTA
        if creative.get('has_clear_cta', True):
            score += 0.15
        
        # Factor: balance de elementos
        if creative.get('has_balanced_layout', True):
            score += 0.1
        
        # Factor: legibilidad
        if creative.get('has_readable_text', True):
            score += 0.1
        
        return min(1.0, score)
    
    def _analyze_copy(self, creative: Dict) -> float:
        """Analiza copy"""
        
        score = 0.5  # Base
        
        headline = creative.get('headline', '')
        cta = creative.get('cta', '')
        
        # Factor: headline length
        if 10 <= len(headline) <= 60:
            score += 0.2
        elif len(headline) > 60:
            score -= 0.1
        
        # Factor: CTA clarity
        strong_ctas = ['√∫nete', 'comienza', 'aprende', 'descubre', 'consigue']
        if any(cta_word in cta.lower() for cta_word in strong_ctas):
            score += 0.2
        
        # Factor: urgency/power words
        power_words = ['gratis', 'ahora', 'limitado', 'exclusivo', 'nuevo']
        if any(word in headline.lower() for word in power_words):
            score += 0.1
        
        return min(1.0, score)
    
    def _generate_recommendations(self, creative: Dict, visual_score: float,
                                 copy_score: float) -> List[str]:
        """Genera recomendaciones"""
        
        recommendations = []
        
        if visual_score < 0.6:
            recommendations.append("Mejorar contraste de colores")
            recommendations.append("Optimizar balance visual")
        
        if copy_score < 0.6:
            recommendations.append("Ajustar longitud del headline")
            recommendations.append("Fortalecer CTA con verbo de acci√≥n")
        
        if not creative.get('has_high_contrast', False):
            recommendations.append("Aumentar contraste para mejor legibilidad")
        
        if len(creative.get('headline', '')) > 60:
            recommendations.append("Reducir headline a menos de 60 caracteres")
        
        return recommendations
    
    def _predict_ctr(self, visual_score: float, copy_score: float) -> float:
        """Predice CTR basado en scores"""
        
        # Modelo simplificado
        base_ctr = 2.0  # CTR base 2%
        
        # Ajuste por visual
        visual_multiplier = 1 + (visual_score - 0.5) * 1.5
        
        # Ajuste por copy
        copy_multiplier = 1 + (copy_score - 0.5) * 1.2
        
        predicted_ctr = base_ctr * visual_multiplier * copy_multiplier
        
        return round(predicted_ctr, 2)
    
    def generate_variant_suggestions(self, creative_id: str) -> List[Dict]:
        """Genera sugerencias de variantes"""
        
        if creative_id not in self.analyses:
            return []
        
        analysis = self.analyses[creative_id]
        
        suggestions = []
        
        # Variante 1: Mejorar visual
        if analysis.visual_score < 0.7:
            suggestions.append({
                'type': 'visual',
                'change': 'Increase contrast and improve layout balance',
                'expected_improvement': '+15% CTR'
            })
        
        # Variante 2: Mejorar copy
        if analysis.copy_score < 0.7:
            suggestions.append({
                'type': 'copy',
                'change': 'Shorten headline and strengthen CTA',
                'expected_improvement': '+12% CTR'
            })
        
        # Variante 3: Combinaci√≥n
        suggestions.append({
            'type': 'combination',
            'change': 'Apply all visual and copy recommendations',
            'expected_improvement': '+25% CTR'
        })
        
        return suggestions

if __name__ == '__main__':
    optimizer = AICreativeOptimizer()
    
    # Analizar creatividad
    creative = {
        'id': 'curso_ia_1',
        'has_high_contrast': True,
        'has_clear_cta': True,
        'has_balanced_layout': True,
        'has_readable_text': True,
        'headline': 'Aprende IA aplicada en 4 semanas',
        'cta': '√önete ahora'
    }
    
    analysis = optimizer.analyze_creative(creative)
    
    print(f"An√°lisis de creatividad:")
    print(f"  Visual Score: {analysis.visual_score:.2f}")
    print(f"  Copy Score: {analysis.copy_score:.2f}")
    print(f"  Overall Score: {analysis.overall_score:.2f}")
    print(f"  Predicted CTR: {analysis.predicted_ctr}%")
    print(f"\nRecomendaciones:")
    for rec in analysis.recommendations:
        print(f"  ‚Ä¢ {rec}")
```

---

## üìÖ Sistema de Gesti√≥n de Calendario Editorial Avanzado

### Script de Calendario Inteligente

**Python**: `scripts/editorial_calendar_manager.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de calendario editorial avanzado
- Planificaci√≥n autom√°tica de publicaciones
- Optimizaci√≥n de timing basado en data
- Detecci√≥n de conflictos y gaps
- Recomendaciones de contenido
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class ContentStatus(Enum):
    DRAFT = "draft"
    SCHEDULED = "scheduled"
    PUBLISHED = "published"
    ARCHIVED = "archived"

@dataclass
class CalendarEvent:
    """Evento del calendario"""
    event_id: str
    carousel_id: str
    platform: str
    scheduled_time: datetime
    status: ContentStatus
    carousel_type: str
    priority: int  # 1-5

class EditorialCalendarManager:
    """Gestor de calendario editorial"""
    
    def __init__(self):
        self.events = {}
        self.optimal_times = {}
        self.content_queue = []
    
    def schedule_carousel(self, carousel_id: str, platform: str,
                        preferred_time: Optional[datetime] = None) -> CalendarEvent:
        """Programa carrusel"""
        
        # Determinar mejor tiempo si no se especifica
        if not preferred_time:
            optimal_time = self._get_optimal_time(platform)
        else:
            optimal_time = preferred_time
        
        # Verificar conflictos
        if self._has_conflict(optimal_time, platform):
            optimal_time = self._find_next_available_slot(optimal_time, platform)
        
        event = CalendarEvent(
            event_id=f"event_{datetime.now().timestamp()}",
            carousel_id=carousel_id,
            platform=platform,
            scheduled_time=optimal_time,
            status=ContentStatus.SCHEDULED,
            carousel_type='carousel',
            priority=3
        )
        
        self.events[event.event_id] = event
        
        return event
    
    def _get_optimal_time(self, platform: str) -> datetime:
        """Obtiene tiempo √≥ptimo para plataforma"""
        
        # Horarios √≥ptimos por plataforma (simplificado)
        optimal_hours = {
            'instagram': [9, 12, 17, 20],  # 9am, 12pm, 5pm, 8pm
            'linkedin': [8, 12, 17],  # 8am, 12pm, 5pm
            'facebook': [9, 13, 19],  # 9am, 1pm, 7pm
            'twitter': [8, 12, 16, 20]  # 8am, 12pm, 4pm, 8pm
        }
        
        # Obtener horas √≥ptimas
        hours = optimal_hours.get(platform, [12])
        
        # Usar la hora m√°s cercana que a√∫n no haya pasado hoy
        now = datetime.now()
        for hour in sorted(hours):
            candidate = now.replace(hour=hour, minute=0, second=0, microsecond=0)
            if candidate > now:
                return candidate
        
        # Si todas pasaron, usar primera hora ma√±ana
        return (now + timedelta(days=1)).replace(hour=hours[0], minute=0, second=0, microsecond=0)
    
    def _has_conflict(self, time: datetime, platform: str) -> bool:
        """Verifica si hay conflicto de horario"""
        
        # Verificar eventos en la misma plataforma en ventana de 2 horas
        window_start = time - timedelta(hours=1)
        window_end = time + timedelta(hours=1)
        
        for event in self.events.values():
            if (event.platform == platform and
                event.status == ContentStatus.SCHEDULED and
                window_start <= event.scheduled_time <= window_end):
                return True
        
        return False
    
    def _find_next_available_slot(self, preferred_time: datetime,
                                 platform: str) -> datetime:
        """Encuentra siguiente slot disponible"""
        
        candidate = preferred_time + timedelta(hours=2)
        
        max_attempts = 48  # M√°ximo 2 d√≠as hacia adelante
        attempts = 0
        
        while self._has_conflict(candidate, platform) and attempts < max_attempts:
            candidate += timedelta(hours=2)
            attempts += 1
        
        return candidate
    
    def detect_gaps(self, days_ahead: int = 7) -> List[Dict]:
        """Detecta gaps en calendario"""
        
        cutoff = datetime.now() + timedelta(days=days_ahead)
        
        scheduled_events = [
            e for e in self.events.values()
            if e.status == ContentStatus.SCHEDULED and e.scheduled_time <= cutoff
        ]
        
        # Agrupar por d√≠a
        events_by_day = {}
        for event in scheduled_events:
            day_key = event.scheduled_time.date()
            if day_key not in events_by_day:
                events_by_day[day_key] = []
            events_by_day[day_key].append(event)
        
        gaps = []
        
        # Verificar cada d√≠a
        current_date = datetime.now().date()
        end_date = cutoff.date()
        
        while current_date <= end_date:
            day_events = events_by_day.get(current_date, [])
            
            # Verificar si hay menos de 2 publicaciones por d√≠a
            if len(day_events) < 2:
                gaps.append({
                    'date': current_date.isoformat(),
                    'current_posts': len(day_events),
                    'recommended_posts': 2,
                    'gap': 2 - len(day_events)
                })
            
            current_date += timedelta(days=1)
        
        return gaps
    
    def get_upcoming_content(self, days: int = 7) -> List[CalendarEvent]:
        """Obtiene contenido pr√≥ximos d√≠as"""
        
        cutoff = datetime.now() + timedelta(days=days)
        
        upcoming = [
            e for e in self.events.values()
            if e.status == ContentStatus.SCHEDULED and
            e.scheduled_time <= cutoff
        ]
        
        return sorted(upcoming, key=lambda x: x.scheduled_time)

if __name__ == '__main__':
    from datetime import timedelta
    
    calendar = EditorialCalendarManager()
    
    # Programar carrusel
    event = calendar.schedule_carousel('curso_ia_1', 'instagram')
    print(f"Carrusel programado: {event.carousel_id} para {event.scheduled_time}")
    
    # Detectar gaps
    gaps = calendar.detect_gaps(days_ahead=7)
    if gaps:
        print(f"\nGaps detectados: {len(gaps)}")
        for gap in gaps[:3]:
            print(f"  {gap['date']}: {gap['gap']} publicaciones faltantes")
```

---

## üìà Sistema de An√°lisis de ROI por Canal y Segmento

### Script de An√°lisis Avanzado de ROI

**Python**: `scripts/advanced_roi_by_channel_segment.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis de ROI por canal y segmento
- C√°lculo de ROI por canal (Instagram, LinkedIn, Facebook)
- ROI por segmento de audiencia
- ROI por tipo de contenido
- Comparaci√≥n y benchmarking
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class ROIMetrics:
    """M√©tricas de ROI"""
    channel: str
    segment: str
    spend: float
    revenue: float
    roi: float
    roas: float
    cac: float
    ltv: float
    period_days: int

class ROIChannelSegmentAnalyzer:
    """Analizador de ROI por canal y segmento"""
    
    def __init__(self):
        self.metrics = {}
    
    def calculate_roi_by_channel(self, date_range: Dict) -> Dict[str, ROIMetrics]:
        """Calcula ROI por canal"""
        
        channels = ['instagram', 'linkedin', 'facebook', 'twitter']
        channel_roi = {}
        
        for channel in channels:
            # Simular datos (en producci√≥n obtener de analytics)
            spend = 5000.0
            revenue = spend * (2.5 if channel == 'instagram' else 2.0 if channel == 'linkedin' else 1.8)
            
            roi = ((revenue - spend) / spend) * 100
            roas = revenue / spend
            cac = spend / 50  # Asumiendo 50 conversiones
            ltv = revenue / 50 * 2  # LTV estimado
            
            metrics = ROIMetrics(
                channel=channel,
                segment='all',
                spend=spend,
                revenue=revenue,
                roi=roi,
                roas=roas,
                cac=cac,
                ltv=ltv,
                period_days=30
            )
            
            channel_roi[channel] = metrics
        
        return channel_roi
    
    def calculate_roi_by_segment(self, channel: str, date_range: Dict) -> Dict[str, ROIMetrics]:
        """Calcula ROI por segmento de audiencia"""
        
        segments = ['interest', 'lookalike', 'retargeting', 'demographic']
        segment_roi = {}
        
        for segment in segments:
            # Simular datos
            base_spend = 2000.0
            
            # ROI var√≠a por segmento
            roi_multipliers = {
                'interest': 2.5,
                'lookalike': 3.0,
                'retargeting': 4.0,
                'demographic': 2.2
            }
            
            revenue = base_spend * roi_multipliers.get(segment, 2.0)
            roi = ((revenue - base_spend) / base_spend) * 100
            
            metrics = ROIMetrics(
                channel=channel,
                segment=segment,
                spend=base_spend,
                revenue=revenue,
                roi=roi,
                roas=revenue / base_spend,
                cac=base_spend / 30,
                ltv=revenue / 30 * 1.5,
                period_days=30
            )
            
            segment_roi[segment] = metrics
        
        return segment_roi
    
    def identify_best_performers(self, roi_data: Dict[str, ROIMetrics],
                                 metric: str = 'roi') -> List[Dict]:
        """Identifica mejores performers"""
        
        sorted_items = sorted(
            roi_data.items(),
            key=lambda x: getattr(x[1], metric),
            reverse=True
        )
        
        return [
            {
                'name': key,
                metric: getattr(value, metric),
                'spend': value.spend,
                'revenue': value.revenue
            }
            for key, value in sorted_items
        ]
    
    def generate_roi_report(self, date_range: Dict) -> Dict:
        """Genera reporte completo de ROI"""
        
        # ROI por canal
        channel_roi = self.calculate_roi_by_channel(date_range)
        
        # ROI por segmento (para canal principal)
        top_channel = max(channel_roi.items(), key=lambda x: x[1].roi)[0]
        segment_roi = self.calculate_roi_by_segment(top_channel, date_range)
        
        # Mejores performers
        best_channels = self.identify_best_performers(channel_roi, 'roi')
        best_segments = self.identify_best_performers(segment_roi, 'roi')
        
        # Totales
        total_spend = sum(m.spend for m in channel_roi.values())
        total_revenue = sum(m.revenue for m in channel_roi.values())
        overall_roi = ((total_revenue - total_spend) / total_spend) * 100
        
        return {
            'period': date_range,
            'overall_metrics': {
                'total_spend': total_spend,
                'total_revenue': total_revenue,
                'overall_roi': overall_roi,
                'overall_roas': total_revenue / total_spend
            },
            'by_channel': {
                k: {
                    'spend': v.spend,
                    'revenue': v.revenue,
                    'roi': v.roi,
                    'roas': v.roas,
                    'cac': v.cac
                }
                for k, v in channel_roi.items()
            },
            'by_segment': {
                k: {
                    'spend': v.spend,
                    'revenue': v.revenue,
                    'roi': v.roi,
                    'roas': v.roas
                }
                for k, v in segment_roi.items()
            },
            'best_performers': {
                'channels': best_channels[:3],
                'segments': best_segments[:3]
            },
            'recommendations': self._generate_roi_recommendations(channel_roi, segment_roi)
        }
    
    def _generate_roi_recommendations(self, channel_roi: Dict, segment_roi: Dict) -> List[str]:
        """Genera recomendaciones basadas en ROI"""
        
        recommendations = []
        
        # Identificar mejor canal
        best_channel = max(channel_roi.items(), key=lambda x: x[1].roi)[0]
        worst_channel = min(channel_roi.items(), key=lambda x: x[1].roi)[0]
        
        if channel_roi[best_channel].roi > 200:
            recommendations.append(f"Escalar inversi√≥n en {best_channel} (ROI: {channel_roi[best_channel].roi:.1f}%)")
        
        if channel_roi[worst_channel].roi < 50:
            recommendations.append(f"Revisar estrategia en {worst_channel} (ROI bajo: {channel_roi[worst_channel].roi:.1f}%)")
        
        # Identificar mejor segmento
        best_segment = max(segment_roi.items(), key=lambda x: x[1].roi)[0]
        if segment_roi[best_segment].roi > 250:
            recommendations.append(f"Incrementar budget para segmento {best_segment}")
        
        return recommendations

if __name__ == '__main__':
    analyzer = ROIChannelSegmentAnalyzer()
    
    date_range = {
        'start': (datetime.now() - timedelta(days=30)).isoformat(),
        'end': datetime.now().isoformat()
    }
    
    report = analyzer.generate_roi_report(date_range)
    
    print(f"Reporte de ROI:")
    print(f"  ROI General: {report['overall_metrics']['overall_roi']:.1f}%")
    print(f"  ROAS General: {report['overall_metrics']['overall_roas']:.2f}x")
    print(f"\nMejor Canal: {report['best_performers']['channels'][0]['name']}")
    print(f"Mejor Segmento: {report['best_performers']['segments'][0]['name']}")
    print(f"\nRecomendaciones:")
    for rec in report['recommendations']:
        print(f"  ‚Ä¢ {rec}")
```

---

## ‚öôÔ∏è Sistema de Automatizaci√≥n de Workflows y Triggers

### Script de Orquestaci√≥n de Automatizaciones

**Python**: `scripts/workflow_automation_orchestrator.py`

```python
#!/usr/bin/env python3
"""
Sistema de automatizaci√≥n de workflows y triggers
- Creaci√≥n y gesti√≥n de workflows complejos
- Triggers basados en eventos y condiciones
- Ejecuci√≥n secuencial y paralela
- Retry logic y error handling
"""
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json
import asyncio

class TriggerType(Enum):
    EVENT = "event"
    TIME = "time"
    CONDITION = "condition"
    WEBHOOK = "webhook"

class WorkflowStatus(Enum):
    DRAFT = "draft"
    ACTIVE = "active"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"

@dataclass
class WorkflowTrigger:
    """Trigger de workflow"""
    trigger_id: str
    trigger_type: TriggerType
    conditions: Dict
    actions: List[str]

@dataclass
class WorkflowStep:
    """Paso de workflow"""
    step_id: str
    name: str
    action_type: str
    config: Dict
    dependencies: List[str]
    timeout: Optional[int] = None

class WorkflowOrchestrator:
    """Orquestador de workflows"""
    
    def __init__(self):
        self.workflows = {}
        self.triggers = {}
        self.execution_history = {}
    
    def create_workflow(self, workflow_id: str, name: str,
                       steps: List[WorkflowStep], triggers: List[WorkflowTrigger]) -> Dict:
        """Crea nuevo workflow"""
        
        workflow = {
            'workflow_id': workflow_id,
            'name': name,
            'steps': {step.step_id: step for step in steps},
            'triggers': {trigger.trigger_id: trigger for trigger in triggers},
            'status': WorkflowStatus.DRAFT,
            'created_at': datetime.now().isoformat()
        }
        
        self.workflows[workflow_id] = workflow
        
        # Registrar triggers
        for trigger in triggers:
            self.triggers[trigger.trigger_id] = {
                'workflow_id': workflow_id,
                'trigger': trigger
            }
        
        return workflow
    
    def execute_workflow(self, workflow_id: str, context: Dict = None) -> Dict:
        """Ejecuta workflow"""
        
        if workflow_id not in self.workflows:
            return {'status': 'error', 'message': 'Workflow not found'}
        
        workflow = self.workflows[workflow_id]
        
        if workflow['status'] != WorkflowStatus.ACTIVE:
            return {'status': 'error', 'message': 'Workflow not active'}
        
        execution_id = f"exec_{datetime.now().timestamp()}"
        context = context or {}
        
        # Ejecutar pasos en orden
        results = []
        for step_id, step in workflow['steps'].items():
            # Verificar dependencias
            if not self._check_dependencies(step, results):
                return {
                    'status': 'failed',
                    'execution_id': execution_id,
                    'failed_at_step': step_id
                }
            
            # Ejecutar paso
            step_result = self._execute_step(step, context)
            results.append({
                'step_id': step_id,
                'result': step_result
            })
            
            # Si falla, detener workflow
            if not step_result.get('success', False):
                return {
                    'status': 'failed',
                    'execution_id': execution_id,
                    'failed_at_step': step_id,
                    'error': step_result.get('error')
                }
        
        # Registrar ejecuci√≥n
        self.execution_history[execution_id] = {
            'workflow_id': workflow_id,
            'status': 'completed',
            'results': results,
            'timestamp': datetime.now().isoformat()
        }
        
        return {
            'status': 'completed',
            'execution_id': execution_id,
            'steps_executed': len(results)
        }
    
    def _check_dependencies(self, step: WorkflowStep, results: List[Dict]) -> bool:
        """Verifica dependencias de paso"""
        
        if not step.dependencies:
            return True
        
        executed_steps = {r['step_id'] for r in results if r['result'].get('success')}
        return all(dep in executed_steps for dep in step.dependencies)
    
    def _execute_step(self, step: WorkflowStep, context: Dict) -> Dict:
        """Ejecuta paso individual"""
        
        # Mapeo de acciones (simplificado)
        action_handlers = {
            'send_notification': self._send_notification,
            'create_task': self._create_task,
            'update_crm': self._update_crm,
            'schedule_post': self._schedule_post,
            'trigger_webhook': self._trigger_webhook
        }
        
        handler = action_handlers.get(step.action_type)
        if not handler:
            return {'success': False, 'error': f'Unknown action: {step.action_type}'}
        
        try:
            result = handler(step.config, context)
            return {'success': True, 'result': result}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _send_notification(self, config: Dict, context: Dict) -> Dict:
        """Env√≠a notificaci√≥n"""
        return {'notification_sent': True, 'channel': config.get('channel', 'email')}
    
    def _create_task(self, config: Dict, context: Dict) -> Dict:
        """Crea tarea"""
        return {'task_created': True, 'task_id': f"task_{datetime.now().timestamp()}"}
    
    def _update_crm(self, config: Dict, context: Dict) -> Dict:
        """Actualiza CRM"""
        return {'crm_updated': True}
    
    def _schedule_post(self, config: Dict, context: Dict) -> Dict:
        """Programa post"""
        return {'post_scheduled': True, 'scheduled_time': config.get('time')}
    
    def _trigger_webhook(self, config: Dict, context: Dict) -> Dict:
        """Dispara webhook"""
        return {'webhook_triggered': True}
    
    def check_triggers(self, event_type: str, event_data: Dict):
        """Verifica triggers basados en evento"""
        
        triggered_workflows = []
        
        for trigger_id, trigger_info in self.triggers.items():
            trigger = trigger_info['trigger']
            
            # Verificar tipo de trigger
            if trigger.trigger_type == TriggerType.EVENT:
                if self._matches_event_trigger(trigger, event_type, event_data):
                    triggered_workflows.append(trigger_info['workflow_id'])
        
        # Ejecutar workflows disparados
        for workflow_id in triggered_workflows:
            self.execute_workflow(workflow_id, event_data)
        
        return triggered_workflows
    
    def _matches_event_trigger(self, trigger: WorkflowTrigger,
                              event_type: str, event_data: Dict) -> bool:
        """Verifica si evento coincide con trigger"""
        
        conditions = trigger.conditions
        
        if conditions.get('event_type') != event_type:
            return False
        
        # Verificar condiciones adicionales
        if 'filters' in conditions:
            for key, expected_value in conditions['filters'].items():
                if event_data.get(key) != expected_value:
                    return False
        
        return True

if __name__ == '__main__':
    orchestrator = WorkflowOrchestrator()
    
    # Crear workflow
    steps = [
        WorkflowStep(
            step_id='step1',
            name='Send Notification',
            action_type='send_notification',
            config={'channel': 'slack', 'message': 'Carousel published'},
            dependencies=[]
        ),
        WorkflowStep(
            step_id='step2',
            name='Create CRM Task',
            action_type='create_task',
            config={'task_type': 'follow_up'},
            dependencies=['step1']
        )
    ]
    
    triggers = [
        WorkflowTrigger(
            trigger_id='trigger1',
            trigger_type=TriggerType.EVENT,
            conditions={'event_type': 'carousel_published'},
            actions=['step1', 'step2']
        )
    ]
    
    workflow = orchestrator.create_workflow('carousel_publish_workflow', 'Carousel Publish', steps, triggers)
    workflow['status'] = WorkflowStatus.ACTIVE
    
    # Ejecutar workflow
    result = orchestrator.execute_workflow('carousel_publish_workflow')
    print(f"Workflow ejecutado: {result['status']}")
```

---

## üîó Sistema de Integraci√≥n Multi-Plataforma Avanzado

### Script de Integraci√≥n Unificada

**Python**: `scripts/multi_platform_integration.py`

```python
#!/usr/bin/env python3
"""
Sistema de integraci√≥n multi-plataforma avanzado
- Integraci√≥n unificada con m√∫ltiples plataformas
- Sincronizaci√≥n bidireccional de datos
- Gesti√≥n de credenciales y autenticaci√≥n
- Error handling y retry autom√°tico
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import requests

@dataclass
class PlatformConfig:
    """Configuraci√≥n de plataforma"""
    platform_id: str
    platform_name: str
    api_endpoint: str
    auth_method: str
    credentials: Dict
    rate_limit: int  # requests per minute

class MultiPlatformIntegration:
    """Integrador multi-plataforma"""
    
    def __init__(self):
        self.platforms = {}
        self.sync_rules = {}
        self.sync_history = {}
    
    def register_platform(self, config: PlatformConfig):
        """Registra plataforma"""
        
        self.platforms[config.platform_id] = config
    
    def sync_carousel_to_platform(self, carousel_id: str, platform_id: str,
                                 carousel_data: Dict) -> Dict:
        """Sincroniza carrusel a plataforma"""
        
        if platform_id not in self.platforms:
            return {'status': 'error', 'message': 'Platform not registered'}
        
        platform = self.platforms[platform_id]
        
        # Adaptar datos seg√∫n plataforma
        adapted_data = self._adapt_for_platform(platform_id, carousel_data)
        
        # Publicar en plataforma
        try:
            result = self._publish_to_platform(platform, adapted_data)
            
            # Registrar sync
            sync_record = {
                'carousel_id': carousel_id,
                'platform_id': platform_id,
                'status': 'success',
                'timestamp': datetime.now().isoformat(),
                'result': result
            }
            
            if carousel_id not in self.sync_history:
                self.sync_history[carousel_id] = []
            
            self.sync_history[carousel_id].append(sync_record)
            
            return {'status': 'success', 'result': result}
        
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    def _adapt_for_platform(self, platform_id: str, carousel_data: Dict) -> Dict:
        """Adapta datos para plataforma espec√≠fica"""
        
        adaptations = {
            'instagram': self._adapt_for_instagram,
            'linkedin': self._adapt_for_linkedin,
            'facebook': self._adapt_for_facebook,
            'twitter': self._adapt_for_twitter
        }
        
        adapter = adaptations.get(platform_id, lambda x: x)
        return adapter(carousel_data)
    
    def _adapt_for_instagram(self, data: Dict) -> Dict:
        """Adapta para Instagram"""
        return {
            'caption': data.get('caption', '')[:2200],  # L√≠mite de Instagram
            'hashtags': data.get('hashtags', [])[:30],  # M√°ximo hashtags
            'image': data.get('image_url'),
            'location': data.get('location')
        }
    
    def _adapt_for_linkedin(self, data: Dict) -> Dict:
        """Adapta para LinkedIn"""
        return {
            'text': data.get('caption', ''),
            'visibility': 'PUBLIC',
            'media': data.get('image_url')
        }
    
    def _adapt_for_facebook(self, data: Dict) -> Dict:
        """Adapta para Facebook"""
        return {
            'message': data.get('caption', ''),
            'link': data.get('landing_page_url'),
            'picture': data.get('image_url')
        }
    
    def _adapt_for_twitter(self, data: Dict) -> Dict:
        """Adapta para Twitter"""
        return {
            'text': data.get('caption', '')[:280],  # L√≠mite de caracteres
            'media_ids': [data.get('image_url')]
        }
    
    def _publish_to_platform(self, platform: PlatformConfig, data: Dict) -> Dict:
        """Publica en plataforma"""
        
        # En producci√≥n, usar SDK espec√≠fico de cada plataforma
        # Aqu√≠ simulamos con requests
        
        return {
            'post_id': f"post_{datetime.now().timestamp()}",
            'platform': platform.platform_name,
            'published_at': datetime.now().isoformat()
        }
    
    def sync_all_platforms(self, carousel_id: str, carousel_data: Dict) -> Dict:
        """Sincroniza a todas las plataformas"""
        
        results = {}
        
        for platform_id in self.platforms.keys():
            result = self.sync_carousel_to_platform(carousel_id, platform_id, carousel_data)
            results[platform_id] = result
        
        success_count = sum(1 for r in results.values() if r.get('status') == 'success')
        
        return {
            'total_platforms': len(results),
            'successful': success_count,
            'failed': len(results) - success_count,
            'results': results
        }
    
    def get_sync_status(self, carousel_id: str) -> Dict:
        """Obtiene estado de sincronizaci√≥n"""
        
        if carousel_id not in self.sync_history:
            return {'status': 'not_synced'}
        
        syncs = self.sync_history[carousel_id]
        
        platform_status = {}
        for sync in syncs:
            platform_status[sync['platform_id']] = {
                'status': sync['status'],
                'timestamp': sync['timestamp']
            }
        
        return {
            'carousel_id': carousel_id,
            'platforms_synced': platform_status,
            'total_syncs': len(syncs)
        }

if __name__ == '__main__':
    integration = MultiPlatformIntegration()
    
    # Registrar plataformas
    integration.register_platform(PlatformConfig(
        platform_id='instagram',
        platform_name='Instagram',
        api_endpoint='https://api.instagram.com',
        auth_method='oauth',
        credentials={'access_token': 'token123'},
        rate_limit=200
    ))
    
    # Sincronizar carrusel
    carousel_data = {
        'caption': 'Aprende IA aplicada en 4 semanas',
        'hashtags': ['IA', 'curso', 'marketing'],
        'image_url': 'https://example.com/image.jpg',
        'landing_page_url': 'https://example.com/landing'
    }
    
    result = integration.sync_all_platforms('curso_ia_1', carousel_data)
    print(f"Sincronizaci√≥n completada: {result['successful']}/{result['total_platforms']} exitosas")
```

---

## üéØ Sistema de Optimizaci√≥n de Landing Pages con A/B Testing

### Script de Optimizaci√≥n de Conversi√≥n

**Python**: `scripts/landing_page_ab_testing.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n de landing pages con A/B testing
- Testing de m√∫ltiples variantes
- An√°lisis estad√≠stico de resultados
- Recomendaciones de optimizaci√≥n
- Tracking de conversiones
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import numpy as np

@dataclass
class LandingPageVariant:
    """Variante de landing page"""
    variant_id: str
    variant_name: str
    headline: str
    cta_text: str
    cta_color: str
    form_fields: List[str]
    visitors: int
    conversions: int
    conversion_rate: float

class LandingPageABTester:
    """Tester A/B de landing pages"""
    
    def __init__(self):
        self.variants = {}
        self.tests = {}
    
    def create_test(self, test_id: str, variants: List[LandingPageVariant],
                   traffic_split: Dict[str, float] = None) -> Dict:
        """Crea test A/B"""
        
        if not traffic_split:
            # Split equitativo
            split_per_variant = 100 / len(variants)
            traffic_split = {v.variant_id: split_per_variant for v in variants}
        
        test = {
            'test_id': test_id,
            'variants': {v.variant_id: v for v in variants},
            'traffic_split': traffic_split,
            'status': 'active',
            'created_at': datetime.now().isoformat(),
            'total_visitors': 0,
            'total_conversions': 0
        }
        
        self.tests[test_id] = test
        
        return test
    
    def record_visitor(self, test_id: str, variant_id: str):
        """Registra visitante"""
        
        if test_id not in self.tests:
            return False
        
        test = self.tests[test_id]
        
        if variant_id not in test['variants']:
            return False
        
        variant = test['variants'][variant_id]
        variant.visitors += 1
        test['total_visitors'] += 1
        
        # Actualizar conversion rate
        if variant.visitors > 0:
            variant.conversion_rate = (variant.conversions / variant.visitors) * 100
        
        return True
    
    def record_conversion(self, test_id: str, variant_id: str):
        """Registra conversi√≥n"""
        
        if test_id not in self.tests:
            return False
        
        test = self.tests[test_id]
        
        if variant_id not in test['variants']:
            return False
        
        variant = test['variants'][variant_id]
        variant.conversions += 1
        test['total_conversions'] += 1
        
        # Actualizar conversion rate
        if variant.visitors > 0:
            variant.conversion_rate = (variant.conversions / variant.visitors) * 100
        
        return True
    
    def analyze_test_results(self, test_id: str, confidence_level: float = 0.95) -> Dict:
        """Analiza resultados del test"""
        
        if test_id not in self.tests:
            return {'status': 'error', 'message': 'Test not found'}
        
        test = self.tests[test_id]
        variants = list(test['variants'].values())
        
        if len(variants) < 2:
            return {'status': 'error', 'message': 'Need at least 2 variants'}
        
        # Calcular m√©tricas
        best_variant = max(variants, key=lambda v: v.conversion_rate)
        
        # Statistical significance (simplificado)
        significance = self._calculate_significance(variants, confidence_level)
        
        # Recomendaciones
        recommendations = self._generate_recommendations(variants, best_variant, significance)
        
        return {
            'test_id': test_id,
            'total_visitors': test['total_visitors'],
            'total_conversions': test['total_conversions'],
            'best_variant': {
                'variant_id': best_variant.variant_id,
                'variant_name': best_variant.variant_name,
                'conversion_rate': best_variant.conversion_rate,
                'visitors': best_variant.visitors,
                'conversions': best_variant.conversions
            },
            'all_variants': [
                {
                    'variant_id': v.variant_id,
                    'conversion_rate': v.conversion_rate,
                    'visitors': v.visitors,
                    'conversions': v.conversions
                }
                for v in variants
            ],
            'statistical_significance': significance,
            'recommendations': recommendations
        }
    
    def _calculate_significance(self, variants: List[LandingPageVariant],
                               confidence_level: float) -> Dict:
        """Calcula significancia estad√≠stica"""
        
        if len(variants) < 2:
            return {'significant': False}
        
        # Comparar primera variante con segunda
        v1, v2 = variants[0], variants[1]
        
        # Test z simplificado
        if v1.visitors == 0 or v2.visitors == 0:
            return {'significant': False, 'reason': 'Insufficient data'}
        
        p1 = v1.conversion_rate / 100
        p2 = v2.conversion_rate / 100
        
        # Pooled proportion
        n1, n2 = v1.visitors, v2.visitors
        x1, x2 = v1.conversions, v2.conversions
        p_pool = (x1 + x2) / (n1 + n2)
        
        if p_pool == 0 or p_pool == 1:
            return {'significant': False, 'reason': 'Invalid proportions'}
        
        # Z-score
        se = np.sqrt(p_pool * (1 - p_pool) * (1/n1 + 1/n2))
        if se == 0:
            return {'significant': False, 'reason': 'Zero standard error'}
        
        z = (p1 - p2) / se
        
        # Critical value for 95% confidence
        critical_value = 1.96
        
        significant = abs(z) > critical_value
        
        return {
            'significant': significant,
            'z_score': z,
            'critical_value': critical_value,
            'confidence_level': confidence_level
        }
    
    def _generate_recommendations(self, variants: List[LandingPageVariant],
                                 best_variant: LandingPageVariant,
                                 significance: Dict) -> List[str]:
        """Genera recomendaciones"""
        
        recommendations = []
        
        if significance.get('significant'):
            recommendations.append(
                f"Variante '{best_variant.variant_name}' muestra mejor√≠a estad√≠sticamente significativa"
            )
            recommendations.append("Implementar variante ganadora como versi√≥n por defecto")
        else:
            recommendations.append("No hay diferencia estad√≠sticamente significativa")
            recommendations.append("Continuar test o aumentar tama√±o de muestra")
        
        # An√°lisis de elementos
        if best_variant.conversion_rate > 10:
            recommendations.append("Conversion rate excelente (>10%), mantener elementos clave")
        
        # Comparaci√≥n con baseline
        if len(variants) >= 2:
            baseline = variants[0]  # Asumir primera es control
            improvement = ((best_variant.conversion_rate - baseline.conversion_rate) / baseline.conversion_rate) * 100
            
            if improvement > 20:
                recommendations.append(f"Mejora significativa: +{improvement:.1f}% vs baseline")
        
        return recommendations

if __name__ == '__main__':
    tester = LandingPageABTester()
    
    # Crear variantes
    variants = [
        LandingPageVariant(
            variant_id='control',
            variant_name='Control',
            headline='Aprende IA aplicada',
            cta_text='√önete ahora',
            cta_color='blue',
            form_fields=['name', 'email'],
            visitors=0,
            conversions=0,
            conversion_rate=0.0
        ),
        LandingPageVariant(
            variant_id='variant_a',
            variant_name='Variant A',
            headline='Domina IA en 4 semanas',
            cta_text='Comienza gratis',
            cta_color='green',
            form_fields=['name', 'email'],
            visitors=0,
            conversions=0,
            conversion_rate=0.0
        )
    ]
    
    # Crear test
    test = tester.create_test('lp_test_1', variants)
    
    # Simular datos
    for _ in range(1000):
        variant_id = 'control' if np.random.random() < 0.5 else 'variant_a'
        tester.record_visitor('lp_test_1', variant_id)
        if np.random.random() < 0.05:  # 5% conversion
            tester.record_conversion('lp_test_1', variant_id)
    
    # Analizar
    results = tester.analyze_test_results('lp_test_1')
    print(f"Mejor variante: {results['best_variant']['variant_name']}")
    print(f"Conversion rate: {results['best_variant']['conversion_rate']:.2f}%")
    print(f"Significancia: {results['statistical_significance']['significant']}")
```

---

## üîê Sistema de Gesti√≥n de Seguridad y Compliance Avanzado

### Script de Seguridad y Auditor√≠a

**Python**: `scripts/security_compliance_manager.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de seguridad y compliance avanzado
- Encriptaci√≥n de datos sensibles
- Auditor√≠a de accesos y cambios
- Cumplimiento GDPR/CCPA
- Detecci√≥n de amenazas
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json
import hashlib

class SecurityLevel(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class AuditLog:
    """Log de auditor√≠a"""
    log_id: str
    user_id: str
    action: str
    resource_type: str
    resource_id: str
    timestamp: datetime
    ip_address: str
    user_agent: str
    success: bool

class SecurityComplianceManager:
    """Gestor de seguridad y compliance"""
    
    def __init__(self):
        self.audit_logs = []
        self.data_retention_policies = {}
        self.access_controls = {}
    
    def log_access(self, user_id: str, action: str, resource_type: str,
                  resource_id: str, ip_address: str, user_agent: str,
                  success: bool = True) -> AuditLog:
        """Registra acceso"""
        
        log = AuditLog(
            log_id=f"log_{datetime.now().timestamp()}",
            user_id=user_id,
            action=action,
            resource_type=resource_type,
            resource_id=resource_id,
            timestamp=datetime.now(),
            ip_address=ip_address,
            user_agent=user_agent,
            success=success
        )
        
        self.audit_logs.append(log)
        
        return log
    
    def check_gdpr_compliance(self, data_subject_id: str) -> Dict:
        """Verifica cumplimiento GDPR"""
        
        # Buscar datos del sujeto
        subject_data = self._get_subject_data(data_subject_id)
        
        # Verificar derechos GDPR
        compliance = {
            'data_subject_id': data_subject_id,
            'right_to_access': True,  # Implementado
            'right_to_rectification': True,
            'right_to_erasure': True,  # Right to be forgotten
            'right_to_portability': True,
            'data_minimization': self._check_data_minimization(subject_data),
            'purpose_limitation': self._check_purpose_limitation(subject_data),
            'retention_period': self._check_retention_period(subject_data),
            'consent_status': self._check_consent(subject_data)
        }
        
        return compliance
    
    def _get_subject_data(self, subject_id: str) -> Dict:
        """Obtiene datos del sujeto"""
        # En producci√≥n, buscar en base de datos
        return {
            'subject_id': subject_id,
            'data_collected': ['name', 'email', 'ip_address'],
            'retention_days': 365,
            'consent_given': True,
            'consent_date': (datetime.now() - timedelta(days=100)).isoformat()
        }
    
    def _check_data_minimization(self, data: Dict) -> bool:
        """Verifica minimizaci√≥n de datos"""
        # Solo datos necesarios
        allowed_fields = ['name', 'email', 'ip_address']
        collected = data.get('data_collected', [])
        return all(field in allowed_fields for field in collected)
    
    def _check_purpose_limitation(self, data: Dict) -> bool:
        """Verifica limitaci√≥n de prop√≥sito"""
        # Datos usados solo para prop√≥sito declarado
        return True  # Simplificado
    
    def _check_retention_period(self, data: Dict) -> bool:
        """Verifica per√≠odo de retenci√≥n"""
        retention = data.get('retention_days', 0)
        max_retention = 730  # 2 a√±os m√°ximo
        return retention <= max_retention
    
    def _check_consent(self, data: Dict) -> Dict:
        """Verifica consentimiento"""
        return {
            'given': data.get('consent_given', False),
            'date': data.get('consent_date'),
            'valid': True
        }
    
    def handle_data_deletion_request(self, data_subject_id: str) -> Dict:
        """Maneja solicitud de eliminaci√≥n de datos (GDPR)"""
        
        # Verificar solicitud v√°lida
        if not self._validate_deletion_request(data_subject_id):
            return {'status': 'error', 'message': 'Invalid request'}
        
        # Eliminar datos personales
        deletion_result = self._delete_subject_data(data_subject_id)
        
        # Registrar eliminaci√≥n
        self.log_access(
            user_id=data_subject_id,
            action='data_deletion',
            resource_type='personal_data',
            resource_id=data_subject_id,
            ip_address='system',
            user_agent='gdpr_automation',
            success=deletion_result.get('success', False)
        )
        
        return deletion_result
    
    def _validate_deletion_request(self, subject_id: str) -> bool:
        """Valida solicitud de eliminaci√≥n"""
        return True  # Simplificado
    
    def _delete_subject_data(self, subject_id: str) -> Dict:
        """Elimina datos del sujeto"""
        return {
            'status': 'success',
            'deleted_at': datetime.now().isoformat(),
            'data_types_deleted': ['name', 'email', 'ip_address']
        }
    
    def detect_suspicious_activity(self, user_id: str, action: str) -> Dict:
        """Detecta actividad sospechosa"""
        
        # Analizar patrones recientes
        recent_actions = [
            log for log in self.audit_logs[-100:]
            if log.user_id == user_id and log.timestamp > (datetime.now() - timedelta(hours=1))
        ]
        
        # Detectar patrones sospechosos
        flags = []
        
        # Muchas acciones en poco tiempo
        if len(recent_actions) > 50:
            flags.append('high_frequency')
        
        # Accesos fallidos repetidos
        failed_actions = [a for a in recent_actions if not a.success]
        if len(failed_actions) > 5:
            flags.append('repeated_failures')
        
        # Acceso desde m√∫ltiples IPs
        unique_ips = set(a.ip_address for a in recent_actions)
        if len(unique_ips) > 3:
            flags.append('multiple_locations')
        
        severity = SecurityLevel.LOW
        if 'repeated_failures' in flags:
            severity = SecurityLevel.HIGH
        elif 'high_frequency' in flags or 'multiple_locations' in flags:
            severity = SecurityLevel.MEDIUM
        
        return {
            'suspicious': len(flags) > 0,
            'flags': flags,
            'severity': severity.value,
            'action_count': len(recent_actions),
            'recommended_action': 'block_user' if severity == SecurityLevel.HIGH else 'monitor'
        }

if __name__ == '__main__':
    security = SecurityComplianceManager()
    
    # Registrar acceso
    security.log_access('user123', 'view', 'carousel', 'curso_ia_1', '192.168.1.1', 'Chrome')
    
    # Verificar GDPR
    compliance = security.check_gdpr_compliance('user123')
    print(f"GDPR Compliance: {compliance['right_to_erasure']}")
    
    # Detectar actividad sospechosa
    for _ in range(10):
        security.log_access('user456', 'delete', 'carousel', 'test', '192.168.1.2', 'Chrome', success=False)
    
    suspicious = security.detect_suspicious_activity('user456', 'delete')
    print(f"Actividad sospechosa detectada: {suspicious['suspicious']}")
    print(f"Severidad: {suspicious['severity']}")
```

---

## üìù Sistema de An√°lisis de Contenido con NLP Avanzado

### Script de Procesamiento de Lenguaje Natural

**Python**: `scripts/nlp_content_analysis.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis de contenido con NLP avanzado
- An√°lisis de sentimiento y emociones
- Extracci√≥n de keywords y entidades
- An√°lisis de legibilidad y complejidad
- Generaci√≥n de insights autom√°ticos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import re

@dataclass
class ContentAnalysis:
    """An√°lisis de contenido"""
    content_id: str
    sentiment_score: float  # -1 a 1
    emotion: str
    keywords: List[str]
    entities: List[str]
    readability_score: float  # 0-100
    complexity_level: str  # simple, medium, complex
    insights: List[str]

class NLPContentAnalyzer:
    """Analizador de contenido con NLP"""
    
    def __init__(self):
        self.analyses = {}
        self.stop_words = {'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'es', 'se'}
    
    def analyze_content(self, content_id: str, text: str) -> ContentAnalysis:
        """Analiza contenido con NLP"""
        
        # An√°lisis de sentimiento
        sentiment_score = self._analyze_sentiment(text)
        emotion = self._detect_emotion(sentiment_score)
        
        # Extracci√≥n de keywords
        keywords = self._extract_keywords(text)
        
        # Extracci√≥n de entidades
        entities = self._extract_entities(text)
        
        # An√°lisis de legibilidad
        readability_score = self._calculate_readability(text)
        complexity_level = self._determine_complexity(readability_score)
        
        # Generar insights
        insights = self._generate_insights(
            sentiment_score, emotion, keywords, readability_score, complexity_level
        )
        
        analysis = ContentAnalysis(
            content_id=content_id,
            sentiment_score=sentiment_score,
            emotion=emotion,
            keywords=keywords,
            entities=entities,
            readability_score=readability_score,
            complexity_level=complexity_level,
            insights=insights
        )
        
        self.analyses[content_id] = analysis
        
        return analysis
    
    def _analyze_sentiment(self, text: str) -> float:
        """Analiza sentimiento del texto"""
        
        positive_words = ['excelente', 'genial', 'fant√°stico', 'incre√≠ble', 'perfecto', 'mejor']
        negative_words = ['terrible', 'horrible', 'malo', 'p√©simo', 'decepcionante', 'problema']
        
        text_lower = text.lower()
        
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            score = min(1.0, 0.5 + (positive_count * 0.15))
        elif negative_count > positive_count:
            score = max(-1.0, -0.5 - (negative_count * 0.15))
        else:
            score = 0.0
        
        return score
    
    def _detect_emotion(self, sentiment_score: float) -> str:
        """Detecta emoci√≥n basada en sentimiento"""
        
        if sentiment_score >= 0.6:
            return 'joy'
        elif sentiment_score >= 0.2:
            return 'positive'
        elif sentiment_score <= -0.6:
            return 'anger'
        elif sentiment_score <= -0.2:
            return 'sadness'
        else:
            return 'neutral'
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extrae keywords importantes"""
        
        # Tokenizar y limpiar
        words = re.findall(r'\b\w+\b', text.lower())
        
        # Filtrar stop words y palabras cortas
        keywords = [
            word for word in words
            if word not in self.stop_words and len(word) > 3
        ]
        
        # Contar frecuencia
        word_freq = {}
        for word in keywords:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # Ordenar por frecuencia y retornar top 10
        sorted_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        
        return [word for word, freq in sorted_keywords[:10]]
    
    def _extract_entities(self, text: str) -> List[str]:
        """Extrae entidades nombradas (simplificado)"""
        
        # Patrones para entidades comunes
        entities = []
        
        # Emails
        emails = re.findall(r'\b[\w.-]+@[\w.-]+\.\w+\b', text)
        entities.extend(emails)
        
        # URLs
        urls = re.findall(r'https?://\S+', text)
        entities.extend(urls)
        
        # N√∫meros (posibles precios, fechas)
        numbers = re.findall(r'\d+', text)
        if len(numbers) > 0:
            entities.append('has_numbers')
        
        return entities[:5]  # Limitar a 5
    
    def _calculate_readability(self, text: str) -> float:
        """Calcula score de legibilidad (simplificado Flesch)"""
        
        sentences = text.split('.')
        words = text.split()
        
        if len(sentences) == 0 or len(words) == 0:
            return 50.0  # Neutral
        
        avg_sentence_length = len(words) / len(sentences)
        avg_word_length = sum(len(word) for word in words) / len(words)
        
        # F√≥rmula simplificada
        readability = 206.835 - (1.015 * avg_sentence_length) - (84.6 * avg_word_length / 100)
        
        return max(0, min(100, readability))
    
    def _determine_complexity(self, readability_score: float) -> str:
        """Determina nivel de complejidad"""
        
        if readability_score >= 70:
            return 'simple'
        elif readability_score >= 50:
            return 'medium'
        else:
            return 'complex'
    
    def _generate_insights(self, sentiment: float, emotion: str, keywords: List[str],
                          readability: float, complexity: str) -> List[str]:
        """Genera insights autom√°ticos"""
        
        insights = []
        
        if sentiment > 0.5:
            insights.append("Contenido con sentimiento muy positivo, ideal para engagement")
        elif sentiment < -0.3:
            insights.append("Contenido con sentimiento negativo, considerar revisi√≥n")
        
        if readability >= 70:
            insights.append("Alta legibilidad, f√°cil de comprender por audiencia general")
        elif readability < 50:
            insights.append("Baja legibilidad, considerar simplificar lenguaje")
        
        if len(keywords) > 5:
            insights.append(f"Contenido rico en keywords: {', '.join(keywords[:3])}")
        
        if complexity == 'simple':
            insights.append("Lenguaje simple, accesible para audiencias amplias")
        
        return insights
    
    def compare_contents(self, content_ids: List[str]) -> Dict:
        """Compara m√∫ltiples contenidos"""
        
        if not all(cid in self.analyses for cid in content_ids):
            return {'status': 'error', 'message': 'Some contents not analyzed'}
        
        analyses = [self.analyses[cid] for cid in content_ids]
        
        avg_sentiment = sum(a.sentiment_score for a in analyses) / len(analyses)
        avg_readability = sum(a.readability_score for a in analyses) / len(analyses)
        
        # Contenido m√°s positivo
        most_positive = max(analyses, key=lambda a: a.sentiment_score)
        
        # Contenido m√°s legible
        most_readable = max(analyses, key=lambda a: a.readability_score)
        
        return {
            'compared_contents': content_ids,
            'average_sentiment': avg_sentiment,
            'average_readability': avg_readability,
            'most_positive': {
                'content_id': most_positive.content_id,
                'sentiment': most_positive.sentiment_score
            },
            'most_readable': {
                'content_id': most_readable.content_id,
                'readability': most_readable.readability_score
            }
        }

if __name__ == '__main__':
    analyzer = NLPContentAnalyzer()
    
    # Analizar contenido
    text = "Aprende IA aplicada en 4 semanas. Curso completo con certificaci√≥n. √önete ahora y transforma tu carrera."
    
    analysis = analyzer.analyze_content('curso_ia_1', text)
    
    print(f"An√°lisis de contenido:")
    print(f"  Sentimiento: {analysis.sentiment_score:.2f} ({analysis.emotion})")
    print(f"  Legibilidad: {analysis.readability_score:.1f} ({analysis.complexity_level})")
    print(f"  Keywords: {', '.join(analysis.keywords[:5])}")
    print(f"  Insights: {len(analysis.insights)} generados")
```

---

## üîÆ Sistema de Predicci√≥n de Tendencias de Contenido

### Script de Forecasting de Tendencias

**Python**: `scripts/content_trends_prediction.py`

```python
#!/usr/bin/env python3
"""
Sistema de predicci√≥n de tendencias de contenido
- An√°lisis de tendencias hist√≥ricas
- Predicci√≥n de futuras tendencias
- Identificaci√≥n de contenido trending
- Recomendaciones de timing
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class TrendPrediction:
    """Predicci√≥n de tendencia"""
    keyword: str
    current_trend: str  # rising, stable, declining
    predicted_trend: str
    confidence: float  # 0-1
    peak_prediction: Optional[datetime]
    recommended_action: str

class ContentTrendsPredictor:
    """Predictor de tendencias de contenido"""
    
    def __init__(self):
        self.trend_data = {}
        self.predictions = {}
    
    def analyze_trend(self, keyword: str, historical_data: List[Dict]) -> Dict:
        """Analiza tendencia hist√≥rica"""
        
        if len(historical_data) < 7:
            return {'status': 'error', 'message': 'Insufficient data'}
        
        # Calcular m√©tricas de tendencia
        recent_data = historical_data[-7:]  # √öltimos 7 d√≠as
        older_data = historical_data[-14:-7] if len(historical_data) >= 14 else historical_data[:7]
        
        recent_avg = sum(d.get('engagement', 0) for d in recent_data) / len(recent_data)
        older_avg = sum(d.get('engagement', 0) for d in older_data) / len(older_data)
        
        # Determinar tendencia
        change_pct = ((recent_avg - older_avg) / older_avg * 100) if older_avg > 0 else 0
        
        if change_pct > 10:
            trend = 'rising'
        elif change_pct < -10:
            trend = 'declining'
        else:
            trend = 'stable'
        
        self.trend_data[keyword] = {
            'keyword': keyword,
            'current_trend': trend,
            'historical_data': historical_data,
            'recent_avg': recent_avg,
            'older_avg': older_avg,
            'change_pct': change_pct,
            'last_updated': datetime.now().isoformat()
        }
        
        return self.trend_data[keyword]
    
    def predict_future_trend(self, keyword: str, days_ahead: int = 7) -> TrendPrediction:
        """Predice tendencia futura"""
        
        if keyword not in self.trend_data:
            return None
        
        trend_info = self.trend_data[keyword]
        current_trend = trend_info['current_trend']
        
        # Predicci√≥n simplificada basada en tendencia actual
        if current_trend == 'rising':
            # Si est√° subiendo, predecir continuaci√≥n (con decay)
            predicted_trend = 'rising'  # Continuar√° subiendo pero m√°s lento
            confidence = 0.7
            peak_prediction = datetime.now() + timedelta(days=3)  # Pico en 3 d√≠as
            recommended_action = 'Publicar contenido relacionado pronto'
        
        elif current_trend == 'stable':
            # Si est√° estable, predecir mantenimiento o leve crecimiento
            predicted_trend = 'stable'
            confidence = 0.6
            peak_prediction = None
            recommended_action = 'Monitorear, podr√≠a estar en transici√≥n'
        
        else:  # declining
            # Si est√° bajando, predecir continuaci√≥n de declive
            predicted_trend = 'declining'
            confidence = 0.8  # Alta confianza en declive
            peak_prediction = None
            recommended_action = 'Evitar contenido relacionado, buscar nuevos temas'
        
        prediction = TrendPrediction(
            keyword=keyword,
            current_trend=current_trend,
            predicted_trend=predicted_trend,
            confidence=confidence,
            peak_prediction=peak_prediction,
            recommended_action=recommended_action
        )
        
        self.predictions[keyword] = prediction
        
        return prediction
    
    def identify_trending_topics(self, min_engagement: float = 1000) -> List[Dict]:
        """Identifica temas trending"""
        
        trending = []
        
        for keyword, trend_info in self.trend_data.items():
            if trend_info['current_trend'] == 'rising' and trend_info['recent_avg'] >= min_engagement:
                trending.append({
                    'keyword': keyword,
                    'trend': trend_info['current_trend'],
                    'engagement_avg': trend_info['recent_avg'],
                    'change_pct': trend_info['change_pct']
                })
        
        # Ordenar por engagement
        trending.sort(key=lambda x: x['engagement_avg'], reverse=True)
        
        return trending[:10]  # Top 10
    
    def get_optimal_posting_time(self, keyword: str) -> Dict:
        """Obtiene tiempo √≥ptimo de publicaci√≥n"""
        
        if keyword not in self.trend_data:
            return {'status': 'error', 'message': 'Keyword not found'}
        
        trend_info = self.trend_data[keyword]
        
        # Analizar horarios de mejor engagement
        historical = trend_info['historical_data']
        
        # Agrupar por hora del d√≠a (simplificado)
        hourly_engagement = {}
        for entry in historical:
            hour = entry.get('hour', 12)  # Asumir mediod√≠a si no hay hora
            hourly_engagement[hour] = hourly_engagement.get(hour, 0) + entry.get('engagement', 0)
        
        if hourly_engagement:
            best_hour = max(hourly_engagement.items(), key=lambda x: x[1])[0]
            
            return {
                'keyword': keyword,
                'optimal_hour': best_hour,
                'expected_engagement': hourly_engagement[best_hour],
                'recommended_post_time': f"{best_hour}:00"
            }
        
        return {'status': 'error', 'message': 'No time data available'}

if __name__ == '__main__':
    predictor = ContentTrendsPredictor()
    
    # Datos hist√≥ricos simulados
    historical = [
        {'engagement': 500, 'date': '2024-01-01', 'hour': 9},
        {'engagement': 600, 'date': '2024-01-02', 'hour': 12},
        {'engagement': 700, 'date': '2024-01-03', 'hour': 15},
        {'engagement': 800, 'date': '2024-01-04', 'hour': 18},
        {'engagement': 900, 'date': '2024-01-05', 'hour': 9},
        {'engagement': 1000, 'date': '2024-01-06', 'hour': 12},
        {'engagement': 1100, 'date': '2024-01-07', 'hour': 15}
    ]
    
    # Analizar tendencia
    trend = predictor.analyze_trend('IA aplicada', historical)
    print(f"Tendencia actual: {trend['current_trend']} ({trend['change_pct']:.1f}%)")
    
    # Predecir futuro
    prediction = predictor.predict_future_trend('IA aplicada')
    if prediction:
        print(f"Predicci√≥n: {prediction.predicted_trend} (confianza: {prediction.confidence:.0%})")
        print(f"Recomendaci√≥n: {prediction.recommended_action}")
```

---

## ‚ö° Sistema de Optimizaci√≥n de Performance y Carga

### Script de Optimizaci√≥n T√©cnica

**Python**: `scripts/performance_optimizer.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n de performance y carga
- An√°lisis de tiempo de carga
- Optimizaci√≥n de im√°genes
- Compresi√≥n de assets
- CDN y caching
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class PerformanceMetrics:
    """M√©tricas de performance"""
    asset_id: str
    load_time_ms: float
    file_size_kb: float
    compression_ratio: float
    optimization_score: float  # 0-100

class PerformanceOptimizer:
    """Optimizador de performance"""
    
    def __init__(self):
        self.metrics = {}
        self.optimization_rules = {
            'max_image_size_kb': 200,
            'max_load_time_ms': 2000,
            'target_compression_ratio': 0.7
        }
    
    def analyze_asset(self, asset_id: str, file_size_kb: float,
                     load_time_ms: float) -> PerformanceMetrics:
        """Analiza performance de asset"""
        
        # Calcular ratio de compresi√≥n (ideal < 1.0)
        compression_ratio = file_size_kb / (file_size_kb * 1.5) if file_size_kb > 0 else 1.0
        
        # Calcular score de optimizaci√≥n
        optimization_score = self._calculate_optimization_score(
            file_size_kb, load_time_ms, compression_ratio
        )
        
        metrics = PerformanceMetrics(
            asset_id=asset_id,
            load_time_ms=load_time_ms,
            file_size_kb=file_size_kb,
            compression_ratio=compression_ratio,
            optimization_score=optimization_score
        )
        
        self.metrics[asset_id] = metrics
        
        return metrics
    
    def _calculate_optimization_score(self, size_kb: float, load_time_ms: float,
                                     compression: float) -> float:
        """Calcula score de optimizaci√≥n"""
        
        score = 100.0
        
        # Penalizar por tama√±o
        if size_kb > self.optimization_rules['max_image_size_kb']:
            penalty = (size_kb - self.optimization_rules['max_image_size_kb']) / 10
            score -= min(30, penalty)
        
        # Penalizar por tiempo de carga
        if load_time_ms > self.optimization_rules['max_load_time_ms']:
            penalty = (load_time_ms - self.optimization_rules['max_load_time_ms']) / 100
            score -= min(30, penalty)
        
        # Penalizar por falta de compresi√≥n
        if compression > 0.9:
            score -= 20  # Muy poco comprimido
        
        return max(0, score)
    
    def generate_optimization_recommendations(self, asset_id: str) -> List[str]:
        """Genera recomendaciones de optimizaci√≥n"""
        
        if asset_id not in self.metrics:
            return []
        
        metrics = self.metrics[asset_id]
        recommendations = []
        
        # Recomendaciones basadas en m√©tricas
        if metrics.file_size_kb > self.optimization_rules['max_image_size_kb']:
            reduction = metrics.file_size_kb - self.optimization_rules['max_image_size_kb']
            recommendations.append(f"Reducir tama√±o de archivo en {reduction:.1f}KB")
            recommendations.append("Aplicar compresi√≥n adicional (WebP, AVIF)")
        
        if metrics.load_time_ms > self.optimization_rules['max_load_time_ms']:
            recommendations.append(f"Optimizar tiempo de carga (actual: {metrics.load_time_ms:.0f}ms)")
            recommendations.append("Considerar uso de CDN")
            recommendations.append("Implementar lazy loading")
        
        if metrics.compression_ratio > 0.9:
            recommendations.append("Aplicar compresi√≥n m√°s agresiva")
            recommendations.append("Considerar formatos modernos (WebP, AVIF)")
        
        if metrics.optimization_score < 70:
            recommendations.append("Score de optimizaci√≥n bajo, aplicar mejoras m√∫ltiples")
        
        return recommendations
    
    def optimize_batch(self, assets: List[Dict]) -> Dict:
        """Optimiza batch de assets"""
        
        results = []
        optimized_count = 0
        
        for asset in assets:
            asset_id = asset.get('id')
            size_kb = asset.get('size_kb', 0)
            load_time = asset.get('load_time_ms', 0)
            
            # Analizar
            metrics = self.analyze_asset(asset_id, size_kb, load_time)
            
            # Generar recomendaciones
            recommendations = self.generate_optimization_recommendations(asset_id)
            
            if metrics.optimization_score >= 80:
                optimized_count += 1
            
            results.append({
                'asset_id': asset_id,
                'current_score': metrics.optimization_score,
                'recommendations': recommendations,
                'needs_optimization': metrics.optimization_score < 80
            })
        
        return {
            'total_assets': len(assets),
            'optimized': optimized_count,
            'needs_optimization': len(assets) - optimized_count,
            'optimization_rate': (optimized_count / len(assets)) * 100 if assets else 0,
            'results': results
        }

if __name__ == '__main__':
    optimizer = PerformanceOptimizer()
    
    # Analizar asset
    metrics = optimizer.analyze_asset('carousel_1_slide1', 350.0, 2500.0)
    
    print(f"Performance Analysis:")
    print(f"  Tiempo de carga: {metrics.load_time_ms:.0f}ms")
    print(f"  Tama√±o: {metrics.file_size_kb:.1f}KB")
    print(f"  Score: {metrics.optimization_score:.1f}/100")
    
    # Recomendaciones
    recommendations = optimizer.generate_optimization_recommendations('carousel_1_slide1')
    print(f"\nRecomendaciones:")
    for rec in recommendations:
        print(f"  ‚Ä¢ {rec}")
```

---

## üí¨ Sistema de Gesti√≥n de Feedback y Mejora Continua

### Script de Feedback Loop

**Python**: `scripts/feedback_improvement_system.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de feedback y mejora continua
- Recolecci√≥n de feedback estructurado
- An√°lisis de patrones de feedback
- Generaci√≥n de acciones de mejora
- Tracking de implementaci√≥n
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class FeedbackType(Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    SUGGESTION = "suggestion"
    BUG = "bug"
    FEATURE_REQUEST = "feature_request"

@dataclass
class Feedback:
    """Feedback de usuario"""
    feedback_id: str
    content_id: str
    user_id: str
    feedback_type: FeedbackType
    rating: int  # 1-5
    comment: str
    timestamp: datetime
    resolved: bool = False

class FeedbackImprovementSystem:
    """Sistema de feedback y mejora"""
    
    def __init__(self):
        self.feedbacks = {}
        self.improvements = {}
        self.implementation_tracking = {}
    
    def submit_feedback(self, content_id: str, user_id: str,
                       feedback_type: FeedbackType, rating: int,
                       comment: str) -> Feedback:
        """Env√≠a feedback"""
        
        feedback = Feedback(
            feedback_id=f"fb_{datetime.now().timestamp()}",
            content_id=content_id,
            user_id=user_id,
            feedback_type=feedback_type,
            rating=rating,
            comment=comment,
            timestamp=datetime.now()
        )
        
        self.feedbacks[feedback.feedback_id] = feedback
        
        # Generar acciones si es necesario
        if rating <= 2 or feedback_type in [FeedbackType.BUG, FeedbackType.NEGATIVE]:
            self._generate_improvement_actions(feedback)
        
        return feedback
    
    def _generate_improvement_actions(self, feedback: Feedback) -> List[Dict]:
        """Genera acciones de mejora desde feedback"""
        
        actions = []
        
        if feedback.feedback_type == FeedbackType.BUG:
            actions.append({
                'type': 'bug_fix',
                'priority': 'high',
                'description': f"Bug reportado: {feedback.comment[:100]}",
                'status': 'pending'
            })
        
        if feedback.rating <= 2:
            actions.append({
                'type': 'content_review',
                'priority': 'medium',
                'description': f"Revisar contenido {feedback.content_id} (rating bajo: {feedback.rating})",
                'status': 'pending'
            })
        
        if feedback.feedback_type == FeedbackType.FEATURE_REQUEST:
            actions.append({
                'type': 'feature_consideration',
                'priority': 'low',
                'description': f"Solicitud de feature: {feedback.comment[:100]}",
                'status': 'pending'
            })
        
        # Guardar acciones
        if feedback.content_id not in self.improvements:
            self.improvements[feedback.content_id] = []
        
        self.improvements[feedback.content_id].extend(actions)
        
        return actions
    
    def analyze_feedback_patterns(self, content_id: str) -> Dict:
        """Analiza patrones de feedback"""
        
        content_feedbacks = [
            f for f in self.feedbacks.values()
            if f.content_id == content_id
        ]
        
        if not content_feedbacks:
            return {'status': 'no_feedback'}
        
        # Calcular m√©tricas
        avg_rating = sum(f.rating for f in content_feedbacks) / len(content_feedbacks)
        
        feedback_by_type = {}
        for fb_type in FeedbackType:
            feedback_by_type[fb_type.value] = sum(
                1 for f in content_feedbacks if f.feedback_type == fb_type
            )
        
        # Palabras m√°s comunes en comentarios negativos
        negative_comments = [f.comment for f in content_feedbacks if f.rating <= 2]
        common_issues = self._extract_common_issues(negative_comments)
        
        return {
            'content_id': content_id,
            'total_feedbacks': len(content_feedbacks),
            'average_rating': avg_rating,
            'feedback_distribution': feedback_by_type,
            'common_issues': common_issues,
            'improvement_actions': len(self.improvements.get(content_id, [])),
            'resolved_feedbacks': sum(1 for f in content_feedbacks if f.resolved)
        }
    
    def _extract_common_issues(self, comments: List[str]) -> List[str]:
        """Extrae problemas comunes"""
        
        if not comments:
            return []
        
        # Palabras clave de problemas
        issue_keywords = {
            'lento': 'Performance issues',
            'confuso': 'Clarity issues',
            'error': 'Technical errors',
            'no funciona': 'Functionality problems',
            'faltante': 'Missing features'
        }
        
        issues_found = []
        for keyword, issue in issue_keywords.items():
            if any(keyword in comment.lower() for comment in comments):
                issues_found.append(issue)
        
        return issues_found
    
    def get_improvement_roadmap(self, content_id: str) -> Dict:
        """Obtiene roadmap de mejoras"""
        
        if content_id not in self.improvements:
            return {'status': 'no_improvements'}
        
        actions = self.improvements[content_id]
        
        # Agrupar por prioridad
        by_priority = {'high': [], 'medium': [], 'low': []}
        for action in actions:
            priority = action.get('priority', 'low')
            by_priority[priority].append(action)
        
        return {
            'content_id': content_id,
            'total_actions': len(actions),
            'actions_by_priority': by_priority,
            'pending_actions': sum(1 for a in actions if a.get('status') == 'pending'),
            'completed_actions': sum(1 for a in actions if a.get('status') == 'completed')
        }
    
    def mark_improvement_completed(self, content_id: str, action_index: int) -> Dict:
        """Marca acci√≥n de mejora como completada"""
        
        if content_id not in self.improvements:
            return {'status': 'error', 'message': 'No improvements found'}
        
        actions = self.improvements[content_id]
        
        if action_index >= len(actions):
            return {'status': 'error', 'message': 'Invalid action index'}
        
        actions[action_index]['status'] = 'completed'
        actions[action_index]['completed_at'] = datetime.now().isoformat()
        
        return {
            'status': 'success',
            'action': actions[action_index]
        }

if __name__ == '__main__':
    system = FeedbackImprovementSystem()
    
    # Enviar feedback
    feedback = system.submit_feedback(
        'curso_ia_1',
        'user123',
        FeedbackType.BUG,
        2,
        'El carrusel no carga correctamente en mobile'
    )
    
    print(f"Feedback enviado: {feedback.feedback_id}")
    
    # Analizar patrones
    patterns = system.analyze_feedback_patterns('curso_ia_1')
    print(f"Rating promedio: {patterns.get('average_rating', 0):.1f}/5")
    
    # Roadmap de mejoras
    roadmap = system.get_improvement_roadmap('curso_ia_1')
    print(f"Acciones pendientes: {roadmap.get('pending_actions', 0)}")
```

---

## üé¨ Sistema de Conversi√≥n de Carruseles a Video

### Script de Generaci√≥n de Video desde Carruseles

**Python**: `scripts/carousel_to_video_converter.py`

```python
#!/usr/bin/env python3
"""
Sistema de conversi√≥n de carruseles a video
- Generaci√≥n de video desde slides
- Transiciones autom√°ticas
- Timing optimizado por slide
- Exportaci√≥n en m√∫ltiples formatos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class VideoConfig:
    """Configuraci√≥n de video"""
    duration_seconds: int
    format: str  # reels, stories, feed
    fps: int
    resolution: tuple  # (width, height)
    transition_type: str  # fade, slide, zoom

@dataclass
class SlideTiming:
    """Timing de slide en video"""
    slide_index: int
    start_time: float
    end_time: float
    duration: float

class CarouselToVideoConverter:
    """Conversor de carrusel a video"""
    
    def __init__(self):
        self.videos = {}
        self.timing_configs = {}
    
    def create_video_from_carousel(self, carousel_id: str, slides: List[str],
                                  config: VideoConfig) -> Dict:
        """Crea video desde carrusel"""
        
        # Calcular timing de slides
        slide_timings = self._calculate_slide_timings(len(slides), config.duration_seconds)
        
        # Generar estructura de video
        video_structure = {
            'video_id': f"video_{datetime.now().timestamp()}",
            'carousel_id': carousel_id,
            'slides': slides,
            'slide_timings': slide_timings,
            'config': config,
            'total_duration': config.duration_seconds,
            'created_at': datetime.now().isoformat()
        }
        
        self.videos[video_structure['video_id']] = video_structure
        
        return video_structure
    
    def _calculate_slide_timings(self, num_slides: int, total_duration: float) -> List[SlideTiming]:
        """Calcula timing de cada slide"""
        
        timings = []
        
        # Distribuir tiempo (primer y √∫ltimo slide m√°s tiempo)
        if num_slides == 1:
            timings.append(SlideTiming(0, 0.0, total_duration, total_duration))
        elif num_slides == 2:
            timings.append(SlideTiming(0, 0.0, total_duration * 0.6, total_duration * 0.6))
            timings.append(SlideTiming(1, total_duration * 0.6, total_duration, total_duration * 0.4))
        else:
            # Primer slide: 20%
            first_duration = total_duration * 0.2
            timings.append(SlideTiming(0, 0.0, first_duration, first_duration))
            
            # Slides intermedios: distribuci√≥n equitativa del 60%
            middle_slides = num_slides - 2
            middle_duration = (total_duration * 0.6) / middle_slides if middle_slides > 0 else 0
            
            current_time = first_duration
            for i in range(1, num_slides - 1):
                timings.append(SlideTiming(i, current_time, current_time + middle_duration, middle_duration))
                current_time += middle_duration
            
            # √öltimo slide: 20%
            last_duration = total_duration * 0.2
            timings.append(SlideTiming(num_slides - 1, current_time, total_duration, last_duration))
        
        return timings
    
    def optimize_for_platform(self, video_id: str, platform: str) -> Dict:
        """Optimiza video para plataforma espec√≠fica"""
        
        if video_id not in self.videos:
            return {'status': 'error', 'message': 'Video not found'}
        
        video = self.videos[video_id]
        
        platform_configs = {
            'instagram_reels': {
                'duration': 15,
                'resolution': (1080, 1920),
                'fps': 30,
                'transition': 'fade'
            },
            'instagram_stories': {
                'duration': 15,
                'resolution': (1080, 1920),
                'fps': 30,
                'transition': 'slide'
            },
            'tiktok': {
                'duration': 15,
                'resolution': (1080, 1920),
                'fps': 30,
                'transition': 'zoom'
            },
            'youtube_shorts': {
                'duration': 15,
                'resolution': (1080, 1920),
                'fps': 30,
                'transition': 'fade'
            },
            'facebook_reels': {
                'duration': 30,
                'resolution': (1080, 1920),
                'fps': 30,
                'transition': 'fade'
            }
        }
        
        platform_config = platform_configs.get(platform)
        if not platform_config:
            return {'status': 'error', 'message': 'Platform not supported'}
        
        # Ajustar configuraci√≥n
        optimized_config = VideoConfig(
            duration_seconds=platform_config['duration'],
            format=platform,
            fps=platform_config['fps'],
            resolution=platform_config['resolution'],
            transition_type=platform_config['transition']
        )
        
        # Recalcular timings
        new_timings = self._calculate_slide_timings(
            len(video['slides']),
            optimized_config.duration_seconds
        )
        
        return {
            'video_id': video_id,
            'platform': platform,
            'optimized_config': {
                'duration': optimized_config.duration_seconds,
                'resolution': optimized_config.resolution,
                'fps': optimized_config.fps,
                'transition': optimized_config.transition_type
            },
            'slide_timings': [
                {
                    'slide_index': t.slide_index,
                    'start_time': t.start_time,
                    'end_time': t.end_time,
                    'duration': t.duration
                }
                for t in new_timings
            ]
        }
    
    def generate_video_script(self, video_id: str) -> str:
        """Genera script de video"""
        
        if video_id not in self.videos:
            return ''
        
        video = self.videos[video_id]
        timings = video['slide_timings']
        
        script_lines = []
        script_lines.append(f"Video Script - {video['carousel_id']}\n")
        script_lines.append(f"Total Duration: {video['total_duration']}s\n")
        script_lines.append("-" * 50)
        
        for timing in timings:
            slide_num = timing.slide_index + 1
            script_lines.append(f"\nSlide {slide_num} ({timing.start_time:.1f}s - {timing.end_time:.1f}s):")
            script_lines.append(f"  Duration: {timing.duration:.1f}s")
            script_lines.append(f"  Transition: {video['config'].transition_type}")
        
        return "\n".join(script_lines)

if __name__ == '__main__':
    converter = CarouselToVideoConverter()
    
    # Crear video desde carrusel
    slides = ['slide1.svg', 'slide2.svg', 'slide3.svg', 'slide4.svg', 'slide5.svg']
    
    config = VideoConfig(
        duration_seconds=15,
        format='reels',
        fps=30,
        resolution=(1080, 1920),
        transition_type='fade'
    )
    
    video = converter.create_video_from_carousel('curso_ia_1', slides, config)
    print(f"Video creado: {video['video_id']}")
    
    # Optimizar para plataforma
    optimized = converter.optimize_for_platform(video['video_id'], 'tiktok')
    print(f"Optimizado para: {optimized['platform']}")
    
    # Generar script
    script = converter.generate_video_script(video['video_id'])
    print(f"\nScript generado:\n{script}")
```

---

## üé® Sistema de Animaci√≥n y Motion Graphics Autom√°tico

### Script de Generaci√≥n de Animaciones

**Python**: `scripts/animation_motion_graphics.py`

```python
#!/usr/bin/env python3
"""
Sistema de animaci√≥n y motion graphics autom√°tico
- Generaci√≥n de animaciones desde assets est√°ticos
- Efectos de transici√≥n autom√°ticos
- Timing y easing personalizables
- Exportaci√≥n en m√∫ltiples formatos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum
import json

class AnimationType(Enum):
    FADE = "fade"
    SLIDE = "slide"
    ZOOM = "zoom"
    ROTATE = "rotate"
    BOUNCE = "bounce"

class EasingType(Enum):
    LINEAR = "linear"
    EASE_IN = "ease_in"
    EASE_OUT = "ease_out"
    EASE_IN_OUT = "ease_in_out"

@dataclass
class AnimationConfig:
    """Configuraci√≥n de animaci√≥n"""
    animation_type: AnimationType
    duration_ms: int
    delay_ms: int
    easing: EasingType
    direction: str  # left, right, up, down

class MotionGraphicsGenerator:
    """Generador de motion graphics"""
    
    def __init__(self):
        self.animations = {}
        self.presets = {
            'subtle': AnimationConfig(AnimationType.FADE, 500, 0, EasingType.EASE_IN_OUT, 'none'),
            'dynamic': AnimationConfig(AnimationType.SLIDE, 800, 100, EasingType.EASE_OUT, 'right'),
            'energetic': AnimationConfig(AnimationType.ZOOM, 600, 0, EasingType.EASE_OUT, 'none')
        }
    
    def create_animation_sequence(self, sequence_id: str, elements: List[Dict],
                                 preset: str = 'subtle') -> Dict:
        """Crea secuencia de animaci√≥n"""
        
        if preset not in self.presets:
            preset = 'subtle'
        
        base_config = self.presets[preset]
        
        sequence = {
            'sequence_id': sequence_id,
            'elements': [],
            'total_duration_ms': 0,
            'preset_used': preset
        }
        
        current_delay = 0
        for i, element in enumerate(elements):
            element_animation = {
                'element_id': element.get('id', f'element_{i}'),
                'content': element.get('content', ''),
                'animation': {
                    'type': base_config.animation_type.value,
                    'duration': base_config.duration_ms,
                    'delay': current_delay,
                    'easing': base_config.easing.value,
                    'direction': base_config.direction
                }
            }
            
            sequence['elements'].append(element_animation)
            current_delay += base_config.duration_ms + base_config.delay_ms
        
        sequence['total_duration_ms'] = current_delay
        
        self.animations[sequence_id] = sequence
        
        return sequence
    
    def generate_css_animations(self, sequence_id: str) -> str:
        """Genera CSS para animaciones"""
        
        if sequence_id not in self.animations:
            return ''
        
        sequence = self.animations[sequence_id]
        css_lines = []
        
        for i, element in enumerate(sequence['elements']):
            anim = element['animation']
            
            # Definir keyframes seg√∫n tipo
            if anim['type'] == 'fade':
                keyframes = f"""
                @keyframes fadeIn_{i} {{
                    from {{ opacity: 0; }}
                    to {{ opacity: 1; }}
                }}"""
            elif anim['type'] == 'slide':
                direction_map = {
                    'right': 'translateX(-100%)',
                    'left': 'translateX(100%)',
                    'up': 'translateY(100%)',
                    'down': 'translateY(-100%)'
                }
                transform = direction_map.get(anim['direction'], 'translateX(-100%)')
                keyframes = f"""
                @keyframes slideIn_{i} {{
                    from {{ transform: {transform}; opacity: 0; }}
                    to {{ transform: translate(0); opacity: 1; }}
                }}"""
            elif anim['type'] == 'zoom':
                keyframes = f"""
                @keyframes zoomIn_{i} {{
                    from {{ transform: scale(0.8); opacity: 0; }}
                    to {{ transform: scale(1); opacity: 1; }}
                }}"""
            else:
                keyframes = f"""
                @keyframes fadeIn_{i} {{
                    from {{ opacity: 0; }}
                    to {{ opacity: 1; }}
                }}"""
            
            css_lines.append(keyframes)
            
            # Aplicar animaci√≥n al elemento
            easing_map = {
                'linear': 'linear',
                'ease_in': 'ease-in',
                'ease_out': 'ease-out',
                'ease_in_out': 'ease-in-out'
            }
            
            animation_name = f"{anim['type']}In_{i}"
            easing = easing_map.get(anim['easing'], 'ease-in-out')
            
            element_css = f"""
            #{element['element_id']} {{
                animation: {animation_name} {anim['duration']}ms {easing} {anim['delay']}ms both;
            }}"""
            
            css_lines.append(element_css)
        
        return "\n".join(css_lines)
    
    def generate_after_effects_markers(self, sequence_id: str) -> List[Dict]:
        """Genera marcadores para After Effects"""
        
        if sequence_id not in self.animations:
            return []
        
        sequence = self.animations[sequence_id]
        markers = []
        
        for element in sequence['elements']:
            marker = {
                'time': element['animation']['delay'] / 1000.0,  # Convertir a segundos
                'name': f"{element['element_id']}_start",
                'comment': f"Animation: {element['animation']['type']}"
            }
            markers.append(marker)
            
            # Marker de fin
            end_marker = {
                'time': (element['animation']['delay'] + element['animation']['duration']) / 1000.0,
                'name': f"{element['element_id']}_end",
                'comment': 'Animation end'
            }
            markers.append(end_marker)
        
        return markers

if __name__ == '__main__':
    generator = MotionGraphicsGenerator()
    
    # Crear secuencia
    elements = [
        {'id': 'headline', 'content': 'Aprende IA aplicada'},
        {'id': 'subheadline', 'content': 'En 4 semanas'},
        {'id': 'cta', 'content': '√önete ahora'}
    ]
    
    sequence = generator.create_animation_sequence('curso_ia_anim', elements, preset='dynamic')
    print(f"Secuencia creada: {sequence['sequence_id']}")
    print(f"Duraci√≥n total: {sequence['total_duration_ms']}ms")
    
    # Generar CSS
    css = generator.generate_css_animations('curso_ia_anim')
    print(f"\nCSS generado ({len(css)} caracteres)")
```

---

## ü§ñ Sistema de Generaci√≥n Autom√°tica de Contenido con IA

### Script de Generaci√≥n Inteligente de Contenido

**Python**: `scripts/ai_content_generation.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de contenido con IA
- Generaci√≥n de headlines con GPT
- Variaciones de copy autom√°ticas
- Optimizaci√≥n basada en performance
- Personalizaci√≥n por audiencia
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class GeneratedContent:
    """Contenido generado"""
    content_id: str
    headline: str
    subheadline: str
    cta: str
    hashtags: List[str]
    caption: str
    variant_type: str
    performance_prediction: float

class AIContentGenerator:
    """Generador de contenido con IA"""
    
    def __init__(self):
        self.generated_content = {}
        self.templates = {
            'metrics': {
                'headline_patterns': [
                    '{number} {metric} que {action}',
                    'Incrementa tu {metric} en {number}%',
                    'Logra {number}x m√°s {metric}'
                ],
                'cta_options': ['Ver resultados', 'Descubre c√≥mo', 'Accede ahora']
            },
            'social_proof': {
                'headline_patterns': [
                    '{number}+ {audience} ya {action}',
                    '√önete a {number} {audience}',
                    'Somos {number}+ {audience}'
                ],
                'cta_options': ['√önete ahora', 'Comienza gratis', 'Forma parte']
            },
            'urgency': {
                'headline_patterns': [
                    'Solo hoy: {offer}',
                    '√öltimas {number} horas',
                    'Termina en {timeframe}'
                ],
                'cta_options': ['Ap√∫ntate ya', 'No te lo pierdas', 'Cons√≠guelo ahora']
            }
        }
    
    def generate_carousel_content(self, product_type: str, variant_type: str,
                                 context: Dict) -> GeneratedContent:
        """Genera contenido de carrusel"""
        
        template = self.templates.get(variant_type, self.templates['metrics'])
        
        # Seleccionar pattern aleatorio (en producci√≥n usar GPT)
        import random
        headline_pattern = random.choice(template['headline_patterns'])
        
        # Rellenar template
        headline = self._fill_template(headline_pattern, context)
        subheadline = self._generate_subheadline(product_type, context)
        cta = random.choice(template['cta_options'])
        hashtags = self._generate_hashtags(product_type, context)
        caption = self._generate_caption(headline, subheadline, cta, hashtags)
        
        # Predecir performance (simplificado)
        performance_prediction = self._predict_performance(variant_type, headline, cta)
        
        content = GeneratedContent(
            content_id=f"gen_{datetime.now().timestamp()}",
            headline=headline,
            subheadline=subheadline,
            cta=cta,
            hashtags=hashtags,
            caption=caption,
            variant_type=variant_type,
            performance_prediction=performance_prediction
        )
        
        self.generated_content[content.content_id] = content
        
        return content
    
    def _fill_template(self, template: str, context: Dict) -> str:
        """Rellena template con contexto"""
        
        # Mapeo de variables comunes
        replacements = {
            '{number}': str(context.get('number', '500')),
            '{metric}': context.get('metric', 'conversiones'),
            '{action}': context.get('action', 'convierten'),
            '{audience}': context.get('audience', 'estudiantes'),
            '{offer}': context.get('offer', 'Descuento 50%'),
            '{timeframe}': context.get('timeframe', '24 horas')
        }
        
        result = template
        for key, value in replacements.items():
            result = result.replace(key, value)
        
        return result
    
    def _generate_subheadline(self, product_type: str, context: Dict) -> str:
        """Genera subheadline"""
        
        subheadlines = {
            'curso_ia': 'Transforma tu carrera con IA aplicada',
            'saas_marketing': 'Automatiza tu marketing con IA',
            'ia_bulk': 'Procesa documentos 10x m√°s r√°pido'
        }
        
        return subheadlines.get(product_type, 'Descubre m√°s')
    
    def _generate_hashtags(self, product_type: str, context: Dict) -> List[str]:
        """Genera hashtags relevantes"""
        
        base_hashtags = {
            'curso_ia': ['IA', 'InteligenciaArtificial', 'CursoIA', 'Tech'],
            'saas_marketing': ['SaaS', 'Marketing', 'Automatizaci√≥n', 'Growth'],
            'ia_bulk': ['IA', 'Productividad', 'Documentos', 'Automatizaci√≥n']
        }
        
        hashtags = base_hashtags.get(product_type, ['Marketing', 'IA'])
        
        # Agregar hashtags contextuales
        if context.get('urgency'):
            hashtags.append('Oportunidad')
        
        if context.get('social_proof'):
            hashtags.append('Comunidad')
        
        return hashtags[:8]  # Limitar a 8
    
    def _generate_caption(self, headline: str, subheadline: str, cta: str,
                         hashtags: List[str]) -> str:
        """Genera caption completo"""
        
        caption_parts = [
            headline,
            subheadline,
            '',
            cta,
            '',
            ' '.join([f'#{tag}' for tag in hashtags])
        ]
        
        return '\n'.join(caption_parts)
    
    def _predict_performance(self, variant_type: str, headline: str, cta: str) -> float:
        """Predice performance (simplificado)"""
        
        score = 0.5  # Base
        
        # Factor: tipo de variante
        variant_scores = {
            'metrics': 0.7,
            'social_proof': 0.8,
            'urgency': 0.75
        }
        score += variant_scores.get(variant_type, 0.5) * 0.2
        
        # Factor: longitud de headline
        if 20 <= len(headline) <= 60:
            score += 0.15
        
        # Factor: CTA claro
        strong_ctas = ['ahora', 'gratis', 'descubre', '√∫nete', 'comienza']
        if any(cta_word in cta.lower() for cta_word in strong_ctas):
            score += 0.15
        
        return min(1.0, score)
    
    def generate_variations(self, base_content: GeneratedContent, count: int = 5) -> List[GeneratedContent]:
        """Genera variaciones de contenido"""
        
        variations = []
        
        for i in range(count):
            # Variar elementos
            variation = GeneratedContent(
                content_id=f"{base_content.content_id}_var_{i}",
                headline=self._vary_text(base_content.headline),
                subheadline=base_content.subheadline,
                cta=self._vary_cta(base_content.cta),
                hashtags=base_content.hashtags,
                caption='',  # Regenerar despu√©s
                variant_type=base_content.variant_type,
                performance_prediction=0.0
            )
            
            # Regenerar caption
            variation.caption = self._generate_caption(
                variation.headline,
                variation.subheadline,
                variation.cta,
                variation.hashtags
            )
            
            # Recalcular predicci√≥n
            variation.performance_prediction = self._predict_performance(
                variation.variant_type,
                variation.headline,
                variation.cta
            )
            
            variations.append(variation)
        
        return variations
    
    def _vary_text(self, text: str) -> str:
        """Var√≠a texto (simplificado)"""
        
        # En producci√≥n usar GPT para variaciones
        variations = [
            text.replace('aumenta', 'incrementa'),
            text.replace('mejora', 'optimiza'),
            text.replace('descubre', 'conoce')
        ]
        
        import random
        return random.choice(variations) if variations else text
    
    def _vary_cta(self, cta: str) -> str:
        """Var√≠a CTA"""
        
        cta_variations = {
            '√önete ahora': ['Comienza ya', 'Accede gratis', 'Forma parte'],
            'Descubre c√≥mo': ['Aprende m√°s', 'Conoce el m√©todo', 'Explora'],
            'Ver resultados': ['Mira resultados', 'Revisa casos', 'Ve ejemplos']
        }
        
        variations = cta_variations.get(cta, [cta])
        import random
        return random.choice(variations)

if __name__ == '__main__':
    generator = AIContentGenerator()
    
    # Generar contenido
    context = {
        'number': '500',
        'metric': 'estudiantes',
        'action': 'han aprendido',
        'audience': 'profesionales'
    }
    
    content = generator.generate_carousel_content('curso_ia', 'social_proof', context)
    
    print(f"Contenido generado:")
    print(f"  Headline: {content.headline}")
    print(f"  CTA: {content.cta}")
    print(f"  Performance predicho: {content.performance_prediction:.1%}")
    
    # Generar variaciones
    variations = generator.generate_variations(content, count=3)
    print(f"\nVariaciones generadas: {len(variations)}")
```

---

## üìä Sistema de An√°lisis Predictivo de Performance

### Script de Forecasting Avanzado

**Python**: `scripts/predictive_performance_analysis.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis predictivo de performance
- Predicci√≥n de CTR y engagement
- Forecasting de conversiones
- An√°lisis de tendencias futuras
- Recomendaciones basadas en ML
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import numpy as np

@dataclass
class PerformancePrediction:
    """Predicci√≥n de performance"""
    carousel_id: str
    predicted_ctr: float
    predicted_engagement: float
    predicted_conversions: int
    confidence: float
    forecast_period_days: int
    recommendations: List[str]

class PredictivePerformanceAnalyzer:
    """Analizador predictivo de performance"""
    
    def __init__(self):
        self.predictions = {}
        self.historical_data = {}
    
    def predict_carousel_performance(self, carousel_id: str,
                                    historical_metrics: List[Dict],
                                    forecast_days: int = 7) -> PerformancePrediction:
        """Predice performance de carrusel"""
        
        if len(historical_metrics) < 3:
            return None
        
        # Analizar tendencias
        trend_analysis = self._analyze_trends(historical_metrics)
        
        # Predecir CTR
        predicted_ctr = self._predict_ctr(trend_analysis, historical_metrics)
        
        # Predecir engagement
        predicted_engagement = self._predict_engagement(trend_analysis, historical_metrics)
        
        # Predecir conversiones
        predicted_conversions = self._predict_conversions(
            predicted_ctr, predicted_engagement, forecast_days
        )
        
        # Calcular confianza
        confidence = self._calculate_confidence(len(historical_metrics), trend_analysis)
        
        # Generar recomendaciones
        recommendations = self._generate_recommendations(
            predicted_ctr, predicted_engagement, trend_analysis
        )
        
        prediction = PerformancePrediction(
            carousel_id=carousel_id,
            predicted_ctr=predicted_ctr,
            predicted_engagement=predicted_engagement,
            predicted_conversions=predicted_conversions,
            confidence=confidence,
            forecast_period_days=forecast_days,
            recommendations=recommendations
        )
        
        self.predictions[carousel_id] = prediction
        
        return prediction
    
    def _analyze_trends(self, metrics: List[Dict]) -> Dict:
        """Analiza tendencias en m√©tricas"""
        
        if len(metrics) < 2:
            return {}
        
        # Calcular cambios
        recent = metrics[-3:] if len(metrics) >= 3 else metrics[-2:]
        older = metrics[:len(metrics)-len(recent)] if len(metrics) > len(recent) else metrics[:1]
        
        recent_avg_ctr = sum(m.get('ctr', 0) for m in recent) / len(recent)
        older_avg_ctr = sum(m.get('ctr', 0) for m in older) / len(older) if older else recent_avg_ctr
        
        recent_avg_engagement = sum(m.get('engagement_rate', 0) for m in recent) / len(recent)
        older_avg_engagement = sum(m.get('engagement_rate', 0) for m in older) / len(older) if older else recent_avg_engagement
        
        ctr_change = ((recent_avg_ctr - older_avg_ctr) / older_avg_ctr * 100) if older_avg_ctr > 0 else 0
        engagement_change = ((recent_avg_engagement - older_avg_engagement) / older_avg_engagement * 100) if older_avg_engagement > 0 else 0
        
        return {
            'ctr_trend': 'rising' if ctr_change > 5 else 'declining' if ctr_change < -5 else 'stable',
            'engagement_trend': 'rising' if engagement_change > 5 else 'declining' if engagement_change < -5 else 'stable',
            'ctr_change_pct': ctr_change,
            'engagement_change_pct': engagement_change
        }
    
    def _predict_ctr(self, trends: Dict, metrics: List[Dict]) -> float:
        """Predice CTR futuro"""
        
        recent_ctr = sum(m.get('ctr', 0) for m in metrics[-3:]) / min(3, len(metrics))
        
        # Ajustar seg√∫n tendencia
        trend = trends.get('ctr_trend', 'stable')
        change_pct = trends.get('ctr_change_pct', 0)
        
        if trend == 'rising':
            # Continuar√° subiendo pero m√°s lento (decay)
            predicted_ctr = recent_ctr * (1 + abs(change_pct) * 0.3 / 100)
        elif trend == 'declining':
            # Continuar√° bajando
            predicted_ctr = recent_ctr * (1 + change_pct * 0.5 / 100)
        else:
            # Estable con leve variaci√≥n
            predicted_ctr = recent_ctr * (1 + np.random.uniform(-0.02, 0.02))
        
        return max(0, predicted_ctr)
    
    def _predict_engagement(self, trends: Dict, metrics: List[Dict]) -> float:
        """Predice engagement futuro"""
        
        recent_engagement = sum(m.get('engagement_rate', 0) for m in metrics[-3:]) / min(3, len(metrics))
        
        trend = trends.get('engagement_trend', 'stable')
        change_pct = trends.get('engagement_change_pct', 0)
        
        if trend == 'rising':
            predicted_engagement = recent_engagement * (1 + abs(change_pct) * 0.3 / 100)
        elif trend == 'declining':
            predicted_engagement = recent_engagement * (1 + change_pct * 0.5 / 100)
        else:
            predicted_engagement = recent_engagement * (1 + np.random.uniform(-0.02, 0.02))
        
        return max(0, predicted_engagement)
    
    def _predict_conversions(self, predicted_ctr: float, predicted_engagement: float,
                            days: int) -> int:
        """Predice conversiones"""
        
        # Modelo simplificado
        # Asumiendo impresiones diarias y conversion rate
        daily_impressions = 10000  # Simplificado
        clicks = daily_impressions * (predicted_ctr / 100)
        
        # Conversion rate basado en engagement
        conversion_rate = 3.0 + (predicted_engagement * 0.2)  # 3-8%
        
        daily_conversions = clicks * (conversion_rate / 100)
        total_conversions = daily_conversions * days
        
        return int(total_conversions)
    
    def _calculate_confidence(self, data_points: int, trends: Dict) -> float:
        """Calcula confianza de predicci√≥n"""
        
        confidence = 0.5  # Base
        
        # M√°s datos = m√°s confianza
        if data_points >= 14:
            confidence += 0.3
        elif data_points >= 7:
            confidence += 0.2
        elif data_points >= 3:
            confidence += 0.1
        
        # Tendencias claras = m√°s confianza
        if trends.get('ctr_trend') != 'stable':
            confidence += 0.1
        
        if trends.get('engagement_trend') != 'stable':
            confidence += 0.1
        
        return min(1.0, confidence)
    
    def _generate_recommendations(self, predicted_ctr: float, predicted_engagement: float,
                                trends: Dict) -> List[str]:
        """Genera recomendaciones"""
        
        recommendations = []
        
        if predicted_ctr < 2.0:
            recommendations.append("CTR bajo, considerar A/B testing de headline y visual")
            recommendations.append("Revisar targeting de audiencia")
        
        if predicted_engagement < 5.0:
            recommendations.append("Engagement bajo, mejorar relevancia del contenido")
            recommendations.append("Considerar interactividad (polls, questions)")
        
        if trends.get('ctr_trend') == 'declining':
            recommendations.append("CTR en declive, crear nueva variante pronto")
        
        if trends.get('engagement_trend') == 'rising':
            recommendations.append("Engagement mejorando, escalar budget si ROI es positivo")
        
        if predicted_ctr > 6.0 and predicted_engagement > 12.0:
            recommendations.append("Performance excelente, replicar elementos en otros carruseles")
        
        return recommendations
    
    def compare_predictions(self, carousel_ids: List[str]) -> Dict:
        """Compara predicciones de m√∫ltiples carruseles"""
        
        predictions = [self.predictions[cid] for cid in carousel_ids if cid in self.predictions]
        
        if not predictions:
            return {'status': 'error', 'message': 'No predictions found'}
        
        # Mejor predicci√≥n de CTR
        best_ctr = max(predictions, key=lambda p: p.predicted_ctr)
        
        # Mejor predicci√≥n de engagement
        best_engagement = max(predictions, key=lambda p: p.predicted_engagement)
        
        # Mejor predicci√≥n de conversiones
        best_conversions = max(predictions, key=lambda p: p.predicted_conversions)
        
        return {
            'compared_carousels': carousel_ids,
            'best_ctr_prediction': {
                'carousel_id': best_ctr.carousel_id,
                'predicted_ctr': best_ctr.predicted_ctr
            },
            'best_engagement_prediction': {
                'carousel_id': best_engagement.carousel_id,
                'predicted_engagement': best_engagement.predicted_engagement
            },
            'best_conversions_prediction': {
                'carousel_id': best_conversions.carousel_id,
                'predicted_conversions': best_conversions.predicted_conversions
            }
        }

if __name__ == '__main__':
    analyzer = PredictivePerformanceAnalyzer()
    
    # Datos hist√≥ricos simulados
    historical = [
        {'ctr': 4.5, 'engagement_rate': 10.0, 'date': '2024-01-01'},
        {'ctr': 5.0, 'engagement_rate': 11.0, 'date': '2024-01-02'},
        {'ctr': 5.5, 'engagement_rate': 12.0, 'date': '2024-01-03'},
        {'ctr': 6.0, 'engagement_rate': 13.0, 'date': '2024-01-04'},
        {'ctr': 6.5, 'engagement_rate': 14.0, 'date': '2024-01-05'}
    ]
    
    # Predecir
    prediction = analyzer.predict_carousel_performance('curso_ia_1', historical, forecast_days=7)
    
    if prediction:
        print(f"Predicci√≥n de performance:")
        print(f"  CTR predicho: {prediction.predicted_ctr:.2f}%")
        print(f"  Engagement predicho: {prediction.predicted_engagement:.1f}%")
        print(f"  Conversiones predichas: {prediction.predicted_conversions}")
        print(f"  Confianza: {prediction.confidence:.0%}")
        print(f"\nRecomendaciones:")
        for rec in prediction.recommendations:
            print(f"  ‚Ä¢ {rec}")
```

---

## üìê Sistema de Gesti√≥n de Templates y Brand Guidelines

### Script de Enforcement de Brand

**Python**: `scripts/brand_guidelines_enforcer.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de templates y brand guidelines
- Validaci√≥n autom√°tica de brand guidelines
- Gesti√≥n de templates reutilizables
- Enforcement de reglas de dise√±o
- Versi√≥n de templates
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class ComplianceLevel(Enum):
    COMPLIANT = "compliant"
    WARNING = "warning"
    VIOLATION = "violation"

@dataclass
class BrandGuideline:
    """Guideline de marca"""
    guideline_id: str
    category: str  # colors, typography, logo, spacing
    rule: str
    validation_pattern: str
    severity: str  # critical, high, medium, low

@dataclass
class TemplateValidation:
    """Validaci√≥n de template"""
    template_id: str
    compliance_level: ComplianceLevel
    violations: List[str]
    warnings: List[str]
    score: float  # 0-100

class BrandGuidelinesEnforcer:
    """Enforcer de brand guidelines"""
    
    def __init__(self):
        self.guidelines = {}
        self.templates = {}
        self.validation_history = {}
    
    def add_guideline(self, category: str, rule: str, validation_pattern: str,
                     severity: str = 'medium') -> BrandGuideline:
        """Agrega guideline de marca"""
        
        guideline = BrandGuideline(
            guideline_id=f"guideline_{datetime.now().timestamp()}",
            category=category,
            rule=rule,
            validation_pattern=validation_pattern,
            severity=severity
        )
        
        if category not in self.guidelines:
            self.guidelines[category] = []
        
        self.guidelines[category].append(guideline)
        
        return guideline
    
    def validate_carousel(self, carousel_id: str, carousel_data: Dict) -> TemplateValidation:
        """Valida carrusel contra brand guidelines"""
        
        violations = []
        warnings = []
        
        # Validar colores
        color_issues = self._validate_colors(carousel_data.get('colors', []))
        violations.extend(color_issues['violations'])
        warnings.extend(color_issues['warnings'])
        
        # Validar tipograf√≠a
        typography_issues = self._validate_typography(carousel_data.get('typography', {}))
        violations.extend(typography_issues['violations'])
        warnings.extend(typography_issues['warnings'])
        
        # Validar logo
        logo_issues = self._validate_logo(carousel_data.get('logo', {}))
        violations.extend(logo_issues['violations'])
        warnings.extend(logo_issues['warnings'])
        
        # Calcular score
        total_checks = len(self.guidelines.get('colors', [])) + \
                      len(self.guidelines.get('typography', [])) + \
                      len(self.guidelines.get('logo', []))
        
        passed_checks = total_checks - len(violations) - len(warnings)
        score = (passed_checks / total_checks * 100) if total_checks > 0 else 100
        
        # Determinar nivel de compliance
        if len(violations) == 0 and len(warnings) == 0:
            compliance_level = ComplianceLevel.COMPLIANT
        elif len(violations) == 0:
            compliance_level = ComplianceLevel.WARNING
        else:
            compliance_level = ComplianceLevel.VIOLATION
        
        validation = TemplateValidation(
            template_id=carousel_id,
            compliance_level=compliance_level,
            violations=violations,
            warnings=warnings,
            score=score
        )
        
        self.validation_history[carousel_id] = validation
        
        return validation
    
    def _validate_colors(self, colors: List[str]) -> Dict:
        """Valida colores contra guidelines"""
        
        violations = []
        warnings = []
        
        # Brand colors permitidos (ejemplo)
        allowed_colors = ['#FF5733', '#33C3F0', '#85C1E2', '#FFFFFF', '#2C3E50']
        
        for color in colors:
            if color not in allowed_colors:
                violations.append(f"Color no permitido: {color}")
        
        if len(colors) > 5:
            warnings.append("Demasiados colores (recomendado: m√°ximo 5)")
        
        return {'violations': violations, 'warnings': warnings}
    
    def _validate_typography(self, typography: Dict) -> Dict:
        """Valida tipograf√≠a contra guidelines"""
        
        violations = []
        warnings = []
        
        allowed_fonts = ['Inter', 'Poppins', 'Roboto', 'Montserrat']
        font = typography.get('font', '')
        
        if font and font not in allowed_fonts:
            violations.append(f"Fuente no permitida: {font}")
        
        font_size = typography.get('size', 0)
        if font_size < 12 or font_size > 72:
            warnings.append(f"Tama√±o de fuente fuera de rango recomendado: {font_size}pt")
        
        return {'violations': violations, 'warnings': warnings}
    
    def _validate_logo(self, logo: Dict) -> Dict:
        """Valida logo contra guidelines"""
        
        violations = []
        warnings = []
        
        if not logo.get('present', False):
            violations.append("Logo requerido no presente")
        
        if logo.get('size', 0) < 40 or logo.get('size', 0) > 120:
            warnings.append(f"Tama√±o de logo fuera de rango recomendado: {logo.get('size')}px")
        
        return {'violations': violations, 'warnings': warnings}
    
    def create_template(self, template_id: str, template_data: Dict,
                       version: str = '1.0.0') -> Dict:
        """Crea template reutilizable"""
        
        # Validar antes de crear
        validation = self.validate_carousel(template_id, template_data)
        
        if validation.compliance_level == ComplianceLevel.VIOLATION:
            return {
                'status': 'error',
                'message': 'Template no cumple con brand guidelines',
                'violations': validation.violations
            }
        
        template = {
            'template_id': template_id,
            'version': version,
            'data': template_data,
            'validation': validation,
            'created_at': datetime.now().isoformat(),
            'usage_count': 0
        }
        
        self.templates[template_id] = template
        
        return {
            'status': 'success',
            'template': template
        }
    
    def get_template(self, template_id: str, version: Optional[str] = None) -> Dict:
        """Obtiene template"""
        
        if template_id not in self.templates:
            return {'status': 'error', 'message': 'Template not found'}
        
        template = self.templates[template_id]
        
        if version and template['version'] != version:
            return {'status': 'error', 'message': 'Version mismatch'}
        
        # Incrementar uso
        template['usage_count'] += 1
        
        return template

if __name__ == '__main__':
    enforcer = BrandGuidelinesEnforcer()
    
    # Agregar guidelines
    enforcer.add_guideline('colors', 'Use only brand colors', 'brand_palette', 'critical')
    enforcer.add_guideline('typography', 'Use approved fonts', 'font_list', 'high')
    
    # Validar carrusel
    carousel_data = {
        'colors': ['#FF5733', '#33C3F0'],
        'typography': {'font': 'Inter', 'size': 24},
        'logo': {'present': True, 'size': 80}
    }
    
    validation = enforcer.validate_carousel('curso_ia_1', carousel_data)
    
    print(f"Validaci√≥n de brand:")
    print(f"  Nivel: {validation.compliance_level.value}")
    print(f"  Score: {validation.score:.1f}/100")
    print(f"  Violaciones: {len(validation.violations)}")
    print(f"  Advertencias: {len(validation.warnings)}")
```

---

## üîÑ Sistema de Sincronizaci√≥n Multi-Canal en Tiempo Real

### Script de Sync Avanzado

**Python**: `scripts/realtime_multi_channel_sync.py`

```python
#!/usr/bin/env python3
"""
Sistema de sincronizaci√≥n multi-canal en tiempo real
- Sincronizaci√≥n bidireccional de contenido
- Actualizaci√≥n autom√°tica en todos los canales
- Resoluci√≥n de conflictos
- Estado unificado
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class SyncStatus(Enum):
    SYNCED = "synced"
    PENDING = "pending"
    CONFLICT = "conflict"
    ERROR = "error"

@dataclass
class SyncState:
    """Estado de sincronizaci√≥n"""
    channel: str
    content_id: str
    last_sync: datetime
    status: SyncStatus
    version: str

class RealtimeMultiChannelSync:
    """Sincronizador multi-canal en tiempo real"""
    
    def __init__(self):
        self.sync_states = {}
        self.channels = {}
        self.conflicts = {}
    
    def register_channel(self, channel_id: str, channel_config: Dict):
        """Registra canal para sincronizaci√≥n"""
        
        self.channels[channel_id] = {
            'config': channel_config,
            'last_sync': None,
            'active': True
        }
    
    def sync_content_to_channels(self, content_id: str, content_data: Dict,
                                target_channels: List[str]) -> Dict:
        """Sincroniza contenido a canales"""
        
        sync_results = {}
        
        for channel_id in target_channels:
            if channel_id not in self.channels:
                sync_results[channel_id] = {
                    'status': 'error',
                    'message': 'Channel not registered'
                }
                continue
            
            channel = self.channels[channel_id]
            
            # Adaptar contenido para canal
            adapted_content = self._adapt_for_channel(channel_id, content_data)
            
            # Sincronizar
            try:
                sync_result = self._sync_to_channel(channel_id, content_id, adapted_content)
                
                # Actualizar estado
                sync_key = f"{channel_id}_{content_id}"
                self.sync_states[sync_key] = SyncState(
                    channel=channel_id,
                    content_id=content_id,
                    last_sync=datetime.now(),
                    status=SyncStatus.SYNCED,
                    version=content_data.get('version', '1.0')
                )
                
                sync_results[channel_id] = sync_result
                
            except Exception as e:
                sync_results[channel_id] = {
                    'status': 'error',
                    'error': str(e)
                }
                
                sync_key = f"{channel_id}_{content_id}"
                self.sync_states[sync_key] = SyncState(
                    channel=channel_id,
                    content_id=content_id,
                    last_sync=datetime.now(),
                    status=SyncStatus.ERROR,
                    version=content_data.get('version', '1.0')
                )
        
        return {
            'content_id': content_id,
            'synced_channels': [c for c, r in sync_results.items() if r.get('status') == 'success'],
            'failed_channels': [c for c, r in sync_results.items() if r.get('status') == 'error'],
            'results': sync_results
        }
    
    def _adapt_for_channel(self, channel_id: str, content: Dict) -> Dict:
        """Adapta contenido para canal espec√≠fico"""
        
        adaptations = {
            'instagram': self._adapt_for_instagram,
            'linkedin': self._adapt_for_linkedin,
            'facebook': self._adapt_for_facebook,
            'twitter': self._adapt_for_twitter
        }
        
        adapter = adaptations.get(channel_id, lambda x: x)
        return adapter(content)
    
    def _adapt_for_instagram(self, content: Dict) -> Dict:
        """Adapta para Instagram"""
        adapted = content.copy()
        adapted['caption'] = content.get('caption', '')[:2200]
        adapted['hashtags'] = content.get('hashtags', [])[:30]
        return adapted
    
    def _adapt_for_linkedin(self, content: Dict) -> Dict:
        """Adapta para LinkedIn"""
        adapted = content.copy()
        adapted['hashtags'] = content.get('hashtags', [])[:5]
        return adapted
    
    def _adapt_for_facebook(self, content: Dict) -> Dict:
        """Adapta para Facebook"""
        return content.copy()
    
    def _adapt_for_twitter(self, content: Dict) -> Dict:
        """Adapta para Twitter"""
        adapted = content.copy()
        adapted['text'] = content.get('caption', '')[:280]
        return adapted
    
    def _sync_to_channel(self, channel_id: str, content_id: str, content: Dict) -> Dict:
        """Sincroniza a canal espec√≠fico"""
        
        # En producci√≥n, usar API real del canal
        return {
            'status': 'success',
            'channel': channel_id,
            'content_id': content_id,
            'synced_at': datetime.now().isoformat()
        }
    
    def detect_conflicts(self, content_id: str) -> List[Dict]:
        """Detecta conflictos entre canales"""
        
        content_syncs = [
            state for key, state in self.sync_states.items()
            if state.content_id == content_id
        ]
        
        if len(content_syncs) < 2:
            return []
        
        # Detectar diferencias de versi√≥n
        versions = set(s.version for s in content_syncs)
        conflicts = []
        
        if len(versions) > 1:
            conflicts.append({
                'type': 'version_mismatch',
                'content_id': content_id,
                'versions': list(versions),
                'channels': [s.channel for s in content_syncs]
            })
        
        # Detectar diferencias de timestamp (m√°s de 1 hora)
        sync_times = [s.last_sync for s in content_syncs]
        if sync_times:
            max_time = max(sync_times)
            min_time = min(sync_times)
            time_diff = (max_time - min_time).total_seconds()
            
            if time_diff > 3600:  # M√°s de 1 hora
                conflicts.append({
                    'type': 'sync_time_mismatch',
                    'content_id': content_id,
                    'time_diff_seconds': time_diff,
                    'channels': [s.channel for s in content_syncs]
                })
        
        self.conflicts[content_id] = conflicts
        
        return conflicts
    
    def resolve_conflict(self, content_id: str, resolution_strategy: str = 'latest') -> Dict:
        """Resuelve conflicto de sincronizaci√≥n"""
        
        if content_id not in self.conflicts:
            return {'status': 'error', 'message': 'No conflicts found'}
        
        conflicts = self.conflicts[content_id]
        
        if resolution_strategy == 'latest':
            # Usar versi√≥n m√°s reciente
            latest_sync = max(
                (s for key, s in self.sync_states.items() if s.content_id == content_id),
                key=lambda x: x.last_sync
            )
            
            return {
                'status': 'resolved',
                'strategy': 'latest',
                'resolved_channel': latest_sync.channel,
                'resolved_version': latest_sync.version
            }
        
        elif resolution_strategy == 'majority':
            # Usar versi√≥n m√°s com√∫n
            versions = {}
            for key, state in self.sync_states.items():
                if state.content_id == content_id:
                    versions[state.version] = versions.get(state.version, 0) + 1
            
            majority_version = max(versions.items(), key=lambda x: x[1])[0]
            
            return {
                'status': 'resolved',
                'strategy': 'majority',
                'resolved_version': majority_version
            }
        
        return {'status': 'error', 'message': 'Unknown resolution strategy'}
    
    def get_unified_status(self, content_id: str) -> Dict:
        """Obtiene estado unificado de sincronizaci√≥n"""
        
        content_syncs = [
            state for key, state in self.sync_states.items()
            if state.content_id == content_id
        ]
        
        if not content_syncs:
            return {'status': 'not_synced', 'channels': []}
        
        # Determinar estado general
        statuses = [s.status for s in content_syncs]
        if all(s == SyncStatus.SYNCED for s in statuses):
            overall_status = 'fully_synced'
        elif any(s == SyncStatus.ERROR for s in statuses):
            overall_status = 'partial_sync'
        else:
            overall_status = 'pending'
        
        return {
            'content_id': content_id,
            'overall_status': overall_status,
            'channels': [
                {
                    'channel': s.channel,
                    'status': s.status.value,
                    'last_sync': s.last_sync.isoformat(),
                    'version': s.version
                }
                for s in content_syncs
            ],
            'has_conflicts': content_id in self.conflicts
        }

if __name__ == '__main__':
    sync = RealtimeMultiChannelSync()
    
    # Registrar canales
    sync.register_channel('instagram', {'api_key': 'key123'})
    sync.register_channel('linkedin', {'api_key': 'key456'})
    
    # Sincronizar contenido
    content_data = {
        'caption': 'Aprende IA aplicada',
        'hashtags': ['IA', 'curso', 'marketing'],
        'version': '1.0'
    }
    
    result = sync.sync_content_to_channels('curso_ia_1', content_data, ['instagram', 'linkedin'])
    print(f"Sincronizaci√≥n: {len(result['synced_channels'])} exitosas")
    
    # Estado unificado
    status = sync.get_unified_status('curso_ia_1')
    print(f"Estado: {status['overall_status']}")
```

---

## üß© Sistema de Componentes Reutilizables y Design System

### Script de Gesti√≥n de Componentes

**Python**: `scripts/reusable_components_manager.py`

```python
#!/usr/bin/env python3
"""
Sistema de componentes reutilizables y design system
- Biblioteca de componentes
- Composici√≥n de carruseles desde componentes
- Versionado de componentes
- Reutilizaci√≥n autom√°tica
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class Component:
    """Componente reutilizable"""
    component_id: str
    name: str
    type: str  # header, footer, cta, metric_card, testimonial
    properties: Dict
    version: str
    usage_count: int

class ReusableComponentsManager:
    """Gestor de componentes reutilizables"""
    
    def __init__(self):
        self.components = {}
        self.compositions = {}
    
    def create_component(self, name: str, component_type: str,
                        properties: Dict, version: str = '1.0.0') -> Component:
        """Crea componente reutilizable"""
        
        component = Component(
            component_id=f"comp_{datetime.now().timestamp()}",
            name=name,
            type=component_type,
            properties=properties,
            version=version,
            usage_count=0
        )
        
        self.components[component.component_id] = component
        
        return component
    
    def compose_carousel_from_components(self, carousel_id: str,
                                       component_ids: List[str]) -> Dict:
        """Compone carrusel desde componentes"""
        
        # Validar componentes
        missing = [cid for cid in component_ids if cid not in self.components]
        if missing:
            return {
                'status': 'error',
                'message': f'Components not found: {missing}'
            }
        
        # Obtener componentes
        components = [self.components[cid] for cid in component_ids]
        
        # Incrementar uso
        for comp in components:
            comp.usage_count += 1
        
        # Componer estructura
        composition = {
            'carousel_id': carousel_id,
            'components': [
                {
                    'id': comp.component_id,
                    'name': comp.name,
                    'type': comp.type,
                    'properties': comp.properties
                }
                for comp in components
            ],
            'composed_at': datetime.now().isoformat()
        }
        
        self.compositions[carousel_id] = composition
        
        return {
            'status': 'success',
            'composition': composition
        }
    
    def get_component_variants(self, component_type: str) -> List[Component]:
        """Obtiene variantes de componente por tipo"""
        
        return [
            comp for comp in self.components.values()
            if comp.type == component_type
        ]
    
    def get_most_used_components(self, limit: int = 10) -> List[Component]:
        """Obtiene componentes m√°s usados"""
        
        sorted_components = sorted(
            self.components.values(),
            key=lambda c: c.usage_count,
            reverse=True
        )
        
        return sorted_components[:limit]
    
    def update_component(self, component_id: str, new_version: str,
                        updated_properties: Dict) -> Component:
        """Actualiza componente (nueva versi√≥n)"""
        
        if component_id not in self.components:
            return None
        
        old_component = self.components[component_id]
        
        # Crear nueva versi√≥n
        new_component = Component(
            component_id=f"{component_id}_v{new_version}",
            name=old_component.name,
            type=old_component.type,
            properties={**old_component.properties, **updated_properties},
            version=new_version,
            usage_count=0
        )
        
        self.components[new_component.component_id] = new_component
        
        return new_component
    
    def generate_component_library_report(self) -> Dict:
        """Genera reporte de biblioteca de componentes"""
        
        # Agrupar por tipo
        by_type = {}
        for comp in self.components.values():
            if comp.type not in by_type:
                by_type[comp.type] = []
            by_type[comp.type].append(comp)
        
        # Calcular estad√≠sticas
        total_usage = sum(comp.usage_count for comp in self.components.values())
        
        return {
            'total_components': len(self.components),
            'components_by_type': {
                comp_type: len(comps)
                for comp_type, comps in by_type.items()
            },
            'total_usage': total_usage,
            'avg_usage_per_component': total_usage / len(self.components) if self.components else 0,
            'most_used': [
                {
                    'id': comp.component_id,
                    'name': comp.name,
                    'type': comp.type,
                    'usage': comp.usage_count
                }
                for comp in self.get_most_used_components(5)
            ]
        }

if __name__ == '__main__':
    manager = ReusableComponentsManager()
    
    # Crear componentes
    header_comp = manager.create_component(
        'Header Standard',
        'header',
        {'text': '{{headline}}', 'style': 'bold', 'size': 48},
        '1.0.0'
    )
    
    cta_comp = manager.create_component(
        'CTA Primary',
        'cta',
        {'text': '{{cta_text}}', 'color': '#FF5733', 'size': 'large'},
        '1.0.0'
    )
    
    # Componer carrusel
    composition = manager.compose_carousel_from_components(
        'curso_ia_1',
        [header_comp.component_id, cta_comp.component_id]
    )
    
    print(f"Carrusel compuesto: {composition['status']}")
    print(f"Componentes: {len(composition['composition']['components'])}")
    
    # Reporte
    report = manager.generate_component_library_report()
    print(f"\nBiblioteca de componentes:")
    print(f"  Total: {report['total_components']}")
    print(f"  Uso total: {report['total_usage']}")
```

---

## üì± Sistema de Adaptaci√≥n Autom√°tica a M√≥vil

### Script de Mobile-First Optimization

**Python**: `scripts/mobile_adaptation_automation.py`

```python
#!/usr/bin/env python3
"""
Sistema de adaptaci√≥n autom√°tica a m√≥vil
- Optimizaci√≥n responsive autom√°tica
- Testing de diferentes tama√±os de pantalla
- Ajuste de elementos para mobile
- Validaci√≥n de touch targets
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class MobileOptimization:
    """Optimizaci√≥n mobile"""
    carousel_id: str
    font_size_adjusted: bool
    touch_targets_validated: bool
    layout_optimized: bool
    mobile_score: float  # 0-100

class MobileAdaptationAutomation:
    """Automatizaci√≥n de adaptaci√≥n mobile"""
    
    def __init__(self):
        self.optimizations = {}
        self.mobile_configs = {
            'iphone_se': {'width': 375, 'height': 667},
            'iphone_12': {'width': 390, 'height': 844},
            'android_standard': {'width': 360, 'height': 640},
            'tablet': {'width': 768, 'height': 1024}
        }
    
    def optimize_for_mobile(self, carousel_id: str, carousel_data: Dict) -> MobileOptimization:
        """Optimiza carrusel para mobile"""
        
        optimizations_applied = []
        
        # Ajustar tama√±o de fuente
        font_size_adjusted = self._adjust_font_sizes(carousel_data)
        if font_size_adjusted:
            optimizations_applied.append('font_size_adjusted')
        
        # Validar touch targets
        touch_targets_validated = self._validate_touch_targets(carousel_data)
        if touch_targets_validated:
            optimizations_applied.append('touch_targets_validated')
        
        # Optimizar layout
        layout_optimized = self._optimize_layout(carousel_data)
        if layout_optimized:
            optimizations_applied.append('layout_optimized')
        
        # Calcular score mobile
        mobile_score = self._calculate_mobile_score(
            font_size_adjusted, touch_targets_validated, layout_optimized
        )
        
        optimization = MobileOptimization(
            carousel_id=carousel_id,
            font_size_adjusted=font_size_adjusted,
            touch_targets_validated=touch_targets_validated,
            layout_optimized=layout_optimized,
            mobile_score=mobile_score
        )
        
        self.optimizations[carousel_id] = optimization
        
        return optimization
    
    def _adjust_font_sizes(self, carousel_data: Dict) -> bool:
        """Ajusta tama√±os de fuente para mobile"""
        
        typography = carousel_data.get('typography', {})
        
        # Verificar si necesita ajuste
        base_size = typography.get('base_size', 16)
        if base_size < 14:  # M√≠nimo recomendado para mobile
            typography['base_size'] = 14
            typography['mobile_adjusted'] = True
            return True
        
        return False
    
    def _validate_touch_targets(self, carousel_data: Dict) -> bool:
        """Valida touch targets (m√≠nimo 44x44px)"""
        
        interactive_elements = carousel_data.get('interactive_elements', [])
        
        for element in interactive_elements:
            width = element.get('width', 0)
            height = element.get('height', 0)
            
            if width < 44 or height < 44:
                element['width'] = max(44, width)
                element['height'] = max(44, height)
                element['mobile_optimized'] = True
        
        return len(interactive_elements) > 0
    
    def _optimize_layout(self, carousel_data: Dict) -> bool:
        """Optimiza layout para mobile"""
        
        layout = carousel_data.get('layout', {})
        
        # Ajustar spacing para pantallas peque√±as
        if layout.get('spacing', 0) > 20:
            layout['mobile_spacing'] = min(20, layout['spacing'] * 0.7)
            layout['mobile_optimized'] = True
            return True
        
        return False
    
    def _calculate_mobile_score(self, font_adj: bool, touch_val: bool,
                               layout_opt: bool) -> float:
        """Calcula score mobile"""
        
        score = 50.0  # Base
        
        if font_adj:
            score += 20
        if touch_val:
            score += 20
        if layout_opt:
            score += 10
        
        return min(100, score)
    
    def test_across_devices(self, carousel_id: str, carousel_data: Dict) -> Dict:
        """Prueba carrusel en diferentes dispositivos"""
        
        results = {}
        
        for device_name, config in self.mobile_configs.items():
            # Simular renderizado en dispositivo
            result = self._simulate_device_render(carousel_data, config)
            
            results[device_name] = {
                'resolution': config,
                'renders_correctly': result['renders_correctly'],
                'issues': result['issues'],
                'score': result['score']
            }
        
        return {
            'carousel_id': carousel_id,
            'device_results': results,
            'overall_mobile_score': sum(r['score'] for r in results.values()) / len(results)
        }
    
    def _simulate_device_render(self, carousel_data: Dict, device_config: Dict) -> Dict:
        """Simula renderizado en dispositivo"""
        
        width = device_config['width']
        height = device_config['height']
        
        issues = []
        
        # Verificar si contenido cabe
        content_width = carousel_data.get('content_width', 1080)
        if content_width > width:
            issues.append('Content too wide for device')
        
        content_height = carousel_data.get('content_height', 1080)
        if content_height > height:
            issues.append('Content too tall for device')
        
        renders_correctly = len(issues) == 0
        
        score = 100 if renders_correctly else max(0, 100 - len(issues) * 30)
        
        return {
            'renders_correctly': renders_correctly,
            'issues': issues,
            'score': score
        }
    
    def generate_mobile_report(self, carousel_id: str) -> Dict:
        """Genera reporte de optimizaci√≥n mobile"""
        
        if carousel_id not in self.optimizations:
            return {'status': 'error', 'message': 'No optimization found'}
        
        optimization = self.optimizations[carousel_id]
        
        return {
            'carousel_id': carousel_id,
            'mobile_score': optimization.mobile_score,
            'optimizations_applied': [
                'font_size_adjusted' if optimization.font_size_adjusted else None,
                'touch_targets_validated' if optimization.touch_targets_validated else None,
                'layout_optimized' if optimization.layout_optimized else None
            ],
            'recommendations': self._generate_mobile_recommendations(optimization)
        }
    
    def _generate_mobile_recommendations(self, optimization: MobileOptimization) -> List[str]:
        """Genera recomendaciones mobile"""
        
        recommendations = []
        
        if not optimization.font_size_adjusted:
            recommendations.append("Ajustar tama√±os de fuente para legibilidad en mobile")
        
        if not optimization.touch_targets_validated:
            recommendations.append("Validar que todos los elementos interactivos tengan tama√±o m√≠nimo 44x44px")
        
        if optimization.mobile_score < 70:
            recommendations.append("Score mobile bajo, aplicar todas las optimizaciones recomendadas")
        
        if optimization.mobile_score >= 90:
            recommendations.append("Optimizaci√≥n mobile excelente, mantener estas pr√°cticas")
        
        return recommendations

if __name__ == '__main__':
    adapter = MobileAdaptationAutomation()
    
    # Optimizar carrusel
    carousel_data = {
        'typography': {'base_size': 12},
        'interactive_elements': [
            {'type': 'button', 'width': 100, 'height': 30},
            {'type': 'link', 'width': 80, 'height': 25}
        ],
        'layout': {'spacing': 30},
        'content_width': 1080,
        'content_height': 1080
    }
    
    optimization = adapter.optimize_for_mobile('curso_ia_1', carousel_data)
    
    print(f"Optimizaci√≥n mobile:")
    print(f"  Score: {optimization.mobile_score:.1f}/100")
    print(f"  Fuente ajustada: {optimization.font_size_adjusted}")
    print(f"  Touch targets: {optimization.touch_targets_validated}")
    
    # Testear en dispositivos
    device_test = adapter.test_across_devices('curso_ia_1', carousel_data)
    print(f"\nTest en dispositivos:")
    print(f"  Score promedio: {device_test['overall_mobile_score']:.1f}/100")
```

---

## ‚ôø Sistema de Validaci√≥n Avanzada de Contraste y Accesibilidad Visual

### Script de Validaci√≥n de Contraste WCAG

**Python**: `scripts/advanced_contrast_validator.py`

```python
#!/usr/bin/env python3
"""
Sistema de validaci√≥n avanzada de contraste y accesibilidad visual
- Validaci√≥n de contraste WCAG 2.1 AA/AAA
- Detecci√≥n de problemas de color
- Sugerencias de correcci√≥n autom√°ticas
- Reportes detallados de accesibilidad
"""
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import json

class WCAGLevel(Enum):
    AA_NORMAL = "AA_NORMAL"  # 4.5:1 para texto normal
    AA_LARGE = "AA_LARGE"    # 3:1 para texto grande
    AAA_NORMAL = "AAA_NORMAL" # 7:1 para texto normal
    AAA_LARGE = "AAA_LARGE"  # 4.5:1 para texto grande

@dataclass
class ContrastResult:
    """Resultado de validaci√≥n de contraste"""
    foreground_color: str
    background_color: str
    contrast_ratio: float
    wcag_level: WCAGLevel
    passes: bool
    text_size: str  # normal, large

class AdvancedContrastValidator:
    """Validador avanzado de contraste"""
    
    def __init__(self):
        self.results = {}
        self.wcag_ratios = {
            WCAGLevel.AA_NORMAL: 4.5,
            WCAGLevel.AA_LARGE: 3.0,
            WCAGLevel.AAA_NORMAL: 7.0,
            WCAGLevel.AAA_LARGE: 4.5
        }
    
    def validate_contrast(self, foreground: str, background: str,
                         text_size: str = 'normal',
                         wcag_level: WCAGLevel = WCAGLevel.AA_NORMAL) -> ContrastResult:
        """Valida contraste entre colores"""
        
        # Convertir hex a RGB
        fg_rgb = self._hex_to_rgb(foreground)
        bg_rgb = self._hex_to_rgb(background)
        
        # Calcular contraste
        contrast = self._calculate_contrast_ratio(fg_rgb, bg_rgb)
        
        # Determinar si pasa
        required_ratio = self.wcag_ratios[wcag_level]
        passes = contrast >= required_ratio
        
        result = ContrastResult(
            foreground_color=foreground,
            background_color=background,
            contrast_ratio=contrast,
            wcag_level=wcag_level,
            passes=passes,
            text_size=text_size
        )
        
        key = f"{foreground}_{background}_{text_size}"
        self.results[key] = result
        
        return result
    
    def _hex_to_rgb(self, hex_color: str) -> Tuple[int, int, int]:
        """Convierte hex a RGB"""
        
        hex_color = hex_color.lstrip('#')
        
        if len(hex_color) == 3:
            hex_color = ''.join([c*2 for c in hex_color])
        
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
    
    def _calculate_contrast_ratio(self, color1: Tuple[int, int, int],
                                 color2: Tuple[int, int, int]) -> float:
        """Calcula ratio de contraste WCAG"""
        
        l1 = self._relative_luminance(color1)
        l2 = self._relative_luminance(color2)
        
        lighter = max(l1, l2)
        darker = min(l1, l2)
        
        return (lighter + 0.05) / (darker + 0.05)
    
    def _relative_luminance(self, rgb: Tuple[int, int, int]) -> float:
        """Calcula luminancia relativa"""
        
        def linearize(component: int) -> float:
            val = component / 255.0
            if val <= 0.03928:
                return val / 12.92
            return ((val + 0.055) / 1.055) ** 2.4
        
        r, g, b = [linearize(c) for c in rgb]
        
        return 0.2126 * r + 0.7152 * g + 0.0722 * b
    
    def find_accessible_colors(self, base_color: str, background: str,
                              target_contrast: float = 4.5) -> List[str]:
        """Encuentra colores accesibles para un color base"""
        
        suggestions = []
        
        # Variar luminosidad
        base_rgb = self._hex_to_rgb(base_color)
        bg_rgb = self._hex_to_rgb(background)
        
        for adjustment in range(-50, 51, 10):
            adjusted_rgb = tuple(
                max(0, min(255, c + adjustment))
                for c in base_rgb
            )
            
            adjusted_hex = self._rgb_to_hex(adjusted_rgb)
            contrast = self._calculate_contrast_ratio(adjusted_rgb, bg_rgb)
            
            if contrast >= target_contrast:
                suggestions.append({
                    'color': adjusted_hex,
                    'contrast': contrast,
                    'adjustment': adjustment
                })
        
        # Ordenar por contraste m√°s cercano al target
        suggestions.sort(key=lambda x: abs(x['contrast'] - target_contrast))
        
        return [s['color'] for s in suggestions[:5]]
    
    def _rgb_to_hex(self, rgb: Tuple[int, int, int]) -> str:
        """Convierte RGB a hex"""
        
        return f"#{''.join(f'{c:02x}' for c in rgb)}"
    
    def validate_carousel_colors(self, carousel_id: str, color_pairs: List[Dict]) -> Dict:
        """Valida todos los pares de color de un carrusel"""
        
        violations = []
        warnings = []
        
        for pair in color_pairs:
            foreground = pair.get('foreground')
            background = pair.get('background')
            text_size = pair.get('text_size', 'normal')
            
            result = self.validate_contrast(
                foreground, background, text_size, WCAGLevel.AA_NORMAL
            )
            
            if not result.passes:
                violations.append({
                    'foreground': foreground,
                    'background': background,
                    'contrast': result.contrast_ratio,
                    'required': self.wcag_ratios[WCAGLevel.AA_NORMAL],
                    'suggestions': self.find_accessible_colors(foreground, background)
                })
            
            # Verificar si cumple AAA
            aaa_result = self.validate_contrast(
                foreground, background, text_size, WCAGLevel.AAA_NORMAL
            )
            
            if not aaa_result.passes:
                warnings.append({
                    'foreground': foreground,
                    'background': background,
                    'contrast': aaa_result.contrast_ratio,
                    'note': 'No cumple AAA, pero cumple AA'
                })
        
        return {
            'carousel_id': carousel_id,
            'total_pairs': len(color_pairs),
            'violations': violations,
            'warnings': warnings,
            'accessibility_score': self._calculate_accessibility_score(
                len(color_pairs), len(violations), len(warnings)
            )
        }
    
    def _calculate_accessibility_score(self, total: int, violations: int,
                                     warnings: int) -> float:
        """Calcula score de accesibilidad"""
        
        if total == 0:
            return 0.0
        
        violation_penalty = (violations / total) * 70
        warning_penalty = (warnings / total) * 15
        
        score = 100 - violation_penalty - warning_penalty
        
        return max(0.0, score)

if __name__ == '__main__':
    validator = AdvancedContrastValidator()
    
    # Validar contraste
    result = validator.validate_contrast('#333333', '#FFFFFF', 'normal', WCAGLevel.AA_NORMAL)
    
    print(f"Validaci√≥n de contraste:")
    print(f"  Ratio: {result.contrast_ratio:.2f}:1")
    print(f"  Pasa WCAG {result.wcag_level.value}: {result.passes}")
    
    # Encontrar colores accesibles
    suggestions = validator.find_accessible_colors('#CCCCCC', '#FFFFFF', 4.5)
    print(f"\nColores accesibles sugeridos: {suggestions[:3]}")
    
    # Validar carrusel
    color_pairs = [
        {'foreground': '#333333', 'background': '#FFFFFF', 'text_size': 'normal'},
        {'foreground': '#CCCCCC', 'background': '#FFFFFF', 'text_size': 'normal'}
    ]
    
    carousel_validation = validator.validate_carousel_colors('curso_ia_1', color_pairs)
    print(f"\nScore de accesibilidad: {carousel_validation['accessibility_score']:.1f}/100")
```

---

## ü§ñ Sistema de Generaci√≥n Autom√°tica de Alt Text con IA

### Script de Alt Text Inteligente

**Python**: `scripts/ai_alt_text_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de alt text con IA
- Generaci√≥n de alt text descriptivo con GPT
- Optimizaci√≥n para SEO y accesibilidad
- Validaci√≥n de calidad de alt text
- Sugerencias de mejora
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class AltTextResult:
    """Resultado de generaci√≥n de alt text"""
    image_path: str
    generated_alt: str
    quality_score: float
    word_count: int
    seo_score: float
    accessibility_score: float
    suggestions: List[str]

class AIAltTextGenerator:
    """Generador de alt text con IA"""
    
    def __init__(self):
        self.generated_alts = {}
        self.quality_keywords = [
            'descriptivo', 'espec√≠fico', 'contextual', 'informative'
        ]
    
    def generate_alt_text(self, image_path: str, image_context: Dict,
                         use_ai: bool = True) -> AltTextResult:
        """Genera alt text para imagen"""
        
        if use_ai:
            # En producci√≥n usar GPT-4 Vision
            alt_text = self._generate_with_ai(image_path, image_context)
        else:
            alt_text = self._generate_basic(image_path, image_context)
        
        # Evaluar calidad
        quality_score = self._evaluate_quality(alt_text, image_context)
        word_count = len(alt_text.split())
        seo_score = self._evaluate_seo(alt_text, image_context)
        accessibility_score = self._evaluate_accessibility(alt_text)
        
        # Generar sugerencias
        suggestions = self._generate_suggestions(
            alt_text, quality_score, word_count
        )
        
        result = AltTextResult(
            image_path=image_path,
            generated_alt=alt_text,
            quality_score=quality_score,
            word_count=word_count,
            seo_score=seo_score,
            accessibility_score=accessibility_score,
            suggestions=suggestions
        )
        
        self.generated_alts[image_path] = result
        
        return result
    
    def _generate_with_ai(self, image_path: str, context: Dict) -> str:
        """Genera alt text con IA (simulado)"""
        
        # En producci√≥n: usar GPT-4 Vision API
        product = context.get('product', 'producto')
        carousel_slide = context.get('slide_number', 1)
        
        templates = [
            f"Slide {carousel_slide} del carrusel de {product} mostrando beneficios clave",
            f"Visualizaci√≥n del {product} destacando caracter√≠sticas principales",
            f"Ilustraci√≥n del slide {carousel_slide} sobre {product} con informaci√≥n relevante"
        ]
        
        import random
        return random.choice(templates)
    
    def _generate_basic(self, image_path: str, context: Dict) -> str:
        """Genera alt text b√°sico sin IA"""
        
        filename = image_path.split('/')[-1]
        product = context.get('product', 'producto')
        
        return f"Imagen de {product} - {filename}"
    
    def _evaluate_quality(self, alt_text: str, context: Dict) -> float:
        """Eval√∫a calidad del alt text"""
        
        score = 0.0
        
        # Longitud adecuada (5-125 palabras)
        word_count = len(alt_text.split())
        if 5 <= word_count <= 125:
            score += 30
        elif word_count < 5:
            score += (word_count / 5) * 30
        else:
            score += max(0, 30 - (word_count - 125) * 0.2)
        
        # Especificidad
        if len(set(alt_text.lower().split())) > 5:
            score += 25
        
        # Contexto relevante
        if context.get('product') and context['product'].lower() in alt_text.lower():
            score += 20
        
        # Sin frases gen√©ricas
        generic_phrases = ['imagen de', 'foto de', 'imagen', 'gr√°fico']
        if not any(phrase in alt_text.lower() for phrase in generic_phrases):
            score += 25
        
        return min(100, score)
    
    def _evaluate_seo(self, alt_text: str, context: Dict) -> float:
        """Eval√∫a SEO del alt text"""
        
        score = 50.0
        
        # Keywords relevantes
        keywords = context.get('keywords', [])
        found_keywords = sum(1 for kw in keywords if kw.lower() in alt_text.lower())
        if keywords:
            score += (found_keywords / len(keywords)) * 30
        
        # Longitud para SEO (10-125 caracteres)
        length = len(alt_text)
        if 10 <= length <= 125:
            score += 20
        
        return min(100, score)
    
    def _evaluate_accessibility(self, alt_text: str) -> float:
        """Eval√∫a accesibilidad del alt text"""
        
        score = 100.0
        
        # No vac√≠o
        if not alt_text.strip():
            score = 0
            return score
        
        # No solo gen√©ricos
        if alt_text.strip().lower() in ['imagen', 'foto', 'gr√°fico', 'imagen de']:
            score -= 50
        
        # Descriptivo
        if len(alt_text.split()) < 3:
            score -= 30
        
        return max(0, score)
    
    def _generate_suggestions(self, alt_text: str, quality_score: float,
                            word_count: int) -> List[str]:
        """Genera sugerencias de mejora"""
        
        suggestions = []
        
        if word_count < 5:
            suggestions.append("Alt text muy corto, agregar m√°s detalles descriptivos")
        
        if word_count > 125:
            suggestions.append("Alt text muy largo, considerar acortarlo a menos de 125 palabras")
        
        if quality_score < 70:
            suggestions.append("Mejorar especificidad y contexto del alt text")
        
        generic_phrases = ['imagen de', 'foto de']
        if any(phrase in alt_text.lower() for phrase in generic_phrases):
            suggestions.append("Evitar frases gen√©ricas como 'imagen de', ser m√°s espec√≠fico")
        
        return suggestions
    
    def batch_generate_alt_texts(self, images: List[Dict]) -> Dict:
        """Genera alt texts en batch"""
        
        results = []
        
        for image in images:
            result = self.generate_alt_text(
                image['path'],
                image.get('context', {})
            )
            results.append(result)
        
        # Calcular estad√≠sticas
        avg_quality = sum(r.quality_score for r in results) / len(results)
        avg_seo = sum(r.seo_score for r in results) / len(results)
        avg_accessibility = sum(r.accessibility_score for r in results) / len(results)
        
        return {
            'total_images': len(images),
            'generated_alts': results,
            'average_quality_score': avg_quality,
            'average_seo_score': avg_seo,
            'average_accessibility_score': avg_accessibility,
            'needs_improvement': [
                r.image_path for r in results
                if r.quality_score < 70 or r.accessibility_score < 70
            ]
        }

if __name__ == '__main__':
    generator = AIAltTextGenerator()
    
    # Generar alt text
    context = {
        'product': 'Curso IA',
        'slide_number': 1,
        'keywords': ['IA', 'curso', 'aprendizaje']
    }
    
    result = generator.generate_alt_text('curso_ia_slide1.png', context)
    
    print(f"Alt text generado:")
    print(f"  Texto: {result.generated_alt}")
    print(f"  Calidad: {result.quality_score:.1f}/100")
    print(f"  SEO: {result.seo_score:.1f}/100")
    print(f"  Accesibilidad: {result.accessibility_score:.1f}/100")
    
    if result.suggestions:
        print(f"\nSugerencias:")
        for sugg in result.suggestions:
            print(f"  ‚Ä¢ {sugg}")
```

---

## ‚å®Ô∏è Sistema de Testing de Navegaci√≥n por Teclado

### Script de Validaci√≥n de Accesibilidad por Teclado

**Python**: `scripts/keyboard_navigation_tester.py`

```python
#!/usr/bin/env python3
"""
Sistema de testing de navegaci√≥n por teclado
- Validaci√≥n de navegaci√≥n por teclado
- Detecci√≥n de trampas de foco
- Validaci√≥n de orden l√≥gico de tab
- Testing autom√°tico de atajos de teclado
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum
import json

class KeyboardIssueType(Enum):
    TRAP_FOCUS = "trap_focus"
    SKIP_FOCUS = "skip_focus"
    LOGICAL_ORDER = "logical_order"
    VISIBLE_INDICATOR = "visible_indicator"
    SHORTCUT_CONFLICT = "shortcut_conflict"

@dataclass
class KeyboardIssue:
    """Problema de navegaci√≥n por teclado"""
    issue_type: KeyboardIssueType
    element_id: str
    description: str
    severity: str  # critical, high, medium, low
    suggestion: str

@dataclass
class KeyboardTestResult:
    """Resultado de test de teclado"""
    carousel_id: str
    total_focusable_elements: int
    issues: List[KeyboardIssue]
    keyboard_score: float
    tab_order_logical: bool

class KeyboardNavigationTester:
    """Tester de navegaci√≥n por teclado"""
    
    def __init__(self):
        self.test_results = {}
        self.focusable_selectors = [
            'a', 'button', 'input', 'select', 'textarea',
            '[tabindex]:not([tabindex="-1"])',
            '[role="button"]', '[role="link"]', '[role="tab"]'
        ]
    
    def test_keyboard_navigation(self, carousel_id: str,
                                carousel_structure: Dict) -> KeyboardTestResult:
        """Testea navegaci√≥n por teclado"""
        
        issues = []
        
        # Identificar elementos enfocables
        focusable_elements = self._identify_focusable_elements(carousel_structure)
        
        # Testear orden l√≥gico
        logical_order_issue = self._test_tab_order(focusable_elements)
        if logical_order_issue:
            issues.append(logical_order_issue)
        
        # Testear trampas de foco
        trap_issues = self._test_focus_traps(focusable_elements)
        issues.extend(trap_issues)
        
        # Testear indicadores visibles
        indicator_issues = self._test_focus_indicators(focusable_elements)
        issues.extend(indicator_issues)
        
        # Testear atajos de teclado
        shortcut_issues = self._test_keyboard_shortcuts(carousel_structure)
        issues.extend(shortcut_issues)
        
        # Calcular score
        keyboard_score = self._calculate_keyboard_score(
            len(focusable_elements), len(issues)
        )
        
        result = KeyboardTestResult(
            carousel_id=carousel_id,
            total_focusable_elements=len(focusable_elements),
            issues=issues,
            keyboard_score=keyboard_score,
            tab_order_logical=logical_order_issue is None
        )
        
        self.test_results[carousel_id] = result
        
        return result
    
    def _identify_focusable_elements(self, structure: Dict) -> List[Dict]:
        """Identifica elementos enfocables"""
        
        elements = []
        
        for slide in structure.get('slides', []):
            for element in slide.get('elements', []):
                if element.get('type') in ['button', 'link', 'input', 'cta']:
                    elements.append({
                        'id': element.get('id', ''),
                        'type': element.get('type', ''),
                        'tabindex': element.get('tabindex', None),
                        'slide': slide.get('slide_number', 0)
                    })
        
        return elements
    
    def _test_tab_order(self, elements: List[Dict]) -> Optional[KeyboardIssue]:
        """Testea orden l√≥gico de tab"""
        
        if len(elements) < 2:
            return None
        
        # Verificar que no haya tabindex > 0 (anti-pattern)
        high_tabindex = [
            e for e in elements
            if e.get('tabindex') and int(e.get('tabindex', 0)) > 0
        ]
        
        if high_tabindex:
            return KeyboardIssue(
                issue_type=KeyboardIssueType.LOGICAL_ORDER,
                element_id=high_tabindex[0]['id'],
                description="Elementos con tabindex > 0 pueden romper el orden l√≥gico",
                severity="high",
                suggestion="Evitar tabindex > 0, usar orden DOM natural"
            )
        
        return None
    
    def _test_focus_traps(self, elements: List[Dict]) -> List[KeyboardIssue]:
        """Testea trampas de foco"""
        
        issues = []
        
        # Detectar elementos con tabindex="-1" que deber√≠an ser accesibles
        hidden_focusable = [
            e for e in elements
            if e.get('tabindex') == '-1' and e.get('type') in ['button', 'link', 'cta']
        ]
        
        for element in hidden_focusable:
            issues.append(KeyboardIssue(
                issue_type=KeyboardIssueType.TRAP_FOCUS,
                element_id=element['id'],
                description="Elemento interactivo con tabindex='-1' no es accesible por teclado",
                severity="critical",
                suggestion="Remover tabindex='-1' o hacer elemento accesible por otro medio"
            ))
        
        return issues
    
    def _test_focus_indicators(self, elements: List[Dict]) -> List[KeyboardIssue]:
        """Testea indicadores visibles de foco"""
        
        issues = []
        
        # En producci√≥n, verificar CSS para focus styles
        # Por ahora, asumir que elementos sin focus style son problema
        
        for element in elements:
            # Simular verificaci√≥n de estilos
            has_focus_style = element.get('has_focus_style', True)
            
            if not has_focus_style:
                issues.append(KeyboardIssue(
                    issue_type=KeyboardIssueType.VISIBLE_INDICATOR,
                    element_id=element['id'],
                    description="Elemento no tiene indicador visual de foco",
                    severity="high",
                    suggestion="Agregar outline o border visible en estado :focus"
                ))
        
        return issues
    
    def _test_keyboard_shortcuts(self, structure: Dict) -> List[KeyboardIssue]:
        """Testea atajos de teclado"""
        
        issues = []
        
        # Detectar posibles conflictos con atajos est√°ndar
        shortcuts = structure.get('keyboard_shortcuts', [])
        
        standard_shortcuts = ['Ctrl+S', 'Ctrl+P', 'Alt+F4', 'Esc', 'Enter', 'Space']
        
        for shortcut in shortcuts:
            if shortcut in standard_shortcuts:
                issues.append(KeyboardIssue(
                    issue_type=KeyboardIssueType.SHORTCUT_CONFLICT,
                    element_id='',
                    description=f"Atajo {shortcut} puede conflictuar con funcionalidad del navegador",
                    severity="medium",
                    suggestion=f"Evitar usar {shortcut}, usar combinaci√≥n √∫nica"
                ))
        
        return issues
    
    def _calculate_keyboard_score(self, total_elements: int,
                                 total_issues: int) -> float:
        """Calcula score de navegaci√≥n por teclado"""
        
        if total_elements == 0:
            return 100.0
        
        # Penalizar por issues cr√≠ticos (70%), altos (20%), medios (10%)
        critical_penalty = sum(1 for _ in range(total_issues)) * 15
        high_penalty = sum(1 for _ in range(total_issues)) * 10
        
        score = 100.0 - min(70, critical_penalty) - min(20, high_penalty)
        
        return max(0.0, score)
    
    def generate_keyboard_report(self, carousel_id: str) -> Dict:
        """Genera reporte de navegaci√≥n por teclado"""
        
        if carousel_id not in self.test_results:
            return {'status': 'error', 'message': 'No test results found'}
        
        result = self.test_results[carousel_id]
        
        # Agrupar issues por tipo
        issues_by_type = {}
        for issue in result.issues:
            issue_type = issue.issue_type.value
            if issue_type not in issues_by_type:
                issues_by_type[issue_type] = []
            issues_by_type[issue_type].append(issue)
        
        return {
            'carousel_id': carousel_id,
            'keyboard_score': result.keyboard_score,
            'total_focusable_elements': result.total_focusable_elements,
            'tab_order_logical': result.tab_order_logical,
            'total_issues': len(result.issues),
            'issues_by_type': {
                k: [
                    {
                        'element_id': i.element_id,
                        'description': i.description,
                        'severity': i.severity,
                        'suggestion': i.suggestion
                    }
                    for i in v
                ]
                for k, v in issues_by_type.items()
            },
            'recommendations': self._generate_recommendations(result)
        }
    
    def _generate_recommendations(self, result: KeyboardTestResult) -> List[str]:
        """Genera recomendaciones"""
        
        recommendations = []
        
        if result.keyboard_score < 70:
            recommendations.append("Score de navegaci√≥n por teclado bajo, revisar issues cr√≠ticos")
        
        if not result.tab_order_logical:
            recommendations.append("Corregir orden l√≥gico de tab para mejor UX")
        
        critical_issues = [i for i in result.issues if i.severity == 'critical']
        if critical_issues:
            recommendations.append(f"Resolver {len(critical_issues)} issues cr√≠ticos de accesibilidad")
        
        if result.keyboard_score >= 90:
            recommendations.append("Excelente navegaci√≥n por teclado, mantener estas pr√°cticas")
        
        return recommendations

if __name__ == '__main__':
    tester = KeyboardNavigationTester()
    
    # Estructura de carrusel
    carousel_structure = {
        'slides': [
            {
                'slide_number': 1,
                'elements': [
                    {'id': 'cta1', 'type': 'button', 'tabindex': None},
                    {'id': 'link1', 'type': 'link', 'tabindex': None}
                ]
            }
        ],
        'keyboard_shortcuts': []
    }
    
    result = tester.test_keyboard_navigation('curso_ia_1', carousel_structure)
    
    print(f"Test de navegaci√≥n por teclado:")
    print(f"  Score: {result.keyboard_score:.1f}/100")
    print(f"  Elementos enfocables: {result.total_focusable_elements}")
    print(f"  Issues: {len(result.issues)}")
    
    # Reporte
    report = tester.generate_keyboard_report('curso_ia_1')
    print(f"\nRecomendaciones: {len(report['recommendations'])}")
```

---

## üìä Sistema de Reportes Ejecutivos de Accesibilidad

### Script de Generaci√≥n de Reportes

**Python**: `scripts/accessibility_executive_reports.py`

```python
#!/usr/bin/env python3
"""
Sistema de reportes ejecutivos de accesibilidad
- Reportes consolidados de accesibilidad
- M√©tricas clave para stakeholders
- Tendencias y mejoras
- Exportaci√≥n a PDF/HTML
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class AccessibilityMetrics:
    """M√©tricas de accesibilidad"""
    wcag_compliance: float
    contrast_score: float
    alt_text_coverage: float
    keyboard_score: float
    overall_score: float

class AccessibilityExecutiveReports:
    """Generador de reportes ejecutivos de accesibilidad"""
    
    def __init__(self):
        self.reports = {}
        self.metrics_history = []
    
    def generate_executive_report(self, report_period: Dict,
                                metrics: AccessibilityMetrics,
                                issues_summary: Dict) -> Dict:
        """Genera reporte ejecutivo"""
        
        report = {
            'report_id': f"accessibility_report_{datetime.now().timestamp()}",
            'period': report_period,
            'generated_at': datetime.now().isoformat(),
            'metrics': {
                'wcag_compliance': metrics.wcag_compliance,
                'contrast_score': metrics.contrast_score,
                'alt_text_coverage': metrics.alt_text_coverage,
                'keyboard_score': metrics.keyboard_score,
                'overall_score': metrics.overall_score
            },
            'issues_summary': issues_summary,
            'trends': self._calculate_trends(),
            'recommendations': self._generate_executive_recommendations(metrics, issues_summary),
            'next_steps': self._generate_next_steps(metrics, issues_summary)
        }
        
        self.reports[report['report_id']] = report
        self.metrics_history.append({
            'date': datetime.now().isoformat(),
            'metrics': metrics
        })
        
        return report
    
    def _calculate_trends(self) -> Dict:
        """Calcula tendencias de m√©tricas"""
        
        if len(self.metrics_history) < 2:
            return {'status': 'insufficient_data'}
        
        recent = self.metrics_history[-1]['metrics']
        previous = self.metrics_history[-2]['metrics']
        
        trends = {
            'wcag_compliance_trend': 'improving' if recent.wcag_compliance > previous.wcag_compliance else 'declining',
            'contrast_score_trend': 'improving' if recent.contrast_score > previous.contrast_score else 'declining',
            'overall_score_trend': 'improving' if recent.overall_score > previous.overall_score else 'declining',
            'change_percentage': {
                'wcag': ((recent.wcag_compliance - previous.wcag_compliance) / previous.wcag_compliance * 100) if previous.wcag_compliance > 0 else 0,
                'overall': ((recent.overall_score - previous.overall_score) / previous.overall_score * 100) if previous.overall_score > 0 else 0
            }
        }
        
        return trends
    
    def _generate_executive_recommendations(self, metrics: AccessibilityMetrics,
                                          issues_summary: Dict) -> List[str]:
        """Genera recomendaciones ejecutivas"""
        
        recommendations = []
        
        if metrics.overall_score < 70:
            recommendations.append(
                "Priorizar accesibilidad: score general bajo requiere atenci√≥n inmediata"
            )
        
        if metrics.wcag_compliance < 90:
            recommendations.append(
                f"Cumplimiento WCAG en {metrics.wcag_compliance:.1f}%, objetivo: 95%+"
            )
        
        critical_issues = issues_summary.get('critical', 0)
        if critical_issues > 0:
            recommendations.append(
                f"Resolver {critical_issues} issues cr√≠ticos para mejorar score"
            )
        
        if metrics.alt_text_coverage < 90:
            recommendations.append(
                f"Cobertura de alt text en {metrics.alt_text_coverage:.1f}%, objetivo: 100%"
            )
        
        if metrics.overall_score >= 90:
            recommendations.append(
                "Excelente score de accesibilidad, mantener estas pr√°cticas"
            )
        
        return recommendations
    
    def _generate_next_steps(self, metrics: AccessibilityMetrics,
                           issues_summary: Dict) -> List[str]:
        """Genera pr√≥ximos pasos"""
        
        next_steps = []
        
        if metrics.contrast_score < 80:
            next_steps.append("Auditar y corregir problemas de contraste en todos los carruseles")
        
        if issues_summary.get('critical', 0) > 0:
            next_steps.append("Crear plan de acci√≥n para resolver issues cr√≠ticos en pr√≥xima semana")
        
        if metrics.alt_text_coverage < 100:
            next_steps.append("Implementar generaci√≥n autom√°tica de alt text para im√°genes faltantes")
        
        if metrics.keyboard_score < 85:
            next_steps.append("Mejorar navegaci√≥n por teclado en componentes interactivos")
        
        next_steps.append("Seguimiento de m√©tricas semanal para trackear mejoras")
        
        return next_steps
    
    def export_to_html(self, report_id: str) -> str:
        """Exporta reporte a HTML"""
        
        if report_id not in self.reports:
            return ''
        
        report = self.reports[report_id]
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Accessibility Executive Report</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background: #f0f0f0; padding: 20px; }}
                .metrics {{ display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px; margin: 20px 0; }}
                .metric-card {{ border: 1px solid #ddd; padding: 15px; border-radius: 5px; }}
                .score {{ font-size: 2em; font-weight: bold; }}
                .recommendations {{ background: #fff9e6; padding: 15px; margin: 20px 0; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Accessibility Executive Report</h1>
                <p>Generated: {report['generated_at']}</p>
            </div>
            
            <div class="metrics">
                <div class="metric-card">
                    <h3>Overall Score</h3>
                    <div class="score">{report['metrics']['overall_score']:.1f}/100</div>
                </div>
                <div class="metric-card">
                    <h3>WCAG Compliance</h3>
                    <div class="score">{report['metrics']['wcag_compliance']:.1f}%</div>
                </div>
                <div class="metric-card">
                    <h3>Contrast Score</h3>
                    <div class="score">{report['metrics']['contrast_score']:.1f}/100</div>
                </div>
            </div>
            
            <div class="recommendations">
                <h2>Recommendations</h2>
                <ul>
                    {' '.join([f'<li>{rec}</li>' for rec in report['recommendations']])}
                </ul>
            </div>
        </body>
        </html>
        """
        
        return html

if __name__ == '__main__':
    reporter = AccessibilityExecutiveReports()
    
    # M√©tricas
    metrics = AccessibilityMetrics(
        wcag_compliance=92.5,
        contrast_score=88.0,
        alt_text_coverage=95.0,
        keyboard_score=91.0,
        overall_score=91.6
    )
    
    issues_summary = {
        'critical': 2,
        'high': 5,
        'medium': 12,
        'low': 8
    }
    
    report = reporter.generate_executive_report(
        {'start': '2024-01-01', 'end': '2024-01-31'},
        metrics,
        issues_summary
    )
    
    print(f"Reporte ejecutivo generado:")
    print(f"  Overall Score: {report['metrics']['overall_score']:.1f}/100")
    print(f"  Recomendaciones: {len(report['recommendations'])}")
    
    # Exportar HTML
    html = reporter.export_to_html(report['report_id'])
    print(f"\nHTML exportado: {len(html)} caracteres")
```

---

## üîç Sistema de Gesti√≥n Avanzada de Metadatos y SEO

### Script de Optimizaci√≥n de Metadatos

**Python**: `scripts/advanced_metadata_seo_manager.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n avanzada de metadatos y SEO
- Generaci√≥n autom√°tica de metadatos SEO
- Optimizaci√≥n de Open Graph y Twitter Cards
- Schema.org markup
- Validaci√≥n y scoring SEO
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class SEOMetadata:
    """Metadatos SEO"""
    title: str
    description: str
    keywords: List[str]
    og_title: str
    og_description: str
    og_image: str
    twitter_card: str
    twitter_title: str
    twitter_description: str
    schema_markup: Dict

@dataclass
class SEOScore:
    """Score SEO"""
    overall_score: float
    title_score: float
    description_score: float
    keywords_score: float
    og_score: float
    twitter_score: float
    schema_score: float

class AdvancedMetadataSEOManager:
    """Gestor avanzado de metadatos SEO"""
    
    def __init__(self):
        self.metadata_cache = {}
        self.optimal_lengths = {
            'title': (30, 60),
            'description': (120, 160),
            'og_title': (60, 90),
            'og_description': (150, 200),
            'twitter_title': (70, 70),
            'twitter_description': (200, 200)
        }
    
    def generate_seo_metadata(self, carousel_id: str, carousel_data: Dict) -> SEOMetadata:
        """Genera metadatos SEO completos"""
        
        # Generar title
        title = self._generate_title(carousel_data)
        
        # Generar description
        description = self._generate_description(carousel_data)
        
        # Extraer keywords
        keywords = self._extract_keywords(carousel_data)
        
        # Open Graph
        og_title = self._optimize_for_og(title, carousel_data)
        og_description = self._optimize_for_og(description, carousel_data)
        og_image = carousel_data.get('og_image', '')
        
        # Twitter Cards
        twitter_card = 'summary_large_image'
        twitter_title = self._optimize_for_twitter(title)
        twitter_description = self._optimize_for_twitter(description)
        
        # Schema.org markup
        schema_markup = self._generate_schema_markup(carousel_data)
        
        metadata = SEOMetadata(
            title=title,
            description=description,
            keywords=keywords,
            og_title=og_title,
            og_description=og_description,
            og_image=og_image,
            twitter_card=twitter_card,
            twitter_title=twitter_title,
            twitter_description=twitter_description,
            schema_markup=schema_markup
        )
        
        self.metadata_cache[carousel_id] = metadata
        
        return metadata
    
    def _generate_title(self, data: Dict) -> str:
        """Genera title SEO optimizado"""
        
        product = data.get('product', 'Producto')
        headline = data.get('headline', '')
        
        # Construir title (producto - headline)
        if headline:
            title = f"{headline} | {product}"
        else:
            title = f"{product} - Aprende m√°s"
        
        # Asegurar longitud √≥ptima
        min_len, max_len = self.optimal_lengths['title']
        if len(title) > max_len:
            title = title[:max_len-3] + "..."
        elif len(title) < min_len:
            title += " - Descubre m√°s"
        
        return title
    
    def _generate_description(self, data: Dict) -> str:
        """Genera description SEO optimizada"""
        
        subheadline = data.get('subheadline', '')
        benefits = data.get('benefits', [])
        
        if subheadline:
            description = subheadline
        elif benefits:
            description = f"{benefits[0]} y m√°s beneficios. " + \
                         f"Descubre c√≥mo {data.get('product', 'este producto')} puede ayudarte."
        else:
            description = f"Descubre {data.get('product', 'este producto')} y transforma tu manera de trabajar."
        
        # Ajustar longitud
        min_len, max_len = self.optimal_lengths['description']
        if len(description) > max_len:
            description = description[:max_len-3] + "..."
        elif len(description) < min_len:
            description += " Aprende m√°s y comienza hoy."
        
        return description
    
    def _extract_keywords(self, data: Dict) -> List[str]:
        """Extrae keywords relevantes"""
        
        keywords = []
        
        # Keywords del producto
        product = data.get('product', '').lower()
        if product:
            keywords.append(product)
        
        # Keywords del headline
        headline_words = data.get('headline', '').lower().split()
        important_words = [w for w in headline_words if len(w) > 4]
        keywords.extend(important_words[:3])
        
        # Keywords del tema
        topic = data.get('topic', '')
        if topic:
            keywords.append(topic.lower())
        
        # Remover duplicados y limitar
        keywords = list(dict.fromkeys(keywords))[:10]
        
        return keywords
    
    def _optimize_for_og(self, text: str, data: Dict) -> str:
        """Optimiza texto para Open Graph"""
        
        # Open Graph permite textos m√°s largos
        if len(text) > self.optimal_lengths['og_title'][1]:
            return text[:self.optimal_lengths['og_title'][1]-3] + "..."
        
        return text
    
    def _optimize_for_twitter(self, text: str) -> str:
        """Optimiza texto para Twitter"""
        
        # Twitter tiene l√≠mites m√°s estrictos
        max_len = self.optimal_lengths['twitter_title'][1]
        if len(text) > max_len:
            return text[:max_len-3] + "..."
        
        return text
    
    def _generate_schema_markup(self, data: Dict) -> Dict:
        """Genera Schema.org markup"""
        
        schema = {
            "@context": "https://schema.org",
            "@type": "Course" if 'curso' in data.get('product', '').lower() else "Product",
            "name": data.get('product', ''),
            "description": data.get('subheadline', ''),
            "provider": {
                "@type": "Organization",
                "name": "Blatam"
            }
        }
        
        # Agregar informaci√≥n adicional si est√° disponible
        if data.get('price'):
            schema['offers'] = {
                "@type": "Offer",
                "price": data.get('price'),
                "priceCurrency": "EUR"
            }
        
        return schema
    
    def validate_seo_metadata(self, metadata: SEOMetadata) -> SEOScore:
        """Valida y scorea metadatos SEO"""
        
        # Score title
        title_score = self._score_title(metadata.title)
        
        # Score description
        description_score = self._score_description(metadata.description)
        
        # Score keywords
        keywords_score = self._score_keywords(metadata.keywords)
        
        # Score Open Graph
        og_score = self._score_og(metadata)
        
        # Score Twitter
        twitter_score = self._score_twitter(metadata)
        
        # Score Schema
        schema_score = 100.0 if metadata.schema_markup else 0.0
        
        # Overall score (promedio ponderado)
        overall_score = (
            title_score * 0.25 +
            description_score * 0.25 +
            keywords_score * 0.15 +
            og_score * 0.15 +
            twitter_score * 0.10 +
            schema_score * 0.10
        )
        
        return SEOScore(
            overall_score=overall_score,
            title_score=title_score,
            description_score=description_score,
            keywords_score=keywords_score,
            og_score=og_score,
            twitter_score=twitter_score,
            schema_score=schema_score
        )
    
    def _score_title(self, title: str) -> float:
        """Scorea title"""
        
        score = 0.0
        min_len, max_len = self.optimal_lengths['title']
        
        length = len(title)
        if min_len <= length <= max_len:
            score += 50
        elif length < min_len:
            score += (length / min_len) * 50
        else:
            score += max(0, 50 - (length - max_len) * 2)
        
        # Keywords al inicio (mejor SEO)
        if len(title.split()) > 0:
            first_word = title.split()[0]
            if len(first_word) > 3:
                score += 25
        
        # Sin palabras stop
        stop_words = ['el', 'la', 'los', 'las', 'un', 'una']
        if not any(title.lower().startswith(sw) for sw in stop_words):
            score += 25
        
        return min(100, score)
    
    def _score_description(self, description: str) -> float:
        """Scorea description"""
        
        score = 0.0
        min_len, max_len = self.optimal_lengths['description']
        
        length = len(description)
        if min_len <= length <= max_len:
            score += 60
        elif length < min_len:
            score += (length / min_len) * 60
        else:
            score += max(0, 60 - (length - max_len) * 2)
        
        # Call to action impl√≠cito
        cta_words = ['descubre', 'aprende', 'comienza', 'obt√©n', 'consigue']
        if any(word in description.lower() for word in cta_words):
            score += 20
        
        # N√∫meros o datos espec√≠ficos
        if any(char.isdigit() for char in description):
            score += 20
        
        return min(100, score)
    
    def _score_keywords(self, keywords: List[str]) -> float:
        """Scorea keywords"""
        
        if not keywords:
            return 0.0
        
        score = min(100, len(keywords) * 10)
        
        # Variedad de keywords
        unique_chars = set(''.join(keywords))
        if len(unique_chars) > 10:
            score += 20
        
        return min(100, score)
    
    def _score_og(self, metadata: SEOMetadata) -> float:
        """Scorea Open Graph"""
        
        score = 0.0
        
        if metadata.og_title:
            score += 40
        
        if metadata.og_description:
            score += 40
        
        if metadata.og_image:
            score += 20
        
        return score
    
    def _score_twitter(self, metadata: SEOMetadata) -> float:
        """Scorea Twitter Cards"""
        
        score = 0.0
        
        if metadata.twitter_title:
            score += 40
        
        if metadata.twitter_description:
            score += 40
        
        if metadata.twitter_card:
            score += 20
        
        return score
    
    def generate_html_meta_tags(self, metadata: SEOMetadata) -> str:
        """Genera HTML con meta tags"""
        
        html_lines = []
        
        # Basic meta
        html_lines.append(f'<meta name="description" content="{metadata.description}">')
        html_lines.append(f'<meta name="keywords" content="{", ".join(metadata.keywords)}">')
        
        # Open Graph
        html_lines.append(f'<meta property="og:title" content="{metadata.og_title}">')
        html_lines.append(f'<meta property="og:description" content="{metadata.og_description}">')
        html_lines.append(f'<meta property="og:image" content="{metadata.og_image}">')
        html_lines.append('<meta property="og:type" content="website">')
        
        # Twitter Cards
        html_lines.append(f'<meta name="twitter:card" content="{metadata.twitter_card}">')
        html_lines.append(f'<meta name="twitter:title" content="{metadata.twitter_title}">')
        html_lines.append(f'<meta name="twitter:description" content="{metadata.twitter_description}">')
        
        # Schema.org
        html_lines.append(f'<script type="application/ld+json">{json.dumps(metadata.schema_markup)}</script>')
        
        return '\n'.join(html_lines)

if __name__ == '__main__':
    manager = AdvancedMetadataSEOManager()
    
    # Generar metadatos
    carousel_data = {
        'product': 'Curso IA',
        'headline': 'Aprende IA Aplicada',
        'subheadline': 'Transforma tu carrera con inteligencia artificial',
        'topic': 'Inteligencia Artificial',
        'benefits': ['Certificado', 'Acceso de por vida', 'Soporte']
    }
    
    metadata = manager.generate_seo_metadata('curso_ia_1', carousel_data)
    
    print(f"Metadatos SEO generados:")
    print(f"  Title: {metadata.title}")
    print(f"  Description: {metadata.description}")
    print(f"  Keywords: {metadata.keywords}")
    
    # Validar
    score = manager.validate_seo_metadata(metadata)
    print(f"\nScore SEO: {score.overall_score:.1f}/100")
    
    # HTML tags
    html = manager.generate_html_meta_tags(metadata)
    print(f"\nMeta tags HTML ({len(html)} caracteres)")
```

---

## üéØ Sistema de Generaci√≥n Autom√°tica de Variantes A/B

### Script de Generaci√≥n Inteligente de Variantes

**Python**: `scripts/auto_ab_variant_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de variantes A/B
- Generaci√≥n inteligente de variantes
- Variaci√≥n de elementos clave (headline, CTA, visual)
- Combinaciones autom√°ticas
- Scoring predictivo de variantes
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import itertools

@dataclass
class ABVariant:
    """Variante A/B"""
    variant_id: str
    base_carousel_id: str
    variant_type: str  # headline, cta, visual, combination
    changes: Dict
    predicted_ctr: float
    predicted_conversion: float

class AutoABVariantGenerator:
    """Generador autom√°tico de variantes A/B"""
    
    def __init__(self):
        self.variants = {}
        self.variant_templates = {
            'headline': {
                'emotional': ['Transforma', 'Revoluciona', 'Libera', 'Potencia'],
                'benefit': ['Aprende', 'Descubre', 'Domina', 'Conquista'],
                'urgency': ['Solo hoy', '√öltima oportunidad', 'No te pierdas', 'Ahora']
            },
            'cta': {
                'direct': ['√önete ahora', 'Comienza ya', 'Accede gratis'],
                'curiosity': ['Descubre c√≥mo', 'Aprende m√°s', 'Explora'],
                'urgency': ['No esperes m√°s', 'Ap√∫ntate ya', 'Cons√≠guelo ahora']
            }
        }
    
    def generate_variants(self, base_carousel_id: str, base_data: Dict,
                         variant_types: List[str], count: int = 5) -> List[ABVariant]:
        """Genera variantes A/B"""
        
        variants = []
        
        for variant_type in variant_types:
            if variant_type == 'headline':
                headline_variants = self._generate_headline_variants(base_data, count)
                variants.extend(headline_variants)
            elif variant_type == 'cta':
                cta_variants = self._generate_cta_variants(base_data, count)
                variants.extend(cta_variants)
            elif variant_type == 'visual':
                visual_variants = self._generate_visual_variants(base_data, count)
                variants.extend(visual_variants)
            elif variant_type == 'combination':
                combo_variants = self._generate_combination_variants(base_data, count)
                variants.extend(combo_variants)
        
        # Predecir performance
        for variant in variants:
            variant.predicted_ctr = self._predict_ctr(variant, base_data)
            variant.predicted_conversion = self._predict_conversion(variant, base_data)
        
        # Ordenar por predicted performance
        variants.sort(key=lambda v: v.predicted_ctr + v.predicted_conversion, reverse=True)
        
        return variants[:count]
    
    def _generate_headline_variants(self, base_data: Dict, count: int) -> List[ABVariant]:
        """Genera variantes de headline"""
        
        variants = []
        base_headline = base_data.get('headline', '')
        
        templates = self.variant_templates['headline']
        
        for i, (style, words) in enumerate(templates.items()):
            if i >= count:
                break
            
            new_headline = f"{words[0]} {base_headline.split()[-1] if base_headline else 'tu carrera'}"
            
            variant = ABVariant(
                variant_id=f"headline_{i}_{datetime.now().timestamp()}",
                base_carousel_id=base_data.get('carousel_id', ''),
                variant_type='headline',
                changes={'headline': new_headline, 'style': style},
                predicted_ctr=0.0,
                predicted_conversion=0.0
            )
            
            variants.append(variant)
        
        return variants
    
    def _generate_cta_variants(self, base_data: Dict, count: int) -> List[ABVariant]:
        """Genera variantes de CTA"""
        
        variants = []
        templates = self.variant_templates['cta']
        
        for i, (style, ctas) in enumerate(templates.items()):
            if i >= count:
                break
            
            new_cta = ctas[0]
            
            variant = ABVariant(
                variant_id=f"cta_{i}_{datetime.now().timestamp()}",
                base_carousel_id=base_data.get('carousel_id', ''),
                variant_type='cta',
                changes={'cta': new_cta, 'style': style},
                predicted_ctr=0.0,
                predicted_conversion=0.0
            )
            
            variants.append(variant)
        
        return variants
    
    def _generate_visual_variants(self, base_data: Dict, count: int) -> List[ABVariant]:
        """Genera variantes visuales"""
        
        variants = []
        visual_styles = ['minimalist', 'bold', 'gradient', 'illustrated', 'photographic']
        
        for i, style in enumerate(visual_styles[:count]):
            variant = ABVariant(
                variant_id=f"visual_{i}_{datetime.now().timestamp()}",
                base_carousel_id=base_data.get('carousel_id', ''),
                variant_type='visual',
                changes={'visual_style': style},
                predicted_ctr=0.0,
                predicted_conversion=0.0
            )
            
            variants.append(variant)
        
        return variants
    
    def _generate_combination_variants(self, base_data: Dict, count: int) -> List[ABVariant]:
        """Genera variantes combinadas"""
        
        variants = []
        
        # Combinar headline + CTA
        headline_styles = list(self.variant_templates['headline'].keys())
        cta_styles = list(self.variant_templates['cta'].keys())
        
        combinations = list(itertools.product(headline_styles, cta_styles))[:count]
        
        for i, (headline_style, cta_style) in enumerate(combinations):
            variant = ABVariant(
                variant_id=f"combo_{i}_{datetime.now().timestamp()}",
                base_carousel_id=base_data.get('carousel_id', ''),
                variant_type='combination',
                changes={
                    'headline_style': headline_style,
                    'cta_style': cta_style
                },
                predicted_ctr=0.0,
                predicted_conversion=0.0
            )
            
            variants.append(variant)
        
        return variants
    
    def _predict_ctr(self, variant: ABVariant, base_data: Dict) -> float:
        """Predice CTR de variante"""
        
        base_ctr = base_data.get('historical_ctr', 3.0)
        
        # Ajustes seg√∫n tipo de variante
        if variant.variant_type == 'headline':
            style = variant.changes.get('style', '')
            multipliers = {
                'emotional': 1.2,
                'benefit': 1.1,
                'urgency': 1.15
            }
            multiplier = multipliers.get(style, 1.0)
            return base_ctr * multiplier
        
        elif variant.variant_type == 'cta':
            style = variant.changes.get('style', '')
            multipliers = {
                'direct': 1.1,
                'curiosity': 1.05,
                'urgency': 1.15
            }
            multiplier = multipliers.get(style, 1.0)
            return base_ctr * multiplier
        
        elif variant.variant_type == 'combination':
            # Combinar multiplicadores
            headline_mult = 1.1 if variant.changes.get('headline_style') == 'emotional' else 1.0
            cta_mult = 1.1 if variant.changes.get('cta_style') == 'urgency' else 1.0
            return base_ctr * headline_mult * cta_mult
        
        return base_ctr
    
    def _predict_conversion(self, variant: ABVariant, base_data: Dict) -> float:
        """Predice tasa de conversi√≥n"""
        
        base_conversion = base_data.get('historical_conversion', 5.0)
        
        # Similar a CTR pero con diferentes multiplicadores
        if variant.variant_type == 'cta':
            style = variant.changes.get('style', '')
            multipliers = {
                'direct': 1.2,
                'curiosity': 1.1,
                'urgency': 1.25
            }
            multiplier = multipliers.get(style, 1.0)
            return base_conversion * multiplier
        
        return base_conversion
    
    def recommend_top_variants(self, variants: List[ABVariant], top_n: int = 3) -> List[ABVariant]:
        """Recomienda mejores variantes"""
        
        # Ordenar por predicted performance
        sorted_variants = sorted(
            variants,
            key=lambda v: v.predicted_ctr + v.predicted_conversion,
            reverse=True
        )
        
        return sorted_variants[:top_n]
    
    def generate_ab_test_plan(self, base_carousel_id: str, variants: List[ABVariant]) -> Dict:
        """Genera plan de A/B testing"""
        
        return {
            'base_carousel_id': base_carousel_id,
            'total_variants': len(variants),
            'test_duration_days': 7,
            'traffic_split': {
                'base': 50,
                'variants': {v.variant_id: 50 / len(variants) for v in variants}
            },
            'success_metrics': ['ctr', 'conversion_rate', 'engagement_rate'],
            'minimum_sample_size': 1000,
            'variants': [
                {
                    'variant_id': v.variant_id,
                    'variant_type': v.variant_type,
                    'changes': v.changes,
                    'predicted_ctr': v.predicted_ctr,
                    'predicted_conversion': v.predicted_conversion
                }
                for v in variants
            ]
        }

if __name__ == '__main__':
    generator = AutoABVariantGenerator()
    
    # Datos base
    base_data = {
        'carousel_id': 'curso_ia_1',
        'headline': 'Aprende IA Aplicada',
        'cta': 'Comienza ahora',
        'historical_ctr': 4.5,
        'historical_conversion': 6.0
    }
    
    # Generar variantes
    variants = generator.generate_variants(
        'curso_ia_1',
        base_data,
        ['headline', 'cta', 'combination'],
        count=6
    )
    
    print(f"Variantes generadas: {len(variants)}")
    
    # Recomendar mejores
    top_variants = generator.recommend_top_variants(variants, top_n=3)
    print(f"\nTop 3 variantes recomendadas:")
    for v in top_variants:
        print(f"  {v.variant_id}: CTR predicho {v.predicted_ctr:.2f}%, Conversi√≥n {v.predicted_conversion:.2f}%")
    
    # Plan de testing
    plan = generator.generate_ab_test_plan('curso_ia_1', variants)
    print(f"\nPlan de A/B testing:")
    print(f"  Duraci√≥n: {plan['test_duration_days']} d√≠as")
    print(f"  Variantes: {plan['total_variants']}")
```

---

## üìä Sistema de Monitoreo de Performance y Alertas Inteligentes

### Script de Monitoreo y Alertas

**Python**: `scripts/intelligent_performance_monitoring.py`

```python
#!/usr/bin/env python3
"""
Sistema de monitoreo de performance y alertas inteligentes
- Monitoreo en tiempo real de m√©tricas
- Alertas predictivas
- Detecci√≥n de anomal√≠as
- Notificaciones multi-canal
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class AlertSeverity(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

@dataclass
class PerformanceAlert:
    """Alerta de performance"""
    alert_id: str
    carousel_id: str
    metric: str
    current_value: float
    threshold: float
    severity: AlertSeverity
    message: str
    timestamp: datetime
    recommended_action: str

class IntelligentPerformanceMonitoring:
    """Sistema de monitoreo inteligente"""
    
    def __init__(self):
        self.alerts = []
        self.metrics_history = {}
        self.thresholds = {
            'ctr': {'critical': 1.0, 'high': 2.0, 'medium': 3.0},
            'conversion_rate': {'critical': 1.0, 'high': 2.0, 'medium': 3.0},
            'engagement_rate': {'critical': 2.0, 'high': 4.0, 'medium': 6.0},
            'cost_per_click': {'critical': 5.0, 'high': 3.0, 'medium': 2.0},
            'roas': {'critical': 1.0, 'high': 2.0, 'medium': 3.0}
        }
    
    def monitor_carousel(self, carousel_id: str, metrics: Dict) -> List[PerformanceAlert]:
        """Monitorea m√©tricas de carrusel"""
        
        alerts = []
        
        # Monitorear cada m√©trica
        for metric_name, value in metrics.items():
            if metric_name in self.thresholds:
                metric_alerts = self._check_metric_thresholds(
                    carousel_id, metric_name, value
                )
                alerts.extend(metric_alerts)
        
        # Detectar anomal√≠as
        anomaly_alerts = self._detect_anomalies(carousel_id, metrics)
        alerts.extend(anomaly_alerts)
        
        # Predecir problemas futuros
        predictive_alerts = self._predict_future_issues(carousel_id, metrics)
        alerts.extend(predictive_alerts)
        
        self.alerts.extend(alerts)
        
        return alerts
    
    def _check_metric_thresholds(self, carousel_id: str, metric: str,
                                 value: float) -> List[PerformanceAlert]:
        """Verifica umbrales de m√©trica"""
        
        alerts = []
        thresholds = self.thresholds.get(metric, {})
        
        # Determinar severidad basada en umbrales
        if metric in ['ctr', 'conversion_rate', 'engagement_rate', 'roas']:
            # M√©tricas donde valores bajos son malos
            if value <= thresholds.get('critical', 0):
                severity = AlertSeverity.CRITICAL
            elif value <= thresholds.get('high', 0):
                severity = AlertSeverity.HIGH
            elif value <= thresholds.get('medium', 0):
                severity = AlertSeverity.MEDIUM
            else:
                return alerts  # No alerta si est√° bien
        else:
            # M√©tricas donde valores altos son malos (ej: cost_per_click)
            if value >= thresholds.get('critical', float('inf')):
                severity = AlertSeverity.CRITICAL
            elif value >= thresholds.get('high', float('inf')):
                severity = AlertSeverity.HIGH
            elif value >= thresholds.get('medium', float('inf')):
                severity = AlertSeverity.MEDIUM
            else:
                return alerts
        
        alert = PerformanceAlert(
            alert_id=f"alert_{datetime.now().timestamp()}",
            carousel_id=carousel_id,
            metric=metric,
            current_value=value,
            threshold=thresholds.get('medium', 0),
            severity=severity,
            message=self._generate_alert_message(metric, value, severity),
            timestamp=datetime.now(),
            recommended_action=self._generate_recommended_action(metric, severity)
        )
        
        alerts.append(alert)
        
        return alerts
    
    def _detect_anomalies(self, carousel_id: str, current_metrics: Dict) -> List[PerformanceAlert]:
        """Detecta anomal√≠as en m√©tricas"""
        
        alerts = []
        
        # Obtener historial
        if carousel_id not in self.metrics_history:
            self.metrics_history[carousel_id] = []
        
        history = self.metrics_history[carousel_id]
        
        if len(history) < 3:
            return alerts  # No hay suficiente historial
        
        # Calcular promedio y desviaci√≥n est√°ndar
        for metric_name, current_value in current_metrics.items():
            historical_values = [
                m.get(metric_name, 0) for m in history[-7:]  # √öltimos 7 d√≠as
                if metric_name in m
            ]
            
            if len(historical_values) < 3:
                continue
            
            avg = sum(historical_values) / len(historical_values)
            std_dev = (
                sum((x - avg) ** 2 for x in historical_values) / len(historical_values)
            ) ** 0.5
            
            # Detectar si est√° fuera de 2 desviaciones est√°ndar
            z_score = abs((current_value - avg) / std_dev) if std_dev > 0 else 0
            
            if z_score > 2:
                alerts.append(PerformanceAlert(
                    alert_id=f"anomaly_{datetime.now().timestamp()}",
                    carousel_id=carousel_id,
                    metric=metric_name,
                    current_value=current_value,
                    threshold=avg,
                    severity=AlertSeverity.HIGH if z_score > 3 else AlertSeverity.MEDIUM,
                    message=f"Anomal√≠a detectada en {metric_name}: {current_value:.2f} vs promedio {avg:.2f}",
                    timestamp=datetime.now(),
                    recommended_action=f"Investigar causa de variaci√≥n en {metric_name}"
                ))
        
        # Actualizar historial
        history.append(current_metrics.copy())
        
        return alerts
    
    def _predict_future_issues(self, carousel_id: str, current_metrics: Dict) -> List[PerformanceAlert]:
        """Predice problemas futuros"""
        
        alerts = []
        
        # Obtener historial
        if carousel_id not in self.metrics_history:
            return alerts
        
        history = self.metrics_history[carousel_id]
        
        if len(history) < 5:
            return alerts
        
        # Analizar tendencias
        for metric_name, current_value in current_metrics.items():
            historical_values = [
                m.get(metric_name, 0) for m in history[-5:]
                if metric_name in m
            ]
            
            if len(historical_values) < 3:
                continue
            
            # Calcular tendencia (regresi√≥n simple)
            trend = self._calculate_trend(historical_values)
            
            # Si la tendencia es negativa y significativa
            if trend < -0.1 and metric_name in ['ctr', 'conversion_rate', 'engagement_rate']:
                alerts.append(PerformanceAlert(
                    alert_id=f"predictive_{datetime.now().timestamp()}",
                    carousel_id=carousel_id,
                    metric=metric_name,
                    current_value=current_value,
                    threshold=historical_values[0],
                    severity=AlertSeverity.MEDIUM,
                    message=f"Tendencia negativa detectada en {metric_name}. Predicci√≥n: continuar√° bajando.",
                    timestamp=datetime.now(),
                    recommended_action=f"Revisar {metric_name} y considerar crear nueva variante"
                ))
        
        return alerts
    
    def _calculate_trend(self, values: List[float]) -> float:
        """Calcula tendencia (pendiente)"""
        
        n = len(values)
        x = list(range(n))
        x_mean = sum(x) / n
        y_mean = sum(values) / n
        
        numerator = sum((x[i] - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
        
        if denominator == 0:
            return 0.0
        
        slope = numerator / denominator
        
        return slope
    
    def _generate_alert_message(self, metric: str, value: float,
                               severity: AlertSeverity) -> str:
        """Genera mensaje de alerta"""
        
        severity_text = {
            AlertSeverity.CRITICAL: "CR√çTICO",
            AlertSeverity.HIGH: "ALTO",
            AlertSeverity.MEDIUM: "MEDIO",
            AlertSeverity.LOW: "BAJO"
        }
        
        return f"[{severity_text[severity]}] {metric.upper()}: {value:.2f}"
    
    def _generate_recommended_action(self, metric: str, severity: AlertSeverity) -> str:
        """Genera acci√≥n recomendada"""
        
        actions = {
            'ctr': {
                AlertSeverity.CRITICAL: "Pausar carrusel y revisar targeting/creatividad inmediatamente",
                AlertSeverity.HIGH: "Revisar headline y visual, considerar A/B testing",
                AlertSeverity.MEDIUM: "Monitorear de cerca y optimizar creatividad"
            },
            'conversion_rate': {
                AlertSeverity.CRITICAL: "Revisar landing page y experiencia de usuario",
                AlertSeverity.HIGH: "Optimizar CTA y mensaje de conversi√≥n",
                AlertSeverity.MEDIUM: "Mejorar relevancia de oferta"
            },
            'engagement_rate': {
                AlertSeverity.CRITICAL: "Revisar contenido y relevancia para audiencia",
                AlertSeverity.HIGH: "Mejorar copy y visual, aumentar interactividad",
                AlertSeverity.MEDIUM: "Refinar mensaje y timing de publicaci√≥n"
            }
        }
        
        metric_actions = actions.get(metric, {})
        return metric_actions.get(severity, "Revisar m√©trica y tomar acci√≥n correctiva")
    
    def get_critical_alerts(self, hours: int = 24) -> List[PerformanceAlert]:
        """Obtiene alertas cr√≠ticas de √∫ltimas horas"""
        
        cutoff = datetime.now() - timedelta(hours=hours)
        
        return [
            alert for alert in self.alerts
            if alert.timestamp >= cutoff and alert.severity == AlertSeverity.CRITICAL
        ]
    
    def generate_monitoring_report(self, carousel_id: str) -> Dict:
        """Genera reporte de monitoreo"""
        
        carousel_alerts = [
            alert for alert in self.alerts
            if alert.carousel_id == carousel_id
        ]
        
        return {
            'carousel_id': carousel_id,
            'total_alerts': len(carousel_alerts),
            'critical_alerts': len([a for a in carousel_alerts if a.severity == AlertSeverity.CRITICAL]),
            'high_alerts': len([a for a in carousel_alerts if a.severity == AlertSeverity.HIGH]),
            'recent_alerts': [
                {
                    'metric': a.metric,
                    'value': a.current_value,
                    'severity': a.severity.value,
                    'message': a.message,
                    'recommended_action': a.recommended_action
                }
                for a in sorted(carousel_alerts, key=lambda x: x.timestamp, reverse=True)[:10]
            ]
        }

if __name__ == '__main__':
    monitor = IntelligentPerformanceMonitoring()
    
    # Monitorear carrusel
    metrics = {
        'ctr': 1.5,  # Bajo
        'conversion_rate': 2.5,  # Medio-bajo
        'engagement_rate': 5.0,  # OK
        'cost_per_click': 4.5,  # Alto
        'roas': 2.5  # OK
    }
    
    alerts = monitor.monitor_carousel('curso_ia_1', metrics)
    
    print(f"Alertas generadas: {len(alerts)}")
    for alert in alerts:
        print(f"  [{alert.severity.value}] {alert.metric}: {alert.message}")
        print(f"    Acci√≥n: {alert.recommended_action}")
    
    # Reporte
    report = monitor.generate_monitoring_report('curso_ia_1')
    print(f"\nReporte de monitoreo:")
    print(f"  Total alertas: {report['total_alerts']}")
    print(f"  Cr√≠ticas: {report['critical_alerts']}")
```

---

## üìÖ Sistema de Calendarizaci√≥n Inteligente y Publicaci√≥n Autom√°tica

### Script de Scheduling Avanzado

**Python**: `scripts/intelligent_scheduling_automation.py`

```python
#!/usr/bin/env python3
"""
Sistema de calendarizaci√≥n inteligente y publicaci√≥n autom√°tica
- Optimizaci√≥n de timing basada en engagement hist√≥rico
- Calendarizaci√≥n multi-plataforma
- Detecci√≥n de conflictos
- Publicaci√≥n autom√°tica programada
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta, time
from enum import Enum
import json

class Platform(Enum):
    INSTAGRAM = "instagram"
    LINKEDIN = "linkedin"
    FACEBOOK = "facebook"
    TWITTER = "twitter"
    TIKTOK = "tiktok"

@dataclass
class ScheduledPost:
    """Post programado"""
    post_id: str
    carousel_id: str
    platform: Platform
    scheduled_time: datetime
    content: Dict
    status: str  # scheduled, published, failed, cancelled

class IntelligentSchedulingAutomation:
    """Sistema de calendarizaci√≥n inteligente"""
    
    def __init__(self):
        self.scheduled_posts = []
        self.optimal_times = {
            Platform.INSTAGRAM: [
                {'day': 'tuesday', 'time': time(11, 0), 'engagement': 0.85},
                {'day': 'wednesday', 'time': time(11, 0), 'engagement': 0.88},
                {'day': 'thursday', 'time': time(11, 0), 'engagement': 0.82},
                {'day': 'friday', 'time': time(13, 0), 'engagement': 0.80}
            ],
            Platform.LINKEDIN: [
                {'day': 'tuesday', 'time': time(8, 0), 'engagement': 0.90},
                {'day': 'wednesday', 'time': time(8, 0), 'engagement': 0.92},
                {'day': 'thursday', 'time': time(8, 0), 'engagement': 0.88},
                {'day': 'tuesday', 'time': time(12, 0), 'engagement': 0.85}
            ],
            Platform.FACEBOOK: [
                {'day': 'tuesday', 'time': time(9, 0), 'engagement': 0.82},
                {'day': 'wednesday', 'time': time(9, 0), 'engagement': 0.85},
                {'day': 'thursday', 'time': time(9, 0), 'engagement': 0.80}
            ],
            Platform.TWITTER: [
                {'day': 'monday', 'time': time(9, 0), 'engagement': 0.75},
                {'day': 'tuesday', 'time': time(9, 0), 'engagement': 0.78},
                {'day': 'wednesday', 'time': time(9, 0), 'engagement': 0.80},
                {'day': 'thursday', 'time': time(9, 0), 'engagement': 0.77},
                {'day': 'friday', 'time': time(9, 0), 'engagement': 0.72}
            ]
        }
    
    def schedule_carousel(self, carousel_id: str, platforms: List[Platform],
                         preferred_date: Optional[datetime] = None,
                         optimize_timing: bool = True) -> List[ScheduledPost]:
        """Programa carrusel en m√∫ltiples plataformas"""
        
        scheduled = []
        
        for platform in platforms:
            if optimize_timing:
                optimal_time = self._find_optimal_time(platform, preferred_date)
            else:
                optimal_time = preferred_date or datetime.now() + timedelta(hours=1)
            
            post = ScheduledPost(
                post_id=f"post_{datetime.now().timestamp()}_{platform.value}",
                carousel_id=carousel_id,
                platform=platform,
                scheduled_time=optimal_time,
                content={'carousel_id': carousel_id},
                status='scheduled'
            )
            
            scheduled.append(post)
            self.scheduled_posts.append(post)
        
        return scheduled
    
    def _find_optimal_time(self, platform: Platform,
                          preferred_date: Optional[datetime] = None) -> datetime:
        """Encuentra tiempo √≥ptimo para publicaci√≥n"""
        
        if preferred_date:
            base_date = preferred_date
        else:
            base_date = datetime.now() + timedelta(days=1)
        
        # Obtener tiempos √≥ptimos para plataforma
        optimal_slots = self.optimal_times.get(platform, [])
        
        if not optimal_slots:
            return base_date.replace(hour=10, minute=0)
        
        # Encontrar slot m√°s cercano
        day_name = base_date.strftime('%A').lower()
        
        # Buscar slot para el d√≠a preferido
        matching_slots = [s for s in optimal_slots if s['day'] == day_name]
        
        if matching_slots:
            # Usar slot con mayor engagement
            best_slot = max(matching_slots, key=lambda x: x['engagement'])
            scheduled_time = base_date.replace(
                hour=best_slot['time'].hour,
                minute=best_slot['time'].minute
            )
        else:
            # Buscar siguiente d√≠a con slot disponible
            for days_ahead in range(7):
                check_date = base_date + timedelta(days=days_ahead)
                day_name = check_date.strftime('%A').lower()
                matching_slots = [s for s in optimal_slots if s['day'] == day_name]
                
                if matching_slots:
                    best_slot = max(matching_slots, key=lambda x: x['engagement'])
                    scheduled_time = check_date.replace(
                        hour=best_slot['time'].hour,
                        minute=best_slot['time'].minute
                    )
                    break
            else:
                # Fallback
                scheduled_time = base_date.replace(hour=10, minute=0)
        
        return scheduled_time
    
    def detect_scheduling_conflicts(self, new_post: ScheduledPost,
                                   window_minutes: int = 60) -> List[ScheduledPost]:
        """Detecta conflictos de calendarizaci√≥n"""
        
        conflicts = []
        
        for existing_post in self.scheduled_posts:
            if existing_post.status != 'scheduled':
                continue
            
            if existing_post.platform != new_post.platform:
                continue
            
            time_diff = abs((existing_post.scheduled_time - new_post.scheduled_time).total_seconds() / 60)
            
            if time_diff < window_minutes:
                conflicts.append(existing_post)
        
        return conflicts
    
    def optimize_schedule(self, platform: Platform, posts: List[ScheduledPost]) -> List[ScheduledPost]:
        """Optimiza calendario de posts"""
        
        optimized = []
        
        for post in posts:
            optimal_time = self._find_optimal_time(platform, post.scheduled_time)
            post.scheduled_time = optimal_time
            optimized.append(post)
        
        return optimized
    
    def get_upcoming_posts(self, hours: int = 24) -> List[ScheduledPost]:
        """Obtiene posts pr√≥ximos"""
        
        cutoff = datetime.now() + timedelta(hours=hours)
        
        return [
            post for post in self.scheduled_posts
            if post.status == 'scheduled' and post.scheduled_time <= cutoff
        ]
    
    def generate_schedule_report(self, start_date: datetime,
                                end_date: datetime) -> Dict:
        """Genera reporte de calendario"""
        
        posts_in_range = [
            post for post in self.scheduled_posts
            if start_date <= post.scheduled_time <= end_date
        ]
        
        by_platform = {}
        for post in posts_in_range:
            platform = post.platform.value
            if platform not in by_platform:
                by_platform[platform] = []
            by_platform[platform].append(post)
        
        return {
            'period': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat()
            },
            'total_posts': len(posts_in_range),
            'posts_by_platform': {
                platform: len(posts)
                for platform, posts in by_platform.items()
            },
            'scheduled_posts': [
                {
                    'post_id': post.post_id,
                    'platform': post.platform.value,
                    'scheduled_time': post.scheduled_time.isoformat(),
                    'carousel_id': post.carousel_id
                }
                for post in sorted(posts_in_range, key=lambda x: x.scheduled_time)
            ]
        }

if __name__ == '__main__':
    scheduler = IntelligentSchedulingAutomation()
    
    # Programar carrusel
    scheduled = scheduler.schedule_carousel(
        'curso_ia_1',
        [Platform.INSTAGRAM, Platform.LINKEDIN],
        optimize_timing=True
    )
    
    print(f"Posts programados: {len(scheduled)}")
    for post in scheduled:
        print(f"  {post.platform.value}: {post.scheduled_time.strftime('%Y-%m-%d %H:%M')}")
    
    # Reporte
    start = datetime.now()
    end = datetime.now() + timedelta(days=7)
    report = scheduler.generate_schedule_report(start, end)
    print(f"\nReporte de calendario:")
    print(f"  Total posts: {report['total_posts']}")
```

---

## üöÄ Sistema de Publicaci√≥n Multi-Plataforma Automatizada

### Script de Publicaci√≥n Autom√°tica

**Python**: `scripts/automated_multi_platform_publisher.py`

```python
#!/usr/bin/env python3
"""
Sistema de publicaci√≥n multi-plataforma automatizada
- Publicaci√≥n simult√°nea en m√∫ltiples plataformas
- Adaptaci√≥n autom√°tica de contenido por plataforma
- Manejo de errores y reintentos
- Tracking de estado de publicaci√≥n
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class PublishStatus(Enum):
    PENDING = "pending"
    PUBLISHING = "publishing"
    SUCCESS = "success"
    FAILED = "failed"
    RETRYING = "retrying"

@dataclass
class PublishResult:
    """Resultado de publicaci√≥n"""
    platform: str
    status: PublishStatus
    post_id: Optional[str]
    url: Optional[str]
    error: Optional[str]
    published_at: Optional[datetime]

class AutomatedMultiPlatformPublisher:
    """Publicador multi-plataforma automatizado"""
    
    def __init__(self):
        self.publish_history = []
        self.platform_adapters = {
            'instagram': self._adapt_for_instagram,
            'linkedin': self._adapt_for_linkedin,
            'facebook': self._adapt_for_facebook,
            'twitter': self._adapt_for_twitter,
            'tiktok': self._adapt_for_tiktok
        }
    
    def publish_carousel(self, carousel_id: str, carousel_data: Dict,
                        platforms: List[str], publish_now: bool = True) -> List[PublishResult]:
        """Publica carrusel en m√∫ltiples plataformas"""
        
        results = []
        
        for platform in platforms:
            # Adaptar contenido para plataforma
            adapted_content = self._adapt_content(platform, carousel_data)
            
            # Publicar
            if publish_now:
                result = self._publish_to_platform(platform, adapted_content, carousel_id)
            else:
                result = PublishResult(
                    platform=platform,
                    status=PublishStatus.PENDING,
                    post_id=None,
                    url=None,
                    error=None,
                    published_at=None
                )
            
            results.append(result)
            self.publish_history.append({
                'carousel_id': carousel_id,
                'platform': platform,
                'result': result,
                'timestamp': datetime.now().isoformat()
            })
        
        return results
    
    def _adapt_content(self, platform: str, content: Dict) -> Dict:
        """Adapta contenido para plataforma"""
        
        adapter = self.platform_adapters.get(platform)
        if adapter:
            return adapter(content)
        
        return content
    
    def _adapt_for_instagram(self, content: Dict) -> Dict:
        """Adapta para Instagram"""
        adapted = content.copy()
        
        # Instagram: m√°ximo 2200 caracteres, hasta 30 hashtags
        if 'caption' in adapted:
            adapted['caption'] = adapted['caption'][:2200]
        
        if 'hashtags' in adapted:
            adapted['hashtags'] = adapted['hashtags'][:30]
        
        adapted['format'] = 'square'  # 1080x1080
        adapted['aspect_ratio'] = '1:1'
        
        return adapted
    
    def _adapt_for_linkedin(self, content: Dict) -> Dict:
        """Adapta para LinkedIn"""
        adapted = content.copy()
        
        # LinkedIn: m√°ximo 3000 caracteres, hasta 5 hashtags recomendado
        if 'caption' in adapted:
            adapted['caption'] = adapted['caption'][:3000]
        
        if 'hashtags' in adapted:
            adapted['hashtags'] = adapted['hashtags'][:5]
        
        adapted['format'] = 'square'  # 1080x1080 o landscape
        adapted['tone'] = 'professional'
        
        return adapted
    
    def _adapt_for_facebook(self, content: Dict) -> Dict:
        """Adapta para Facebook"""
        adapted = content.copy()
        
        # Facebook: flexible, pero optimizado para engagement
        if 'hashtags' in adapted:
            adapted['hashtags'] = adapted['hashtags'][:10]
        
        adapted['format'] = 'square'
        
        return adapted
    
    def _adapt_for_twitter(self, content: Dict) -> Dict:
        """Adapta para Twitter"""
        adapted = content.copy()
        
        # Twitter: 280 caracteres, hasta 2 hashtags recomendado
        if 'caption' in adapted:
            adapted['text'] = adapted['caption'][:280]
            del adapted['caption']
        
        if 'hashtags' in adapted:
            adapted['hashtags'] = adapted['hashtags'][:2]
        
        adapted['format'] = 'square'
        
        return adapted
    
    def _adapt_for_tiktok(self, content: Dict) -> Dict:
        """Adapta para TikTok"""
        adapted = content.copy()
        
        # TikTok: 2200 caracteres, hashtags estrat√©gicos
        if 'caption' in adapted:
            adapted['caption'] = adapted['caption'][:2200]
        
        if 'hashtags' in adapted:
            adapted['hashtags'] = adapted['hashtags'][:5]
        
        adapted['format'] = 'vertical'  # 1080x1920
        adapted['aspect_ratio'] = '9:16'
        
        return adapted
    
    def _publish_to_platform(self, platform: str, content: Dict,
                            carousel_id: str) -> PublishResult:
        """Publica a plataforma espec√≠fica"""
        
        # En producci√≥n: usar APIs reales de cada plataforma
        # Por ahora: simular publicaci√≥n
        
        try:
            # Simular llamada API
            post_id = f"{platform}_{datetime.now().timestamp()}"
            url = f"https://{platform}.com/posts/{post_id}"
            
            result = PublishResult(
                platform=platform,
                status=PublishStatus.SUCCESS,
                post_id=post_id,
                url=url,
                error=None,
                published_at=datetime.now()
            )
            
            return result
            
        except Exception as e:
            result = PublishResult(
                platform=platform,
                status=PublishStatus.FAILED,
                post_id=None,
                url=None,
                error=str(e),
                published_at=None
            )
            
            return result
    
    def retry_failed_publications(self, max_retries: int = 3) -> List[PublishResult]:
        """Reintenta publicaciones fallidas"""
        
        failed = [
            h for h in self.publish_history
            if h['result'].status == PublishStatus.FAILED
        ]
        
        retried = []
        
        for failed_pub in failed[:max_retries]:
            platform = failed_pub['platform']
            content = failed_pub.get('content', {})
            carousel_id = failed_pub['carousel_id']
            
            result = self._publish_to_platform(platform, content, carousel_id)
            result.status = PublishStatus.RETRYING
            
            retried.append(result)
        
        return retried
    
    def get_publication_status(self, carousel_id: str) -> Dict:
        """Obtiene estado de publicaci√≥n"""
        
        publications = [
            h for h in self.publish_history
            if h['carousel_id'] == carousel_id
        ]
        
        statuses = {
            'success': len([p for p in publications if p['result'].status == PublishStatus.SUCCESS]),
            'failed': len([p for p in publications if p['result'].status == PublishStatus.FAILED]),
            'pending': len([p for p in publications if p['result'].status == PublishStatus.PENDING])
        }
        
        return {
            'carousel_id': carousel_id,
            'total_platforms': len(publications),
            'statuses': statuses,
            'publications': [
                {
                    'platform': p['platform'],
                    'status': p['result'].status.value,
                    'url': p['result'].url,
                    'published_at': p['result'].published_at.isoformat() if p['result'].published_at else None
                }
                for p in publications
            ]
        }

if __name__ == '__main__':
    publisher = AutomatedMultiPlatformPublisher()
    
    # Publicar carrusel
    carousel_data = {
        'caption': 'Aprende IA aplicada y transforma tu carrera',
        'hashtags': ['IA', 'Curso', 'Marketing', 'Tech'],
        'images': ['slide1.png', 'slide2.png']
    }
    
    results = publisher.publish_carousel(
        'curso_ia_1',
        carousel_data,
        ['instagram', 'linkedin', 'facebook'],
        publish_now=True
    )
    
    print(f"Publicaciones realizadas: {len(results)}")
    for result in results:
        print(f"  {result.platform}: {result.status.value}")
        if result.url:
            print(f"    URL: {result.url}")
    
    # Estado
    status = publisher.get_publication_status('curso_ia_1')
    print(f"\nEstado de publicaci√≥n:")
    print(f"  Exitosas: {status['statuses']['success']}")
    print(f"  Fallidas: {status['statuses']['failed']}")
```

---

## üìà Sistema de An√°lisis de Performance Comparativa Multi-Plataforma

### Script de An√°lisis Comparativo

**Python**: `scripts/cross_platform_performance_analyzer.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis de performance comparativa multi-plataforma
- Comparaci√≥n de m√©tricas entre plataformas
- Identificaci√≥n de mejor/worst performing platforms
- Recomendaciones de optimizaci√≥n por plataforma
- Reportes comparativos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class PlatformMetrics:
    """M√©tricas por plataforma"""
    platform: str
    impressions: int
    clicks: int
    engagement: int
    conversions: int
    ctr: float
    engagement_rate: float
    conversion_rate: float
    roas: float
    cost: float

class CrossPlatformPerformanceAnalyzer:
    """Analizador de performance multi-plataforma"""
    
    def __init__(self):
        self.metrics_history = {}
    
    def analyze_cross_platform_performance(self, carousel_id: str,
                                         metrics_by_platform: Dict[str, PlatformMetrics]) -> Dict:
        """Analiza performance comparativa"""
        
        # Calcular promedios
        avg_ctr = sum(m.ctr for m in metrics_by_platform.values()) / len(metrics_by_platform)
        avg_engagement = sum(m.engagement_rate for m in metrics_by_platform.values()) / len(metrics_by_platform)
        avg_conversion = sum(m.conversion_rate for m in metrics_by_platform.values()) / len(metrics_by_platform)
        avg_roas = sum(m.roas for m in metrics_by_platform.values()) / len(metrics_by_platform)
        
        # Identificar mejores y peores
        best_platform = max(metrics_by_platform.items(), key=lambda x: x[1].roas)
        worst_platform = min(metrics_by_platform.items(), key=lambda x: x[1].roas)
        
        # An√°lisis por m√©trica
        best_by_metric = {
            'ctr': max(metrics_by_platform.items(), key=lambda x: x[1].ctr),
            'engagement': max(metrics_by_platform.items(), key=lambda x: x[1].engagement_rate),
            'conversion': max(metrics_by_platform.items(), key=lambda x: x[1].conversion_rate),
            'roas': best_platform
        }
        
        # Generar recomendaciones
        recommendations = self._generate_recommendations(
            metrics_by_platform, avg_ctr, avg_engagement, avg_conversion, avg_roas
        )
        
        analysis = {
            'carousel_id': carousel_id,
            'analysis_date': datetime.now().isoformat(),
            'platforms_analyzed': list(metrics_by_platform.keys()),
            'averages': {
                'ctr': avg_ctr,
                'engagement_rate': avg_engagement,
                'conversion_rate': avg_conversion,
                'roas': avg_roas
            },
            'best_performing': {
                'platform': best_platform[0],
                'roas': best_platform[1].roas,
                'metrics': {
                    'ctr': best_platform[1].ctr,
                    'engagement_rate': best_platform[1].engagement_rate,
                    'conversion_rate': best_platform[1].conversion_rate
                }
            },
            'worst_performing': {
                'platform': worst_platform[0],
                'roas': worst_platform[1].roas,
                'metrics': {
                    'ctr': worst_platform[1].ctr,
                    'engagement_rate': worst_platform[1].engagement_rate,
                    'conversion_rate': worst_platform[1].conversion_rate
                }
            },
            'best_by_metric': {
                metric: {
                    'platform': platform,
                    'value': metrics_by_platform[platform].__dict__[metric if metric != 'engagement' else 'engagement_rate']
                }
                for metric, (platform, _) in best_by_metric.items()
            },
            'recommendations': recommendations,
            'detailed_metrics': {
                platform: {
                    'impressions': m.impressions,
                    'clicks': m.clicks,
                    'engagement': m.engagement,
                    'conversions': m.conversions,
                    'ctr': m.ctr,
                    'engagement_rate': m.engagement_rate,
                    'conversion_rate': m.conversion_rate,
                    'roas': m.roas,
                    'cost': m.cost
                }
                for platform, m in metrics_by_platform.items()
            }
        }
        
        self.metrics_history[carousel_id] = analysis
        
        return analysis
    
    def _generate_recommendations(self, metrics_by_platform: Dict[str, PlatformMetrics],
                                 avg_ctr: float, avg_engagement: float,
                                 avg_conversion: float, avg_roas: float) -> List[str]:
        """Genera recomendaciones"""
        
        recommendations = []
        
        # Analizar cada plataforma
        for platform, metrics in metrics_by_platform.items():
            if metrics.ctr < avg_ctr * 0.8:
                recommendations.append(
                    f"{platform}: CTR {metrics.ctr:.2f}% est√° {((avg_ctr - metrics.ctr) / avg_ctr * 100):.1f}% por debajo del promedio. "
                    f"Revisar targeting y creatividad."
                )
            
            if metrics.engagement_rate < avg_engagement * 0.8:
                recommendations.append(
                    f"{platform}: Engagement rate {metrics.engagement_rate:.2f}% est√° por debajo del promedio. "
                    f"Mejorar copy y timing de publicaci√≥n."
                )
            
            if metrics.conversion_rate < avg_conversion * 0.8:
                recommendations.append(
                    f"{platform}: Conversion rate {metrics.conversion_rate:.2f}% est√° por debajo del promedio. "
                    f"Optimizar CTA y landing page experience."
                )
            
            if metrics.roas > avg_roas * 1.2:
                recommendations.append(
                    f"{platform}: ROAS excelente ({metrics.roas:.2f}). Considerar aumentar budget."
                )
            
            if metrics.roas < avg_roas * 0.8:
                recommendations.append(
                    f"{platform}: ROAS bajo ({metrics.roas:.2f}). Considerar reducir budget o pausar si no mejora."
                )
        
        # Recomendaci√≥n general
        best_platform = max(metrics_by_platform.items(), key=lambda x: x[1].roas)
        worst_platform = min(metrics_by_platform.items(), key=lambda x: x[1].roas)
        
        recommendations.append(
            f"Plataforma estrella: {best_platform[0]} con ROAS de {best_platform[1].roas:.2f}. "
            f"Replicar estrategia en otras plataformas."
        )
        
        recommendations.append(
            f"Plataforma a optimizar: {worst_platform[0]} con ROAS de {worst_platform[1].roas:.2f}. "
            f"Revisar estrategia o considerar pausar."
        )
        
        return recommendations
    
    def compare_periods(self, carousel_id: str, period1: Dict, period2: Dict) -> Dict:
        """Compara performance entre dos per√≠odos"""
        
        changes = {}
        
        for platform in period1.get('platforms', []):
            if platform not in period2.get('platforms', []):
                continue
            
            metrics1 = period1['metrics'][platform]
            metrics2 = period2['metrics'][platform]
            
            changes[platform] = {
                'ctr_change': ((metrics2['ctr'] - metrics1['ctr']) / metrics1['ctr'] * 100) if metrics1['ctr'] > 0 else 0,
                'engagement_change': ((metrics2['engagement_rate'] - metrics1['engagement_rate']) / metrics1['engagement_rate'] * 100) if metrics1['engagement_rate'] > 0 else 0,
                'conversion_change': ((metrics2['conversion_rate'] - metrics1['conversion_rate']) / metrics1['conversion_rate'] * 100) if metrics1['conversion_rate'] > 0 else 0,
                'roas_change': ((metrics2['roas'] - metrics1['roas']) / metrics1['roas'] * 100) if metrics1['roas'] > 0 else 0
            }
        
        return {
            'carousel_id': carousel_id,
            'period1': period1,
            'period2': period2,
            'changes': changes,
            'summary': {
                'improved_platforms': [
                    p for p, c in changes.items()
                    if c['roas_change'] > 0
                ],
                'declined_platforms': [
                    p for p, c in changes.items()
                    if c['roas_change'] < 0
                ]
            }
        }
    
    def generate_comparative_report(self, carousel_id: str) -> Dict:
        """Genera reporte comparativo"""
        
        if carousel_id not in self.metrics_history:
            return {'status': 'error', 'message': 'No analysis found'}
        
        analysis = self.metrics_history[carousel_id]
        
        return {
            'report_id': f"comparative_report_{datetime.now().timestamp()}",
            'generated_at': datetime.now().isoformat(),
            'analysis': analysis,
            'summary': {
                'total_platforms': len(analysis['platforms_analyzed']),
                'best_platform': analysis['best_performing']['platform'],
                'worst_platform': analysis['worst_performing']['platform'],
                'performance_gap': analysis['best_performing']['roas'] - analysis['worst_performing']['roas']
            }
        }

if __name__ == '__main__':
    analyzer = CrossPlatformPerformanceAnalyzer()
    
    # M√©tricas por plataforma
    metrics = {
        'instagram': PlatformMetrics(
            platform='instagram',
            impressions=10000,
            clicks=450,
            engagement=850,
            conversions=45,
            ctr=4.5,
            engagement_rate=8.5,
            conversion_rate=5.0,
            roas=3.5,
            cost=500.0
        ),
        'linkedin': PlatformMetrics(
            platform='linkedin',
            impressions=8000,
            clicks=520,
            engagement=600,
            conversions=62,
            ctr=6.5,
            engagement_rate=7.5,
            conversion_rate=11.9,
            roas=4.8,
            cost=650.0
        ),
        'facebook': PlatformMetrics(
            platform='facebook',
            impressions=12000,
            clicks=360,
            engagement=720,
            conversions=36,
            ctr=3.0,
            engagement_rate=6.0,
            conversion_rate=10.0,
            roas=2.8,
            cost=480.0
        )
    }
    
    # Analizar
    analysis = analyzer.analyze_cross_platform_performance('curso_ia_1', metrics)
    
    print(f"An√°lisis comparativo:")
    print(f"  Mejor plataforma: {analysis['best_performing']['platform']} (ROAS: {analysis['best_performing']['roas']:.2f})")
    print(f"  Peor plataforma: {analysis['worst_performing']['platform']} (ROAS: {analysis['worst_performing']['roas']:.2f})")
    print(f"\nRecomendaciones: {len(analysis['recommendations'])}")
    for rec in analysis['recommendations'][:3]:
        print(f"  ‚Ä¢ {rec}")
```

---

## üé® Sistema de Gesti√≥n de Contenido Generado por Usuarios (UGC) y Testimonios

### Script de UGC Management Avanzado

**Python**: `scripts/advanced_ugc_testimonial_manager.py`

```python
#!/usr/bin/env python3
"""
Sistema de gesti√≥n de contenido generado por usuarios y testimonios
- Colecci√≥n autom√°tica de UGC desde plataformas sociales
- Moderaci√≥n con IA
- Solicitud autom√°tica de permisos
- Conversi√≥n de UGC a carruseles
- Gesti√≥n de testimonios
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class UGCStatus(Enum):
    COLLECTED = "collected"
    MODERATING = "moderating"
    APPROVED = "approved"
    REJECTED = "rejected"
    PERMISSION_PENDING = "permission_pending"
    READY_TO_USE = "ready_to_use"

@dataclass
class UGCItem:
    """Item de contenido generado por usuario"""
    ugc_id: str
    source_platform: str
    author: str
    content_url: str
    content_type: str  # image, video, testimonial
    status: UGCStatus
    moderation_score: float
    permission_granted: bool
    converted_to_carousel: bool

class AdvancedUGCTestimonialManager:
    """Gestor avanzado de UGC y testimonios"""
    
    def __init__(self):
        self.ugc_items = {}
        self.testimonials = {}
    
    def collect_ugc_from_platform(self, platform: str, hashtag: str,
                                 mentions: List[str]) -> List[UGCItem]:
        """Recolecta UGC desde plataforma"""
        
        collected = []
        
        # En producci√≥n: usar API de la plataforma (Instagram, Twitter, etc.)
        # Por ahora: simular colecci√≥n
        
        for i, mention in enumerate(mentions):
            ugc_item = UGCItem(
                ugc_id=f"ugc_{platform}_{datetime.now().timestamp()}_{i}",
                source_platform=platform,
                author=mention.get('author', 'user'),
                content_url=mention.get('url', ''),
                content_type=mention.get('type', 'image'),
                status=UGCStatus.COLLECTED,
                moderation_score=0.0,
                permission_granted=False,
                converted_to_carousel=False
            )
            
            collected.append(ugc_item)
            self.ugc_items[ugc_item.ugc_id] = ugc_item
        
        return collected
    
    def moderate_ugc(self, ugc_id: str, content_data: Dict) -> Dict:
        """Modera UGC con IA"""
        
        if ugc_id not in self.ugc_items:
            return {'status': 'error', 'message': 'UGC not found'}
        
        ugc = self.ugc_items[ugc_id]
        
        # En producci√≥n: usar GPT-4 o modelo de moderaci√≥n
        # An√°lisis de contenido, sentimiento, calidad
        
        moderation_score = self._calculate_moderation_score(content_data)
        
        # Determinar aprobaci√≥n
        if moderation_score >= 0.7:
            ugc.status = UGCStatus.APPROVED
            approval_status = 'approved'
        elif moderation_score >= 0.5:
            ugc.status = UGCStatus.MODERATING
            approval_status = 'needs_review'
        else:
            ugc.status = UGCStatus.REJECTED
            approval_status = 'rejected'
        
        ugc.moderation_score = moderation_score
        
        return {
            'ugc_id': ugc_id,
            'moderation_score': moderation_score,
            'approval_status': approval_status,
            'recommendations': self._generate_moderation_recommendations(moderation_score)
        }
    
    def _calculate_moderation_score(self, content: Dict) -> float:
        """Calcula score de moderaci√≥n"""
        
        score = 0.5  # Base
        
        # Calidad de imagen/video
        if content.get('quality') == 'high':
            score += 0.2
        
        # Relevancia del contenido
        if content.get('relevance') == 'high':
            score += 0.2
        
        # Sentimiento positivo
        if content.get('sentiment') == 'positive':
            score += 0.1
        
        # Sin contenido inapropiado
        if not content.get('inappropriate', False):
            score += 0.1
        
        return min(1.0, score)
    
    def _generate_moderation_recommendations(self, score: float) -> List[str]:
        """Genera recomendaciones de moderaci√≥n"""
        
        recommendations = []
        
        if score < 0.5:
            recommendations.append("Contenido no apropiado para uso")
            recommendations.append("Considerar rechazar")
        elif score < 0.7:
            recommendations.append("Revisar manualmente antes de aprobar")
            recommendations.append("Puede necesitar edici√≥n")
        else:
            recommendations.append("Contenido aprobado para uso")
        
        return recommendations
    
    def request_permission(self, ugc_id: str, usage_purpose: str) -> Dict:
        """Solicita permiso para usar UGC"""
        
        if ugc_id not in self.ugc_items:
            return {'status': 'error', 'message': 'UGC not found'}
        
        ugc = self.ugc_items[ugc_id]
        
        # En producci√≥n: enviar mensaje directo o email
        # Por ahora: simular solicitud
        
        permission_request = {
            'ugc_id': ugc_id,
            'author': ugc.author,
            'usage_purpose': usage_purpose,
            'requested_at': datetime.now().isoformat(),
            'status': 'pending'
        }
        
        ugc.status = UGCStatus.PERMISSION_PENDING
        
        return {
            'status': 'success',
            'permission_request': permission_request
        }
    
    def convert_ugc_to_carousel(self, ugc_id: str, carousel_template: Dict) -> Dict:
        """Convierte UGC a carrusel"""
        
        if ugc_id not in self.ugc_items:
            return {'status': 'error', 'message': 'UGC not found'}
        
        ugc = self.ugc_items[ugc_id]
        
        if ugc.status != UGCStatus.APPROVED:
            return {'status': 'error', 'message': 'UGC not approved'}
        
        if not ugc.permission_granted:
            return {'status': 'error', 'message': 'Permission not granted'}
        
        # Crear carrusel desde UGC
        carousel_id = f"ugc_carousel_{ugc_id}"
        
        carousel_data = {
            'carousel_id': carousel_id,
            'ugc_source': ugc_id,
            'slides': [
                {
                    'slide_number': 1,
                    'image': ugc.content_url,
                    'text': f"Gracias @{ugc.author} por compartir tu experiencia",
                    'style': 'testimonial'
                }
            ],
            'template': carousel_template
        }
        
        ugc.converted_to_carousel = True
        
        return {
            'status': 'success',
            'carousel_id': carousel_id,
            'carousel_data': carousel_data
        }
    
    def manage_testimonial(self, testimonial_id: str, testimonial_data: Dict) -> Dict:
        """Gestiona testimonio"""
        
        testimonial = {
            'testimonial_id': testimonial_id,
            'author': testimonial_data.get('author', ''),
            'text': testimonial_data.get('text', ''),
            'rating': testimonial_data.get('rating', 5),
            'product': testimonial_data.get('product', ''),
            'verified': testimonial_data.get('verified', False),
            'created_at': datetime.now().isoformat()
        }
        
        self.testimonials[testimonial_id] = testimonial
        
        return testimonial
    
    def get_ready_ugc(self) -> List[UGCItem]:
        """Obtiene UGC listo para usar"""
        
        return [
            ugc for ugc in self.ugc_items.values()
            if ugc.status == UGCStatus.APPROVED and ugc.permission_granted
        ]
    
    def generate_ugc_report(self) -> Dict:
        """Genera reporte de UGC"""
        
        return {
            'total_ugc': len(self.ugc_items),
            'by_status': {
                status.value: len([u for u in self.ugc_items.values() if u.status == status])
                for status in UGCStatus
            },
            'converted_count': len([u for u in self.ugc_items.values() if u.converted_to_carousel]),
            'average_moderation_score': sum(u.moderation_score for u in self.ugc_items.values()) / len(self.ugc_items) if self.ugc_items else 0
        }

if __name__ == '__main__':
    manager = AdvancedUGCTestimonialManager()
    
    # Recolectar UGC
    mentions = [
        {'author': '@usuario1', 'url': 'https://instagram.com/p/abc123', 'type': 'image'},
        {'author': '@usuario2', 'url': 'https://instagram.com/p/def456', 'type': 'video'}
    ]
    
    collected = manager.collect_ugc_from_platform('instagram', '#cursoIA', mentions)
    print(f"UGC recolectado: {len(collected)}")
    
    # Moderar
    for ugc in collected:
        result = manager.moderate_ugc(ugc.ugc_id, {'quality': 'high', 'relevance': 'high', 'sentiment': 'positive'})
        print(f"  {ugc.ugc_id}: Score {result['moderation_score']:.2f} - {result['approval_status']}")
```

---

## üîÑ Sistema de Automatizaci√≥n de Workflows y Triggers Complejos

### Script de Orchestration Avanzado

**Python**: `scripts/advanced_workflow_orchestrator.py`

```python
#!/usr/bin/env python3
"""
Sistema de automatizaci√≥n de workflows y triggers complejos
- Workflows basados en eventos, tiempo, condiciones
- Triggers m√∫ltiples y condicionales
- Ejecuci√≥n de pasos con dependencias
- Manejo de errores y reintentos
- Logging y audit trail
"""
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class TriggerType(Enum):
    EVENT = "event"
    TIME = "time"
    CONDITION = "condition"
    WEBHOOK = "webhook"

class WorkflowStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class WorkflowStep:
    """Paso de workflow"""
    step_id: str
    name: str
    action: str
    parameters: Dict
    depends_on: List[str]
    retry_count: int
    timeout_seconds: int

@dataclass
class WorkflowTrigger:
    """Trigger de workflow"""
    trigger_type: TriggerType
    condition: Dict
    enabled: bool

class AdvancedWorkflowOrchestrator:
    """Orquestador avanzado de workflows"""
    
    def __init__(self):
        self.workflows = {}
        self.executions = {}
        self.action_handlers = {}
    
    def create_workflow(self, workflow_id: str, name: str, steps: List[WorkflowStep],
                       triggers: List[WorkflowTrigger]) -> Dict:
        """Crea workflow"""
        
        workflow = {
            'workflow_id': workflow_id,
            'name': name,
            'steps': {step.step_id: step for step in steps},
            'triggers': triggers,
            'created_at': datetime.now().isoformat(),
            'enabled': True
        }
        
        self.workflows[workflow_id] = workflow
        
        return workflow
    
    def register_action_handler(self, action_name: str, handler: Callable):
        """Registra handler para acci√≥n"""
        
        self.action_handlers[action_name] = handler
    
    def execute_workflow(self, workflow_id: str, context: Dict = None) -> Dict:
        """Ejecuta workflow"""
        
        if workflow_id not in self.workflows:
            return {'status': 'error', 'message': 'Workflow not found'}
        
        workflow = self.workflows[workflow_id]
        
        execution_id = f"exec_{datetime.now().timestamp()}"
        
        execution = {
            'execution_id': execution_id,
            'workflow_id': workflow_id,
            'status': WorkflowStatus.RUNNING,
            'started_at': datetime.now().isoformat(),
            'steps_completed': [],
            'steps_failed': [],
            'context': context or {}
        }
        
        self.executions[execution_id] = execution
        
        # Ejecutar pasos en orden de dependencias
        try:
            completed_steps = []
            remaining_steps = list(workflow['steps'].keys())
            
            while remaining_steps:
                # Encontrar pasos sin dependencias pendientes
                ready_steps = [
                    step_id for step_id in remaining_steps
                    if all(dep in completed_steps for dep in workflow['steps'][step_id].depends_on)
                ]
                
                if not ready_steps:
                    # Dependencias circulares o pasos bloqueados
                    execution['status'] = WorkflowStatus.FAILED
                    execution['error'] = 'Circular dependency or blocked steps'
                    break
                
                # Ejecutar pasos listos
                for step_id in ready_steps:
                    step = workflow['steps'][step_id]
                    result = self._execute_step(step, execution['context'])
                    
                    if result['success']:
                        completed_steps.append(step_id)
                        execution['steps_completed'].append(step_id)
                    else:
                        execution['steps_failed'].append({
                            'step_id': step_id,
                            'error': result.get('error', 'Unknown error')
                        })
                        execution['status'] = WorkflowStatus.FAILED
                
                remaining_steps = [s for s in remaining_steps if s not in ready_steps]
                
                if execution['status'] == WorkflowStatus.FAILED:
                    break
            
            if execution['status'] != WorkflowStatus.FAILED:
                execution['status'] = WorkflowStatus.COMPLETED
                execution['completed_at'] = datetime.now().isoformat()
        
        except Exception as e:
            execution['status'] = WorkflowStatus.FAILED
            execution['error'] = str(e)
        
        return execution
    
    def _execute_step(self, step: WorkflowStep, context: Dict) -> Dict:
        """Ejecuta paso de workflow"""
        
        handler = self.action_handlers.get(step.action)
        
        if not handler:
            return {'success': False, 'error': f'Handler not found for action: {step.action}'}
        
        try:
            # Ejecutar con timeout
            result = handler(step.parameters, context)
            return {'success': True, 'result': result}
        
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def check_triggers(self) -> List[str]:
        """Verifica triggers y ejecuta workflows"""
        
        triggered_workflows = []
        
        for workflow_id, workflow in self.workflows.items():
            if not workflow.get('enabled', True):
                continue
            
            for trigger in workflow.get('triggers', []):
                if not trigger.enabled:
                    continue
                
                if self._evaluate_trigger(trigger):
                    # Ejecutar workflow
                    execution = self.execute_workflow(workflow_id)
                    triggered_workflows.append(workflow_id)
                    break
        
        return triggered_workflows
    
    def _evaluate_trigger(self, trigger: WorkflowTrigger) -> bool:
        """Eval√∫a si trigger debe activarse"""
        
        if trigger.trigger_type == TriggerType.TIME:
            # Verificar condici√≥n de tiempo
            schedule = trigger.condition.get('schedule', {})
            return self._check_time_schedule(schedule)
        
        elif trigger.trigger_type == TriggerType.CONDITION:
            # Verificar condici√≥n
            condition = trigger.condition.get('condition', '')
            return self._evaluate_condition(condition)
        
        elif trigger.trigger_type == TriggerType.EVENT:
            # Evento ya ocurri√≥ (evaluado externamente)
            return trigger.condition.get('triggered', False)
        
        return False
    
    def _check_time_schedule(self, schedule: Dict) -> bool:
        """Verifica schedule de tiempo"""
        
        # Simplificado: verificar si es hora programada
        current_time = datetime.now()
        scheduled_hour = schedule.get('hour', current_time.hour)
        scheduled_minute = schedule.get('minute', current_time.minute)
        
        return current_time.hour == scheduled_hour and current_time.minute == scheduled_minute
    
    def _evaluate_condition(self, condition: str) -> bool:
        """Eval√∫a condici√≥n (simplificado)"""
        
        # En producci√≥n: parser m√°s complejo
        # Por ahora: condiciones simples
        return True
    
    def get_workflow_execution_history(self, workflow_id: str, limit: int = 10) -> List[Dict]:
        """Obtiene historial de ejecuciones"""
        
        executions = [
            e for e in self.executions.values()
            if e['workflow_id'] == workflow_id
        ]
        
        executions.sort(key=lambda x: x.get('started_at', ''), reverse=True)
        
        return executions[:limit]
    
    def generate_workflow_report(self, workflow_id: str) -> Dict:
        """Genera reporte de workflow"""
        
        if workflow_id not in self.workflows:
            return {'status': 'error', 'message': 'Workflow not found'}
        
        workflow = self.workflows[workflow_id]
        executions = self.get_workflow_execution_history(workflow_id, limit=100)
        
        total_executions = len(executions)
        successful = len([e for e in executions if e['status'] == WorkflowStatus.COMPLETED])
        failed = len([e for e in executions if e['status'] == WorkflowStatus.FAILED])
        
        return {
            'workflow_id': workflow_id,
            'workflow_name': workflow['name'],
            'total_executions': total_executions,
            'success_rate': (successful / total_executions * 100) if total_executions > 0 else 0,
            'failed_count': failed,
            'recent_executions': executions[:5]
        }

if __name__ == '__main__':
    orchestrator = AdvancedWorkflowOrchestrator()
    
    # Registrar handlers
    def publish_action(params: Dict, context: Dict) -> Dict:
        return {'published': True, 'post_id': 'post123'}
    
    orchestrator.register_action_handler('publish', publish_action)
    
    # Crear workflow
    steps = [
        WorkflowStep('step1', 'Validate', 'validate', {}, [], 0, 30),
        WorkflowStep('step2', 'Publish', 'publish', {'platform': 'instagram'}, ['step1'], 3, 60)
    ]
    
    triggers = [
        WorkflowTrigger(TriggerType.TIME, {'schedule': {'hour': 11, 'minute': 0}}, True)
    ]
    
    workflow = orchestrator.create_workflow('publish_workflow', 'Publish Carousel', steps, triggers)
    print(f"Workflow creado: {workflow['workflow_id']}")
```

---

## üîó Sistema de Integraci√≥n API Avanzada y Webhooks

### Script de Gesti√≥n de Integraciones

**Python**: `scripts/advanced_api_webhook_manager.py`

```python
#!/usr/bin/env python3
"""
Sistema de integraci√≥n API avanzada y webhooks
- Gesti√≥n de integraciones con plataformas externas
- Webhook handlers con verificaci√≥n de firma
- Rate limiting y throttling
- Retry logic inteligente
- Logging y monitoreo de APIs
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json
import hmac
import hashlib

class IntegrationStatus(Enum):
    ACTIVE = "active"
    INACTIVE = "inactive"
    ERROR = "error"
    RATE_LIMITED = "rate_limited"

@dataclass
class APIIntegration:
    """Integraci√≥n API"""
    integration_id: str
    platform: str
    api_key: str
    api_secret: str
    webhook_url: Optional[str]
    status: IntegrationStatus
    rate_limit: int
    requests_made: int
    last_request: Optional[datetime]

@dataclass
class WebhookEvent:
    """Evento de webhook"""
    event_id: str
    integration_id: str
    event_type: str
    payload: Dict
    signature: str
    received_at: datetime
    processed: bool

class AdvancedAPIWebhookManager:
    """Gestor avanzado de APIs y webhooks"""
    
    def __init__(self):
        self.integrations = {}
        self.webhook_events = []
        self.rate_limiters = {}
    
    def register_integration(self, platform: str, api_key: str, api_secret: str,
                            webhook_url: Optional[str] = None,
                            rate_limit: int = 100) -> APIIntegration:
        """Registra integraci√≥n API"""
        
        integration = APIIntegration(
            integration_id=f"integration_{datetime.now().timestamp()}",
            platform=platform,
            api_key=api_key,
            api_secret=api_secret,
            webhook_url=webhook_url,
            status=IntegrationStatus.ACTIVE,
            rate_limit=rate_limit,
            requests_made=0,
            last_request=None
        )
        
        self.integrations[integration.integration_id] = integration
        self.rate_limiters[integration.integration_id] = {
            'limit': rate_limit,
            'window_start': datetime.now(),
            'requests': []
        }
        
        return integration
    
    def make_api_request(self, integration_id: str, endpoint: str,
                        method: str = 'GET', payload: Optional[Dict] = None) -> Dict:
        """Realiza request API con rate limiting"""
        
        if integration_id not in self.integrations:
            return {'status': 'error', 'message': 'Integration not found'}
        
        integration = self.integrations[integration_id]
        
        # Verificar rate limit
        if not self._check_rate_limit(integration_id):
            integration.status = IntegrationStatus.RATE_LIMITED
            return {'status': 'error', 'message': 'Rate limit exceeded'}
        
        # Realizar request (simulado)
        try:
            # En producci√≥n: usar requests library
            response = self._execute_api_request(integration, endpoint, method, payload)
            
            # Actualizar estad√≠sticas
            integration.requests_made += 1
            integration.last_request = datetime.now()
            
            return {
                'status': 'success',
                'response': response,
                'integration_id': integration_id
            }
        
        except Exception as e:
            integration.status = IntegrationStatus.ERROR
            return {
                'status': 'error',
                'error': str(e),
                'integration_id': integration_id
            }
    
    def _check_rate_limit(self, integration_id: str) -> bool:
        """Verifica rate limit"""
        
        limiter = self.rate_limiters.get(integration_id)
        if not limiter:
            return True
        
        # Limpiar requests fuera de la ventana (1 minuto)
        window_start = limiter['window_start']
        now = datetime.now()
        
        if (now - window_start).total_seconds() > 60:
            limiter['requests'] = []
            limiter['window_start'] = now
        
        # Verificar l√≠mite
        if len(limiter['requests']) >= limiter['limit']:
            return False
        
        limiter['requests'].append(now)
        return True
    
    def _execute_api_request(self, integration: APIIntegration, endpoint: str,
                            method: str, payload: Optional[Dict]) -> Dict:
        """Ejecuta request API (simulado)"""
        
        # En producci√≥n: implementar llamadas reales
        return {
            'endpoint': endpoint,
            'method': method,
            'payload': payload,
            'timestamp': datetime.now().isoformat()
        }
    
    def receive_webhook(self, integration_id: str, payload: Dict,
                       signature: str) -> WebhookEvent:
        """Recibe y procesa webhook"""
        
        # Verificar firma
        if not self._verify_webhook_signature(integration_id, payload, signature):
            raise ValueError('Invalid webhook signature')
        
        event = WebhookEvent(
            event_id=f"webhook_{datetime.now().timestamp()}",
            integration_id=integration_id,
            event_type=payload.get('type', 'unknown'),
            payload=payload,
            signature=signature,
            received_at=datetime.now(),
            processed=False
        )
        
        self.webhook_events.append(event)
        
        # Procesar evento
        self._process_webhook_event(event)
        
        return event
    
    def _verify_webhook_signature(self, integration_id: str, payload: Dict,
                                 signature: str) -> bool:
        """Verifica firma de webhook"""
        
        if integration_id not in self.integrations:
            return False
        
        integration = self.integrations[integration_id]
        
        # Crear firma esperada
        payload_str = json.dumps(payload, sort_keys=True)
        expected_signature = hmac.new(
            integration.api_secret.encode(),
            payload_str.encode(),
            hashlib.sha256
        ).hexdigest()
        
        return hmac.compare_digest(expected_signature, signature)
    
    def _process_webhook_event(self, event: WebhookEvent):
        """Procesa evento de webhook"""
        
        # En producci√≥n: routing a handlers espec√≠ficos
        event.processed = True
        
        # Handlers por tipo de evento
        handlers = {
            'carousel.published': self._handle_carousel_published,
            'carousel.updated': self._handle_carousel_updated,
            'metric.update': self._handle_metric_update
        }
        
        handler = handlers.get(event.event_type)
        if handler:
            handler(event)
    
    def _handle_carousel_published(self, event: WebhookEvent):
        """Handler para carrusel publicado"""
        pass
    
    def _handle_carousel_updated(self, event: WebhookEvent):
        """Handler para carrusel actualizado"""
        pass
    
    def _handle_metric_update(self, event: WebhookEvent):
        """Handler para actualizaci√≥n de m√©tricas"""
        pass
    
    def retry_failed_requests(self, integration_id: str, max_retries: int = 3) -> List[Dict]:
        """Reintenta requests fallidos"""
        
        # En producci√≥n: implementar cola de retry
        return []
    
    def get_integration_health(self, integration_id: str) -> Dict:
        """Obtiene salud de integraci√≥n"""
        
        if integration_id not in self.integrations:
            return {'status': 'error', 'message': 'Integration not found'}
        
        integration = self.integrations[integration_id]
        
        return {
            'integration_id': integration_id,
            'platform': integration.platform,
            'status': integration.status.value,
            'requests_made': integration.requests_made,
            'rate_limit': integration.rate_limit,
            'last_request': integration.last_request.isoformat() if integration.last_request else None,
            'health_score': self._calculate_health_score(integration)
        }
    
    def _calculate_health_score(self, integration: APIIntegration) -> float:
        """Calcula score de salud de integraci√≥n"""
        
        score = 100.0
        
        if integration.status == IntegrationStatus.ERROR:
            score -= 50
        elif integration.status == IntegrationStatus.RATE_LIMITED:
            score -= 30
        
        # Penalizar si no hay requests recientes (posible inactividad)
        if integration.last_request:
            hours_since_last = (datetime.now() - integration.last_request).total_seconds() / 3600
            if hours_since_last > 24:
                score -= 20
        
        return max(0.0, score)

if __name__ == '__main__':
    manager = AdvancedAPIWebhookManager()
    
    # Registrar integraci√≥n
    integration = manager.register_integration(
        'instagram',
        'api_key_123',
        'api_secret_456',
        webhook_url='https://example.com/webhook',
        rate_limit=100
    )
    
    print(f"Integraci√≥n registrada: {integration.integration_id}")
    
    # Health check
    health = manager.get_integration_health(integration.integration_id)
    print(f"Health score: {health['health_score']:.1f}/100")
```

---

## üé≠ Sistema de Personalizaci√≥n Din√°mica Basada en Contexto Temporal

### Script de Personalizaci√≥n Contextual

**Python**: `scripts/contextual_dynamic_personalization.py`

```python
#!/usr/bin/env python3
"""
Sistema de personalizaci√≥n din√°mica basada en contexto temporal
- Personalizaci√≥n por hora del d√≠a, d√≠a de semana, temporada
- Adaptaci√≥n a eventos y festividades
- Personalizaci√≥n por ubicaci√≥n geogr√°fica
- Personalizaci√≥n por comportamiento del usuario
- A/B testing de personalizaciones
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, time
from enum import Enum
import json

class PersonalizationContext(Enum):
    MORNING = "morning"  # 6-12
    AFTERNOON = "afternoon"  # 12-18
    EVENING = "evening"  # 18-22
    NIGHT = "night"  # 22-6
    WEEKDAY = "weekday"
    WEEKEND = "weekend"
    HOLIDAY = "holiday"
    SEASON = "season"

@dataclass
class PersonalizedContent:
    """Contenido personalizado"""
    content_id: str
    base_carousel_id: str
    context: PersonalizationContext
    personalized_headline: str
    personalized_cta: str
    personalization_rules: Dict
    performance_prediction: float

class ContextualDynamicPersonalization:
    """Sistema de personalizaci√≥n contextual"""
    
    def __init__(self):
        self.personalizations = {}
        self.context_rules = {
            PersonalizationContext.MORNING: {
                'headline_tone': 'energizing',
                'cta_tone': 'action',
                'visual_style': 'bright'
            },
            PersonalizationContext.AFTERNOON: {
                'headline_tone': 'informative',
                'cta_tone': 'discovery',
                'visual_style': 'balanced'
            },
            PersonalizationContext.EVENING: {
                'headline_tone': 'relaxed',
                'cta_tone': 'commitment',
                'visual_style': 'warm'
            },
            PersonalizationContext.WEEKDAY: {
                'headline_focus': 'professional',
                'cta_focus': 'productivity'
            },
            PersonalizationContext.WEEKEND: {
                'headline_focus': 'personal_growth',
                'cta_focus': 'exploration'
            }
        }
    
    def personalize_carousel(self, carousel_id: str, base_content: Dict,
                            user_context: Dict) -> PersonalizedContent:
        """Personaliza carrusel basado en contexto"""
        
        # Determinar contexto temporal
        temporal_context = self._determine_temporal_context()
        
        # Aplicar reglas de personalizaci√≥n
        personalized_headline = self._personalize_headline(
            base_content.get('headline', ''),
            temporal_context,
            user_context
        )
        
        personalized_cta = self._personalize_cta(
            base_content.get('cta', ''),
            temporal_context,
            user_context
        )
        
        # Predecir performance
        performance_prediction = self._predict_personalized_performance(
            temporal_context, user_context
        )
        
        personalized = PersonalizedContent(
            content_id=f"personalized_{carousel_id}_{datetime.now().timestamp()}",
            base_carousel_id=carousel_id,
            context=temporal_context,
            personalized_headline=personalized_headline,
            personalized_cta=personalized_cta,
            personalization_rules={
                'temporal_context': temporal_context.value,
                'user_context': user_context
            },
            performance_prediction=performance_prediction
        )
        
        self.personalizations[personalized.content_id] = personalized
        
        return personalized
    
    def _determine_temporal_context(self) -> List[PersonalizationContext]:
        """Determina contexto temporal"""
        
        contexts = []
        now = datetime.now()
        
        # Contexto por hora
        hour = now.hour
        if 6 <= hour < 12:
            contexts.append(PersonalizationContext.MORNING)
        elif 12 <= hour < 18:
            contexts.append(PersonalizationContext.AFTERNOON)
        elif 18 <= hour < 22:
            contexts.append(PersonalizationContext.EVENING)
        else:
            contexts.append(PersonalizationContext.NIGHT)
        
        # Contexto por d√≠a
        weekday = now.weekday()
        if weekday < 5:
            contexts.append(PersonalizationContext.WEEKDAY)
        else:
            contexts.append(PersonalizationContext.WEEKEND)
        
        # Temporada (simplificado)
        month = now.month
        if month in [12, 1, 2]:
            contexts.append(PersonalizationContext.SEASON)  # Winter
        elif month in [3, 4, 5]:
            contexts.append(PersonalizationContext.SEASON)  # Spring
        elif month in [6, 7, 8]:
            contexts.append(PersonalizationContext.SEASON)  # Summer
        else:
            contexts.append(PersonalizationContext.SEASON)  # Fall
        
        return contexts
    
    def _personalize_headline(self, base_headline: str,
                              contexts: List[PersonalizationContext],
                              user_context: Dict) -> str:
        """Personaliza headline"""
        
        personalized = base_headline
        
        # Aplicar reglas por contexto
        for context in contexts:
            rules = self.context_rules.get(context, {})
            
            tone = rules.get('headline_tone', '')
            focus = rules.get('headline_focus', '')
            
            if tone == 'energizing':
                personalized = f"¬°{personalized}!" if not personalized.startswith('¬°') else personalized
            
            if focus == 'professional':
                personalized = personalized.replace('aprende', 'domina')
        
        return personalized
    
    def _personalize_cta(self, base_cta: str,
                         contexts: List[PersonalizationContext],
                         user_context: Dict) -> str:
        """Personaliza CTA"""
        
        personalized = base_cta
        
        for context in contexts:
            rules = self.context_rules.get(context, {})
            
            tone = rules.get('cta_tone', '')
            
            if tone == 'action':
                personalized = personalized.replace('descubre', 'comienza ya')
            elif tone == 'discovery':
                personalized = personalized.replace('comienza', 'explora')
        
        return personalized
    
    def _predict_personalized_performance(self,
                                          contexts: List[PersonalizationContext],
                                          user_context: Dict) -> float:
        """Predice performance de personalizaci√≥n"""
        
        base_score = 0.6
        
        # Ajustar seg√∫n contexto
        if PersonalizationContext.MORNING in contexts:
            base_score += 0.1  # Mejor engagement en ma√±anas
        
        if PersonalizationContext.WEEKDAY in contexts:
            base_score += 0.1  # Mejor en d√≠as laborales para B2B
        
        # Ajustar seg√∫n comportamiento del usuario
        if user_context.get('previous_engagement', 0) > 0.5:
            base_score += 0.15
        
        return min(1.0, base_score)
    
    def personalize_for_event(self, carousel_id: str, base_content: Dict,
                             event_type: str) -> PersonalizedContent:
        """Personaliza para evento espec√≠fico"""
        
        event_personalizations = {
            'black_friday': {
                'headline_prefix': 'üî• Black Friday: ',
                'cta': 'Consigue tu descuento ahora',
                'urgency': True
            },
            'cyber_monday': {
                'headline_prefix': 'üíª Cyber Monday: ',
                'cta': 'Oferta especial limitada',
                'urgency': True
            },
            'new_year': {
                'headline_prefix': 'üéâ A√±o Nuevo: ',
                'cta': 'Comienza el a√±o transform√°ndote',
                'motivational': True
            }
        }
        
        event_rules = event_personalizations.get(event_type, {})
        
        headline = event_rules.get('headline_prefix', '') + base_content.get('headline', '')
        cta = event_rules.get('cta', base_content.get('cta', ''))
        
        personalized = PersonalizedContent(
            content_id=f"event_{carousel_id}_{datetime.now().timestamp()}",
            base_carousel_id=carousel_id,
            context=PersonalizationContext.HOLIDAY,
            personalized_headline=headline,
            personalized_cta=cta,
            personalization_rules={'event_type': event_type},
            performance_prediction=0.8  # Eventos tienen mayor engagement
        )
        
        return personalized
    
    def get_personalization_recommendations(self, carousel_id: str,
                                           historical_performance: Dict) -> List[str]:
        """Genera recomendaciones de personalizaci√≥n"""
        
        recommendations = []
        
        # Analizar mejor performing context
        best_context = historical_performance.get('best_context', '')
        if best_context:
            recommendations.append(
                f"Personalizar m√°s contenido para contexto '{best_context}' (mejor performance)"
            )
        
        # Analizar timing
        best_time = historical_performance.get('best_time', '')
        if best_time:
            recommendations.append(
                f"Publicar m√°s contenido a las {best_time} (mejor engagement)"
            )
        
        # Analizar eventos
        if historical_performance.get('event_boost', 0) > 1.2:
            recommendations.append(
                "Eventos especiales aumentan engagement significativamente. Crear m√°s contenido para eventos"
            )
        
        return recommendations

if __name__ == '__main__':
    personalizer = ContextualDynamicPersonalization()
    
    # Personalizar carrusel
    base_content = {
        'headline': 'Aprende IA aplicada',
        'cta': 'Descubre c√≥mo',
        'product': 'Curso IA'
    }
    
    user_context = {
        'previous_engagement': 0.7,
        'location': 'Spain',
        'timezone': 'Europe/Madrid'
    }
    
    personalized = personalizer.personalize_carousel('curso_ia_1', base_content, user_context)
    
    print(f"Personalizaci√≥n creada:")
    print(f"  Headline: {personalized.personalized_headline}")
    print(f"  CTA: {personalized.personalized_cta}")
    print(f"  Contexto: {personalized.context.value}")
    print(f"  Performance predicho: {personalized.performance_prediction:.1%}")
```

---

## üìä Sistema de Analytics Unificado Multi-Fuente

### Script de Agregaci√≥n de Analytics

**Python**: `scripts/unified_multi_source_analytics.py`

```python
#!/usr/bin/env python3
"""
Sistema de analytics unificado multi-fuente
- Agregaci√≥n de datos de m√∫ltiples fuentes (GA4, Meta, CRM, etc.)
- Normalizaci√≥n de m√©tricas
- C√°lculo de m√©tricas derivadas
- Dashboard unificado
- Exportaci√≥n a BI tools
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class UnifiedMetric:
    """M√©trica unificada"""
    metric_name: str
    value: float
    source: str
    timestamp: datetime
    dimensions: Dict

class UnifiedMultiSourceAnalytics:
    """Sistema de analytics unificado"""
    
    def __init__(self):
        self.metrics_cache = {}
        self.data_sources = {
            'ga4': self._fetch_ga4_data,
            'meta': self._fetch_meta_data,
            'hubspot': self._fetch_hubspot_data,
            'pipedrive': self._fetch_pipedrive_data
        }
    
    def aggregate_metrics(self, carousel_id: str, start_date: datetime,
                         end_date: datetime, sources: List[str]) -> Dict:
        """Agrega m√©tricas de m√∫ltiples fuentes"""
        
        aggregated = {
            'carousel_id': carousel_id,
            'period': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat()
            },
            'sources': sources,
            'metrics': {},
            'unified_metrics': {}
        }
        
        # Obtener datos de cada fuente
        for source in sources:
            if source in self.data_sources:
                source_data = self.data_sources[source](carousel_id, start_date, end_date)
                aggregated['metrics'][source] = source_data
        
        # Normalizar y unificar m√©tricas
        aggregated['unified_metrics'] = self._normalize_metrics(aggregated['metrics'])
        
        return aggregated
    
    def _fetch_ga4_data(self, carousel_id: str, start: datetime, end: datetime) -> Dict:
        """Obtiene datos de GA4"""
        
        # En producci√≥n: usar GA4 API
        return {
            'impressions': 15000,
            'clicks': 675,
            'sessions': 800,
            'conversions': 54,
            'revenue': 5400.0
        }
    
    def _fetch_meta_data(self, carousel_id: str, start: datetime, end: datetime) -> Dict:
        """Obtiene datos de Meta"""
        
        # En producci√≥n: usar Meta API
        return {
            'impressions': 18000,
            'clicks': 810,
            'engagement': 1458,
            'spend': 900.0
        }
    
    def _fetch_hubspot_data(self, carousel_id: str, start: datetime, end: datetime) -> Dict:
        """Obtiene datos de HubSpot"""
        
        # En producci√≥n: usar HubSpot API
        return {
            'leads': 45,
            'contacts_created': 52,
            'deals_created': 12,
            'deal_value': 4800.0
        }
    
    def _fetch_pipedrive_data(self, carousel_id: str, start: datetime, end: datetime) -> Dict:
        """Obtiene datos de Pipedrive"""
        
        # En producci√≥n: usar Pipedrive API
        return {
            'deals': 10,
            'deal_value': 4200.0,
            'won_deals': 8
        }
    
    def _normalize_metrics(self, source_metrics: Dict) -> Dict:
        """Normaliza m√©tricas de diferentes fuentes"""
        
        unified = {
            'impressions': 0,
            'clicks': 0,
            'engagement': 0,
            'conversions': 0,
            'revenue': 0.0,
            'spend': 0.0,
            'roas': 0.0,
            'ctr': 0.0,
            'conversion_rate': 0.0
        }
        
        # Agregar m√©tricas comunes
        for source, metrics in source_metrics.items():
            unified['impressions'] += metrics.get('impressions', 0)
            unified['clicks'] += metrics.get('clicks', 0)
            unified['engagement'] += metrics.get('engagement', 0)
            unified['conversions'] += metrics.get('conversions', 0)
            unified['conversions'] += metrics.get('leads', 0)  # Leads tambi√©n son conversiones
            unified['revenue'] += metrics.get('revenue', 0.0)
            unified['revenue'] += metrics.get('deal_value', 0.0)
            unified['spend'] += metrics.get('spend', 0.0)
        
        # Calcular m√©tricas derivadas
        if unified['impressions'] > 0:
            unified['ctr'] = (unified['clicks'] / unified['impressions']) * 100
        
        if unified['clicks'] > 0:
            unified['conversion_rate'] = (unified['conversions'] / unified['clicks']) * 100
        
        if unified['spend'] > 0:
            unified['roas'] = unified['revenue'] / unified['spend']
        
        return unified
    
    def generate_unified_dashboard(self, carousel_id: str, period_days: int = 7) -> Dict:
        """Genera dashboard unificado"""
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        aggregated = self.aggregate_metrics(
            carousel_id,
            start_date,
            end_date,
            ['ga4', 'meta', 'hubspot']
        )
        
        unified = aggregated['unified_metrics']
        
        dashboard = {
            'carousel_id': carousel_id,
            'period': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat(),
                'days': period_days
            },
            'kpis': {
                'impressions': unified['impressions'],
                'clicks': unified['clicks'],
                'ctr': unified['ctr'],
                'engagement': unified['engagement'],
                'conversions': unified['conversions'],
                'conversion_rate': unified['conversion_rate'],
                'revenue': unified['revenue'],
                'spend': unified['spend'],
                'roas': unified['roas']
            },
            'trends': self._calculate_trends(carousel_id, start_date, end_date),
            'benchmarks': self._compare_to_benchmarks(unified),
            'recommendations': self._generate_analytics_recommendations(unified)
        }
        
        return dashboard
    
    def _calculate_trends(self, carousel_id: str, start: datetime, end: datetime) -> Dict:
        """Calcula tendencias"""
        
        # Simplificado: en producci√≥n comparar con per√≠odo anterior
        return {
            'impressions_trend': 'stable',
            'ctr_trend': 'rising',
            'conversion_trend': 'stable'
        }
    
    def _compare_to_benchmarks(self, metrics: Dict) -> Dict:
        """Compara con benchmarks de industria"""
        
        industry_benchmarks = {
            'ctr': 3.5,
            'conversion_rate': 5.0,
            'roas': 3.0
        }
        
        comparison = {}
        
        for metric, benchmark in industry_benchmarks.items():
            value = metrics.get(metric, 0)
            if value > benchmark * 1.1:
                comparison[metric] = 'above_benchmark'
            elif value < benchmark * 0.9:
                comparison[metric] = 'below_benchmark'
            else:
                comparison[metric] = 'at_benchmark'
        
        return comparison
    
    def _generate_analytics_recommendations(self, metrics: Dict) -> List[str]:
        """Genera recomendaciones basadas en analytics"""
        
        recommendations = []
        
        if metrics['ctr'] < 2.0:
            recommendations.append("CTR por debajo del promedio. Optimizar headline y visual")
        
        if metrics['conversion_rate'] < 3.0:
            recommendations.append("Conversion rate bajo. Mejorar landing page y CTA")
        
        if metrics['roas'] > 4.0:
            recommendations.append("ROAS excelente. Considerar aumentar budget")
        
        if metrics['roas'] < 2.0:
            recommendations.append("ROAS bajo. Revisar targeting y oferta")
        
        return recommendations
    
    def export_to_bi_tool(self, dashboard_data: Dict, tool: str) -> Dict:
        """Exporta a herramienta BI"""
        
        exports = {
            'tableau': self._export_to_tableau,
            'powerbi': self._export_to_powerbi,
            'looker': self._export_to_looker
        }
        
        exporter = exports.get(tool)
        if exporter:
            return exporter(dashboard_data)
        
        return {'status': 'error', 'message': 'BI tool not supported'}
    
    def _export_to_tableau(self, data: Dict) -> Dict:
        """Exporta a Tableau"""
        # En producci√≥n: usar Tableau API
        return {'status': 'success', 'format': 'tableau', 'data': data}
    
    def _export_to_powerbi(self, data: Dict) -> Dict:
        """Exporta a Power BI"""
        # En producci√≥n: usar Power BI API
        return {'status': 'success', 'format': 'powerbi', 'data': data}
    
    def _export_to_looker(self, data: Dict) -> Dict:
        """Exporta a Looker"""
        # En producci√≥n: usar Looker API
        return {'status': 'success', 'format': 'looker', 'data': data}

if __name__ == '__main__':
    analytics = UnifiedMultiSourceAnalytics()
    
    # Dashboard unificado
    dashboard = analytics.generate_unified_dashboard('curso_ia_1', period_days=7)
    
    print(f"Dashboard unificado:")
    print(f"  CTR: {dashboard['kpis']['ctr']:.2f}%")
    print(f"  Conversiones: {dashboard['kpis']['conversions']}")
    print(f"  ROAS: {dashboard['kpis']['roas']:.2f}")
    print(f"\nRecomendaciones: {len(dashboard['recommendations'])}")
```

---

## üîê Sistema de Seguridad Avanzada y Protecci√≥n de Datos

### Script de Gesti√≥n de Seguridad

**Python**: `scripts/advanced_security_data_protection.py`

```python
#!/usr/bin/env python3
"""
Sistema de seguridad avanzada y protecci√≥n de datos
- Encriptaci√≥n de datos sensibles
- Gesti√≥n de accesos y permisos
- Auditor√≠a de acciones
- Detecci√≥n de amenazas
- Cumplimiento GDPR/CCPA
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json
import hashlib

class SecurityEventType(Enum):
    LOGIN = "login"
    ACCESS_DENIED = "access_denied"
    DATA_EXPORT = "data_export"
    DATA_DELETION = "data_deletion"
    PERMISSION_CHANGE = "permission_change"
    SUSPICIOUS_ACTIVITY = "suspicious_activity"

@dataclass
class SecurityEvent:
    """Evento de seguridad"""
    event_id: str
    event_type: SecurityEventType
    user_id: str
    resource: str
    action: str
    timestamp: datetime
    ip_address: Optional[str]
    severity: str  # low, medium, high, critical

class AdvancedSecurityDataProtection:
    """Sistema de seguridad avanzada"""
    
    def __init__(self):
        self.security_events = []
        self.access_logs = []
        self.encrypted_data = {}
    
    def encrypt_sensitive_data(self, data: str, key: str) -> str:
        """Encripta datos sensibles"""
        
        # En producci√≥n: usar biblioteca de encriptaci√≥n robusta (cryptography)
        # Por ahora: hash simplificado para demostraci√≥n
        encrypted = hashlib.sha256(f"{data}{key}".encode()).hexdigest()
        
        self.encrypted_data[encrypted] = {
            'encrypted_at': datetime.now().isoformat(),
            'key_hash': hashlib.sha256(key.encode()).hexdigest()
        }
        
        return encrypted
    
    def decrypt_sensitive_data(self, encrypted_data: str, key: str) -> Optional[str]:
        """Desencripta datos sensibles"""
        
        # En producci√≥n: implementar desencriptaci√≥n real
        # Por ahora: verificaci√≥n de hash
        if encrypted_data in self.encrypted_data:
            key_hash = hashlib.sha256(key.encode()).hexdigest()
            if self.encrypted_data[encrypted_data]['key_hash'] == key_hash:
                return "decrypted_data"  # En producci√≥n: retornar datos reales
        
        return None
    
    def check_access_permission(self, user_id: str, resource: str,
                               action: str) -> bool:
        """Verifica permisos de acceso"""
        
        # En producci√≥n: sistema de permisos completo (RBAC)
        # Por ahora: verificaci√≥n simplificada
        
        permissions = {
            'admin': ['read', 'write', 'delete', 'export'],
            'editor': ['read', 'write'],
            'viewer': ['read']
        }
        
        user_role = self._get_user_role(user_id)
        allowed_actions = permissions.get(user_role, [])
        
        has_permission = action in allowed_actions
        
        # Log de acceso
        self._log_access(user_id, resource, action, has_permission)
        
        return has_permission
    
    def _get_user_role(self, user_id: str) -> str:
        """Obtiene rol de usuario"""
        
        # En producci√≥n: consultar base de datos de usuarios
        return 'editor'  # Default
    
    def _log_access(self, user_id: str, resource: str, action: str, allowed: bool):
        """Registra acceso"""
        
        log_entry = {
            'user_id': user_id,
            'resource': resource,
            'action': action,
            'allowed': allowed,
            'timestamp': datetime.now().isoformat()
        }
        
        self.access_logs.append(log_entry)
        
        # Crear evento de seguridad si acceso denegado
        if not allowed:
            event = SecurityEvent(
                event_id=f"security_{datetime.now().timestamp()}",
                event_type=SecurityEventType.ACCESS_DENIED,
                user_id=user_id,
                resource=resource,
                action=action,
                timestamp=datetime.now(),
                ip_address=None,
                severity='medium'
            )
            self.security_events.append(event)
    
    def detect_suspicious_activity(self, user_id: str, actions: List[Dict]) -> List[SecurityEvent]:
        """Detecta actividad sospechosa"""
        
        suspicious_events = []
        
        # Detectar patrones sospechosos
        # Ejemplo: muchos intentos de acceso en poco tiempo
        recent_actions = [
            a for a in actions
            if (datetime.now() - datetime.fromisoformat(a['timestamp'])).total_seconds() < 300
        ]
        
        if len(recent_actions) > 10:
            event = SecurityEvent(
                event_id=f"suspicious_{datetime.now().timestamp()}",
                event_type=SecurityEventType.SUSPICIOUS_ACTIVITY,
                user_id=user_id,
                resource='multiple',
                action='rapid_access',
                timestamp=datetime.now(),
                ip_address=None,
                severity='high'
            )
            suspicious_events.append(event)
            self.security_events.append(event)
        
        return suspicious_events
    
    def generate_audit_report(self, start_date: datetime,
                              end_date: datetime) -> Dict:
        """Genera reporte de auditor√≠a"""
        
        events_in_range = [
            e for e in self.security_events
            if start_date <= e.timestamp <= end_date
        ]
        
        access_logs_in_range = [
            log for log in self.access_logs
            if start_date <= datetime.fromisoformat(log['timestamp']) <= end_date
        ]
        
        return {
            'period': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat()
            },
            'total_security_events': len(events_in_range),
            'events_by_type': {
                event_type.value: len([e for e in events_in_range if e.event_type == event_type])
                for event_type in SecurityEventType
            },
            'events_by_severity': {
                severity: len([e for e in events_in_range if e.severity == severity])
                for severity in ['low', 'medium', 'high', 'critical']
            },
            'total_access_attempts': len(access_logs_in_range),
            'denied_access': len([log for log in access_logs_in_range if not log['allowed']]),
            'critical_events': [
                {
                    'event_id': e.event_id,
                    'type': e.event_type.value,
                    'user_id': e.user_id,
                    'severity': e.severity,
                    'timestamp': e.timestamp.isoformat()
                }
                for e in events_in_range if e.severity in ['high', 'critical']
            ]
        }
    
    def gdpr_data_export(self, user_id: str) -> Dict:
        """Exporta datos de usuario (GDPR)"""
        
        # En producci√≥n: exportar todos los datos del usuario
        return {
            'user_id': user_id,
            'exported_at': datetime.now().isoformat(),
            'data': {
                'profile': {},
                'activity': [],
                'preferences': {}
            }
        }
    
    def gdpr_data_deletion(self, user_id: str) -> Dict:
        """Elimina datos de usuario (GDPR)"""
        
        # En producci√≥n: eliminar todos los datos del usuario
        event = SecurityEvent(
            event_id=f"gdpr_deletion_{datetime.now().timestamp()}",
            event_type=SecurityEventType.DATA_DELETION,
            user_id=user_id,
            resource='user_data',
            action='delete',
            timestamp=datetime.now(),
            ip_address=None,
            severity='high'
        )
        
        self.security_events.append(event)
        
        return {
            'user_id': user_id,
            'deleted_at': datetime.now().isoformat(),
            'status': 'completed'
        }

if __name__ == '__main__':
    security = AdvancedSecurityDataProtection()
    
    # Verificar permisos
    has_access = security.check_access_permission('user123', 'carousel_1', 'delete')
    print(f"Acceso permitido: {has_access}")
    
    # Reporte de auditor√≠a
    start = datetime.now() - timedelta(days=7)
    end = datetime.now()
    audit = security.generate_audit_report(start, end)
    print(f"\nReporte de auditor√≠a:")
    print(f"  Eventos de seguridad: {audit['total_security_events']}")
    print(f"  Accesos denegados: {audit['denied_access']}")
```

---

## üåê Sistema de Localizaci√≥n y Traducci√≥n Autom√°tica Multi-Idioma

### Script de Localizaci√≥n Avanzada

**Python**: `scripts/advanced_localization_translation.py`

```python
#!/usr/bin/env python3
"""
Sistema de localizaci√≥n y traducci√≥n autom√°tica multi-idioma
- Traducci√≥n autom√°tica con IA (GPT)
- Adaptaci√≥n cultural (monedas, formatos, referencias)
- Testing de performance por mercado
- Gesti√≥n de assets localizados
- Detecci√≥n de idioma del usuario
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class LocalizedContent:
    """Contenido localizado"""
    locale: str
    original_carousel_id: str
    localized_headline: str
    localized_subheadline: str
    localized_cta: str
    cultural_adaptations: Dict
    translation_quality_score: float

class AdvancedLocalizationTranslation:
    """Sistema de localizaci√≥n avanzada"""
    
    def __init__(self):
        self.localizations = {}
        self.supported_locales = ['es', 'en', 'pt', 'fr', 'de', 'it']
        self.cultural_adaptations = {
            'es': {
                'currency': 'EUR',
                'date_format': 'DD/MM/YYYY',
                'number_format': '1.234,56',
                'time_format': '24h'
            },
            'en': {
                'currency': 'USD',
                'date_format': 'MM/DD/YYYY',
                'number_format': '1,234.56',
                'time_format': '12h'
            },
            'pt': {
                'currency': 'EUR',
                'date_format': 'DD/MM/YYYY',
                'number_format': '1.234,56',
                'time_format': '24h'
            }
        }
    
    def localize_carousel(self, carousel_id: str, source_locale: str,
                         target_locale: str, carousel_data: Dict) -> LocalizedContent:
        """Localiza carrusel a otro idioma"""
        
        # Traducir contenido
        localized_headline = self._translate_text(
            carousel_data.get('headline', ''),
            source_locale,
            target_locale
        )
        
        localized_subheadline = self._translate_text(
            carousel_data.get('subheadline', ''),
            source_locale,
            target_locale
        )
        
        localized_cta = self._translate_text(
            carousel_data.get('cta', ''),
            source_locale,
            target_locale
        )
        
        # Adaptaciones culturales
        cultural_adaptations = self._apply_cultural_adaptations(
            carousel_data,
            target_locale
        )
        
        # Evaluar calidad de traducci√≥n
        translation_quality = self._evaluate_translation_quality(
            localized_headline,
            localized_subheadline,
            localized_cta
        )
        
        localized = LocalizedContent(
            locale=target_locale,
            original_carousel_id=carousel_id,
            localized_headline=localized_headline,
            localized_subheadline=localized_subheadline,
            localized_cta=localized_cta,
            cultural_adaptations=cultural_adaptations,
            translation_quality_score=translation_quality
        )
        
        key = f"{carousel_id}_{target_locale}"
        self.localizations[key] = localized
        
        return localized
    
    def _translate_text(self, text: str, source: str, target: str) -> str:
        """Traduce texto"""
        
        # En producci√≥n: usar GPT-4 o servicio de traducci√≥n
        # Por ahora: traducci√≥n simplificada
        
        translations = {
            ('es', 'en'): {
                'Aprende IA aplicada': 'Learn Applied AI',
                'Transforma tu carrera': 'Transform your career',
                '√önete ahora': 'Join now'
            },
            ('en', 'es'): {
                'Learn Applied AI': 'Aprende IA aplicada',
                'Transform your career': 'Transforma tu carrera',
                'Join now': '√önete ahora'
            }
        }
        
        translation_map = translations.get((source, target), {})
        return translation_map.get(text, f"[{target}] {text}")
    
    def _apply_cultural_adaptations(self, carousel_data: Dict,
                                   locale: str) -> Dict:
        """Aplica adaptaciones culturales"""
        
        adaptations = self.cultural_adaptations.get(locale, {})
        
        adapted = {
            'currency_symbol': self._get_currency_symbol(adaptations.get('currency', 'USD')),
            'price_format': adaptations.get('number_format', '1,234.56'),
            'date_format': adaptations.get('date_format', 'MM/DD/YYYY')
        }
        
        # Adaptar precios si existen
        if 'price' in carousel_data:
            price = carousel_data['price']
            currency = adaptations.get('currency', 'USD')
            adapted['price'] = self._convert_currency(price, currency)
        
        return adapted
    
    def _get_currency_symbol(self, currency: str) -> str:
        """Obtiene s√≠mbolo de moneda"""
        
        symbols = {
            'EUR': '‚Ç¨',
            'USD': '$',
            'GBP': '¬£',
            'BRL': 'R$'
        }
        
        return symbols.get(currency, '$')
    
    def _convert_currency(self, amount: float, target_currency: str) -> float:
        """Convierte moneda"""
        
        # En producci√≥n: usar API de cambio de divisas
        # Por ahora: conversi√≥n simplificada
        rates = {
            'EUR': 1.0,
            'USD': 1.1,
            'GBP': 0.85
        }
        
        rate = rates.get(target_currency, 1.0)
        return amount * rate
    
    def _evaluate_translation_quality(self, headline: str, subheadline: str,
                                     cta: str) -> float:
        """Eval√∫a calidad de traducci√≥n"""
        
        score = 0.5  # Base
        
        # Verificar que no haya texto original sin traducir
        if not any(char in headline for char in '[]'):
            score += 0.2
        
        if len(headline) > 10 and len(subheadline) > 10:
            score += 0.2
        
        if len(cta) > 5:
            score += 0.1
        
        return min(1.0, score)
    
    def detect_user_language(self, user_data: Dict) -> str:
        """Detecta idioma del usuario"""
        
        # Detectar desde m√∫ltiples fuentes
        if 'language_preference' in user_data:
            return user_data['language_preference']
        
        if 'browser_language' in user_data:
            browser_lang = user_data['browser_language']
            # Extraer c√≥digo de idioma (ej: 'es-ES' -> 'es')
            return browser_lang.split('-')[0] if '-' in browser_lang else browser_lang[:2]
        
        if 'location' in user_data:
            location_languages = {
                'Spain': 'es',
                'Mexico': 'es',
                'United States': 'en',
                'Brazil': 'pt',
                'France': 'fr',
                'Germany': 'de'
            }
            return location_languages.get(user_data['location'], 'en')
        
        return 'en'  # Default
    
    def get_localized_performance(self, carousel_id: str, locale: str) -> Dict:
        """Obtiene performance por mercado localizado"""
        
        # En producci√≥n: obtener m√©tricas reales
        return {
            'carousel_id': carousel_id,
            'locale': locale,
            'impressions': 0,
            'clicks': 0,
            'conversions': 0,
            'ctr': 0.0,
            'conversion_rate': 0.0
        }
    
    def generate_localization_report(self) -> Dict:
        """Genera reporte de localizaci√≥n"""
        
        return {
            'total_localizations': len(self.localizations),
            'locales_covered': list(set(l.locale for l in self.localizations.values())),
            'average_quality_score': sum(l.translation_quality_score for l in self.localizations.values()) / len(self.localizations) if self.localizations else 0,
            'localizations_by_locale': {
                locale: len([l for l in self.localizations.values() if l.locale == locale])
                for locale in self.supported_locales
            }
        }

if __name__ == '__main__':
    localizer = AdvancedLocalizationTranslation()
    
    # Localizar carrusel
    carousel_data = {
        'headline': 'Aprende IA aplicada',
        'subheadline': 'Transforma tu carrera',
        'cta': '√önete ahora',
        'price': 299.0
    }
    
    localized = localizer.localize_carousel('curso_ia_1', 'es', 'en', carousel_data)
    
    print(f"Localizaci√≥n creada:")
    print(f"  Headline: {localized.localized_headline}")
    print(f"  CTA: {localized.localized_cta}")
    print(f"  Calidad traducci√≥n: {localized.translation_quality_score:.1%}")
    print(f"  Adaptaciones: {localized.cultural_adaptations}")
```

---

## üéØ Sistema de Optimizaci√≥n Autom√°tica Basada en ML

### Script de Auto-Optimizaci√≥n con Machine Learning

**Python**: `scripts/ml_auto_optimization_engine.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n autom√°tica basada en ML
- Aprendizaje autom√°tico de patrones de √©xito
- Auto-optimizaci√≥n de headlines, CTAs, visuals
- Predicci√≥n de variantes ganadoras
- Optimizaci√≥n continua
- Feature importance analysis
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import numpy as np

@dataclass
class MLPrediction:
    """Predicci√≥n ML"""
    carousel_id: str
    predicted_ctr: float
    predicted_engagement: float
    predicted_conversion: float
    confidence: float
    recommended_changes: List[str]

class MLAutoOptimizationEngine:
    """Motor de auto-optimizaci√≥n ML"""
    
    def __init__(self):
        self.models = {}
        self.training_data = []
        self.feature_importance = {}
    
    def train_model(self, training_data: List[Dict]) -> Dict:
        """Entrena modelo ML"""
        
        # En producci√≥n: usar scikit-learn, XGBoost, etc.
        # Por ahora: modelo simplificado
        
        # Extraer features
        features = self._extract_features(training_data)
        
        # Entrenar (simulado)
        model_info = {
            'model_id': f"model_{datetime.now().timestamp()}",
            'trained_at': datetime.now().isoformat(),
            'training_samples': len(training_data),
            'features': list(features[0].keys()) if features else [],
            'accuracy': 0.85  # Simulado
        }
        
        self.models[model_info['model_id']] = model_info
        self.training_data.extend(training_data)
        
        # Calcular feature importance
        self.feature_importance = self._calculate_feature_importance(training_data)
        
        return model_info
    
    def _extract_features(self, data: List[Dict]) -> List[Dict]:
        """Extrae features de datos de entrenamiento"""
        
        features = []
        
        for record in data:
            feature_set = {
                'headline_length': len(record.get('headline', '')),
                'headline_words': len(record.get('headline', '').split()),
                'cta_length': len(record.get('cta', '')),
                'has_numbers': any(char.isdigit() for char in record.get('headline', '')),
                'has_urgency_words': self._has_urgency_words(record.get('headline', '')),
                'visual_style': record.get('visual_style', 'standard'),
                'variant_type': record.get('variant_type', 'standard')
            }
            features.append(feature_set)
        
        return features
    
    def _has_urgency_words(self, text: str) -> int:
        """Detecta palabras de urgencia"""
        
        urgency_words = ['ahora', 'urgente', 'limitado', 'solo hoy', 'r√°pido']
        return 1 if any(word in text.lower() for word in urgency_words) else 0
    
    def _calculate_feature_importance(self, data: List[Dict]) -> Dict:
        """Calcula importancia de features"""
        
        # En producci√≥n: usar feature importance del modelo
        # Por ahora: an√°lisis simplificado basado en correlaciones
        
        return {
            'headline_length': 0.25,
            'cta_style': 0.20,
            'visual_style': 0.18,
            'has_numbers': 0.15,
            'has_urgency_words': 0.12,
            'variant_type': 0.10
        }
    
    def predict_performance(self, carousel_id: str, carousel_data: Dict) -> MLPrediction:
        """Predice performance usando ML"""
        
        # Extraer features
        features = self._extract_features([carousel_data])[0]
        
        # Predecir (simulado)
        predicted_ctr = self._predict_ctr_from_features(features)
        predicted_engagement = self._predict_engagement_from_features(features)
        predicted_conversion = self._predict_conversion_from_features(features)
        
        # Generar recomendaciones
        recommended_changes = self._generate_optimization_recommendations(
            features, predicted_ctr, predicted_engagement
        )
        
        # Calcular confianza
        confidence = self._calculate_confidence(len(self.training_data))
        
        prediction = MLPrediction(
            carousel_id=carousel_id,
            predicted_ctr=predicted_ctr,
            predicted_engagement=predicted_engagement,
            predicted_conversion=predicted_conversion,
            confidence=confidence,
            recommended_changes=recommended_changes
        )
        
        return prediction
    
    def _predict_ctr_from_features(self, features: Dict) -> float:
        """Predice CTR desde features"""
        
        # Modelo simplificado basado en feature importance
        base_ctr = 3.0
        
        # Ajustes seg√∫n features
        if features.get('headline_length', 0) in range(30, 70):
            base_ctr += 1.0
        
        if features.get('has_numbers', 0):
            base_ctr += 0.5
        
        if features.get('has_urgency_words', 0):
            base_ctr += 0.8
        
        return base_ctr
    
    def _predict_engagement_from_features(self, features: Dict) -> float:
        """Predice engagement desde features"""
        
        base_engagement = 5.0
        
        if features.get('visual_style') == 'bold':
            base_engagement += 2.0
        
        if features.get('has_numbers', 0):
            base_engagement += 1.5
        
        return base_engagement
    
    def _predict_conversion_from_features(self, features: Dict) -> float:
        """Predice conversi√≥n desde features"""
        
        base_conversion = 4.0
        
        if features.get('cta_length', 0) in range(8, 25):
            base_conversion += 1.5
        
        if features.get('variant_type') == 'urgency':
            base_conversion += 2.0
        
        return base_conversion
    
    def _generate_optimization_recommendations(self, features: Dict,
                                             predicted_ctr: float,
                                             predicted_engagement: float) -> List[str]:
        """Genera recomendaciones de optimizaci√≥n"""
        
        recommendations = []
        
        if predicted_ctr < 3.0:
            recommendations.append("Ajustar longitud de headline (30-70 caracteres √≥ptimo)")
            recommendations.append("Considerar agregar n√∫meros o datos espec√≠ficos")
        
        if predicted_engagement < 6.0:
            recommendations.append("Mejorar estilo visual (bold/gradient aumentan engagement)")
            recommendations.append("Agregar elementos visuales m√°s llamativos")
        
        if features.get('cta_length', 0) < 8:
            recommendations.append("CTA muy corto, expandir a 8-25 caracteres")
        
        if not features.get('has_urgency_words', 0):
            recommendations.append("Considerar agregar palabras de urgencia para aumentar CTR")
        
        return recommendations
    
    def _calculate_confidence(self, training_samples: int) -> float:
        """Calcula confianza de predicci√≥n"""
        
        if training_samples < 10:
            return 0.3
        elif training_samples < 50:
            return 0.6
        elif training_samples < 200:
            return 0.8
        else:
            return 0.95
    
    def auto_optimize_carousel(self, carousel_id: str, base_data: Dict) -> Dict:
        """Auto-optimiza carrusel usando ML"""
        
        # Predecir performance actual
        current_prediction = self.predict_performance(carousel_id, base_data)
        
        # Generar variantes optimizadas
        optimized_variants = []
        
        # Variante 1: Optimizar headline
        if current_prediction.predicted_ctr < 4.0:
            optimized_data = base_data.copy()
            optimized_data['headline'] = self._optimize_headline(base_data.get('headline', ''))
            optimized_variant = self.predict_performance(f"{carousel_id}_opt1", optimized_data)
            optimized_variants.append(optimized_variant)
        
        # Variante 2: Optimizar CTA
        if current_prediction.predicted_conversion < 5.0:
            optimized_data = base_data.copy()
            optimized_data['cta'] = self._optimize_cta(base_data.get('cta', ''))
            optimized_variant = self.predict_performance(f"{carousel_id}_opt2", optimized_data)
            optimized_variants.append(optimized_variant)
        
        # Seleccionar mejor variante
        best_variant = max(optimized_variants, key=lambda v: v.predicted_ctr + v.predicted_conversion) if optimized_variants else None
        
        return {
            'carousel_id': carousel_id,
            'current_prediction': {
                'ctr': current_prediction.predicted_ctr,
                'engagement': current_prediction.predicted_engagement,
                'conversion': current_prediction.predicted_conversion
            },
            'best_optimized_variant': {
                'carousel_id': best_variant.carousel_id if best_variant else None,
                'predicted_improvement': {
                    'ctr': (best_variant.predicted_ctr - current_prediction.predicted_ctr) if best_variant else 0,
                    'conversion': (best_variant.predicted_conversion - current_prediction.predicted_conversion) if best_variant else 0
                },
                'recommended_changes': best_variant.recommended_changes if best_variant else []
            } if best_variant else None
        }
    
    def _optimize_headline(self, headline: str) -> str:
        """Optimiza headline usando ML insights"""
        
        # Agregar elementos que mejoran performance seg√∫n feature importance
        if len(headline) < 30:
            headline += " - Descubre c√≥mo"
        
        if not any(char.isdigit() for char in headline):
            headline = f"500+ {headline.lower()}"
        
        return headline
    
    def _optimize_cta(self, cta: str) -> str:
        """Optimiza CTA usando ML insights"""
        
        if len(cta) < 8:
            cta = "√önete ahora y transforma tu carrera"
        
        return cta
    
    def get_feature_importance_report(self) -> Dict:
        """Obtiene reporte de importancia de features"""
        
        return {
            'feature_importance': self.feature_importance,
            'top_features': sorted(
                self.feature_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )[:5],
            'insights': self._generate_feature_insights()
        }
    
    def _generate_feature_insights(self) -> List[str]:
        """Genera insights de features"""
        
        insights = []
        
        top_feature = max(self.feature_importance.items(), key=lambda x: x[1])
        insights.append(f"Feature m√°s importante: {top_feature[0]} ({top_feature[1]:.1%})")
        
        if 'has_numbers' in self.feature_importance and self.feature_importance['has_numbers'] > 0.1:
            insights.append("N√∫meros en headlines aumentan significativamente el CTR")
        
        if 'has_urgency_words' in self.feature_importance and self.feature_importance['has_urgency_words'] > 0.1:
            insights.append("Palabras de urgencia mejoran el engagement")
        
        return insights

if __name__ == '__main__':
    engine = MLAutoOptimizationEngine()
    
    # Entrenar modelo
    training_data = [
        {
            'headline': 'Aprende IA aplicada',
            'cta': '√önete ahora',
            'visual_style': 'bold',
            'variant_type': 'social_proof',
            'ctr': 4.5,
            'engagement': 8.0,
            'conversion': 5.5
        }
    ]
    
    model_info = engine.train_model(training_data)
    print(f"Modelo entrenado: {model_info['model_id']}")
    
    # Predecir
    carousel_data = {
        'headline': 'Aprende IA',
        'cta': '√önete',
        'visual_style': 'standard',
        'variant_type': 'standard'
    }
    
    prediction = engine.predict_performance('curso_ia_1', carousel_data)
    print(f"\nPredicci√≥n ML:")
    print(f"  CTR predicho: {prediction.predicted_ctr:.2f}%")
    print(f"  Engagement: {prediction.predicted_engagement:.1f}%")
    print(f"  Confianza: {prediction.confidence:.0%}")
    
    # Auto-optimizar
    optimization = engine.auto_optimize_carousel('curso_ia_1', carousel_data)
    print(f"\nOptimizaci√≥n autom√°tica:")
    if optimization['best_optimized_variant']:
        print(f"  Mejora CTR: +{optimization['best_optimized_variant']['predicted_improvement']['ctr']:.2f}%")
```

---

## üé® Sistema de Generaci√≥n Autom√°tica de Variantes Visuales con IA

### Script de Generaci√≥n Visual IA

**Python**: `scripts/ai_visual_variant_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de variantes visuales con IA
- Generaci√≥n de variantes visuales usando DALL-E/Midjourney
- An√°lisis de estilo visual existente
- Optimizaci√≥n de composici√≥n y colores
- Generaci√≥n de m√∫ltiples variantes autom√°ticamente
- Testing de performance visual
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class VisualVariant:
    """Variante visual generada"""
    variant_id: str
    carousel_id: str
    visual_url: str
    style: str
    color_palette: List[str]
    composition_score: float
    brand_alignment_score: float

class AIVisualVariantGenerator:
    """Generador de variantes visuales con IA"""
    
    def __init__(self):
        self.generated_variants = {}
        self.visual_styles = {
            'bold': {
                'description': 'Colores vibrantes, alto contraste',
                'color_intensity': 'high',
                'composition': 'dynamic'
            },
            'minimalist': {
                'description': 'Espacios en blanco, colores sutiles',
                'color_intensity': 'low',
                'composition': 'clean'
            },
            'professional': {
                'description': 'Paleta corporativa, dise√±o limpio',
                'color_intensity': 'medium',
                'composition': 'balanced'
            },
            'energetic': {
                'description': 'Gradientes, movimiento, dinamismo',
                'color_intensity': 'high',
                'composition': 'dynamic'
            }
        }
    
    def generate_visual_variants(self, carousel_id: str, base_visual: Dict,
                                 variant_count: int = 5) -> List[VisualVariant]:
        """Genera variantes visuales usando IA"""
        
        variants = []
        
        # Analizar estilo base
        base_style = self._analyze_visual_style(base_visual)
        
        # Generar variantes en diferentes estilos
        styles_to_try = ['bold', 'minimalist', 'professional', 'energetic']
        
        for i, style in enumerate(styles_to_try[:variant_count]):
            variant_data = self._generate_variant_for_style(
                carousel_id,
                base_visual,
                style,
                i
            )
            
            variant = VisualVariant(
                variant_id=f"{carousel_id}_visual_{style}_{i}",
                carousel_id=carousel_id,
                visual_url=variant_data['url'],  # En producci√≥n: URL real generada
                style=style,
                color_palette=variant_data['colors'],
                composition_score=variant_data['composition_score'],
                brand_alignment_score=variant_data['brand_alignment']
            )
            
            variants.append(variant)
            self.generated_variants[variant.variant_id] = variant
        
        return variants
    
    def _analyze_visual_style(self, visual: Dict) -> Dict:
        """Analiza estilo visual existente"""
        
        # En producci√≥n: usar visi√≥n por computadora o an√°lisis de imagen
        return {
            'dominant_colors': visual.get('colors', []),
            'composition_type': visual.get('composition', 'balanced'),
            'color_intensity': visual.get('intensity', 'medium'),
            'visual_elements': visual.get('elements', [])
        }
    
    def _generate_variant_for_style(self, carousel_id: str, base_visual: Dict,
                                   style: str, index: int) -> Dict:
        """Genera variante para estilo espec√≠fico"""
        
        style_config = self.visual_styles.get(style, {})
        
        # En producci√≥n: llamar a DALL-E API con prompt optimizado
        prompt = self._create_image_generation_prompt(
            base_visual,
            style,
            style_config
        )
        
        # Simular generaci√≥n
        variant_data = {
            'url': f"https://example.com/generated/{carousel_id}_{style}_{index}.png",
            'colors': self._generate_color_palette(style),
            'composition_score': self._calculate_composition_score(style),
            'brand_alignment': self._calculate_brand_alignment(style, base_visual)
        }
        
        return variant_data
    
    def _create_image_generation_prompt(self, base_visual: Dict, style: str,
                                     style_config: Dict) -> str:
        """Crea prompt para generaci√≥n de imagen"""
        
        base_description = base_visual.get('description', 'social media carousel')
        
        style_prompts = {
            'bold': f"Bold, vibrant colors, high contrast, dynamic composition, {base_description}",
            'minimalist': f"Minimalist design, white space, subtle colors, clean composition, {base_description}",
            'professional': f"Professional, corporate style, balanced composition, {base_description}",
            'energetic': f"Energetic, gradients, motion, dynamic, vibrant, {base_description}"
        }
        
        return style_prompts.get(style, base_description)
    
    def _generate_color_palette(self, style: str) -> List[str]:
        """Genera paleta de colores para estilo"""
        
        palettes = {
            'bold': ['#FF6B6B', '#4ECDC4', '#FFE66D', '#FF8C94'],
            'minimalist': ['#F5F5F5', '#333333', '#CCCCCC', '#FFFFFF'],
            'professional': ['#2C3E50', '#3498DB', '#E74C3C', '#95A5A6'],
            'energetic': ['#FF5722', '#FFC107', '#2196F3', '#9C27B0']
        }
        
        return palettes.get(style, ['#000000', '#FFFFFF'])
    
    def _calculate_composition_score(self, style: str) -> float:
        """Calcula score de composici√≥n"""
        
        # Estilos din√°micos y balanced tienen mejor composici√≥n
        composition_scores = {
            'bold': 0.85,
            'minimalist': 0.75,
            'professional': 0.80,
            'energetic': 0.90
        }
        
        return composition_scores.get(style, 0.70)
    
    def _calculate_brand_alignment(self, style: str, base_visual: Dict) -> float:
        """Calcula alineaci√≥n con brand"""
        
        # En producci√≥n: comparar con brand guidelines
        base_score = 0.70
        
        if style == 'professional':
            base_score += 0.15  # Mejor alineaci√≥n con brand corporativo
        
        return min(1.0, base_score)
    
    def optimize_visual_for_performance(self, variant_id: str,
                                        performance_data: Dict) -> Dict:
        """Optimiza visual basado en performance"""
        
        if variant_id not in self.generated_variants:
            return {'status': 'error', 'message': 'Variant not found'}
        
        variant = self.generated_variants[variant_id]
        
        # Analizar qu√© elementos funcionaron mejor
        performance_insights = self._analyze_visual_performance(
            variant,
            performance_data
        )
        
        # Generar recomendaciones
        recommendations = self._generate_visual_recommendations(
            variant,
            performance_insights
        )
        
        return {
            'variant_id': variant_id,
            'performance_insights': performance_insights,
            'recommendations': recommendations,
            'optimized_variant': self._create_optimized_variant(
                variant,
                recommendations
            )
        }
    
    def _analyze_visual_performance(self, variant: VisualVariant,
                                   performance_data: Dict) -> Dict:
        """Analiza performance de variante visual"""
        
        ctr = performance_data.get('ctr', 0)
        engagement = performance_data.get('engagement', 0)
        
        return {
            'ctr_score': 'high' if ctr > 4.0 else 'medium' if ctr > 2.5 else 'low',
            'engagement_score': 'high' if engagement > 7.0 else 'medium' if engagement > 4.0 else 'low',
            'best_performing_elements': self._identify_best_elements(variant, performance_data)
        }
    
    def _identify_best_elements(self, variant: VisualVariant,
                               performance_data: Dict) -> List[str]:
        """Identifica elementos que funcionan mejor"""
        
        elements = []
        
        if variant.composition_score > 0.8:
            elements.append('high_composition_score')
        
        if len([c for c in variant.color_palette if self._is_vibrant_color(c)]) > 2:
            elements.append('vibrant_colors')
        
        return elements
    
    def _is_vibrant_color(self, color: str) -> bool:
        """Verifica si color es vibrante"""
        
        # Simplificado: en producci√≥n usar an√°lisis de color
        vibrant_colors = ['FF', 'FF6B', 'FFC1', '2196']
        return any(vc in color.upper() for vc in vibrant_colors)
    
    def _generate_visual_recommendations(self, variant: VisualVariant,
                                       insights: Dict) -> List[str]:
        """Genera recomendaciones visuales"""
        
        recommendations = []
        
        if insights['ctr_score'] == 'low':
            recommendations.append("Aumentar contraste de colores para mejorar CTR")
            recommendations.append("Agregar elementos visuales m√°s llamativos")
        
        if insights['engagement_score'] == 'low':
            recommendations.append("Optimizar composici√≥n para aumentar engagement")
            recommendations.append("Considerar estilo m√°s din√°mico")
        
        return recommendations
    
    def _create_optimized_variant(self, variant: VisualVariant,
                                 recommendations: List[str]) -> Dict:
        """Crea variante optimizada basada en recomendaciones"""
        
        # En producci√≥n: generar nueva variante con cambios aplicados
        return {
            'variant_id': f"{variant.variant_id}_optimized",
            'applied_changes': recommendations,
            'predicted_improvement': {
                'ctr': '+1.5%',
                'engagement': '+2.0%'
            }
        }

if __name__ == '__main__':
    generator = AIVisualVariantGenerator()
    
    # Generar variantes
    base_visual = {
        'description': 'AI course carousel',
        'colors': ['#3498DB', '#2C3E50'],
        'composition': 'balanced'
    }
    
    variants = generator.generate_visual_variants('curso_ia_1', base_visual, variant_count=4)
    
    print(f"Variantes visuales generadas: {len(variants)}")
    for variant in variants:
        print(f"  - {variant.style}: Score {variant.composition_score:.2f}")
```

---

## üì± Sistema de Adaptaci√≥n Autom√°tica Multi-Dispositivo

### Script de Adaptaci√≥n Multi-Dispositivo

**Python**: `scripts/multi_device_adaptation.py`

```python
#!/usr/bin/env python3
"""
Sistema de adaptaci√≥n autom√°tica multi-dispositivo
- Detecci√≥n autom√°tica de dispositivo
- Optimizaci√≥n por tama√±o de pantalla
- Adaptaci√≥n de tipograf√≠as y espaciados
- Optimizaci√≥n de im√°genes por dispositivo
- Testing en m√∫ltiples dispositivos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

class DeviceType(Enum):
    MOBILE = "mobile"
    TABLET = "tablet"
    DESKTOP = "desktop"
    TV = "tv"

@dataclass
class DeviceProfile:
    """Perfil de dispositivo"""
    device_type: DeviceType
    screen_width: int
    screen_height: int
    pixel_density: float
    viewport_width: int
    viewport_height: int

class MultiDeviceAdaptation:
    """Sistema de adaptaci√≥n multi-dispositivo"""
    
    def __init__(self):
        self.device_profiles = {
            DeviceType.MOBILE: DeviceProfile(
                device_type=DeviceType.MOBILE,
                screen_width=375,
                screen_height=812,
                pixel_density=2.0,
                viewport_width=375,
                viewport_height=667
            ),
            DeviceType.TABLET: DeviceProfile(
                device_type=DeviceType.TABLET,
                screen_width=768,
                screen_height=1024,
                pixel_density=2.0,
                viewport_width=768,
                viewport_height=1024
            ),
            DeviceType.DESKTOP: DeviceProfile(
                device_type=DeviceType.DESKTOP,
                screen_width=1920,
                screen_height=1080,
                pixel_density=1.0,
                viewport_width=1920,
                viewport_height=1080
            )
        }
    
    def detect_device(self, user_agent: str, screen_width: int,
                     screen_height: int) -> DeviceType:
        """Detecta tipo de dispositivo"""
        
        # Detectar por tama√±o de pantalla
        if screen_width < 768:
            return DeviceType.MOBILE
        elif screen_width < 1024:
            return DeviceType.TABLET
        else:
            return DeviceType.DESKTOP
    
    def adapt_carousel_for_device(self, carousel_id: str, carousel_data: Dict,
                                  device_type: DeviceType) -> Dict:
        """Adapta carrusel para dispositivo"""
        
        device_profile = self.device_profiles.get(device_type)
        if not device_profile:
            return carousel_data
        
        adapted = carousel_data.copy()
        
        # Adaptar tipograf√≠a
        adapted['typography'] = self._adapt_typography(
            carousel_data.get('typography', {}),
            device_type
        )
        
        # Adaptar espaciados
        adapted['spacing'] = self._adapt_spacing(
            carousel_data.get('spacing', {}),
            device_type
        )
        
        # Adaptar im√°genes
        adapted['images'] = self._adapt_images(
            carousel_data.get('images', []),
            device_type,
            device_profile
        )
        
        # Adaptar layout
        adapted['layout'] = self._adapt_layout(
            carousel_data.get('layout', {}),
            device_type
        )
        
        return adapted
    
    def _adapt_typography(self, typography: Dict, device_type: DeviceType) -> Dict:
        """Adapta tipograf√≠a por dispositivo"""
        
        base_sizes = typography.get('font_sizes', {})
        
        multipliers = {
            DeviceType.MOBILE: 0.85,  # Reducir 15% en m√≥vil
            DeviceType.TABLET: 0.95,  # Reducir 5% en tablet
            DeviceType.DESKTOP: 1.0   # Tama√±o completo en desktop
        }
        
        multiplier = multipliers.get(device_type, 1.0)
        
        adapted_sizes = {}
        for element, size in base_sizes.items():
            adapted_sizes[element] = int(size * multiplier)
        
        return {
            'font_sizes': adapted_sizes,
            'line_height': typography.get('line_height', 1.5) * (1.0 + (1 - multiplier))
        }
    
    def _adapt_spacing(self, spacing: Dict, device_type: DeviceType) -> Dict:
        """Adapta espaciados por dispositivo"""
        
        multipliers = {
            DeviceType.MOBILE: 0.75,
            DeviceType.TABLET: 0.90,
            DeviceType.DESKTOP: 1.0
        }
        
        multiplier = multipliers.get(device_type, 1.0)
        
        adapted = {}
        for key, value in spacing.items():
            if isinstance(value, (int, float)):
                adapted[key] = int(value * multiplier)
            else:
                adapted[key] = value
        
        return adapted
    
    def _adapt_images(self, images: List[Dict], device_type: DeviceType,
                     device_profile: DeviceProfile) -> List[Dict]:
        """Adapta im√°genes por dispositivo"""
        
        adapted_images = []
        
        for image in images:
            adapted_image = image.copy()
            
            # Calcular dimensiones optimizadas
            original_width = image.get('width', 1200)
            original_height = image.get('height', 627)
            
            # Ratio de aspecto
            aspect_ratio = original_height / original_width
            
            # Ancho m√°ximo por dispositivo
            max_widths = {
                DeviceType.MOBILE: device_profile.screen_width,
                DeviceType.TABLET: device_profile.screen_width,
                DeviceType.DESKTOP: 1200
            }
            
            max_width = max_widths.get(device_type, 1200)
            optimized_width = min(original_width, max_width)
            optimized_height = int(optimized_width * aspect_ratio)
            
            adapted_image['optimized_width'] = optimized_width
            adapted_image['optimized_height'] = optimized_height
            adapted_image['device'] = device_type.value
            adapted_image['url'] = self._generate_optimized_image_url(
                image.get('url', ''),
                optimized_width,
                optimized_height
            )
            
            adapted_images.append(adapted_image)
        
        return adapted_images
    
    def _generate_optimized_image_url(self, base_url: str, width: int,
                                    height: int) -> str:
        """Genera URL de imagen optimizada"""
        
        # En producci√≥n: usar CDN con par√°metros de resize
        return f"{base_url}?w={width}&h={height}&fit=crop"
    
    def _adapt_layout(self, layout: Dict, device_type: DeviceType) -> Dict:
        """Adapta layout por dispositivo"""
        
        adapted = layout.copy()
        
        # M√≥vil: layout vertical
        if device_type == DeviceType.MOBILE:
            adapted['orientation'] = 'vertical'
            adapted['columns'] = 1
            adapted['padding'] = layout.get('padding', 20) * 0.8
        
        # Tablet: layout h√≠brido
        elif device_type == DeviceType.TABLET:
            adapted['orientation'] = 'mixed'
            adapted['columns'] = 2
            adapted['padding'] = layout.get('padding', 20) * 0.9
        
        # Desktop: layout horizontal
        else:
            adapted['orientation'] = 'horizontal'
            adapted['columns'] = 3
            adapted['padding'] = layout.get('padding', 20)
        
        return adapted
    
    def generate_device_specific_assets(self, carousel_id: str,
                                       carousel_data: Dict) -> Dict:
        """Genera assets espec√≠ficos por dispositivo"""
        
        assets = {}
        
        for device_type in DeviceType:
            if device_type == DeviceType.TV:  # Saltar TV por ahora
                continue
            
            adapted = self.adapt_carousel_for_device(
                carousel_id,
                carousel_data,
                device_type
            )
            
            assets[device_type.value] = {
                'carousel_id': f"{carousel_id}_{device_type.value}",
                'device_type': device_type.value,
                'adapted_data': adapted,
                'file_urls': self._generate_device_files(adapted, device_type)
            }
        
        return assets
    
    def _generate_device_files(self, adapted_data: Dict,
                              device_type: DeviceType) -> Dict:
        """Genera URLs de archivos por dispositivo"""
        
        return {
            'carousel_svg': f"carousels/{adapted_data.get('carousel_id', '')}_{device_type.value}.svg",
            'carousel_png': f"carousels/{adapted_data.get('carousel_id', '')}_{device_type.value}.png",
            'images': [
                img.get('url', '') for img in adapted_data.get('images', [])
            ]
        }
    
    def test_across_devices(self, carousel_id: str) -> Dict:
        """Testea carrusel en m√∫ltiples dispositivos"""
        
        test_results = {}
        
        for device_type in [DeviceType.MOBILE, DeviceType.TABLET, DeviceType.DESKTOP]:
            device_profile = self.device_profiles.get(device_type)
            
            test_result = {
                'device_type': device_type.value,
                'viewport': {
                    'width': device_profile.viewport_width,
                    'height': device_profile.viewport_height
                },
                'tests': {
                    'typography_readable': True,
                    'images_loaded': True,
                    'layout_valid': True,
                    'touch_targets_adequate': device_type == DeviceType.MOBILE
                },
                'performance_score': self._calculate_device_performance(device_type)
            }
            
            test_results[device_type.value] = test_result
        
        return {
            'carousel_id': carousel_id,
            'device_tests': test_results,
            'overall_score': sum(t['performance_score'] for t in test_results.values()) / len(test_results)
        }
    
    def _calculate_device_performance(self, device_type: DeviceType) -> float:
        """Calcula score de performance por dispositivo"""
        
        scores = {
            DeviceType.MOBILE: 0.85,
            DeviceType.TABLET: 0.90,
            DeviceType.DESKTOP: 0.95
        }
        
        return scores.get(device_type, 0.80)

if __name__ == '__main__':
    adapter = MultiDeviceAdaptation()
    
    # Detectar dispositivo
    device = adapter.detect_device('Mozilla/5.0', 375, 812)
    print(f"Dispositivo detectado: {device.value}")
    
    # Adaptar carrusel
    carousel_data = {
        'carousel_id': 'curso_ia_1',
        'typography': {
            'font_sizes': {
                'headline': 48,
                'body': 16
            }
        },
        'spacing': {
            'padding': 40,
            'margin': 20
        },
        'images': [{
            'url': 'https://example.com/image.jpg',
            'width': 1200,
            'height': 627
        }],
        'layout': {
            'columns': 3,
            'padding': 20
        }
    }
    
    adapted = adapter.adapt_carousel_for_device('curso_ia_1', carousel_data, device)
    print(f"\nCarrusel adaptado para {device.value}")
    print(f"  Font size headline: {adapted['typography']['font_sizes']['headline']}")
    print(f"  Padding: {adapted['spacing']['padding']}")
```

---

## üîÑ Sistema de Sincronizaci√≥n y Versionado de Contenido

### Script de Sincronizaci√≥n de Contenido

**Python**: `scripts/content_sync_versioning.py`

```python
#!/usr/bin/env python3
"""
Sistema de sincronizaci√≥n y versionado de contenido
- Versionado sem√°ntico de carruseles
- Sincronizaci√≥n entre m√∫ltiples fuentes
- Resoluci√≥n de conflictos autom√°tica
- Historial de cambios completo
- Rollback a versiones anteriores
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class VersionChangeType(Enum):
    CREATED = "created"
    UPDATED = "updated"
    DELETED = "deleted"
    SYNCED = "synced"

@dataclass
class ContentVersion:
    """Versi√≥n de contenido"""
    version: str  # Semantic versioning (1.2.3)
    carousel_id: str
    content: Dict
    change_type: VersionChangeType
    changed_by: str
    changed_at: datetime
    change_notes: str

class ContentSyncVersioning:
    """Sistema de sincronizaci√≥n y versionado"""
    
    def __init__(self):
        self.versions = {}
        self.sync_sources = {}
    
    def create_version(self, carousel_id: str, content: Dict,
                      change_type: VersionChangeType, changed_by: str,
                      change_notes: str = "") -> ContentVersion:
        """Crea nueva versi√≥n"""
        
        # Determinar versi√≥n
        current_version = self._get_latest_version(carousel_id)
        new_version = self._increment_version(current_version, change_type)
        
        version = ContentVersion(
            version=new_version,
            carousel_id=carousel_id,
            content=content,
            change_type=change_type,
            changed_by=changed_by,
            changed_at=datetime.now(),
            change_notes=change_notes
        )
        
        # Guardar versi√≥n
        key = f"{carousel_id}_{new_version}"
        self.versions[key] = version
        
        return version
    
    def _get_latest_version(self, carousel_id: str) -> Optional[str]:
        """Obtiene √∫ltima versi√≥n"""
        
        versions_for_carousel = [
            v for k, v in self.versions.items()
            if k.startswith(f"{carousel_id}_")
        ]
        
        if not versions_for_carousel:
            return None
        
        latest = max(versions_for_carousel, key=lambda v: v.changed_at)
        return latest.version
    
    def _increment_version(self, current_version: Optional[str],
                          change_type: VersionChangeType) -> str:
        """Incrementa versi√≥n seg√∫n tipo de cambio"""
        
        if not current_version:
            return "1.0.0"
        
        major, minor, patch = map(int, current_version.split('.'))
        
        if change_type == VersionChangeType.CREATED:
            return f"{major + 1}.0.0"
        elif change_type == VersionChangeType.UPDATED:
            return f"{major}.{minor + 1}.0"
        else:
            return f"{major}.{minor}.{patch + 1}"
    
    def sync_from_source(self, carousel_id: str, source: str, content: Dict) -> Dict:
        """Sincroniza contenido desde fuente externa"""
        
        # Verificar cambios
        current_content = self._get_current_content(carousel_id)
        
        if current_content == content:
            return {
                'status': 'no_changes',
                'carousel_id': carousel_id,
                'source': source
            }
        
        # Detectar cambios
        changes = self._detect_changes(current_content, content)
        
        # Resolver conflictos si existen
        resolved_content = self._resolve_conflicts(
            current_content,
            content,
            changes
        )
        
        # Crear versi√≥n sincronizada
        version = self.create_version(
            carousel_id,
            resolved_content,
            VersionChangeType.SYNCED,
            source,
            f"Synced from {source}"
        )
        
        # Registrar sincronizaci√≥n
        self.sync_sources[f"{carousel_id}_{source}"] = {
            'last_sync': datetime.now().isoformat(),
            'version': version.version
        }
        
        return {
            'status': 'synced',
            'carousel_id': carousel_id,
            'version': version.version,
            'changes': changes,
            'conflicts_resolved': len([c for c in changes if c.get('conflict')])
        }
    
    def _get_current_content(self, carousel_id: str) -> Optional[Dict]:
        """Obtiene contenido actual"""
        
        latest_version = self._get_latest_version(carousel_id)
        if not latest_version:
            return None
        
        key = f"{carousel_id}_{latest_version}"
        version = self.versions.get(key)
        return version.content if version else None
    
    def _detect_changes(self, old_content: Dict, new_content: Dict) -> List[Dict]:
        """Detecta cambios entre versiones"""
        
        changes = []
        
        if not old_content:
            return [{'type': 'created', 'field': 'all'}]
        
        # Comparar campos
        all_keys = set(list(old_content.keys()) + list(new_content.keys()))
        
        for key in all_keys:
            old_value = old_content.get(key)
            new_value = new_content.get(key)
            
            if old_value != new_value:
                change = {
                    'field': key,
                    'old_value': old_value,
                    'new_value': new_value,
                    'type': 'updated'
                }
                
                # Detectar conflictos
                if old_value and new_value and old_value != new_value:
                    change['conflict'] = True
                
                changes.append(change)
        
        return changes
    
    def _resolve_conflicts(self, current: Dict, incoming: Dict,
                          changes: List[Dict]) -> Dict:
        """Resuelve conflictos autom√°ticamente"""
        
        resolved = current.copy()
        
        for change in changes:
            if change.get('conflict'):
                # Estrategia: preferir contenido m√°s reciente
                # En producci√≥n: l√≥gica m√°s sofisticada
                resolved[change['field']] = change['new_value']
            else:
                resolved[change['field']] = change['new_value']
        
        return resolved
    
    def rollback_to_version(self, carousel_id: str, target_version: str) -> Dict:
        """Hace rollback a versi√≥n anterior"""
        
        key = f"{carousel_id}_{target_version}"
        target_version_obj = self.versions.get(key)
        
        if not target_version_obj:
            return {
                'status': 'error',
                'message': f'Version {target_version} not found'
            }
        
        # Crear nueva versi√≥n con contenido de versi√≥n anterior
        rollback_version = self.create_version(
            carousel_id,
            target_version_obj.content,
            VersionChangeType.UPDATED,
            'system',
            f"Rollback to version {target_version}"
        )
        
        return {
            'status': 'rolled_back',
            'carousel_id': carousel_id,
            'from_version': self._get_latest_version(carousel_id),
            'to_version': target_version,
            'new_version': rollback_version.version
        }
    
    def get_version_history(self, carousel_id: str) -> List[Dict]:
        """Obtiene historial de versiones"""
        
        versions_for_carousel = [
            v for k, v in self.versions.items()
            if k.startswith(f"{carousel_id}_")
        ]
        
        # Ordenar por fecha
        sorted_versions = sorted(versions_for_carousel, key=lambda v: v.changed_at)
        
        return [
            {
                'version': v.version,
                'change_type': v.change_type.value,
                'changed_by': v.changed_by,
                'changed_at': v.changed_at.isoformat(),
                'change_notes': v.change_notes
            }
            for v in sorted_versions
        ]
    
    def compare_versions(self, carousel_id: str, version1: str,
                        version2: str) -> Dict:
        """Compara dos versiones"""
        
        key1 = f"{carousel_id}_{version1}"
        key2 = f"{carousel_id}_{version2}"
        
        v1 = self.versions.get(key1)
        v2 = self.versions.get(key2)
        
        if not v1 or not v2:
            return {'status': 'error', 'message': 'Version not found'}
        
        changes = self._detect_changes(v1.content, v2.content)
        
        return {
            'version1': version1,
            'version2': version2,
            'changes': changes,
            'total_changes': len(changes)
        }

if __name__ == '__main__':
    versioner = ContentSyncVersioning()
    
    # Crear versi√≥n inicial
    content = {
        'headline': 'Aprende IA aplicada',
        'cta': '√önete ahora'
    }
    
    v1 = versioner.create_version(
        'curso_ia_1',
        content,
        VersionChangeType.CREATED,
        'user123',
        'Initial version'
    )
    
    print(f"Versi√≥n creada: {v1.version}")
    
    # Actualizar
    content['headline'] = 'Domina IA aplicada'
    v2 = versioner.create_version(
        'curso_ia_1',
        content,
        VersionChangeType.UPDATED,
        'user123',
        'Updated headline'
    )
    
    print(f"Versi√≥n actualizada: {v2.version}")
    
    # Historial
    history = versioner.get_version_history('curso_ia_1')
    print(f"\nHistorial: {len(history)} versiones")
```

---

## üé¨ Sistema de Generaci√≥n Autom√°tica de Videos desde Carruseles

### Script de Conversi√≥n Carrusel a Video

**Python**: `scripts/carousel_to_video_advanced.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de videos desde carruseles
- Conversi√≥n de slides a video animado
- Transiciones autom√°ticas personalizables
- Sincronizaci√≥n de audio/voiceover
- Optimizaci√≥n por plataforma (Reels, TikTok, YouTube Shorts)
- Exportaci√≥n en m√∫ltiples formatos y resoluciones
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class VideoPlatform(Enum):
    INSTAGRAM_REELS = "instagram_reels"  # 1080x1920, 15-90s
    TIKTOK = "tiktok"  # 1080x1920, 15-60s
    YOUTUBE_SHORTS = "youtube_shorts"  # 1080x1920, 15-60s
    FACEBOOK_REELS = "facebook_reels"  # 1080x1920, 15-90s
    LINKEDIN_VIDEO = "linkedin_video"  # 1280x720, 3-10min

@dataclass
class VideoSpec:
    """Especificaciones de video"""
    platform: VideoPlatform
    width: int
    height: int
    duration: float  # segundos
    frame_rate: int
    format: str  # mp4, mov, etc.

@dataclass
class SlideAnimation:
    """Animaci√≥n de slide"""
    slide_index: int
    animation_type: str  # fade, slide, zoom, etc.
    duration: float
    transition_duration: float
    easing: str

class CarouselToVideoAdvanced:
    """Sistema avanzado de conversi√≥n carrusel a video"""
    
    def __init__(self):
        self.video_specs = {
            VideoPlatform.INSTAGRAM_REELS: VideoSpec(
                platform=VideoPlatform.INSTAGRAM_REELS,
                width=1080,
                height=1920,
                duration=30.0,
                frame_rate=30,
                format='mp4'
            ),
            VideoPlatform.TIKTOK: VideoSpec(
                platform=VideoPlatform.TIKTOK,
                width=1080,
                height=1920,
                duration=15.0,
                frame_rate=30,
                format='mp4'
            ),
            VideoPlatform.YOUTUBE_SHORTS: VideoSpec(
                platform=VideoPlatform.YOUTUBE_SHORTS,
                width=1080,
                height=1920,
                duration=60.0,
                frame_rate=30,
                format='mp4'
            ),
            VideoPlatform.LINKEDIN_VIDEO: VideoSpec(
                platform=VideoPlatform.LINKEDIN_VIDEO,
                width=1280,
                height=720,
                duration=180.0,
                frame_rate=30,
                format='mp4'
            )
        }
        self.animation_types = ['fade', 'slide_left', 'slide_right', 'slide_up', 'slide_down', 'zoom_in', 'zoom_out', 'none']
    
    def generate_video_from_carousel(self, carousel_id: str, carousel_data: Dict,
                                   platform: VideoPlatform, options: Optional[Dict] = None) -> Dict:
        """Genera video desde carrusel"""
        
        video_spec = self.video_specs.get(platform)
        if not video_spec:
            return {'status': 'error', 'message': 'Platform not supported'}
        
        options = options or {}
        
        # Obtener slides del carrusel
        slides = carousel_data.get('slides', [])
        if not slides:
            return {'status': 'error', 'message': 'No slides found'}
        
        # Calcular timing por slide
        slide_durations = self._calculate_slide_durations(
            len(slides),
            video_spec.duration,
            options.get('min_slide_duration', 2.0),
            options.get('max_slide_duration', 5.0)
        )
        
        # Generar animaciones
        animations = self._generate_animations(
            slides,
            slide_durations,
            options.get('animation_style', 'fade')
        )
        
        # Generar timeline
        timeline = self._create_video_timeline(slides, animations, video_spec)
        
        # Generar video (en producci√≥n: usar FFmpeg o similar)
        video_url = self._render_video(carousel_id, timeline, video_spec)
        
        return {
            'status': 'success',
            'carousel_id': carousel_id,
            'platform': platform.value,
            'video_url': video_url,
            'specifications': {
                'width': video_spec.width,
                'height': video_spec.height,
                'duration': video_spec.duration,
                'frame_rate': video_spec.frame_rate,
                'format': video_spec.format
            },
            'timeline': timeline,
            'slides_count': len(slides)
        }
    
    def _calculate_slide_durations(self, total_slides: int, total_duration: float,
                                   min_duration: float, max_duration: float) -> List[float]:
        """Calcula duraci√≥n por slide"""
        
        durations = []
        
        # Distribuir tiempo equitativamente con l√≠mites
        base_duration = total_duration / total_slides
        
        for _ in range(total_slides):
            duration = max(min_duration, min(max_duration, base_duration))
            durations.append(duration)
        
        # Ajustar √∫ltima slide para ajustar a duraci√≥n total
        total = sum(durations)
        if total != total_duration:
            durations[-1] += (total_duration - total)
        
        return durations
    
    def _generate_animations(self, slides: List[Dict], durations: List[float],
                          animation_style: str) -> List[SlideAnimation]:
        """Genera animaciones para slides"""
        
        animations = []
        
        for i, (slide, duration) in enumerate(zip(slides, durations)):
            # Primera slide: fade in
            if i == 0:
                anim_type = 'fade'
            # √öltima slide: fade out
            elif i == len(slides) - 1:
                anim_type = 'fade'
            # Slides intermedias: usar estilo especificado
            else:
                anim_type = animation_style
            
            # Calcular duraci√≥n de transici√≥n
            transition_duration = min(0.5, duration * 0.2)
            
            animation = SlideAnimation(
                slide_index=i,
                animation_type=anim_type,
                duration=duration,
                transition_duration=transition_duration,
                easing='ease-in-out'
            )
            
            animations.append(animation)
        
        return animations
    
    def _create_video_timeline(self, slides: List[Dict], animations: List[SlideAnimation],
                             video_spec: VideoSpec) -> List[Dict]:
        """Crea timeline del video"""
        
        timeline = []
        current_time = 0.0
        
        for i, (slide, animation) in enumerate(zip(slides, animations)):
            timeline_entry = {
                'slide_index': i,
                'start_time': current_time,
                'end_time': current_time + animation.duration,
                'animation': {
                    'type': animation.animation_type,
                    'duration': animation.duration,
                    'transition_duration': animation.transition_duration,
                    'easing': animation.easing
                },
                'content': {
                    'headline': slide.get('headline', ''),
                    'body': slide.get('body', ''),
                    'image_url': slide.get('image_url', '')
                }
            }
            
            timeline.append(timeline_entry)
            current_time += animation.duration
        
        return timeline
    
    def _render_video(self, carousel_id: str, timeline: List[Dict],
                    video_spec: VideoSpec) -> str:
        """Renderiza video"""
        
        # En producci√≥n: usar FFmpeg o librer√≠a de video
        # Por ahora: retornar URL simulada
        
        video_id = f"{carousel_id}_{video_spec.platform.value}_{datetime.now().timestamp()}"
        return f"https://cdn.example.com/videos/{video_id}.{video_spec.format}"
    
    def add_voiceover_to_video(self, video_id: str, voiceover_script: str,
                              voice_settings: Dict) -> Dict:
        """Agrega voiceover a video"""
        
        # En producci√≥n: usar TTS API (Google, Amazon Polly, etc.)
        
        return {
            'video_id': video_id,
            'voiceover_added': True,
            'voiceover_url': f"https://cdn.example.com/audio/{video_id}_voiceover.mp3",
            'script': voiceover_script,
            'settings': voice_settings
        }
    
    def add_background_music(self, video_id: str, music_track: str,
                            volume: float = 0.3) -> Dict:
        """Agrega m√∫sica de fondo"""
        
        return {
            'video_id': video_id,
            'music_added': True,
            'music_url': music_track,
            'volume': volume
        }
    
    def generate_multiplatform_videos(self, carousel_id: str,
                                    carousel_data: Dict) -> Dict:
        """Genera videos para m√∫ltiples plataformas"""
        
        platforms = [
            VideoPlatform.INSTAGRAM_REELS,
            VideoPlatform.TIKTOK,
            VideoPlatform.YOUTUBE_SHORTS
        ]
        
        videos = {}
        
        for platform in platforms:
            result = self.generate_video_from_carousel(
                carousel_id,
                carousel_data,
                platform
            )
            
            if result.get('status') == 'success':
                videos[platform.value] = result
        
        return {
            'carousel_id': carousel_id,
            'videos_generated': len(videos),
            'videos': videos
        }

if __name__ == '__main__':
    converter = CarouselToVideoAdvanced()
    
    # Datos de carrusel
    carousel_data = {
        'slides': [
            {
                'headline': 'Aprende IA aplicada',
                'body': 'Transforma tu carrera',
                'image_url': 'https://example.com/image1.jpg'
            },
            {
                'headline': '500+ estudiantes',
                'body': 'Ya se han unido',
                'image_url': 'https://example.com/image2.jpg'
            }
        ]
    }
    
    # Generar video para Instagram Reels
    video = converter.generate_video_from_carousel(
        'curso_ia_1',
        carousel_data,
        VideoPlatform.INSTAGRAM_REELS,
        options={'animation_style': 'slide_left'}
    )
    
    print(f"Video generado: {video['video_url']}")
    print(f"  Duraci√≥n: {video['specifications']['duration']}s")
    print(f"  Resoluci√≥n: {video['specifications']['width']}x{video['specifications']['height']}")
```

---

## üéµ Sistema de Generaci√≥n Autom√°tica de Audio y Voiceover

### Script de Generaci√≥n de Audio

**Python**: `scripts/audio_voiceover_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de audio y voiceover
- Text-to-Speech con m√∫ltiples voces
- Sincronizaci√≥n con slides de carrusel
- Efectos de sonido autom√°ticos
- M√∫sica de fondo inteligente
- Optimizaci√≥n por duraci√≥n y formato
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class VoiceGender(Enum):
    MALE = "male"
    FEMALE = "female"
    NEUTRAL = "neutral"

class VoiceLanguage(Enum):
    SPANISH = "es"
    ENGLISH = "en"
    PORTUGUESE = "pt"

@dataclass
class VoiceSettings:
    """Configuraci√≥n de voz"""
    gender: VoiceGender
    language: VoiceLanguage
    speed: float  # 0.5-2.0
    pitch: float  # -20 to +20 semitones
    volume: float  # 0.0-1.0
    voice_id: str

@dataclass
class AudioTrack:
    """Pista de audio"""
    track_id: str
    audio_url: str
    duration: float
    track_type: str  # voiceover, music, sound_effect
    start_time: float
    end_time: float

class AudioVoiceoverGenerator:
    """Generador de audio y voiceover"""
    
    def __init__(self):
        self.available_voices = {
            'es_male_1': VoiceSettings(
                gender=VoiceGender.MALE,
                language=VoiceLanguage.SPANISH,
                speed=1.0,
                pitch=0.0,
                volume=1.0,
                voice_id='es_male_1'
            ),
            'es_female_1': VoiceSettings(
                gender=VoiceGender.FEMALE,
                language=VoiceLanguage.SPANISH,
                speed=1.0,
                pitch=0.0,
                volume=1.0,
                voice_id='es_female_1'
            ),
            'en_male_1': VoiceSettings(
                gender=VoiceGender.MALE,
                language=VoiceLanguage.ENGLISH,
                speed=1.0,
                pitch=0.0,
                volume=1.0,
                voice_id='en_male_1'
            )
        }
        self.sound_effects_library = {
            'slide_transition': 'transition_swipe.mp3',
            'highlight': 'highlight_chime.mp3',
            'complete': 'success_chord.mp3'
        }
    
    def generate_voiceover(self, carousel_id: str, script: str,
                          voice_settings: VoiceSettings) -> Dict:
        """Genera voiceover desde texto"""
        
        # En producci√≥n: usar TTS API (Google Cloud TTS, Amazon Polly, ElevenLabs)
        # Por ahora: simulado
        
        # Calcular duraci√≥n estimada
        words_per_minute = 150 * voice_settings.speed
        word_count = len(script.split())
        duration = (word_count / words_per_minute) * 60
        
        audio_url = f"https://cdn.example.com/audio/{carousel_id}_{voice_settings.voice_id}_{datetime.now().timestamp()}.mp3"
        
        return {
            'carousel_id': carousel_id,
            'audio_url': audio_url,
            'duration': duration,
            'voice_settings': {
                'gender': voice_settings.gender.value,
                'language': voice_settings.language.value,
                'speed': voice_settings.speed,
                'pitch': voice_settings.pitch
            },
            'script': script,
            'word_count': word_count
        }
    
    def generate_synchronized_audio(self, carousel_id: str,
                                   slides_with_scripts: List[Dict],
                                   voice_settings: VoiceSettings) -> Dict:
        """Genera audio sincronizado con slides"""
        
        audio_tracks = []
        current_time = 0.0
        
        for i, slide_data in enumerate(slides_with_scripts):
            script = slide_data.get('script', '')
            slide_duration = slide_data.get('duration', 3.0)
            
            # Generar voiceover para slide
            voiceover = self.generate_voiceover(
                f"{carousel_id}_slide_{i}",
                script,
                voice_settings
            )
            
            # Ajustar duraci√≥n para que coincida con slide
            if voiceover['duration'] > slide_duration:
                # Acelerar audio
                speed_multiplier = voiceover['duration'] / slide_duration
                adjusted_settings = VoiceSettings(
                    gender=voice_settings.gender,
                    language=voice_settings.language,
                    speed=voice_settings.speed * speed_multiplier,
                    pitch=voice_settings.pitch,
                    volume=voice_settings.volume,
                    voice_id=voice_settings.voice_id
                )
                voiceover = self.generate_voiceover(
                    f"{carousel_id}_slide_{i}",
                    script,
                    adjusted_settings
                )
            
            # Crear track de audio
            track = AudioTrack(
                track_id=f"{carousel_id}_voice_{i}",
                audio_url=voiceover['audio_url'],
                duration=voiceover['duration'],
                track_type='voiceover',
                start_time=current_time,
                end_time=current_time + voiceover['duration']
            )
            
            audio_tracks.append(track)
            
            # Agregar efecto de sonido de transici√≥n (excepto √∫ltima slide)
            if i < len(slides_with_scripts) - 1:
                transition_track = AudioTrack(
                    track_id=f"{carousel_id}_transition_{i}",
                    audio_url=f"https://cdn.example.com/sfx/{self.sound_effects_library['slide_transition']}",
                    duration=0.3,
                    track_type='sound_effect',
                    start_time=current_time + voiceover['duration'] - 0.3,
                    end_time=current_time + voiceover['duration']
                )
                audio_tracks.append(transition_track)
            
            current_time += slide_duration
        
        # Mezclar tracks
        final_audio = self._mix_audio_tracks(audio_tracks)
        
        return {
            'carousel_id': carousel_id,
            'final_audio_url': final_audio['url'],
            'total_duration': current_time,
            'tracks': [
                {
                    'track_id': t.track_id,
                    'type': t.track_type,
                    'start_time': t.start_time,
                    'end_time': t.end_time,
                    'duration': t.duration
                }
                for t in audio_tracks
            ]
        }
    
    def _mix_audio_tracks(self, tracks: List[AudioTrack]) -> Dict:
        """Mezcla tracks de audio"""
        
        # En producci√≥n: usar FFmpeg o librer√≠a de audio para mezclar
        # Por ahora: simulado
        
        total_duration = max(t.end_time for t in tracks) if tracks else 0.0
        
        return {
            'url': f"https://cdn.example.com/audio/mixed_{datetime.now().timestamp()}.mp3",
            'duration': total_duration,
            'tracks_count': len(tracks)
        }
    
    def add_background_music(self, audio_url: str, music_track: str,
                            volume: float = 0.2, fade_in: float = 1.0,
                            fade_out: float = 1.0) -> Dict:
        """Agrega m√∫sica de fondo a audio"""
        
        # En producci√≥n: usar FFmpeg para mezclar con volumen reducido
        
        return {
            'original_audio': audio_url,
            'music_track': music_track,
            'mixed_audio_url': f"https://cdn.example.com/audio/mixed_with_music_{datetime.now().timestamp()}.mp3",
            'music_volume': volume,
            'fade_in': fade_in,
            'fade_out': fade_out
        }
    
    def generate_script_from_carousel(self, carousel_data: Dict) -> List[Dict]:
        """Genera script de voiceover desde datos de carrusel"""
        
        slides = carousel_data.get('slides', [])
        scripts = []
        
        for i, slide in enumerate(slides):
            headline = slide.get('headline', '')
            body = slide.get('body', '')
            
            # Combinar headline y body para script
            script_text = f"{headline}. {body}"
            
            scripts.append({
                'slide_index': i,
                'script': script_text,
                'word_count': len(script_text.split()),
                'estimated_duration': len(script_text.split()) / 2.5  # ~150 WPM
            })
        
        return scripts
    
    def optimize_audio_for_platform(self, audio_url: str, platform: str) -> Dict:
        """Optimiza audio para plataforma espec√≠fica"""
        
        platform_settings = {
            'instagram': {
                'format': 'mp3',
                'bitrate': 128,
                'sample_rate': 44100
            },
            'tiktok': {
                'format': 'mp3',
                'bitrate': 192,
                'sample_rate': 48000
            },
            'youtube': {
                'format': 'mp3',
                'bitrate': 256,
                'sample_rate': 48000
            }
        }
        
        settings = platform_settings.get(platform, platform_settings['instagram'])
        
        return {
            'original_audio': audio_url,
            'optimized_audio_url': f"https://cdn.example.com/audio/optimized_{platform}_{datetime.now().timestamp()}.mp3",
            'platform': platform,
            'settings': settings
        }

if __name__ == '__main__':
    generator = AudioVoiceoverGenerator()
    
    # Generar voiceover
    voice_settings = generator.available_voices['es_female_1']
    
    voiceover = generator.generate_voiceover(
        'curso_ia_1',
        'Aprende IA aplicada y transforma tu carrera profesional.',
        voice_settings
    )
    
    print(f"Voiceover generado:")
    print(f"  URL: {voiceover['audio_url']}")
    print(f"  Duraci√≥n: {voiceover['duration']:.2f}s")
    print(f"  Palabras: {voiceover['word_count']}")
```

---

## üìä Sistema de Dashboard Interactivo en Tiempo Real

### Script de Dashboard Interactivo

**Python**: `scripts/interactive_realtime_dashboard.py`

```python
#!/usr/bin/env python3
"""
Sistema de dashboard interactivo en tiempo real
- Visualizaci√≥n de m√©tricas en tiempo real
- Gr√°ficos interactivos (Chart.js, D3.js)
- Filtros din√°micos por fecha, plataforma, producto
- Exportaci√≥n de reportes (PDF, Excel, PNG)
- Alertas visuales y notificaciones
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class DashboardMetric:
    """M√©trica del dashboard"""
    metric_name: str
    value: float
    previous_value: float
    change_percentage: float
    trend: str  # up, down, stable
    formatted_value: str

class InteractiveRealtimeDashboard:
    """Dashboard interactivo en tiempo real"""
    
    def __init__(self):
        self.metrics_cache = {}
        self.update_interval = 60  # segundos
    
    def generate_dashboard_data(self, filters: Optional[Dict] = None) -> Dict:
        """Genera datos del dashboard"""
        
        filters = filters or {}
        
        # Obtener per√≠odo
        end_date = datetime.now()
        days = filters.get('days', 7)
        start_date = end_date - timedelta(days=days)
        
        # Obtener m√©tricas
        kpis = self._calculate_kpis(start_date, end_date, filters)
        trends = self._calculate_trends(start_date, end_date, filters)
        charts_data = self._generate_charts_data(start_date, end_date, filters)
        
        return {
            'period': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat(),
                'days': days
            },
            'filters': filters,
            'kpis': kpis,
            'trends': trends,
            'charts': charts_data,
            'last_updated': datetime.now().isoformat()
        }
    
    def _calculate_kpis(self, start_date: datetime, end_date: datetime,
                       filters: Dict) -> List[DashboardMetric]:
        """Calcula KPIs"""
        
        # En producci√≥n: obtener datos reales
        kpis = []
        
        metrics_config = [
            {'name': 'total_impressions', 'format': '{:,.0f}'},
            {'name': 'total_clicks', 'format': '{:,.0f}'},
            {'name': 'average_ctr', 'format': '{:.2f}%'},
            {'name': 'total_conversions', 'format': '{:,.0f}'},
            {'name': 'conversion_rate', 'format': '{:.2f}%'},
            {'name': 'total_revenue', 'format': '‚Ç¨{:,.2f}'},
            {'name': 'roas', 'format': '{:.2f}x'}
        ]
        
        for metric_config in metrics_config:
            current_value = self._get_metric_value(metric_config['name'], start_date, end_date)
            previous_value = self._get_previous_period_value(metric_config['name'], start_date, end_date)
            
            change_pct = ((current_value - previous_value) / previous_value * 100) if previous_value > 0 else 0
            
            trend = 'up' if change_pct > 5 else 'down' if change_pct < -5 else 'stable'
            
            metric = DashboardMetric(
                metric_name=metric_config['name'],
                value=current_value,
                previous_value=previous_value,
                change_percentage=change_pct,
                trend=trend,
                formatted_value=metric_config['format'].format(current_value)
            )
            
            kpis.append(metric)
        
        return kpis
    
    def _get_metric_value(self, metric_name: str, start: datetime, end: datetime) -> float:
        """Obtiene valor de m√©trica"""
        
        # Simulado: en producci√≥n obtener de base de datos
        values = {
            'total_impressions': 50000,
            'total_clicks': 2500,
            'average_ctr': 5.0,
            'total_conversions': 150,
            'conversion_rate': 6.0,
            'total_revenue': 15000.0,
            'roas': 4.5
        }
        
        return values.get(metric_name, 0.0)
    
    def _get_previous_period_value(self, metric_name: str, current_start: datetime,
                                  current_end: datetime) -> float:
        """Obtiene valor del per√≠odo anterior"""
        
        period_duration = current_end - current_start
        previous_end = current_start
        previous_start = previous_end - period_duration
        
        return self._get_metric_value(metric_name, previous_start, previous_end)
    
    def _calculate_trends(self, start_date: datetime, end_date: datetime,
                         filters: Dict) -> Dict:
        """Calcula tendencias"""
        
        # Comparar con per√≠odo anterior
        period_duration = end_date - start_date
        previous_end = start_date
        previous_start = previous_end - period_duration
        
        current_data = self._get_period_data(start_date, end_date)
        previous_data = self._get_period_data(previous_start, previous_end)
        
        trends = {}
        
        for metric in ['impressions', 'clicks', 'conversions', 'revenue']:
            current = current_data.get(metric, 0)
            previous = previous_data.get(metric, 0)
            
            if previous > 0:
                change_pct = ((current - previous) / previous) * 100
            else:
                change_pct = 0
            
            trends[metric] = {
                'current': current,
                'previous': previous,
                'change_percentage': change_pct,
                'trend': 'up' if change_pct > 5 else 'down' if change_pct < -5 else 'stable'
            }
        
        return trends
    
    def _get_period_data(self, start: datetime, end: datetime) -> Dict:
        """Obtiene datos del per√≠odo"""
        
        # Simulado
        return {
            'impressions': 50000,
            'clicks': 2500,
            'conversions': 150,
            'revenue': 15000.0
        }
    
    def _generate_charts_data(self, start_date: datetime, end_date: datetime,
                            filters: Dict) -> Dict:
        """Genera datos para gr√°ficos"""
        
        # Datos diarios para gr√°fico de l√≠nea
        daily_data = []
        current_date = start_date
        
        while current_date <= end_date:
            daily_data.append({
                'date': current_date.isoformat(),
                'impressions': 5000 + (current_date.day * 200),
                'clicks': 250 + (current_date.day * 10),
                'conversions': 15 + (current_date.day * 1)
            })
            current_date += timedelta(days=1)
        
        # Datos por plataforma para gr√°fico de barras
        platform_data = [
            {'platform': 'Instagram', 'impressions': 25000, 'clicks': 1250, 'conversions': 75},
            {'platform': 'LinkedIn', 'impressions': 15000, 'clicks': 750, 'conversions': 45},
            {'platform': 'Facebook', 'impressions': 10000, 'clicks': 500, 'conversions': 30}
        ]
        
        # Datos por producto para gr√°fico de dona
        product_data = [
            {'product': 'Curso IA', 'revenue': 9000, 'percentage': 60},
            {'product': 'SaaS Marketing', 'revenue': 4500, 'percentage': 30},
            {'product': 'IA Bulk', 'revenue': 1500, 'percentage': 10}
        ]
        
        return {
            'line_chart': {
                'type': 'line',
                'data': daily_data,
                'metrics': ['impressions', 'clicks', 'conversions']
            },
            'bar_chart': {
                'type': 'bar',
                'data': platform_data,
                'metrics': ['impressions', 'clicks', 'conversions']
            },
            'doughnut_chart': {
                'type': 'doughnut',
                'data': product_data,
                'metric': 'revenue'
            }
        }
    
    def export_dashboard_report(self, dashboard_data: Dict, format: str) -> Dict:
        """Exporta reporte del dashboard"""
        
        formats = {
            'pdf': self._export_to_pdf,
            'excel': self._export_to_excel,
            'png': self._export_to_png,
            'html': self._export_to_html
        }
        
        exporter = formats.get(format.lower())
        if not exporter:
            return {'status': 'error', 'message': 'Format not supported'}
        
        return exporter(dashboard_data)
    
    def _export_to_pdf(self, data: Dict) -> Dict:
        """Exporta a PDF"""
        # En producci√≥n: usar reportlab o weasyprint
        return {
            'status': 'success',
            'format': 'pdf',
            'file_url': f"https://cdn.example.com/reports/dashboard_{datetime.now().timestamp()}.pdf"
        }
    
    def _export_to_excel(self, data: Dict) -> Dict:
        """Exporta a Excel"""
        # En producci√≥n: usar openpyxl o pandas
        return {
            'status': 'success',
            'format': 'excel',
            'file_url': f"https://cdn.example.com/reports/dashboard_{datetime.now().timestamp()}.xlsx"
        }
    
    def _export_to_png(self, data: Dict) -> Dict:
        """Exporta a PNG"""
        # En producci√≥n: usar selenium o playwright para captura
        return {
            'status': 'success',
            'format': 'png',
            'file_url': f"https://cdn.example.com/reports/dashboard_{datetime.now().timestamp()}.png"
        }
    
    def _export_to_html(self, data: Dict) -> Dict:
        """Exporta a HTML interactivo"""
        # En producci√≥n: generar HTML con Chart.js embebido
        return {
            'status': 'success',
            'format': 'html',
            'file_url': f"https://cdn.example.com/reports/dashboard_{datetime.now().timestamp()}.html"
        }

if __name__ == '__main__':
    dashboard = InteractiveRealtimeDashboard()
    
    # Generar dashboard
    dashboard_data = dashboard.generate_dashboard_data(filters={'days': 7, 'platform': 'instagram'})
    
    print(f"Dashboard generado:")
    print(f"  KPIs: {len(dashboard_data['kpis'])}")
    print(f"  Gr√°ficos: {len(dashboard_data['charts'])}")
    print(f"  √öltima actualizaci√≥n: {dashboard_data['last_updated']}")
    
    # Exportar reporte
    report = dashboard.export_dashboard_report(dashboard_data, 'pdf')
    print(f"\nReporte exportado: {report['file_url']}")
```

---

## ü§ñ Sistema de Chatbot y Asistente Virtual para Gesti√≥n de Carruseles

### Script de Chatbot Inteligente

**Python**: `scripts/ai_chatbot_carousel_assistant.py`

```python
#!/usr/bin/env python3
"""
Sistema de chatbot y asistente virtual para gesti√≥n de carruseles
- Chatbot conversacional para consultas y acciones
- Generaci√≥n autom√°tica de contenido mediante conversaci√≥n
- An√°lisis de performance mediante lenguaje natural
- Recomendaciones interactivas
- Integraci√≥n con GPT-4 para respuestas inteligentes
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class IntentType(Enum):
    CREATE_CAROUSEL = "create_carousel"
    ANALYZE_PERFORMANCE = "analyze_performance"
    GENERATE_CONTENT = "generate_content"
    GET_RECOMMENDATIONS = "get_recommendations"
    UPDATE_CAROUSEL = "update_carousel"
    SCHEDULE_POST = "schedule_post"
    COMPARE_CAROUSELS = "compare_carousels"

@dataclass
class ChatMessage:
    """Mensaje de chat"""
    role: str  # user, assistant, system
    content: str
    timestamp: datetime
    intent: Optional[IntentType]

@dataclass
class ChatSession:
    """Sesi√≥n de chat"""
    session_id: str
    user_id: str
    messages: List[ChatMessage]
    context: Dict
    created_at: datetime

class AIChatbotCarouselAssistant:
    """Asistente virtual de carruseles con IA"""
    
    def __init__(self):
        self.sessions = {}
        self.intent_patterns = {
            IntentType.CREATE_CAROUSEL: ['crear', 'nuevo', 'generar', 'hacer carrusel'],
            IntentType.ANALYZE_PERFORMANCE: ['analizar', 'performance', 'm√©tricas', 'resultados'],
            IntentType.GENERATE_CONTENT: ['generar', 'crear contenido', 'copy', 'texto'],
            IntentType.GET_RECOMMENDATIONS: ['recomendar', 'sugerir', 'mejorar', 'optimizar'],
            IntentType.UPDATE_CAROUSEL: ['actualizar', 'modificar', 'cambiar', 'editar'],
            IntentType.SCHEDULE_POST: ['programar', 'agendar', 'publicar', 'post'],
            IntentType.COMPARE_CAROUSELS: ['comparar', 'versus', 'diferencias']
        }
    
    def create_session(self, user_id: str) -> ChatSession:
        """Crea nueva sesi√≥n de chat"""
        
        session = ChatSession(
            session_id=f"session_{datetime.now().timestamp()}",
            user_id=user_id,
            messages=[],
            context={},
            created_at=datetime.now()
        )
        
        # Mensaje de bienvenida
        welcome_message = ChatMessage(
            role='assistant',
            content="¬°Hola! Soy tu asistente de carruseles sociales. ¬øEn qu√© puedo ayudarte? Puedo ayudarte a crear carruseles, analizar performance, generar contenido y m√°s.",
            timestamp=datetime.now(),
            intent=None
        )
        
        session.messages.append(welcome_message)
        self.sessions[session.session_id] = session
        
        return session
    
    def process_message(self, session_id: str, user_message: str) -> Dict:
        """Procesa mensaje del usuario"""
        
        if session_id not in self.sessions:
            return {'status': 'error', 'message': 'Session not found'}
        
        session = self.sessions[session_id]
        
        # Agregar mensaje del usuario
        user_msg = ChatMessage(
            role='user',
            content=user_message,
            timestamp=datetime.now(),
            intent=None
        )
        session.messages.append(user_msg)
        
        # Detectar intenci√≥n
        intent = self._detect_intent(user_message)
        user_msg.intent = intent
        
        # Procesar seg√∫n intenci√≥n
        response = self._handle_intent(intent, user_message, session)
        
        # Agregar respuesta del asistente
        assistant_msg = ChatMessage(
            role='assistant',
            content=response['content'],
            timestamp=datetime.now(),
            intent=intent
        )
        session.messages.append(assistant_msg)
        
        return {
            'status': 'success',
            'response': response['content'],
            'intent': intent.value if intent else None,
            'actions': response.get('actions', [])
        }
    
    def _detect_intent(self, message: str) -> Optional[IntentType]:
        """Detecta intenci√≥n del mensaje"""
        
        message_lower = message.lower()
        
        for intent, patterns in self.intent_patterns.items():
            if any(pattern in message_lower for pattern in patterns):
                return intent
        
        return None
    
    def _handle_intent(self, intent: Optional[IntentType], message: str,
                      session: ChatSession) -> Dict:
        """Maneja intenci√≥n detectada"""
        
        if not intent:
            return {
                'content': "No estoy seguro de qu√© quieres hacer. ¬øPuedes ser m√°s espec√≠fico? Puedo ayudarte a crear carruseles, analizar performance o generar contenido.",
                'actions': []
            }
        
        handlers = {
            IntentType.CREATE_CAROUSEL: self._handle_create_carousel,
            IntentType.ANALYZE_PERFORMANCE: self._handle_analyze_performance,
            IntentType.GENERATE_CONTENT: self._handle_generate_content,
            IntentType.GET_RECOMMENDATIONS: self._handle_get_recommendations,
            IntentType.UPDATE_CAROUSEL: self._handle_update_carousel,
            IntentType.SCHEDULE_POST: self._handle_schedule_post,
            IntentType.COMPARE_CAROUSELS: self._handle_compare_carousels
        }
        
        handler = handlers.get(intent)
        if handler:
            return handler(message, session)
        
        return {
            'content': f"Intenci√≥n '{intent.value}' detectada pero a√∫n no implementada completamente.",
            'actions': []
        }
    
    def _handle_create_carousel(self, message: str, session: ChatSession) -> Dict:
        """Maneja creaci√≥n de carrusel"""
        
        # En producci√≥n: extraer detalles del mensaje con NLP
        # Por ahora: respuesta gen√©rica
        
        return {
            'content': "¬°Perfecto! Voy a ayudarte a crear un nuevo carrusel. ¬øSobre qu√© producto quieres crear el carrusel? (Curso IA, SaaS Marketing, IA Bulk)",
            'actions': ['waiting_for_product_selection']
        }
    
    def _handle_analyze_performance(self, message: str, session: ChatSession) -> Dict:
        """Maneja an√°lisis de performance"""
        
        # En producci√≥n: extraer ID de carrusel del mensaje y obtener m√©tricas reales
        
        return {
            'content': "Aqu√≠ tienes el an√°lisis de performance de tus carruseles:\n\nüìä **M√©tricas generales (√∫ltimos 7 d√≠as):**\n- Impresiones: 50,000\n- Clics: 2,500\n- CTR: 5.0%\n- Conversiones: 150\n- ROAS: 4.5x\n\n¬øQuieres que profundice en alg√∫n carrusel espec√≠fico?",
            'actions': []
        }
    
    def _handle_generate_content(self, message: str, session: ChatSession) -> Dict:
        """Maneja generaci√≥n de contenido"""
        
        return {
            'content': "Puedo generar contenido para tus carruseles. ¬øQu√© tipo de contenido necesitas?\n- Headlines\n- CTAs\n- Copy completo\n- Hashtags\n\n¬øSobre qu√© producto o tema?",
            'actions': ['waiting_for_content_type']
        }
    
    def _handle_get_recommendations(self, message: str, session: ChatSession) -> Dict:
        """Maneja recomendaciones"""
        
        return {
            'content': "Bas√°ndome en el an√°lisis de tus carruseles, aqu√≠ tienes mis recomendaciones:\n\n‚úÖ **Optimizaciones sugeridas:**\n1. Headlines con n√∫meros aumentan CTR en un 30%\n2. CTAs m√°s espec√≠ficos mejoran conversi√≥n\n3. Colores vibrantes aumentan engagement\n\n¬øQuieres que genere variantes optimizadas?",
            'actions': ['offer_optimization']
        }
    
    def _handle_update_carousel(self, message: str, session: ChatSession) -> Dict:
        """Maneja actualizaci√≥n de carrusel"""
        
        return {
            'content': "Puedo ayudarte a actualizar un carrusel. ¬øCu√°l es el ID del carrusel que quieres modificar?",
            'actions': ['waiting_for_carousel_id']
        }
    
    def _handle_schedule_post(self, message: str, session: ChatSession) -> Dict:
        """Maneja programaci√≥n de posts"""
        
        return {
            'content': "¬°Perfecto! Puedo programar tu carrusel. ¬øEn qu√© plataforma quieres publicar? (Instagram, LinkedIn, Facebook)\n\n¬øY cu√°ndo quieres que se publique? (hoy, ma√±ana, fecha espec√≠fica)",
            'actions': ['waiting_for_schedule_details']
        }
    
    def _handle_compare_carousels(self, message: str, session: ChatSession) -> Dict:
        """Maneja comparaci√≥n de carruseles"""
        
        return {
            'content': "Puedo comparar el performance de diferentes carruseles. ¬øQu√© carruseles quieres comparar? Dame los IDs.",
            'actions': ['waiting_for_carousel_ids']
        }
    
    def generate_carousel_via_conversation(self, session_id: str) -> Dict:
        """Genera carrusel mediante conversaci√≥n guiada"""
        
        if session_id not in self.sessions:
            return {'status': 'error', 'message': 'Session not found'}
        
        session = self.sessions[session_id]
        
        # Extraer informaci√≥n del contexto de conversaci√≥n
        context = session.context
        
        # En producci√≥n: usar GPT-4 para generar carrusel completo basado en conversaci√≥n
        
        return {
            'status': 'success',
            'carousel_id': f"carousel_{datetime.now().timestamp()}",
            'generated_from': 'conversation',
            'context_used': context
        }

if __name__ == '__main__':
    chatbot = AIChatbotCarouselAssistant()
    
    # Crear sesi√≥n
    session = chatbot.create_session('user123')
    print(f"Sesi√≥n creada: {session.session_id}")
    print(f"Mensaje inicial: {session.messages[0].content}\n")
    
    # Procesar mensajes
    messages = [
        "Quiero crear un nuevo carrusel para el Curso IA",
        "Analiza el performance de mis carruseles",
        "Genera contenido para un carrusel de SaaS Marketing"
    ]
    
    for msg in messages:
        response = chatbot.process_message(session.session_id, msg)
        print(f"Usuario: {msg}")
        print(f"Asistente: {response['response']}")
        print(f"Intenci√≥n: {response.get('intent', 'N/A')}\n")
```

---

## üîç Sistema de B√∫squeda Inteligente y Recomendaciones de Contenido

### Script de B√∫squeda y Recomendaciones

**Python**: `scripts/intelligent_content_search.py`

```python
#!/usr/bin/env python3
"""
Sistema de b√∫squeda inteligente y recomendaciones de contenido
- B√∫squeda sem√°ntica de carruseles
- Recomendaciones basadas en ML
- B√∫squeda por similitud visual
- Filtrado avanzado multi-criterio
- Historial de b√∫squedas y aprendizaje
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class SearchResult:
    """Resultado de b√∫squeda"""
    carousel_id: str
    relevance_score: float
    match_reasons: List[str]
    metadata: Dict

class IntelligentContentSearch:
    """Sistema de b√∫squeda inteligente"""
    
    def __init__(self):
        self.search_history = []
        self.carousel_index = {}
        self.embeddings_cache = {}
    
    def semantic_search(self, query: str, limit: int = 10,
                       filters: Optional[Dict] = None) -> List[SearchResult]:
        """B√∫squeda sem√°ntica de carruseles"""
        
        filters = filters or {}
        
        # En producci√≥n: usar embeddings (OpenAI, Sentence-BERT) para b√∫squeda sem√°ntica
        # Por ahora: b√∫squeda por keywords mejorada
        
        # Extraer keywords del query
        keywords = self._extract_keywords(query)
        
        # Buscar en √≠ndice
        results = []
        
        for carousel_id, carousel_data in self.carousel_index.items():
            # Calcular score de relevancia
            relevance = self._calculate_relevance(carousel_data, keywords, query)
            
            if relevance > 0:
                # Aplicar filtros
                if self._passes_filters(carousel_data, filters):
                    match_reasons = self._get_match_reasons(carousel_data, keywords)
                    
                    result = SearchResult(
                        carousel_id=carousel_id,
                        relevance_score=relevance,
                        match_reasons=match_reasons,
                        metadata={
                            'headline': carousel_data.get('headline', ''),
                            'product': carousel_data.get('product', ''),
                            'created_at': carousel_data.get('created_at', '')
                        }
                    )
                    results.append(result)
        
        # Ordenar por relevancia
        results.sort(key=lambda x: x.relevance_score, reverse=True)
        
        # Limitar resultados
        results = results[:limit]
        
        # Guardar en historial
        self.search_history.append({
            'query': query,
            'timestamp': datetime.now().isoformat(),
            'results_count': len(results),
            'filters': filters
        })
        
        return results
    
    def _extract_keywords(self, query: str) -> List[str]:
        """Extrae keywords del query"""
        
        # Stop words en espa√±ol
        stop_words = {'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'ser', 'se', 'no', 'haber', 'por', 'con', 'su', 'para', 'como', 'estar', 'tener', 'le', 'lo', 'todo', 'pero', 'm√°s', 'hacer', 'o', 'poder', 'decir', 'este', 'ir', 'otro', 'ese', 'la', 'si', 'me', 'ya', 'ver', 'porque', 'dar', 'cuando', '√©l', 'muy', 'sin', 'vez', 'mucho', 'saber', 'qu√©', 'sobre', 'mi', 'alguno', 'mismo', 'yo', 'tambi√©n', 'hasta'}
        
        # Normalizar y dividir
        words = query.lower().split()
        keywords = [w for w in words if w not in stop_words and len(w) > 2]
        
        return keywords
    
    def _calculate_relevance(self, carousel_data: Dict, keywords: List[str],
                            query: str) -> float:
        """Calcula relevancia de carrusel"""
        
        score = 0.0
        
        # Buscar keywords en headline
        headline = carousel_data.get('headline', '').lower()
        for keyword in keywords:
            if keyword in headline:
                score += 2.0  # Mayor peso en headline
        
        # Buscar keywords en body
        body = carousel_data.get('body', '').lower()
        for keyword in keywords:
            if keyword in body:
                score += 1.0
        
        # Buscar keywords en hashtags
        hashtags = carousel_data.get('hashtags', [])
        for keyword in keywords:
            if any(keyword in tag.lower() for tag in hashtags):
                score += 1.5
        
        # Buscar en producto
        product = carousel_data.get('product', '').lower()
        if any(keyword in product for keyword in keywords):
            score += 1.0
        
        return score
    
    def _passes_filters(self, carousel_data: Dict, filters: Dict) -> bool:
        """Verifica si carrusel pasa filtros"""
        
        if not filters:
            return True
        
        # Filtro por producto
        if 'product' in filters:
            if carousel_data.get('product', '') != filters['product']:
                return False
        
        # Filtro por fecha
        if 'date_from' in filters or 'date_to' in filters:
            created_at = carousel_data.get('created_at', '')
            if created_at:
                # En producci√≥n: comparar fechas correctamente
                pass
        
        # Filtro por performance m√≠nimo
        if 'min_ctr' in filters:
            ctr = carousel_data.get('ctr', 0)
            if ctr < filters['min_ctr']:
                return False
        
        return True
    
    def _get_match_reasons(self, carousel_data: Dict, keywords: List[str]) -> List[str]:
        """Obtiene razones de coincidencia"""
        
        reasons = []
        
        headline = carousel_data.get('headline', '').lower()
        body = carousel_data.get('body', '').lower()
        
        for keyword in keywords:
            if keyword in headline:
                reasons.append(f"Keyword '{keyword}' encontrado en headline")
            elif keyword in body:
                reasons.append(f"Keyword '{keyword}' encontrado en body")
        
        return reasons
    
    def recommend_similar_carousels(self, carousel_id: str, limit: int = 5) -> List[SearchResult]:
        """Recomienda carruseles similares"""
        
        if carousel_id not in self.carousel_index:
            return []
        
        reference_carousel = self.carousel_index[carousel_id]
        
        # Calcular similitud con otros carruseles
        similarities = []
        
        for other_id, other_data in self.carousel_index.items():
            if other_id == carousel_id:
                continue
            
            similarity = self._calculate_similarity(reference_carousel, other_data)
            
            if similarity > 0:
                similarities.append((other_id, similarity, other_data))
        
        # Ordenar por similitud
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # Crear resultados
        results = []
        for other_id, similarity, other_data in similarities[:limit]:
            result = SearchResult(
                carousel_id=other_id,
                relevance_score=similarity,
                match_reasons=[f"Similitud: {similarity:.1%}"],
                metadata={
                    'headline': other_data.get('headline', ''),
                    'product': other_data.get('product', ''),
                    'similarity_score': similarity
                }
            )
            results.append(result)
        
        return results
    
    def _calculate_similarity(self, carousel1: Dict, carousel2: Dict) -> float:
        """Calcula similitud entre carruseles"""
        
        similarity = 0.0
        
        # Similitud por producto
        if carousel1.get('product') == carousel2.get('product'):
            similarity += 0.3
        
        # Similitud por keywords comunes
        keywords1 = set(self._extract_keywords(carousel1.get('headline', '') + ' ' + carousel1.get('body', '')))
        keywords2 = set(self._extract_keywords(carousel2.get('headline', '') + ' ' + carousel2.get('body', '')))
        
        if keywords1 or keywords2:
            common_keywords = keywords1.intersection(keywords2)
            total_keywords = keywords1.union(keywords2)
            if total_keywords:
                similarity += (len(common_keywords) / len(total_keywords)) * 0.5
        
        # Similitud por hashtags comunes
        hashtags1 = set(carousel1.get('hashtags', []))
        hashtags2 = set(carousel2.get('hashtags', []))
        if hashtags1 or hashtags2:
            common_hashtags = hashtags1.intersection(hashtags2)
            total_hashtags = hashtags1.union(hashtags2)
            if total_hashtags:
                similarity += (len(common_hashtags) / len(total_hashtags)) * 0.2
        
        return min(1.0, similarity)
    
    def get_search_suggestions(self, partial_query: str) -> List[str]:
        """Genera sugerencias de b√∫squeda"""
        
        # En producci√≥n: usar historial de b√∫squedas y autocompletado
        suggestions = []
        
        # Sugerencias comunes
        common_queries = [
            'carrusel curso ia',
            'an√°lisis performance',
            'carruseles alto ctr',
            'generar contenido',
            'optimizar carrusel'
        ]
        
        for query in common_queries:
            if partial_query.lower() in query.lower():
                suggestions.append(query)
        
        return suggestions[:5]
    
    def get_trending_searches(self, days: int = 7) -> List[Dict]:
        """Obtiene b√∫squedas trending"""
        
        cutoff_date = datetime.now() - timedelta(days=days)
        
        recent_searches = [
            s for s in self.search_history
            if datetime.fromisoformat(s['timestamp']) >= cutoff_date
        ]
        
        # Contar frecuencia de queries
        query_counts = {}
        for search in recent_searches:
            query = search['query'].lower()
            query_counts[query] = query_counts.get(query, 0) + 1
        
        # Ordenar por frecuencia
        trending = sorted(
            query_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        return [
            {'query': query, 'count': count}
            for query, count in trending
        ]

if __name__ == '__main__':
    search = IntelligentContentSearch()
    
    # Indexar algunos carruseles (simulado)
    search.carousel_index = {
        'curso_ia_1': {
            'headline': 'Aprende IA aplicada',
            'body': 'Transforma tu carrera con inteligencia artificial',
            'product': 'Curso IA',
            'hashtags': ['ia', 'aprendizaje', 'carrera'],
            'created_at': '2025-01-15'
        },
        'saas_marketing_1': {
            'headline': 'Marketing SaaS efectivo',
            'body': 'Estrategias para SaaS',
            'product': 'SaaS Marketing',
            'hashtags': ['saas', 'marketing', 'estrategia'],
            'created_at': '2025-01-20'
        }
    }
    
    # B√∫squeda sem√°ntica
    results = search.semantic_search('IA aprendizaje', limit=5)
    print(f"Resultados de b√∫squeda: {len(results)}")
    for result in results:
        print(f"  - {result.carousel_id}: {result.relevance_score:.2f}")
    
    # Recomendaciones similares
    similar = search.recommend_similar_carousels('curso_ia_1', limit=3)
    print(f"\nCarruseles similares: {len(similar)}")
    for result in similar:
        print(f"  - {result.carousel_id}: {result.relevance_score:.1%}")
```

---

## üéØ Sistema de Scoring y Ranking Autom√°tico de Carruseles

### Script de Scoring y Ranking

**Python**: `scripts/carousel_scoring_ranking.py`

```python
#!/usr/bin/env python3
"""
Sistema de scoring y ranking autom√°tico de carruseles
- Scoring multi-dimensional (CTR, conversi√≥n, engagement, ROI)
- Ranking autom√°tico por performance
- Clasificaci√≥n por categor√≠as (mejor performing, trending, declinando)
- Predicci√≥n de potencial de √©xito
- Recomendaciones de optimizaci√≥n basadas en score
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class CarouselScore:
    """Score de carrusel"""
    carousel_id: str
    overall_score: float  # 0-100
    ctr_score: float
    conversion_score: float
    engagement_score: float
    roi_score: float
    trend_score: float
    potential_score: float
    category: str  # top_performer, good, average, needs_improvement

class CarouselScoringRanking:
    """Sistema de scoring y ranking"""
    
    def __init__(self):
        self.scores_cache = {}
        self.weights = {
            'ctr': 0.25,
            'conversion': 0.30,
            'engagement': 0.15,
            'roi': 0.20,
            'trend': 0.10
        }
    
    def calculate_score(self, carousel_id: str, performance_data: Dict) -> CarouselScore:
        """Calcula score completo de carrusel"""
        
        # Calcular scores individuales
        ctr_score = self._calculate_ctr_score(performance_data.get('ctr', 0))
        conversion_score = self._calculate_conversion_score(performance_data.get('conversion_rate', 0))
        engagement_score = self._calculate_engagement_score(performance_data.get('engagement_rate', 0))
        roi_score = self._calculate_roi_score(performance_data.get('roas', 0))
        trend_score = self._calculate_trend_score(performance_data.get('trend', 'stable'))
        potential_score = self._calculate_potential_score(performance_data)
        
        # Calcular score general (ponderado)
        overall_score = (
            ctr_score * self.weights['ctr'] +
            conversion_score * self.weights['conversion'] +
            engagement_score * self.weights['engagement'] +
            roi_score * self.weights['roi'] +
            trend_score * self.weights['trend']
        ) * 100  # Escalar a 0-100
        
        # Clasificar por categor√≠a
        category = self._classify_carousel(overall_score)
        
        score = CarouselScore(
            carousel_id=carousel_id,
            overall_score=overall_score,
            ctr_score=ctr_score * 100,
            conversion_score=conversion_score * 100,
            engagement_score=engagement_score * 100,
            roi_score=roi_score * 100,
            trend_score=trend_score * 100,
            potential_score=potential_score * 100,
            category=category
        )
        
        self.scores_cache[carousel_id] = score
        
        return score
    
    def _calculate_ctr_score(self, ctr: float) -> float:
        """Calcula score de CTR"""
        
        # Benchmarks: 2% bajo, 5% promedio, 8%+ excelente
        if ctr >= 8.0:
            return 1.0
        elif ctr >= 5.0:
            return 0.7 + ((ctr - 5.0) / 3.0) * 0.3
        elif ctr >= 2.0:
            return 0.4 + ((ctr - 2.0) / 3.0) * 0.3
        else:
            return (ctr / 2.0) * 0.4
    
    def _calculate_conversion_score(self, conversion_rate: float) -> float:
        """Calcula score de conversi√≥n"""
        
        # Benchmarks: 2% bajo, 5% promedio, 10%+ excelente
        if conversion_rate >= 10.0:
            return 1.0
        elif conversion_rate >= 5.0:
            return 0.7 + ((conversion_rate - 5.0) / 5.0) * 0.3
        elif conversion_rate >= 2.0:
            return 0.4 + ((conversion_rate - 2.0) / 3.0) * 0.3
        else:
            return (conversion_rate / 2.0) * 0.4
    
    def _calculate_engagement_score(self, engagement_rate: float) -> float:
        """Calcula score de engagement"""
        
        # Benchmarks: 3% bajo, 6% promedio, 10%+ excelente
        if engagement_rate >= 10.0:
            return 1.0
        elif engagement_rate >= 6.0:
            return 0.7 + ((engagement_rate - 6.0) / 4.0) * 0.3
        elif engagement_rate >= 3.0:
            return 0.4 + ((engagement_rate - 3.0) / 3.0) * 0.3
        else:
            return (engagement_rate / 3.0) * 0.4
    
    def _calculate_roi_score(self, roas: float) -> float:
        """Calcula score de ROI"""
        
        # Benchmarks: 2x bajo, 3x promedio, 5x+ excelente
        if roas >= 5.0:
            return 1.0
        elif roas >= 3.0:
            return 0.7 + ((roas - 3.0) / 2.0) * 0.3
        elif roas >= 2.0:
            return 0.4 + ((roas - 2.0) / 1.0) * 0.3
        else:
            return (roas / 2.0) * 0.4
    
    def _calculate_trend_score(self, trend: str) -> float:
        """Calcula score de tendencia"""
        
        trend_scores = {
            'rising': 1.0,
            'stable': 0.7,
            'declining': 0.3
        }
        
        return trend_scores.get(trend, 0.5)
    
    def _calculate_potential_score(self, performance_data: Dict) -> float:
        """Calcula score de potencial futuro"""
        
        # Basado en trend y crecimiento reciente
        potential = 0.5  # Base
        
        trend = performance_data.get('trend', 'stable')
        if trend == 'rising':
            potential += 0.3
        elif trend == 'declining':
            potential -= 0.2
        
        # Si tiene buen CTR pero baja conversi√≥n, potencial de mejora
        ctr = performance_data.get('ctr', 0)
        conversion = performance_data.get('conversion_rate', 0)
        
        if ctr > 5.0 and conversion < 5.0:
            potential += 0.2  # Potencial de optimizaci√≥n de conversi√≥n
        
        return max(0.0, min(1.0, potential))
    
    def _classify_carousel(self, overall_score: float) -> str:
        """Clasifica carrusel por score"""
        
        if overall_score >= 80:
            return 'top_performer'
        elif overall_score >= 60:
            return 'good'
        elif overall_score >= 40:
            return 'average'
        else:
            return 'needs_improvement'
    
    def rank_carousels(self, carousels_data: List[Dict],
                      sort_by: str = 'overall_score') -> List[Dict]:
        """Rankea carruseles"""
        
        ranked = []
        
        for carousel_data in carousels_data:
            carousel_id = carousel_data.get('carousel_id')
            performance = carousel_data.get('performance', {})
            
            score = self.calculate_score(carousel_id, performance)
            
            ranked.append({
                'carousel_id': carousel_id,
                'score': {
                    'overall': score.overall_score,
                    'ctr': score.ctr_score,
                    'conversion': score.conversion_score,
                    'engagement': score.engagement_score,
                    'roi': score.roi_score,
                    'potential': score.potential_score
                },
                'category': score.category,
                'ranking_metric': score.overall_score if sort_by == 'overall_score' else getattr(score, sort_by, score.overall_score)
            })
        
        # Ordenar
        ranked.sort(key=lambda x: x['ranking_metric'], reverse=True)
        
        # Agregar posici√≥n
        for i, item in enumerate(ranked, 1):
            item['rank'] = i
        
        return ranked
    
    def get_top_performers(self, carousels_data: List[Dict], limit: int = 10) -> List[Dict]:
        """Obtiene top performers"""
        
        ranked = self.rank_carousels(carousels_data)
        
        return [
            c for c in ranked
            if c['category'] == 'top_performer'
        ][:limit]
    
    def get_improvement_recommendations(self, carousel_id: str) -> List[str]:
        """Obtiene recomendaciones de mejora basadas en score"""
        
        if carousel_id not in self.scores_cache:
            return []
        
        score = self.scores_cache[carousel_id]
        recommendations = []
        
        # Recomendaciones basadas en scores bajos
        if score.ctr_score < 60:
            recommendations.append("CTR bajo. Optimizar headline y visual para aumentar clicks")
        
        if score.conversion_score < 60:
            recommendations.append("Conversion rate bajo. Mejorar landing page y CTA")
        
        if score.engagement_score < 60:
            recommendations.append("Engagement bajo. Agregar elementos interactivos y llamativos")
        
        if score.roi_score < 60:
            recommendations.append("ROAS bajo. Revisar targeting y oferta")
        
        if score.trend_score < 50:
            recommendations.append("Tendencia declinando. Considerar refresh o pausar")
        
        # Recomendaciones basadas en potencial
        if score.potential_score > 70 and score.overall_score < 70:
            recommendations.append("Alto potencial detectado. Optimizaci√≥n podr√≠a mejorar significativamente el score")
        
        return recommendations

if __name__ == '__main__':
    scoring = CarouselScoringRanking()
    
    # Datos de ejemplo
    carousels = [
        {
            'carousel_id': 'curso_ia_1',
            'performance': {
                'ctr': 6.5,
                'conversion_rate': 7.0,
                'engagement_rate': 8.5,
                'roas': 4.2,
                'trend': 'rising'
            }
        },
        {
            'carousel_id': 'saas_marketing_1',
            'performance': {
                'ctr': 3.2,
                'conversion_rate': 4.5,
                'engagement_rate': 5.0,
                'roas': 2.8,
                'trend': 'stable'
            }
        }
    ]
    
    # Rankear
    ranked = scoring.rank_carousels(carousels)
    print("Ranking de carruseles:")
    for item in ranked:
        print(f"  {item['rank']}. {item['carousel_id']}: {item['score']['overall']:.1f} ({item['category']})")
    
    # Recomendaciones
    recommendations = scoring.get_improvement_recommendations('saas_marketing_1')
    print(f"\nRecomendaciones para saas_marketing_1:")
    for rec in recommendations:
        print(f"  - {rec}")
```

---

## üé® Sistema de Generaci√≥n Autom√°tica de Design Systems y Componentes Reutilizables

### Script de Design System Generator

**Python**: `scripts/design_system_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de design systems y componentes reutilizables
- Generaci√≥n de componentes SVG reutilizables
- Sistema de tokens de dise√±o (colores, tipograf√≠a, espaciados)
- Biblioteca de componentes pre-configurados
- Generaci√≥n de variantes autom√°ticas
- Exportaci√≥n a m√∫ltiples formatos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class DesignToken:
    """Token de dise√±o"""
    name: str
    value: str
    category: str  # color, typography, spacing, etc.
    description: str

@dataclass
class DesignComponent:
    """Componente de dise√±o"""
    component_id: str
    name: str
    type: str  # button, card, header, etc.
    svg_template: str
    variants: List[str]
    properties: Dict

class DesignSystemGenerator:
    """Generador de design systems"""
    
    def __init__(self):
        self.design_tokens = {}
        self.components = {}
        self.color_palette = {
            'primary': '#3498DB',
            'secondary': '#2C3E50',
            'success': '#27AE60',
            'warning': '#F39C12',
            'error': '#E74C3C',
            'background': '#FFFFFF',
            'text': '#333333'
        }
    
    def create_design_system(self, name: str, brand_colors: Dict) -> Dict:
        """Crea design system completo"""
        
        # Generar tokens de color
        color_tokens = self._generate_color_tokens(brand_colors)
        
        # Generar tokens de tipograf√≠a
        typography_tokens = self._generate_typography_tokens()
        
        # Generar tokens de espaciado
        spacing_tokens = self._generate_spacing_tokens()
        
        # Generar componentes base
        base_components = self._generate_base_components()
        
        design_system = {
            'name': name,
            'created_at': datetime.now().isoformat(),
            'tokens': {
                'colors': color_tokens,
                'typography': typography_tokens,
                'spacing': spacing_tokens
            },
            'components': base_components,
            'version': '1.0.0'
        }
        
        return design_system
    
    def _generate_color_tokens(self, brand_colors: Dict) -> List[DesignToken]:
        """Genera tokens de color"""
        
        tokens = []
        
        for color_name, color_value in brand_colors.items():
            token = DesignToken(
                name=f'color_{color_name}',
                value=color_value,
                category='color',
                description=f'Primary {color_name} color'
            )
            tokens.append(token)
        
        # Agregar variaciones (light, dark, etc.)
        for color_name, color_value in brand_colors.items():
            # Light variant (lighter shade)
            light_token = DesignToken(
                name=f'color_{color_name}_light',
                value=self._lighten_color(color_value),
                category='color',
                description=f'Light variant of {color_name}'
            )
            tokens.append(light_token)
            
            # Dark variant
            dark_token = DesignToken(
                name=f'color_{color_name}_dark',
                value=self._darken_color(color_value),
                category='color',
                description=f'Dark variant of {color_name}'
            )
            tokens.append(dark_token)
        
        return tokens
    
    def _lighten_color(self, hex_color: str) -> str:
        """Aclara color"""
        
        # Simplificado: en producci√≥n usar librer√≠a de colores
        # Por ahora: retornar color modificado
        return hex_color  # Placeholder
    
    def _darken_color(self, hex_color: str) -> str:
        """Oscurece color"""
        
        return hex_color  # Placeholder
    
    def _generate_typography_tokens(self) -> List[DesignToken]:
        """Genera tokens de tipograf√≠a"""
        
        tokens = [
            DesignToken('font_size_h1', '48px', 'typography', 'Heading 1 size'),
            DesignToken('font_size_h2', '36px', 'typography', 'Heading 2 size'),
            DesignToken('font_size_h3', '24px', 'typography', 'Heading 3 size'),
            DesignToken('font_size_body', '16px', 'typography', 'Body text size'),
            DesignToken('font_size_small', '14px', 'typography', 'Small text size'),
            DesignToken('font_family_primary', 'Arial, sans-serif', 'typography', 'Primary font family'),
            DesignToken('line_height_normal', '1.5', 'typography', 'Normal line height'),
            DesignToken('font_weight_bold', '700', 'typography', 'Bold font weight')
        ]
        
        return tokens
    
    def _generate_spacing_tokens(self) -> List[DesignToken]:
        """Genera tokens de espaciado"""
        
        tokens = [
            DesignToken('spacing_xs', '4px', 'spacing', 'Extra small spacing'),
            DesignToken('spacing_sm', '8px', 'spacing', 'Small spacing'),
            DesignToken('spacing_md', '16px', 'spacing', 'Medium spacing'),
            DesignToken('spacing_lg', '24px', 'spacing', 'Large spacing'),
            DesignToken('spacing_xl', '32px', 'spacing', 'Extra large spacing'),
            DesignToken('spacing_xxl', '48px', 'spacing', 'Extra extra large spacing')
        ]
        
        return tokens
    
    def _generate_base_components(self) -> List[DesignComponent]:
        """Genera componentes base"""
        
        components = [
            DesignComponent(
                component_id='button_primary',
                name='Primary Button',
                type='button',
                svg_template='<rect x="0" y="0" width="200" height="50" fill="{color_primary}"/>',
                variants=['default', 'hover', 'active'],
                properties={'width': 200, 'height': 50, 'border_radius': 8}
            ),
            DesignComponent(
                component_id='card_basic',
                name='Basic Card',
                type='card',
                svg_template='<rect x="0" y="0" width="400" height="300" fill="{color_background}"/>',
                variants=['default', 'hover', 'elevated'],
                properties={'width': 400, 'height': 300, 'padding': 24}
            ),
            DesignComponent(
                component_id='header_section',
                name='Section Header',
                type='header',
                svg_template='<text x="0" y="40" font-size="{font_size_h1}" fill="{color_text}">{text}</text>',
                variants=['default', 'centered', 'left_aligned'],
                properties={'height': 80}
            )
        ]
        
        return components
    
    def generate_component_variant(self, component_id: str, variant_name: str,
                                  properties: Dict) -> DesignComponent:
        """Genera variante de componente"""
        
        if component_id not in self.components:
            base_component = self._get_base_component(component_id)
        else:
            base_component = self.components[component_id]
        
        # Crear nueva variante
        variant = DesignComponent(
            component_id=f"{component_id}_{variant_name}",
            name=f"{base_component.name} - {variant_name}",
            type=base_component.type,
            svg_template=base_component.svg_template,
            variants=base_component.variants + [variant_name],
            properties={**base_component.properties, **properties}
        )
        
        self.components[variant.component_id] = variant
        
        return variant
    
    def _get_base_component(self, component_id: str) -> Optional[DesignComponent]:
        """Obtiene componente base"""
        
        base_components = self._generate_base_components()
        return next((c for c in base_components if c.component_id == component_id), None)
    
    def export_design_system(self, design_system: Dict, format: str) -> Dict:
        """Exporta design system a formato espec√≠fico"""
        
        formats = {
            'json': self._export_to_json,
            'css': self._export_to_css,
            'scss': self._export_to_scss,
            'figma': self._export_to_figma
        }
        
        exporter = formats.get(format.lower())
        if not exporter:
            return {'status': 'error', 'message': 'Format not supported'}
        
        return exporter(design_system)
    
    def _export_to_json(self, design_system: Dict) -> Dict:
        """Exporta a JSON"""
        
        return {
            'status': 'success',
            'format': 'json',
            'content': json.dumps(design_system, indent=2)
        }
    
    def _export_to_css(self, design_system: Dict) -> Dict:
        """Exporta a CSS variables"""
        
        css_vars = []
        css_vars.append(':root {')
        
        for category, tokens in design_system['tokens'].items():
            for token in tokens:
                var_name = f'--{token.name.replace("_", "-")}'
                css_vars.append(f'  {var_name}: {token.value};')
        
        css_vars.append('}')
        
        return {
            'status': 'success',
            'format': 'css',
            'content': '\n'.join(css_vars)
        }
    
    def _export_to_scss(self, design_system: Dict) -> Dict:
        """Exporta a SCSS variables"""
        
        scss_vars = []
        
        for category, tokens in design_system['tokens'].items():
            scss_vars.append(f'// {category.upper()}')
            for token in tokens:
                var_name = f'${token.name}'
                scss_vars.append(f'{var_name}: {token.value};')
            scss_vars.append('')
        
        return {
            'status': 'success',
            'format': 'scss',
            'content': '\n'.join(scss_vars)
        }
    
    def _export_to_figma(self, design_system: Dict) -> Dict:
        """Exporta para Figma (simplificado)"""
        
        # En producci√≥n: usar Figma API
        return {
            'status': 'success',
            'format': 'figma',
            'message': 'Design system ready for Figma import'
        }

if __name__ == '__main__':
    generator = DesignSystemGenerator()
    
    # Crear design system
    brand_colors = {
        'primary': '#3498DB',
        'secondary': '#2C3E50'
    }
    
    design_system = generator.create_design_system('Blatam Design System', brand_colors)
    
    print(f"Design System creado: {design_system['name']}")
    print(f"  Tokens: {len(design_system['tokens']['colors'])} colores")
    print(f"  Componentes: {len(design_system['components'])}")
    
    # Exportar a CSS
    css_export = generator.export_design_system(design_system, 'css')
    print(f"\nExportado a CSS: {len(css_export['content'].split('\\n'))} l√≠neas")
```

---

## üì± Sistema de Testing Automatizado Multi-Plataforma y Multi-Dispositivo

### Script de Testing Automatizado

**Python**: `scripts/automated_multi_platform_testing.py`

```python
#!/usr/bin/env python3
"""
Sistema de testing automatizado multi-plataforma y multi-dispositivo
- Testing en m√∫ltiples plataformas sociales
- Testing en m√∫ltiples dispositivos y resoluciones
- Validaci√≥n autom√°tica de rendimiento
- Testing de accesibilidad automatizado
- Screenshots y reportes autom√°ticos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class Platform(Enum):
    INSTAGRAM = "instagram"
    LINKEDIN = "linkedin"
    FACEBOOK = "facebook"
    TWITTER = "twitter"
    TIKTOK = "tiktok"

class Device(Enum):
    MOBILE_IPHONE = "mobile_iphone"
    MOBILE_ANDROID = "mobile_android"
    TABLET_IPAD = "tablet_ipad"
    DESKTOP = "desktop"

@dataclass
class TestResult:
    """Resultado de test"""
    test_id: str
    platform: Optional[Platform]
    device: Optional[Device]
    status: str  # passed, failed, warning
    score: float
    issues: List[str]
    screenshots: List[str]

class AutomatedMultiPlatformTesting:
    """Sistema de testing automatizado"""
    
    def __init__(self):
        self.test_results = {}
        self.platform_specs = {
            Platform.INSTAGRAM: {'max_width': 1080, 'max_height': 1350, 'aspect_ratio': 1.0},
            Platform.LINKEDIN: {'max_width': 1200, 'max_height': 627, 'aspect_ratio': 1.91},
            Platform.FACEBOOK: {'max_width': 1200, 'max_height': 630, 'aspect_ratio': 1.91},
            Platform.TWITTER: {'max_width': 1200, 'max_height': 675, 'aspect_ratio': 1.78},
            Platform.TIKTOK: {'max_width': 1080, 'max_height': 1920, 'aspect_ratio': 0.56}
        }
    
    def run_full_test_suite(self, carousel_id: str, carousel_data: Dict) -> Dict:
        """Ejecuta suite completa de tests"""
        
        test_results = []
        
        # Test en todas las plataformas
        for platform in Platform:
            platform_result = self.test_on_platform(carousel_id, carousel_data, platform)
            test_results.append(platform_result)
        
        # Test en todos los dispositivos
        for device in Device:
            device_result = self.test_on_device(carousel_id, carousel_data, device)
            test_results.append(device_result)
        
        # Test de performance
        performance_result = self.test_performance(carousel_id, carousel_data)
        test_results.append(performance_result)
        
        # Test de accesibilidad
        accessibility_result = self.test_accessibility(carousel_id, carousel_data)
        test_results.append(accessibility_result)
        
        # Calcular score general
        overall_score = sum(r.score for r in test_results) / len(test_results) if test_results else 0
        
        # Agregar resultados al historial
        self.test_results[carousel_id] = {
            'carousel_id': carousel_id,
            'overall_score': overall_score,
            'test_count': len(test_results),
            'passed': len([r for r in test_results if r.status == 'passed']),
            'failed': len([r for r in test_results if r.status == 'failed']),
            'warnings': len([r for r in test_results if r.status == 'warning']),
            'results': test_results,
            'timestamp': datetime.now().isoformat()
        }
        
        return self.test_results[carousel_id]
    
    def test_on_platform(self, carousel_id: str, carousel_data: Dict,
                        platform: Platform) -> TestResult:
        """Test en plataforma espec√≠fica"""
        
        issues = []
        
        # Verificar dimensiones
        specs = self.platform_specs.get(platform, {})
        width = carousel_data.get('width', 0)
        height = carousel_data.get('height', 0)
        
        if width > specs.get('max_width', float('inf')):
            issues.append(f"Ancho {width}px excede m√°ximo {specs['max_width']}px para {platform.value}")
        
        if height > specs.get('max_height', float('inf')):
            issues.append(f"Alto {height}px excede m√°ximo {specs['max_height']}px para {platform.value}")
        
        # Verificar aspect ratio
        if width and height:
            aspect_ratio = width / height
            expected_ratio = specs.get('aspect_ratio', 1.0)
            
            if abs(aspect_ratio - expected_ratio) > 0.1:
                issues.append(f"Aspect ratio {aspect_ratio:.2f} no coincide con {expected_ratio:.2f} para {platform.value}")
        
        # Verificar contenido requerido
        if not carousel_data.get('headline'):
            issues.append(f"Falta headline requerido para {platform.value}")
        
        # Calcular score
        score = 100.0 - (len(issues) * 20)
        status = 'passed' if score >= 80 else 'failed' if score < 60 else 'warning'
        
        return TestResult(
            test_id=f"{carousel_id}_platform_{platform.value}",
            platform=platform,
            device=None,
            status=status,
            score=max(0.0, score),
            issues=issues,
            screenshots=[f"https://cdn.example.com/screenshots/{carousel_id}_{platform.value}.png"]
        )
    
    def test_on_device(self, carousel_id: str, carousel_data: Dict,
                      device: Device) -> TestResult:
        """Test en dispositivo espec√≠fico"""
        
        issues = []
        
        # Verificar legibilidad de texto
        font_sizes = carousel_data.get('typography', {}).get('font_sizes', {})
        
        min_font_sizes = {
            Device.MOBILE_IPHONE: {'headline': 24, 'body': 14},
            Device.MOBILE_ANDROID: {'headline': 24, 'body': 14},
            Device.TABLET_IPAD: {'headline': 32, 'body': 16},
            Device.DESKTOP: {'headline': 40, 'body': 16}
        }
        
        device_min_sizes = min_font_sizes.get(device, {})
        
        for element, min_size in device_min_sizes.items():
            actual_size = font_sizes.get(element, 0)
            if actual_size < min_size:
                issues.append(f"Font size {element} ({actual_size}px) muy peque√±o para {device.value} (m√≠nimo {min_size}px)")
        
        # Verificar touch targets en m√≥viles
        if device in [Device.MOBILE_IPHONE, Device.MOBILE_ANDROID]:
            cta_size = carousel_data.get('cta', {}).get('size', {})
            if cta_size.get('height', 0) < 44:  # M√≠nimo recomendado iOS
                issues.append(f"CTA muy peque√±o para touch ({cta_size.get('height', 0)}px, m√≠nimo 44px)")
        
        # Calcular score
        score = 100.0 - (len(issues) * 25)
        status = 'passed' if score >= 80 else 'failed' if score < 60 else 'warning'
        
        return TestResult(
            test_id=f"{carousel_id}_device_{device.value}",
            platform=None,
            device=device,
            status=status,
            score=max(0.0, score),
            issues=issues,
            screenshots=[f"https://cdn.example.com/screenshots/{carousel_id}_{device.value}.png"]
        )
    
    def test_performance(self, carousel_id: str, carousel_data: Dict) -> TestResult:
        """Test de performance"""
        
        issues = []
        
        # Verificar tama√±o de archivo
        file_size = carousel_data.get('file_size', 0)  # En KB
        
        if file_size > 500:
            issues.append(f"Tama√±o de archivo muy grande: {file_size}KB (recomendado < 500KB)")
        
        # Verificar n√∫mero de im√°genes
        image_count = len(carousel_data.get('images', []))
        if image_count > 10:
            issues.append(f"Demasiadas im√°genes: {image_count} (recomendado < 10)")
        
        # Verificar optimizaci√≥n
        optimized_images = carousel_data.get('optimized_images', 0)
        total_images = image_count
        if total_images > 0 and optimized_images < total_images:
            issues.append(f"Im√°genes no optimizadas: {total_images - optimized_images}/{total_images}")
        
        score = 100.0 - (len(issues) * 30)
        status = 'passed' if score >= 80 else 'failed' if score < 60 else 'warning'
        
        return TestResult(
            test_id=f"{carousel_id}_performance",
            platform=None,
            device=None,
            status=status,
            score=max(0.0, score),
            issues=issues,
            screenshots=[]
        )
    
    def test_accessibility(self, carousel_id: str, carousel_data: Dict) -> TestResult:
        """Test de accesibilidad"""
        
        issues = []
        
        # Verificar alt text
        images = carousel_data.get('images', [])
        images_without_alt = [img for img in images if not img.get('alt_text')]
        
        if images_without_alt:
            issues.append(f"Im√°genes sin alt text: {len(images_without_alt)}")
        
        # Verificar contraste de colores
        text_color = carousel_data.get('text_color', '#000000')
        background_color = carousel_data.get('background_color', '#FFFFFF')
        
        # Simplificado: en producci√≥n calcular ratio de contraste real
        if text_color == background_color:
            issues.append("Colores de texto y fondo id√©nticos (sin contraste)")
        
        # Verificar texto alternativo
        if not carousel_data.get('headline'):
            issues.append("Falta texto alternativo para contenido principal")
        
        score = 100.0 - (len(issues) * 25)
        status = 'passed' if score >= 80 else 'failed' if score < 60 else 'warning'
        
        return TestResult(
            test_id=f"{carousel_id}_accessibility",
            platform=None,
            device=None,
            status=status,
            score=max(0.0, score),
            issues=issues,
            screenshots=[]
        )
    
    def generate_test_report(self, carousel_id: str, format: str = 'html') -> Dict:
        """Genera reporte de tests"""
        
        if carousel_id not in self.test_results:
            return {'status': 'error', 'message': 'No test results found'}
        
        test_data = self.test_results[carousel_id]
        
        formats = {
            'html': self._generate_html_report,
            'json': self._generate_json_report,
            'pdf': self._generate_pdf_report
        }
        
        generator = formats.get(format.lower())
        if not generator:
            return {'status': 'error', 'message': 'Format not supported'}
        
        return generator(test_data)
    
    def _generate_html_report(self, test_data: Dict) -> Dict:
        """Genera reporte HTML"""
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head><title>Test Report - {test_data['carousel_id']}</title></head>
        <body>
        <h1>Test Report: {test_data['carousel_id']}</h1>
        <p>Overall Score: {test_data['overall_score']:.1f}/100</p>
        <p>Tests Passed: {test_data['passed']}/{test_data['test_count']}</p>
        <h2>Detailed Results</h2>
        <ul>
        """
        
        for result in test_data['results']:
            html += f"<li>{result.test_id}: {result.status} ({result.score:.1f}/100)</li>"
        
        html += "</ul></body></html>"
        
        return {
            'status': 'success',
            'format': 'html',
            'content': html
        }
    
    def _generate_json_report(self, test_data: Dict) -> Dict:
        """Genera reporte JSON"""
        
        return {
            'status': 'success',
            'format': 'json',
            'content': json.dumps(test_data, indent=2, default=str)
        }
    
    def _generate_pdf_report(self, test_data: Dict) -> Dict:
        """Genera reporte PDF"""
        
        # En producci√≥n: usar reportlab o weasyprint
        return {
            'status': 'success',
            'format': 'pdf',
            'file_url': f"https://cdn.example.com/reports/{test_data['carousel_id']}_test_report.pdf"
        }

if __name__ == '__main__':
    tester = AutomatedMultiPlatformTesting()
    
    # Datos de carrusel de ejemplo
    carousel_data = {
        'carousel_id': 'curso_ia_1',
        'width': 1200,
        'height': 627,
        'headline': 'Aprende IA aplicada',
        'typography': {
            'font_sizes': {
                'headline': 48,
                'body': 16
            }
        },
        'cta': {
            'size': {'height': 50}
        },
        'images': [{'alt_text': 'IA course'}],
        'text_color': '#000000',
        'background_color': '#FFFFFF',
        'file_size': 350,
        'optimized_images': 1
    }
    
    # Ejecutar tests
    results = tester.run_full_test_suite('curso_ia_1', carousel_data)
    
    print(f"Tests ejecutados: {results['test_count']}")
    print(f"Score general: {results['overall_score']:.1f}/100")
    print(f"Passed: {results['passed']}, Failed: {results['failed']}, Warnings: {results['warnings']}")
    
    # Generar reporte
    report = tester.generate_test_report('curso_ia_1', 'html')
    print(f"\nReporte generado: {report['format']}")
```

---

## üéØ Sistema de Segmentaci√≥n Avanzada y Personalizaci√≥n Din√°mica por Audiencia

### Script de Segmentaci√≥n y Personalizaci√≥n

**Python**: `scripts/advanced_audience_segmentation_personalization.py`

```python
#!/usr/bin/env python3
"""
Sistema de segmentaci√≥n avanzada y personalizaci√≥n din√°mica por audiencia
- Segmentaci√≥n multi-dimensional (demogr√°fica, psicogr√°fica, comportamental)
- Personalizaci√≥n din√°mica de contenido por segmento
- Testing A/B por segmento
- An√°lisis de performance por audiencia
- Recomendaciones de segmentaci√≥n optimizada
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class SegmentDimension(Enum):
    DEMOGRAPHIC = "demographic"
    PSYCHOGRAPHIC = "psychographic"
    BEHAVIORAL = "behavioral"
    GEOGRAPHIC = "geographic"

@dataclass
class AudienceSegment:
    """Segmento de audiencia"""
    segment_id: str
    name: str
    dimensions: Dict
    size: int
    characteristics: Dict
    personalized_content: Dict

class AdvancedAudienceSegmentationPersonalization:
    """Sistema de segmentaci√≥n avanzada"""
    
    def __init__(self):
        self.segments = {}
        self.personalization_rules = {}
    
    def create_segment(self, name: str, criteria: Dict) -> AudienceSegment:
        """Crea segmento de audiencia"""
        
        segment = AudienceSegment(
            segment_id=f"segment_{datetime.now().timestamp()}",
            name=name,
            dimensions=self._extract_dimensions(criteria),
            size=0,  # Se calcular√° din√°micamente
            characteristics=criteria,
            personalized_content={}
        )
        
        self.segments[segment.segment_id] = segment
        
        return segment
    
    def _extract_dimensions(self, criteria: Dict) -> Dict:
        """Extrae dimensiones de criterios"""
        
        dimensions = {
            SegmentDimension.DEMOGRAPHIC: {},
            SegmentDimension.PSYCHOGRAPHIC: {},
            SegmentDimension.BEHAVIORAL: {},
            SegmentDimension.GEOGRAPHIC: {}
        }
        
        # Demogr√°fico
        if 'age_range' in criteria:
            dimensions[SegmentDimension.DEMOGRAPHIC]['age'] = criteria['age_range']
        if 'gender' in criteria:
            dimensions[SegmentDimension.DEMOGRAPHIC]['gender'] = criteria['gender']
        if 'education' in criteria:
            dimensions[SegmentDimension.DEMOGRAPHIC]['education'] = criteria['education']
        
        # Psicogr√°fico
        if 'interests' in criteria:
            dimensions[SegmentDimension.PSYCHOGRAPHIC]['interests'] = criteria['interests']
        if 'values' in criteria:
            dimensions[SegmentDimension.PSYCHOGRAPHIC]['values'] = criteria['values']
        if 'lifestyle' in criteria:
            dimensions[SegmentDimension.PSYCHOGRAPHIC]['lifestyle'] = criteria['lifestyle']
        
        # Comportamental
        if 'purchase_history' in criteria:
            dimensions[SegmentDimension.BEHAVIORAL]['purchase_history'] = criteria['purchase_history']
        if 'engagement_level' in criteria:
            dimensions[SegmentDimension.BEHAVIORAL]['engagement'] = criteria['engagement_level']
        
        # Geogr√°fico
        if 'location' in criteria:
            dimensions[SegmentDimension.GEOGRAPHIC]['location'] = criteria['location']
        if 'timezone' in criteria:
            dimensions[SegmentDimension.GEOGRAPHIC]['timezone'] = criteria['timezone']
        
        return dimensions
    
    def personalize_content_for_segment(self, carousel_id: str, segment_id: str,
                                      base_content: Dict) -> Dict:
        """Personaliza contenido para segmento"""
        
        if segment_id not in self.segments:
            return base_content
        
        segment = self.segments[segment_id]
        
        personalized = base_content.copy()
        
        # Personalizar headline seg√∫n segmento
        personalized['headline'] = self._personalize_headline(
            base_content.get('headline', ''),
            segment
        )
        
        # Personalizar CTA seg√∫n segmento
        personalized['cta'] = self._personalize_cta(
            base_content.get('cta', ''),
            segment
        )
        
        # Personalizar visual seg√∫n segmento
        personalized['visual_style'] = self._personalize_visual(
            base_content.get('visual_style', 'standard'),
            segment
        )
        
        # Personalizar copy seg√∫n segmento
        personalized['copy'] = self._personalize_copy(
            base_content.get('copy', ''),
            segment
        )
        
        return personalized
    
    def _personalize_headline(self, base_headline: str, segment: AudienceSegment) -> str:
        """Personaliza headline para segmento"""
        
        personalized = base_headline
        
        # Personalizaci√≥n por demograf√≠a
        if 'age' in segment.dimensions.get(SegmentDimension.DEMOGRAPHIC, {}):
            age_range = segment.dimensions[SegmentDimension.DEMOGRAPHIC]['age']
            if age_range[1] < 30:  # J√≥venes
                personalized = personalized.replace('aprende', 'domina r√°pido')
        
        # Personalizaci√≥n por psicograf√≠a
        if 'interests' in segment.dimensions.get(SegmentDimension.PSYCHOGRAPHIC, {}):
            interests = segment.dimensions[SegmentDimension.PSYCHOGRAPHIC]['interests']
            if 'tech' in interests:
                personalized = f"Tech Pro: {personalized}"
        
        # Personalizaci√≥n por comportamiento
        if 'engagement' in segment.dimensions.get(SegmentDimension.BEHAVIORAL, {}):
            engagement = segment.dimensions[SegmentDimension.BEHAVIORAL]['engagement']
            if engagement == 'high':
                personalized = f"VIP: {personalized}"
        
        return personalized
    
    def _personalize_cta(self, base_cta: str, segment: AudienceSegment) -> str:
        """Personaliza CTA para segmento"""
        
        personalized = base_cta
        
        # CTAs m√°s directos para segmentos con alto engagement
        if 'engagement' in segment.dimensions.get(SegmentDimension.BEHAVIORAL, {}):
            engagement = segment.dimensions[SegmentDimension.BEHAVIORAL]['engagement']
            if engagement == 'high':
                personalized = personalized.replace('descubre', 'compra ahora')
        
        return personalized
    
    def _personalize_visual(self, base_visual: str, segment: AudienceSegment) -> str:
        """Personaliza visual para segmento"""
        
        # Visuales m√°s vibrantes para audiencias j√≥venes
        if 'age' in segment.dimensions.get(SegmentDimension.DEMOGRAPHIC, {}):
            age_range = segment.dimensions[SegmentDimension.DEMOGRAPHIC]['age']
            if age_range[1] < 30:
                return 'bold'
            elif age_range[0] > 45:
                return 'professional'
        
        return base_visual
    
    def _personalize_copy(self, base_copy: str, segment: AudienceSegment) -> str:
        """Personaliza copy para segmento"""
        
        personalized = base_copy
        
        # Copy m√°s t√©cnico para segmentos tech-savvy
        if 'interests' in segment.dimensions.get(SegmentDimension.PSYCHOGRAPHIC, {}):
            interests = segment.dimensions[SegmentDimension.PSYCHOGRAPHIC]['interests']
            if 'tech' in interests:
                personalized = personalized.replace('f√°cil', 'eficiente')
        
        return personalized
    
    def analyze_segment_performance(self, segment_id: str, 
                                   performance_data: List[Dict]) -> Dict:
        """Analiza performance por segmento"""
        
        if segment_id not in self.segments:
            return {'status': 'error', 'message': 'Segment not found'}
        
        segment_data = [d for d in performance_data if d.get('segment_id') == segment_id]
        
        if not segment_data:
            return {
                'segment_id': segment_id,
                'message': 'No performance data available'
            }
        
        # Calcular m√©tricas agregadas
        total_impressions = sum(d.get('impressions', 0) for d in segment_data)
        total_clicks = sum(d.get('clicks', 0) for d in segment_data)
        total_conversions = sum(d.get('conversions', 0) for d in segment_data)
        
        ctr = (total_clicks / total_impressions * 100) if total_impressions > 0 else 0
        conversion_rate = (total_conversions / total_clicks * 100) if total_clicks > 0 else 0
        
        return {
            'segment_id': segment_id,
            'segment_name': self.segments[segment_id].name,
            'metrics': {
                'impressions': total_impressions,
                'clicks': total_clicks,
                'conversions': total_conversions,
                'ctr': ctr,
                'conversion_rate': conversion_rate
            },
            'benchmark_comparison': self._compare_to_benchmark(ctr, conversion_rate)
        }
    
    def _compare_to_benchmark(self, ctr: float, conversion_rate: float) -> Dict:
        """Compara m√©tricas con benchmarks"""
        
        industry_ctr_benchmark = 3.5
        industry_conversion_benchmark = 5.0
        
        return {
            'ctr_vs_benchmark': 'above' if ctr > industry_ctr_benchmark else 'below',
            'conversion_vs_benchmark': 'above' if conversion_rate > industry_conversion_benchmark else 'below',
            'ctr_difference': ctr - industry_ctr_benchmark,
            'conversion_difference': conversion_rate - industry_conversion_benchmark
        }
    
    def get_segmentation_recommendations(self, performance_data: List[Dict]) -> List[str]:
        """Genera recomendaciones de segmentaci√≥n"""
        
        recommendations = []
        
        # Analizar diferencias entre segmentos
        segments_performance = {}
        for data in performance_data:
            segment_id = data.get('segment_id')
            if segment_id:
                if segment_id not in segments_performance:
                    segments_performance[segment_id] = []
                segments_performance[segment_id].append(data)
        
        # Comparar performance entre segmentos
        segment_ctrs = {}
        for segment_id, data_list in segments_performance.items():
            total_impressions = sum(d.get('impressions', 0) for d in data_list)
            total_clicks = sum(d.get('clicks', 0) for d in data_list)
            ctr = (total_clicks / total_impressions * 100) if total_impressions > 0 else 0
            segment_ctrs[segment_id] = ctr
        
        if segment_ctrs:
            best_segment = max(segment_ctrs.items(), key=lambda x: x[1])
            worst_segment = min(segment_ctrs.items(), key=lambda x: x[1])
            
            if best_segment[1] > worst_segment[1] * 1.5:
                recommendations.append(
                    f"Segmento '{best_segment[0]}' tiene CTR {best_segment[1]:.2f}% vs {worst_segment[1]:.2f}%. "
                    f"Considerar aumentar budget para segmento ganador"
                )
        
        return recommendations

if __name__ == '__main__':
    segmenter = AdvancedAudienceSegmentationPersonalization()
    
    # Crear segmentos
    tech_segment = segmenter.create_segment('Tech Enthusiasts', {
        'age_range': [25, 35],
        'interests': ['tech', 'ai', 'programming'],
        'engagement_level': 'high',
        'location': 'Spain'
    })
    
    print(f"Segmento creado: {tech_segment.name}")
    print(f"  ID: {tech_segment.segment_id}")
    
    # Personalizar contenido
    base_content = {
        'headline': 'Aprende IA aplicada',
        'cta': 'Descubre c√≥mo',
        'visual_style': 'standard',
        'copy': 'Curso f√°cil de seguir'
    }
    
    personalized = segmenter.personalize_content_for_segment(
        'curso_ia_1',
        tech_segment.segment_id,
        base_content
    )
    
    print(f"\nContenido personalizado:")
    print(f"  Headline: {personalized['headline']}")
    print(f"  CTA: {personalized['cta']}")
    print(f"  Visual: {personalized['visual_style']}")
```

---

## üé® Sistema de Generaci√≥n Autom√°tica de Contenido Visual con IA

### Script de Generaci√≥n Visual IA

**Python**: `scripts/ai_visual_content_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de contenido visual con IA
- Generaci√≥n de im√°genes usando DALL-E/Stable Diffusion
- Generaci√≥n de ilustraciones y gr√°ficos
- Optimizaci√≥n autom√°tica de im√°genes
- Generaci√≥n de variantes visuales
- An√°lisis de calidad visual
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class GeneratedImage:
    """Imagen generada"""
    image_id: str
    url: str
    prompt: str
    style: str
    quality_score: float
    relevance_score: float

class AIVisualContentGenerator:
    """Generador de contenido visual con IA"""
    
    def __init__(self):
        self.generated_images = {}
        self.image_styles = {
            'professional': {
                'description': 'Clean, corporate, business-oriented',
                'color_palette': 'neutral, professional',
                'mood': 'serious, trustworthy'
            },
            'vibrant': {
                'description': 'Bold colors, energetic, eye-catching',
                'color_palette': 'vibrant, saturated',
                'mood': 'energetic, dynamic'
            },
            'minimalist': {
                'description': 'Simple, clean, lots of white space',
                'color_palette': 'minimal, monochromatic',
                'mood': 'calm, focused'
            },
            'modern': {
                'description': 'Contemporary, sleek, trendy',
                'color_palette': 'modern, gradient',
                'mood': 'fresh, innovative'
            }
        }
    
    def generate_image(self, prompt: str, style: str = 'professional',
                     carousel_context: Optional[Dict] = None) -> GeneratedImage:
        """Genera imagen usando IA"""
        
        # Enriquecer prompt con contexto del carrusel
        enriched_prompt = self._enrich_prompt(prompt, style, carousel_context)
        
        # En producci√≥n: llamar a DALL-E API o Stable Diffusion
        # Por ahora: simulado
        
        image = GeneratedImage(
            image_id=f"img_{datetime.now().timestamp()}",
            url=f"https://cdn.example.com/generated/{datetime.now().timestamp()}.png",
            prompt=enriched_prompt,
            style=style,
            quality_score=0.85,  # Se calcular√≠a basado en an√°lisis real
            relevance_score=0.90  # Se calcular√≠a basado en prompt matching
        )
        
        self.generated_images[image.image_id] = image
        
        return image
    
    def _enrich_prompt(self, base_prompt: str, style: str,
                      context: Optional[Dict]) -> str:
        """Enriquece prompt con estilo y contexto"""
        
        style_config = self.image_styles.get(style, {})
        
        enriched = f"{base_prompt}, {style_config.get('description', '')}"
        
        if context:
            # Agregar informaci√≥n del producto
            if 'product' in context:
                enriched += f", featuring {context['product']}"
            
            # Agregar colores de marca
            if 'brand_colors' in context:
                colors = ', '.join(context['brand_colors'][:3])
                enriched += f", color scheme: {colors}"
        
        return enriched
    
    def generate_image_variants(self, base_image_id: str, variant_count: int = 3) -> List[GeneratedImage]:
        """Genera variantes de imagen"""
        
        if base_image_id not in self.generated_images:
            return []
        
        base_image = self.generated_images[base_image_id]
        variants = []
        
        # Generar variantes con diferentes estilos
        styles = ['professional', 'vibrant', 'minimalist', 'modern']
        
        for i, style in enumerate(styles[:variant_count]):
            variant_prompt = self._create_variant_prompt(base_image.prompt, style)
            
            variant = self.generate_image(variant_prompt, style)
            variant.image_id = f"{base_image_id}_variant_{i}"
            
            variants.append(variant)
        
        return variants
    
    def _create_variant_prompt(self, base_prompt: str, style: str) -> str:
        """Crea prompt para variante"""
        
        style_config = self.image_styles.get(style, {})
        
        # Remover estilo anterior y agregar nuevo
        prompt_without_style = base_prompt.split(',')[0]  # Simplificado
        return f"{prompt_without_style}, {style_config.get('description', '')}"
    
    def generate_illustration(self, concept: str, carousel_context: Dict) -> GeneratedImage:
        """Genera ilustraci√≥n para concepto"""
        
        prompt = f"Illustration of {concept}, {carousel_context.get('visual_style', 'modern')} style"
        
        return self.generate_image(prompt, 'modern', carousel_context)
    
    def generate_graphic(self, data_type: str, data: Dict) -> GeneratedImage:
        """Genera gr√°fico de datos"""
        
        prompt = f"Data visualization, {data_type} chart, showing {data.get('title', 'data')}, professional, clean"
        
        return self.generate_image(prompt, 'professional')
    
    def analyze_image_quality(self, image_id: str) -> Dict:
        """Analiza calidad de imagen generada"""
        
        if image_id not in self.generated_images:
            return {'status': 'error', 'message': 'Image not found'}
        
        image = self.generated_images[image_id]
        
        # En producci√≥n: usar visi√≥n por computadora para an√°lisis real
        # Por ahora: an√°lisis simplificado
        
        analysis = {
            'image_id': image_id,
            'quality_score': image.quality_score,
            'relevance_score': image.relevance_score,
            'aspects': {
                'clarity': 0.85,
                'composition': 0.80,
                'color_balance': 0.90,
                'brand_alignment': 0.75
            },
            'recommendations': self._generate_quality_recommendations(image)
        }
        
        return analysis
    
    def _generate_quality_recommendations(self, image: GeneratedImage) -> List[str]:
        """Genera recomendaciones de calidad"""
        
        recommendations = []
        
        if image.quality_score < 0.8:
            recommendations.append("Considerar regenerar con prompt m√°s espec√≠fico")
        
        if image.relevance_score < 0.8:
            recommendations.append("Relevancia baja, ajustar prompt para mejor match")
        
        return recommendations
    
    def optimize_image_for_platform(self, image_id: str, platform: str) -> Dict:
        """Optimiza imagen para plataforma espec√≠fica"""
        
        if image_id not in self.generated_images:
            return {'status': 'error', 'message': 'Image not found'}
        
        platform_specs = {
            'instagram': {'width': 1080, 'height': 1080, 'format': 'jpg'},
            'linkedin': {'width': 1200, 'height': 627, 'format': 'jpg'},
            'facebook': {'width': 1200, 'height': 630, 'format': 'jpg'},
            'twitter': {'width': 1200, 'height': 675, 'format': 'jpg'}
        }
        
        specs = platform_specs.get(platform, platform_specs['instagram'])
        
        return {
            'image_id': image_id,
            'platform': platform,
            'optimized_url': f"https://cdn.example.com/optimized/{image_id}_{platform}.{specs['format']}",
            'dimensions': {
                'width': specs['width'],
                'height': specs['height']
            },
            'format': specs['format']
        }

if __name__ == '__main__':
    generator = AIVisualContentGenerator()
    
    # Generar imagen
    carousel_context = {
        'product': 'Curso IA',
        'brand_colors': ['#3498DB', '#2C3E50'],
        'visual_style': 'professional'
    }
    
    image = generator.generate_image(
        'Artificial intelligence course illustration',
        style='professional',
        carousel_context=carousel_context
    )
    
    print(f"Imagen generada: {image.image_id}")
    print(f"  URL: {image.url}")
    print(f"  Quality: {image.quality_score:.1%}")
    print(f"  Relevance: {image.relevance_score:.1%}")
    
    # Generar variantes
    variants = generator.generate_image_variants(image.image_id, variant_count=2)
    print(f"\nVariantes generadas: {len(variants)}")
```

---

## üîÑ Sistema de Sincronizaci√≥n Bidireccional con Plataformas Externas

### Script de Sincronizaci√≥n Bidireccional

**Python**: `scripts/bidirectional_platform_sync.py`

```python
#!/usr/bin/env python3
"""
Sistema de sincronizaci√≥n bidireccional con plataformas externas
- Sincronizaci√≥n bidireccional con CMS, DAM, Figma, Canva
- Detecci√≥n y resoluci√≥n de conflictos
- Historial de sincronizaciones
- Webhooks para actualizaciones en tiempo real
- Mapeo de campos entre plataformas
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class SyncDirection(Enum):
    PUSH = "push"  # Local -> External
    PULL = "pull"  # External -> Local
    BIDIRECTIONAL = "bidirectional"

class SyncStatus(Enum):
    SUCCESS = "success"
    PARTIAL = "partial"
    FAILED = "failed"
    CONFLICT = "conflict"

@dataclass
class SyncResult:
    """Resultado de sincronizaci√≥n"""
    sync_id: str
    platform: str
    direction: SyncDirection
    status: SyncStatus
    items_synced: int
    conflicts: List[Dict]
    timestamp: datetime

class BidirectionalPlatformSync:
    """Sistema de sincronizaci√≥n bidireccional"""
    
    def __init__(self):
        self.sync_history = []
        self.platform_configs = {
            'figma': {
                'api_endpoint': 'https://api.figma.com/v1',
                'field_mapping': {
                    'headline': 'name',
                    'description': 'description',
                    'image_url': 'image_url'
                }
            },
            'canva': {
                'api_endpoint': 'https://api.canva.com/v1',
                'field_mapping': {
                    'headline': 'title',
                    'description': 'caption',
                    'image_url': 'thumbnail_url'
                }
            },
            'contentful': {
                'api_endpoint': 'https://api.contentful.com',
                'field_mapping': {
                    'headline': 'fields.headline',
                    'description': 'fields.description',
                    'image_url': 'fields.image'
                }
            }
        }
    
    def sync_to_platform(self, carousel_id: str, carousel_data: Dict,
                        platform: str, direction: SyncDirection = SyncDirection.PUSH) -> SyncResult:
        """Sincroniza carrusel a plataforma externa"""
        
        if platform not in self.platform_configs:
            return SyncResult(
                sync_id=f"sync_{datetime.now().timestamp()}",
                platform=platform,
                direction=direction,
                status=SyncStatus.FAILED,
                items_synced=0,
                conflicts=[],
                timestamp=datetime.now()
            )
        
        config = self.platform_configs[platform]
        
        # Mapear campos
        mapped_data = self._map_fields(carousel_data, config['field_mapping'])
        
        # En producci√≥n: hacer llamada API real
        # Por ahora: simulado
        
        # Detectar conflictos
        conflicts = self._detect_conflicts(carousel_id, platform, mapped_data)
        
        if conflicts:
            status = SyncStatus.CONFLICT
        else:
            status = SyncStatus.SUCCESS
        
        result = SyncResult(
            sync_id=f"sync_{datetime.now().timestamp()}",
            platform=platform,
            direction=direction,
            status=status,
            items_synced=1,
            conflicts=conflicts,
            timestamp=datetime.now()
        )
        
        self.sync_history.append(result)
        
        return result
    
    def sync_from_platform(self, platform: str, external_id: str) -> Dict:
        """Sincroniza desde plataforma externa"""
        
        if platform not in self.platform_configs:
            return {'status': 'error', 'message': 'Platform not configured'}
        
        config = self.platform_configs[platform]
        
        # En producci√≥n: obtener datos de API externa
        # Por ahora: simulado
        
        external_data = {
            'headline': 'External headline',
            'description': 'External description',
            'image_url': 'https://example.com/external.jpg'
        }
        
        # Mapear campos inverso
        mapped_data = self._reverse_map_fields(external_data, config['field_mapping'])
        
        # Detectar cambios
        changes = self._detect_changes(external_data, mapped_data)
        
        return {
            'status': 'success',
            'platform': platform,
            'external_id': external_id,
            'data': mapped_data,
            'changes': changes
        }
    
    def _map_fields(self, data: Dict, field_mapping: Dict) -> Dict:
        """Mapea campos locales a formato de plataforma externa"""
        
        mapped = {}
        
        for local_field, external_field in field_mapping.items():
            if local_field in data:
                # Manejar campos anidados (ej: 'fields.headline')
                keys = external_field.split('.')
                current = mapped
                
                for key in keys[:-1]:
                    if key not in current:
                        current[key] = {}
                    current = current[key]
                
                current[keys[-1]] = data[local_field]
        
        return mapped
    
    def _reverse_map_fields(self, data: Dict, field_mapping: Dict) -> Dict:
        """Mapea campos de plataforma externa a formato local"""
        
        mapped = {}
        
        # Crear mapeo inverso
        reverse_mapping = {v: k for k, v in field_mapping.items()}
        
        # Extraer valores anidados
        for external_field, local_field in reverse_mapping.items():
            keys = external_field.split('.')
            value = data
            
            try:
                for key in keys:
                    value = value[key]
                mapped[local_field] = value
            except (KeyError, TypeError):
                pass
        
        return mapped
    
    def _detect_conflicts(self, carousel_id: str, platform: str,
                         new_data: Dict) -> List[Dict]:
        """Detecta conflictos de sincronizaci√≥n"""
        
        conflicts = []
        
        # En producci√≥n: comparar con √∫ltima versi√≥n sincronizada
        # Por ahora: simulado
        
        # Ejemplo de conflicto: campo modificado en ambas plataformas
        last_sync = self._get_last_sync(carousel_id, platform)
        if last_sync:
            # Comparar campos cr√≠ticos
            if 'headline' in new_data and last_sync.get('headline') != new_data.get('headline'):
                conflicts.append({
                    'field': 'headline',
                    'local_value': last_sync.get('headline'),
                    'external_value': new_data.get('headline'),
                    'timestamp': datetime.now().isoformat()
                })
        
        return conflicts
    
    def _get_last_sync(self, carousel_id: str, platform: str) -> Optional[Dict]:
        """Obtiene √∫ltima sincronizaci√≥n"""
        
        # En producci√≥n: consultar base de datos
        return None
    
    def _detect_changes(self, old_data: Dict, new_data: Dict) -> List[Dict]:
        """Detecta cambios entre datos"""
        
        changes = []
        
        all_keys = set(list(old_data.keys()) + list(new_data.keys()))
        
        for key in all_keys:
            old_value = old_data.get(key)
            new_value = new_data.get(key)
            
            if old_value != new_value:
                changes.append({
                    'field': key,
                    'old_value': old_value,
                    'new_value': new_value
                })
        
        return changes
    
    def resolve_conflict(self, conflict: Dict, resolution: str) -> Dict:
        """Resuelve conflicto de sincronizaci√≥n"""
        
        # resolution: 'keep_local', 'keep_external', 'merge'
        
        if resolution == 'keep_local':
            return {
                'status': 'resolved',
                'action': 'keep_local',
                'field': conflict['field'],
                'value': conflict['local_value']
            }
        elif resolution == 'keep_external':
            return {
                'status': 'resolved',
                'action': 'keep_external',
                'field': conflict['field'],
                'value': conflict['external_value']
            }
        elif resolution == 'merge':
            # Merge inteligente (ej: combinar ambos valores)
            return {
                'status': 'resolved',
                'action': 'merge',
                'field': conflict['field'],
                'value': f"{conflict['local_value']} - {conflict['external_value']}"
            }
        
        return {'status': 'error', 'message': 'Invalid resolution'}
    
    def setup_webhook(self, platform: str, webhook_url: str) -> Dict:
        """Configura webhook para sincronizaci√≥n autom√°tica"""
        
        # En producci√≥n: registrar webhook en plataforma externa
        
        return {
            'status': 'success',
            'platform': platform,
            'webhook_url': webhook_url,
            'events': ['create', 'update', 'delete'],
            'configured_at': datetime.now().isoformat()
        }
    
    def get_sync_history(self, carousel_id: Optional[str] = None,
                        platform: Optional[str] = None) -> List[Dict]:
        """Obtiene historial de sincronizaciones"""
        
        history = self.sync_history
        
        # Filtrar por carrusel si se especifica
        if carousel_id:
            # En producci√≥n: filtrar por carousel_id real
            pass
        
        # Filtrar por plataforma si se especifica
        if platform:
            history = [h for h in history if h.platform == platform]
        
        return [
            {
                'sync_id': h.sync_id,
                'platform': h.platform,
                'direction': h.direction.value,
                'status': h.status.value,
                'items_synced': h.items_synced,
                'conflicts_count': len(h.conflicts),
                'timestamp': h.timestamp.isoformat()
            }
            for h in history
        ]

if __name__ == '__main__':
    sync = BidirectionalPlatformSync()
    
    # Sincronizar a Figma
    carousel_data = {
        'headline': 'Aprende IA aplicada',
        'description': 'Transforma tu carrera',
        'image_url': 'https://example.com/image.jpg'
    }
    
    result = sync.sync_to_platform('curso_ia_1', carousel_data, 'figma')
    
    print(f"Sincronizaci√≥n realizada:")
    print(f"  Plataforma: {result.platform}")
    print(f"  Estado: {result.status.value}")
    print(f"  Items sincronizados: {result.items_synced}")
    print(f"  Conflictos: {len(result.conflicts)}")
    
    # Historial
    history = sync.get_sync_history()
    print(f"\nHistorial: {len(history)} sincronizaciones")
```

---

## üìà Sistema de An√°lisis Predictivo Avanzado y Forecasting

### Script de An√°lisis Predictivo

**Python**: `scripts/advanced_predictive_analysis_forecasting.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis predictivo avanzado y forecasting
- Predicci√≥n de CTR, engagement y conversiones
- Forecasting de tr√°fico y revenue
- Detecci√≥n de tendencias y patrones
- An√°lisis de estacionalidad
- Recomendaciones basadas en predicciones
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

@dataclass
class Prediction:
    """Predicci√≥n"""
    metric: str
    predicted_value: float
    confidence_interval: Dict  # {'lower': float, 'upper': float}
    confidence_level: float
    forecast_period: str
    factors: List[str]

class AdvancedPredictiveAnalysisForecasting:
    """Sistema de an√°lisis predictivo avanzado"""
    
    def __init__(self):
        self.predictions = {}
        self.historical_data = []
    
    def predict_ctr(self, carousel_id: str, historical_data: List[Dict],
                   forecast_days: int = 7) -> Prediction:
        """Predice CTR futuro"""
        
        # Calcular CTR hist√≥rico promedio
        historical_ctrs = [d.get('ctr', 0) for d in historical_data if d.get('ctr')]
        
        if not historical_ctrs:
            base_ctr = 3.5  # Benchmark de industria
        else:
            base_ctr = sum(historical_ctrs) / len(historical_ctrs)
        
        # Ajustar por tendencia
        trend = self._calculate_trend(historical_ctrs)
        predicted_ctr = base_ctr * (1 + trend)
        
        # Calcular intervalo de confianza (simplificado)
        std_dev = self._calculate_std_dev(historical_ctrs) if historical_ctrs else 1.0
        confidence_interval = {
            'lower': max(0, predicted_ctr - 1.96 * std_dev),
            'upper': predicted_ctr + 1.96 * std_dev
        }
        
        # Factores que influyen
        factors = self._identify_ctr_factors(historical_data)
        
        prediction = Prediction(
            metric='ctr',
            predicted_value=predicted_ctr,
            confidence_interval=confidence_interval,
            confidence_level=0.95,
            forecast_period=f"{forecast_days} days",
            factors=factors
        )
        
        self.predictions[f"{carousel_id}_ctr"] = prediction
        
        return prediction
    
    def predict_conversions(self, carousel_id: str, historical_data: List[Dict],
                          forecast_days: int = 7) -> Prediction:
        """Predice conversiones futuras"""
        
        # Calcular conversiones hist√≥ricas
        historical_conversions = [d.get('conversions', 0) for d in historical_data]
        
        # Predicci√≥n basada en promedio y tendencia
        if historical_conversions:
            avg_conversions = sum(historical_conversions) / len(historical_conversions)
            trend = self._calculate_trend(historical_conversions)
            predicted = avg_conversions * (1 + trend) * (forecast_days / 7)  # Escalar a per√≠odo
        else:
            predicted = 10.0  # Estimaci√≥n conservadora
        
        # Intervalo de confianza
        std_dev = self._calculate_std_dev(historical_conversions) if historical_conversions else 5.0
        confidence_interval = {
            'lower': max(0, predicted - 1.96 * std_dev),
            'upper': predicted + 1.96 * std_dev
        }
        
        prediction = Prediction(
            metric='conversions',
            predicted_value=predicted,
            confidence_interval=confidence_interval,
            confidence_level=0.95,
            forecast_period=f"{forecast_days} days",
            factors=['historical_performance', 'trend', 'seasonality']
        )
        
        return prediction
    
    def predict_revenue(self, carousel_id: str, historical_data: List[Dict],
                       forecast_days: int = 7, avg_order_value: float = 100.0) -> Prediction:
        """Predice revenue futuro"""
        
        # Predecir conversiones primero
        conversions_prediction = self.predict_conversions(carousel_id, historical_data, forecast_days)
        
        # Revenue = Conversiones * AOV
        predicted_revenue = conversions_prediction.predicted_value * avg_order_value
        
        # Intervalo de confianza para revenue
        confidence_interval = {
            'lower': conversions_prediction.confidence_interval['lower'] * avg_order_value,
            'upper': conversions_prediction.confidence_interval['upper'] * avg_order_value
        }
        
        prediction = Prediction(
            metric='revenue',
            predicted_value=predicted_revenue,
            confidence_interval=confidence_interval,
            confidence_level=0.95,
            forecast_period=f"{forecast_days} days",
            factors=['conversions', 'aov', 'conversion_rate_trend']
        )
        
        return prediction
    
    def forecast_traffic(self, carousel_id: str, historical_data: List[Dict],
                        forecast_days: int = 30) -> Dict:
        """Forecasting de tr√°fico"""
        
        # Datos diarios hist√≥ricos
        daily_traffic = {}
        for data in historical_data:
            date = data.get('date', datetime.now().isoformat())
            daily_traffic[date] = data.get('impressions', 0)
        
        # Calcular promedio diario
        if daily_traffic:
            avg_daily = sum(daily_traffic.values()) / len(daily_traffic)
        else:
            avg_daily = 1000  # Estimaci√≥n
        
        # Aplicar tendencia y estacionalidad
        trend_factor = self._calculate_trend(list(daily_traffic.values()))
        seasonal_factor = self._calculate_seasonal_factor(datetime.now())
        
        # Forecast diario
        forecast = {}
        for day in range(forecast_days):
            date = (datetime.now() + timedelta(days=day)).isoformat()
            daily_forecast = avg_daily * (1 + trend_factor) * seasonal_factor
            forecast[date] = daily_forecast
        
        total_forecast = sum(forecast.values())
        
        return {
            'carousel_id': carousel_id,
            'forecast_period_days': forecast_days,
            'total_forecasted_traffic': total_forecast,
            'daily_average': total_forecast / forecast_days,
            'daily_breakdown': forecast,
            'confidence': 0.85
        }
    
    def _calculate_trend(self, values: List[float]) -> float:
        """Calcula tendencia (simplificado: crecimiento porcentual promedio)"""
        
        if len(values) < 2:
            return 0.0
        
        # Calcular crecimiento promedio
        growth_rates = []
        for i in range(1, len(values)):
            if values[i-1] > 0:
                growth = (values[i] - values[i-1]) / values[i-1]
                growth_rates.append(growth)
        
        if growth_rates:
            return sum(growth_rates) / len(growth_rates)
        
        return 0.0
    
    def _calculate_std_dev(self, values: List[float]) -> float:
        """Calcula desviaci√≥n est√°ndar"""
        
        if len(values) < 2:
            return 0.0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        
        return variance ** 0.5
    
    def _identify_ctr_factors(self, historical_data: List[Dict]) -> List[str]:
        """Identifica factores que influyen en CTR"""
        
        factors = []
        
        # Analizar correlaciones (simplificado)
        if any('numbers' in d.get('headline', '') for d in historical_data):
            factors.append('headlines_with_numbers')
        
        if any(d.get('visual_style') == 'bold' for d in historical_data):
            factors.append('vibrant_visuals')
        
        return factors
    
    def _calculate_seasonal_factor(self, date: datetime) -> float:
        """Calcula factor estacional"""
        
        # Simplificado: factores por mes
        seasonal_factors = {
            1: 0.9,   # Enero: menor tr√°fico
            2: 0.95,
            3: 1.0,
            4: 1.05,
            5: 1.1,
            6: 1.0,
            7: 0.95,  # Julio: vacaciones
            8: 0.95,
            9: 1.05,
            10: 1.1,
            11: 1.15,  # Noviembre: Black Friday
            12: 1.2    # Diciembre: Navidad
        }
        
        month = date.month
        return seasonal_factors.get(month, 1.0)
    
    def detect_anomalies(self, carousel_id: str, recent_data: List[Dict],
                        historical_baseline: List[Dict]) -> List[Dict]:
        """Detecta anomal√≠as en datos recientes"""
        
        anomalies = []
        
        # Calcular baseline (promedio hist√≥rico)
        baseline_ctr = sum(d.get('ctr', 0) for d in historical_baseline) / len(historical_baseline) if historical_baseline else 3.5
        baseline_std = self._calculate_std_dev([d.get('ctr', 0) for d in historical_baseline]) if historical_baseline else 1.0
        
        # Detectar anomal√≠as en datos recientes
        for data in recent_data:
            ctr = data.get('ctr', 0)
            
            # Z-score
            if baseline_std > 0:
                z_score = abs(ctr - baseline_ctr) / baseline_std
                
                if z_score > 2:  # Anomal√≠a significativa
                    anomalies.append({
                        'date': data.get('date', datetime.now().isoformat()),
                        'metric': 'ctr',
                        'value': ctr,
                        'baseline': baseline_ctr,
                        'z_score': z_score,
                        'severity': 'high' if z_score > 3 else 'medium',
                        'type': 'spike' if ctr > baseline_ctr else 'drop'
                    })
        
        return anomalies
    
    def generate_predictive_recommendations(self, predictions: Dict) -> List[str]:
        """Genera recomendaciones basadas en predicciones"""
        
        recommendations = []
        
        # CTR predictions
        if 'ctr' in predictions:
            ctr_pred = predictions['ctr']
            if ctr_pred.predicted_value < 3.0:
                recommendations.append(
                    f"CTR predicho bajo ({ctr_pred.predicted_value:.2f}%). "
                    "Considerar optimizar headlines y visuals"
                )
        
        # Conversion predictions
        if 'conversions' in predictions:
            conv_pred = predictions['conversions']
            if conv_pred.predicted_value < 10:
                recommendations.append(
                    f"Conversiones predichas bajas ({conv_pred.predicted_value:.1f}). "
                    "Revisar landing page y CTA"
                )
        
        # Revenue predictions
        if 'revenue' in predictions:
            revenue_pred = predictions['revenue']
            if revenue_pred.predicted_value < 500:
                recommendations.append(
                    f"Revenue predicho bajo (‚Ç¨{revenue_pred.predicted_value:.2f}). "
                    "Considerar aumentar budget o mejorar targeting"
                )
        
        return recommendations

if __name__ == '__main__':
    predictor = AdvancedPredictiveAnalysisForecasting()
    
    # Datos hist√≥ricos de ejemplo
    historical = [
        {'date': '2025-01-01', 'ctr': 4.5, 'conversions': 12, 'impressions': 1000},
        {'date': '2025-01-02', 'ctr': 5.0, 'conversions': 15, 'impressions': 1200},
        {'date': '2025-01-03', 'ctr': 4.8, 'conversions': 14, 'impressions': 1100}
    ]
    
    # Predecir CTR
    ctr_prediction = predictor.predict_ctr('curso_ia_1', historical, forecast_days=7)
    print(f"CTR predicho: {ctr_prediction.predicted_value:.2f}%")
    print(f"  Intervalo: [{ctr_prediction.confidence_interval['lower']:.2f}%, {ctr_prediction.confidence_interval['upper']:.2f}%]")
    print(f"  Factores: {', '.join(ctr_prediction.factors)}")
    
    # Forecast de tr√°fico
    traffic_forecast = predictor.forecast_traffic('curso_ia_1', historical, forecast_days=7)
    print(f"\nTr√°fico previsto (7 d√≠as): {traffic_forecast['total_forecasted_traffic']:.0f} impresiones")
    print(f"  Promedio diario: {traffic_forecast['daily_average']:.0f}")
```

---

## üéØ Sistema de Optimizaci√≥n Autom√°tica de Budget con IA

### Script de Optimizaci√≥n de Budget IA

**Python**: `scripts/ai_budget_optimization.py`

```python
#!/usr/bin/env python3
"""
Sistema de optimizaci√≥n autom√°tica de budget con IA
- Optimizaci√≥n de budget por carrusel
- Redistribuci√≥n autom√°tica basada en performance
- Predicci√≥n de ROI por carrusel
- Optimizaci√≥n multi-objetivo (ROI, conversiones, revenue)
- Alertas autom√°ticas de budget
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class BudgetAllocation:
    """Asignaci√≥n de budget"""
    carousel_id: str
    current_budget: float
    recommended_budget: float
    performance_score: float
    predicted_roi: float
    adjustment_reason: str

class AIBudgetOptimization:
    """Sistema de optimizaci√≥n de budget con IA"""
    
    def __init__(self):
        self.allocations = {}
        self.optimization_history = []
    
    def optimize_budget_allocation(self, total_budget: float,
                                  carousels_data: List[Dict],
                                  objective: str = 'roi') -> List[BudgetAllocation]:
        """Optimiza asignaci√≥n de budget"""
        
        # Calcular scores de performance para cada carrusel
        carousel_scores = []
        
        for carousel in carousels_data:
            carousel_id = carousel.get('carousel_id')
            performance = carousel.get('performance', {})
            
            # Calcular score seg√∫n objetivo
            if objective == 'roi':
                score = self._calculate_roi_score(performance)
            elif objective == 'conversions':
                score = self._calculate_conversion_score(performance)
            elif objective == 'revenue':
                score = self._calculate_revenue_score(performance)
            else:
                score = self._calculate_composite_score(performance)
            
            predicted_roi = self._predict_roi(performance)
            
            carousel_scores.append({
                'carousel_id': carousel_id,
                'score': score,
                'current_budget': performance.get('spend', 0),
                'predicted_roi': predicted_roi,
                'performance': performance
            })
        
        # Ordenar por score
        carousel_scores.sort(key=lambda x: x['score'], reverse=True)
        
        # Asignar budget proporcional al score
        total_score = sum(c['score'] for c in carousel_scores)
        
        allocations = []
        for carousel_info in carousel_scores:
            if total_score > 0:
                score_ratio = carousel_info['score'] / total_score
                recommended_budget = total_budget * score_ratio
            else:
                recommended_budget = total_budget / len(carousel_scores)  # Distribuci√≥n equitativa
            
            current_budget = carousel_info['current_budget']
            
            # Determinar raz√≥n de ajuste
            if recommended_budget > current_budget * 1.2:
                reason = 'increase_high_performer'
            elif recommended_budget < current_budget * 0.8:
                reason = 'decrease_low_performer'
            else:
                reason = 'maintain'
            
            allocation = BudgetAllocation(
                carousel_id=carousel_info['carousel_id'],
                current_budget=current_budget,
                recommended_budget=recommended_budget,
                performance_score=carousel_info['score'],
                predicted_roi=carousel_info['predicted_roi'],
                adjustment_reason=reason
            )
            
            allocations.append(allocation)
            self.allocations[carousel_info['carousel_id']] = allocation
        
        # Guardar en historial
        self.optimization_history.append({
            'timestamp': datetime.now().isoformat(),
            'total_budget': total_budget,
            'objective': objective,
            'allocations': [
                {
                    'carousel_id': a.carousel_id,
                    'current': a.current_budget,
                    'recommended': a.recommended_budget
                }
                for a in allocations
            ]
        })
        
        return allocations
    
    def _calculate_roi_score(self, performance: Dict) -> float:
        """Calcula score basado en ROI"""
        
        roas = performance.get('roas', 0)
        spend = performance.get('spend', 0)
        
        # Score = ROAS * (log de spend para normalizar)
        if spend > 0:
            import math
            spend_factor = math.log(spend + 1) / 10  # Normalizar
            score = roas * spend_factor
        else:
            score = 0.0
        
        return max(0.0, score)
    
    def _calculate_conversion_score(self, performance: Dict) -> float:
        """Calcula score basado en conversiones"""
        
        conversions = performance.get('conversions', 0)
        conversion_rate = performance.get('conversion_rate', 0)
        
        # Score = conversiones * conversion_rate
        score = conversions * (conversion_rate / 100)
        
        return max(0.0, score)
    
    def _calculate_revenue_score(self, performance: Dict) -> float:
        """Calcula score basado en revenue"""
        
        revenue = performance.get('revenue', 0)
        spend = performance.get('spend', 0)
        
        # Score = revenue / spend (ROAS)
        if spend > 0:
            score = revenue / spend
        else:
            score = 0.0
        
        return max(0.0, score)
    
    def _calculate_composite_score(self, performance: Dict) -> float:
        """Calcula score compuesto (m√∫ltiples m√©tricas)"""
        
        ctr = performance.get('ctr', 0) / 10  # Normalizar
        conversion_rate = performance.get('conversion_rate', 0) / 10  # Normalizar
        roas = performance.get('roas', 0) / 5  # Normalizar
        
        # Score ponderado
        score = (ctr * 0.3) + (conversion_rate * 0.3) + (roas * 0.4)
        
        return max(0.0, score)
    
    def _predict_roi(self, performance: Dict) -> float:
        """Predice ROI futuro"""
        
        current_roas = performance.get('roas', 0)
        trend = performance.get('trend', 'stable')
        
        # Ajustar por tendencia
        if trend == 'rising':
            predicted = current_roas * 1.1
        elif trend == 'declining':
            predicted = current_roas * 0.9
        else:
            predicted = current_roas
        
        return max(0.0, predicted)
    
    def generate_budget_recommendations(self, allocations: List[BudgetAllocation]) -> List[str]:
        """Genera recomendaciones de budget"""
        
        recommendations = []
        
        # Identificar mejores performers
        top_performers = sorted(
            allocations,
            key=lambda x: x.performance_score,
            reverse=True
        )[:3]
        
        for alloc in top_performers:
            if alloc.adjustment_reason == 'increase_high_performer':
                increase_pct = ((alloc.recommended_budget - alloc.current_budget) / alloc.current_budget) * 100
                recommendations.append(
                    f"Incrementar budget de {alloc.carousel_id} en {increase_pct:.1f}% "
                    f"(ROI predicho: {alloc.predicted_roi:.2f}x)"
                )
        
        # Identificar bajo performers
        low_performers = [
            a for a in allocations
            if a.adjustment_reason == 'decrease_low_performer'
        ]
        
        for alloc in low_performers:
            decrease_pct = ((alloc.current_budget - alloc.recommended_budget) / alloc.current_budget) * 100
            recommendations.append(
                f"Reducir budget de {alloc.carousel_id} en {decrease_pct:.1f}% "
                f"(performance bajo: {alloc.performance_score:.2f})"
            )
        
        return recommendations
    
    def check_budget_alerts(self, allocations: List[BudgetAllocation]) -> List[Dict]:
        """Verifica alertas de budget"""
        
        alerts = []
        
        for alloc in allocations:
            # Alerta: budget muy desbalanceado
            if alloc.recommended_budget > alloc.current_budget * 2:
                alerts.append({
                    'carousel_id': alloc.carousel_id,
                    'type': 'budget_imbalance',
                    'severity': 'high',
                    'message': f"Budget recomendado ({alloc.recommended_budget:.2f}) es m√°s del doble del actual ({alloc.current_budget:.2f})",
                    'recommended_action': 'increase_budget'
                })
            
            # Alerta: ROI predicho muy bajo
            if alloc.predicted_roi < 2.0:
                alerts.append({
                    'carousel_id': alloc.carousel_id,
                    'type': 'low_roi',
                    'severity': 'medium',
                    'message': f"ROI predicho bajo: {alloc.predicted_roi:.2f}x",
                    'recommended_action': 'optimize_or_pause'
                })
        
        return alerts

if __name__ == '__main__':
    optimizer = AIBudgetOptimization()
    
    # Datos de carruseles
    carousels = [
        {
            'carousel_id': 'curso_ia_1',
            'performance': {
                'ctr': 6.5,
                'conversion_rate': 7.0,
                'roas': 4.2,
                'spend': 500,
                'revenue': 2100,
                'trend': 'rising'
            }
        },
        {
            'carousel_id': 'saas_marketing_1',
            'performance': {
                'ctr': 3.2,
                'conversion_rate': 4.5,
                'roas': 2.8,
                'spend': 300,
                'revenue': 840,
                'trend': 'stable'
            }
        }
    ]
    
    # Optimizar budget
    allocations = optimizer.optimize_budget_allocation(
        total_budget=1000,
        carousels_data=carousels,
        objective='roi'
    )
    
    print("Asignaciones optimizadas:")
    for alloc in allocations:
        change_pct = ((alloc.recommended_budget - alloc.current_budget) / alloc.current_budget) * 100
        print(f"  {alloc.carousel_id}: ‚Ç¨{alloc.current_budget:.2f} -> ‚Ç¨{alloc.recommended_budget:.2f} ({change_pct:+.1f}%)")
    
    # Recomendaciones
    recommendations = optimizer.generate_budget_recommendations(allocations)
    print(f"\nRecomendaciones: {len(recommendations)}")
    for rec in recommendations:
        print(f"  - {rec}")
```

---

## üé≠ Sistema de Generaci√≥n Autom√°tica de Storyboards y Narrativas

### Script de Generaci√≥n de Storyboards

**Python**: `scripts/storyboard_narrative_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de storyboards y narrativas
- Generaci√≥n de narrativas coherentes para carruseles
- Storyboards visuales con transiciones
- Arcos narrativos (problema-soluci√≥n, journey, etc.)
- Adaptaci√≥n de narrativa por audiencia
- Exportaci√≥n a m√∫ltiples formatos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import json

class NarrativeArc(Enum):
    PROBLEM_SOLUTION = "problem_solution"
    JOURNEY = "journey"
    BEFORE_AFTER = "before_after"
    TESTIMONIAL = "testimonial"
    EDUCATIONAL = "educational"

@dataclass
class StoryboardSlide:
    """Slide de storyboard"""
    slide_number: int
    headline: str
    body: str
    visual_description: str
    transition_type: str
    narrative_role: str  # hook, problem, solution, proof, cta

@dataclass
class Storyboard:
    """Storyboard completo"""
    storyboard_id: str
    narrative_arc: NarrativeArc
    slides: List[StoryboardSlide]
    target_audience: str
    emotional_tone: str

class StoryboardNarrativeGenerator:
    """Generador de storyboards y narrativas"""
    
    def __init__(self):
        self.storyboards = {}
        self.narrative_templates = {
            NarrativeArc.PROBLEM_SOLUTION: {
                'structure': ['hook', 'problem', 'pain_points', 'solution', 'benefits', 'proof', 'cta'],
                'emotional_journey': ['attention', 'pain', 'relief', 'hope', 'confidence', 'urgency']
            },
            NarrativeArc.JOURNEY: {
                'structure': ['hook', 'starting_point', 'challenges', 'transformation', 'results', 'invitation'],
                'emotional_journey': ['curiosity', 'empathy', 'struggle', 'breakthrough', 'success', 'aspiration']
            },
            NarrativeArc.BEFORE_AFTER: {
                'structure': ['hook', 'before', 'struggle', 'after', 'transformation', 'how', 'cta'],
                'emotional_journey': ['recognition', 'frustration', 'desire', 'achievement', 'proof', 'action']
            }
        }
    
    def generate_storyboard(self, carousel_id: str, product_data: Dict,
                          narrative_arc: NarrativeArc, target_audience: str) -> Storyboard:
        """Genera storyboard completo"""
        
        template = self.narrative_templates.get(narrative_arc, {})
        structure = template.get('structure', [])
        emotional_journey = template.get('emotional_journey', [])
        
        slides = []
        
        for i, (step, emotion) in enumerate(zip(structure, emotional_journey)):
            slide_content = self._generate_slide_content(
                step,
                emotion,
                product_data,
                i,
                len(structure)
            )
            
            slide = StoryboardSlide(
                slide_number=i + 1,
                headline=slide_content['headline'],
                body=slide_content['body'],
                visual_description=slide_content['visual'],
                transition_type=self._determine_transition(i, len(structure)),
                narrative_role=step
            )
            
            slides.append(slide)
        
        storyboard = Storyboard(
            storyboard_id=f"storyboard_{carousel_id}_{datetime.now().timestamp()}",
            narrative_arc=narrative_arc,
            slides=slides,
            target_audience=target_audience,
            emotional_tone=self._determine_overall_tone(emotional_journey)
        )
        
        self.storyboards[storyboard.storyboard_id] = storyboard
        
        return storyboard
    
    def _generate_slide_content(self, step: str, emotion: str, product_data: Dict,
                               position: int, total: int) -> Dict:
        """Genera contenido para slide espec√≠fico"""
        
        product_name = product_data.get('product', 'Producto')
        benefits = product_data.get('benefits', [])
        pain_points = product_data.get('pain_points', [])
        
        content_templates = {
            'hook': {
                'headline': f"¬øQuieres {benefits[0] if benefits else 'mejorar'}?",
                'body': f"Descubre c√≥mo {product_name} puede transformar tu experiencia",
                'visual': 'Eye-catching visual with question mark or compelling image'
            },
            'problem': {
                'headline': pain_points[0] if pain_points else 'El problema que enfrentas',
                'body': 'Muchas personas luchan con este desaf√≠o diariamente',
                'visual': 'Visual showing frustration or challenge'
            },
            'solution': {
                'headline': f"{product_name} es la soluci√≥n",
                'body': f"Con {product_name}, puedes {benefits[0] if benefits else 'lograr tus objetivos'}",
                'visual': 'Product/service visual with solution iconography'
            },
            'benefits': {
                'headline': f"Beneficios de {product_name}",
                'body': f"‚Ä¢ {benefits[0] if len(benefits) > 0 else 'Beneficio 1'}\n‚Ä¢ {benefits[1] if len(benefits) > 1 else 'Beneficio 2'}",
                'visual': 'Visual showing key benefits with icons'
            },
            'proof': {
                'headline': '500+ personas ya lo han logrado',
                'body': '√önete a nuestra comunidad de √©xito',
                'visual': 'Social proof visual with numbers and testimonials'
            },
            'cta': {
                'headline': '¬°Comienza ahora!',
                'body': 'No pierdas esta oportunidad √∫nica',
                'visual': 'Strong CTA visual with urgency elements'
            }
        }
        
        template = content_templates.get(step, content_templates['hook'])
        
        return {
            'headline': template['headline'],
            'body': template['body'],
            'visual': template['visual']
        }
    
    def _determine_transition(self, position: int, total: int) -> str:
        """Determina tipo de transici√≥n"""
        
        if position == 0:
            return 'fade_in'
        elif position == total - 1:
            return 'fade_out'
        else:
            return 'slide_left'
    
    def _determine_overall_tone(self, emotional_journey: List[str]) -> str:
        """Determina tono emocional general"""
        
        positive_emotions = ['hope', 'confidence', 'success', 'achievement', 'aspiration']
        
        if any(emotion in positive_emotions for emotion in emotional_journey):
            return 'empowering'
        elif 'urgency' in emotional_journey or 'action' in emotional_journey:
            return 'urgent'
        else:
            return 'inspirational'
    
    def adapt_narrative_for_audience(self, storyboard_id: str,
                                    audience_profile: Dict) -> Storyboard:
        """Adapta narrativa para audiencia espec√≠fica"""
        
        if storyboard_id not in self.storyboards:
            return None
        
        base_storyboard = self.storyboards[storyboard_id]
        
        # Adaptar slides seg√∫n perfil de audiencia
        adapted_slides = []
        
        for slide in base_storyboard.slides:
            adapted_headline = self._adapt_headline_for_audience(
                slide.headline,
                audience_profile
            )
            
            adapted_body = self._adapt_body_for_audience(
                slide.body,
                audience_profile
            )
            
            adapted_slide = StoryboardSlide(
                slide_number=slide.slide_number,
                headline=adapted_headline,
                body=adapted_body,
                visual_description=slide.visual_description,
                transition_type=slide.transition_type,
                narrative_role=slide.narrative_role
            )
            
            adapted_slides.append(adapted_slide)
        
        adapted_storyboard = Storyboard(
            storyboard_id=f"{storyboard_id}_adapted",
            narrative_arc=base_storyboard.narrative_arc,
            slides=adapted_slides,
            target_audience=audience_profile.get('type', 'general'),
            emotional_tone=base_storyboard.emotional_tone
        )
        
        return adapted_storyboard
    
    def _adapt_headline_for_audience(self, headline: str, profile: Dict) -> str:
        """Adapta headline para audiencia"""
        
        adapted = headline
        
        # Adaptar seg√∫n nivel t√©cnico
        if profile.get('tech_level') == 'expert':
            adapted = adapted.replace('f√°cil', 'avanzado')
            adapted = adapted.replace('simple', 'sofisticado')
        
        # Adaptar seg√∫n rol
        if profile.get('role') == 'manager':
            adapted = adapted.replace('aprende', 'implementa')
        
        return adapted
    
    def _adapt_body_for_audience(self, body: str, profile: Dict) -> str:
        """Adapta body para audiencia"""
        
        adapted = body
        
        if profile.get('company_size') == 'enterprise':
            adapted = adapted.replace('personas', 'equipos grandes')
        
        return adapted
    
    def export_storyboard(self, storyboard_id: str, format: str) -> Dict:
        """Exporta storyboard a formato espec√≠fico"""
        
        if storyboard_id not in self.storyboards:
            return {'status': 'error', 'message': 'Storyboard not found'}
        
        storyboard = self.storyboards[storyboard_id]
        
        formats = {
            'json': self._export_to_json,
            'markdown': self._export_to_markdown,
            'csv': self._export_to_csv
        }
        
        exporter = formats.get(format.lower())
        if not exporter:
            return {'status': 'error', 'message': 'Format not supported'}
        
        return exporter(storyboard)
    
    def _export_to_json(self, storyboard: Storyboard) -> Dict:
        """Exporta a JSON"""
        
        return {
            'status': 'success',
            'format': 'json',
            'content': json.dumps({
                'storyboard_id': storyboard.storyboard_id,
                'narrative_arc': storyboard.narrative_arc.value,
                'slides': [
                    {
                        'number': s.slide_number,
                        'headline': s.headline,
                        'body': s.body,
                        'visual': s.visual_description,
                        'transition': s.transition_type,
                        'role': s.narrative_role
                    }
                    for s in storyboard.slides
                ]
            }, indent=2)
        }
    
    def _export_to_markdown(self, storyboard: Storyboard) -> Dict:
        """Exporta a Markdown"""
        
        md_lines = [
            f"# Storyboard: {storyboard.storyboard_id}",
            f"**Narrative Arc:** {storyboard.narrative_arc.value}",
            f"**Target Audience:** {storyboard.target_audience}",
            f"**Emotional Tone:** {storyboard.emotional_tone}",
            "",
            "## Slides",
            ""
        ]
        
        for slide in storyboard.slides:
            md_lines.append(f"### Slide {slide.slide_number}: {slide.narrative_role}")
            md_lines.append(f"**Headline:** {slide.headline}")
            md_lines.append(f"**Body:** {slide.body}")
            md_lines.append(f"**Visual:** {slide.visual_description}")
            md_lines.append(f"**Transition:** {slide.transition_type}")
            md_lines.append("")
        
        return {
            'status': 'success',
            'format': 'markdown',
            'content': '\n'.join(md_lines)
        }
    
    def _export_to_csv(self, storyboard: Storyboard) -> Dict:
        """Exporta a CSV"""
        
        csv_lines = ['Slide Number,Headline,Body,Visual Description,Transition,Role']
        
        for slide in storyboard.slides:
            csv_lines.append(
                f"{slide.slide_number},\"{slide.headline}\",\"{slide.body}\","
                f"\"{slide.visual_description}\",{slide.transition_type},{slide.narrative_role}"
            )
        
        return {
            'status': 'success',
            'format': 'csv',
            'content': '\n'.join(csv_lines)
        }

if __name__ == '__main__':
    generator = StoryboardNarrativeGenerator()
    
    # Datos de producto
    product_data = {
        'product': 'Curso IA',
        'benefits': ['Aprender IA aplicada', 'Transformar carrera', 'Proyectos reales'],
        'pain_points': ['Falta de conocimiento pr√°ctico', 'No saber por d√≥nde empezar']
    }
    
    # Generar storyboard
    storyboard = generator.generate_storyboard(
        'curso_ia_1',
        product_data,
        NarrativeArc.PROBLEM_SOLUTION,
        'Profesionales tech'
    )
    
    print(f"Storyboard generado: {storyboard.storyboard_id}")
    print(f"  Slides: {len(storyboard.slides)}")
    print(f"  Narrative Arc: {storyboard.narrative_arc.value}")
    print(f"  Tone: {storyboard.emotional_tone}")
    
    # Exportar
    export = generator.export_storyboard(storyboard.storyboard_id, 'markdown')
    print(f"\nExportado a {export['format']}")
```

---

## üé® Sistema de Generaci√≥n Autom√°tica de Brand Guidelines y Templates

### Script de Brand Guidelines Generator

**Python**: `scripts/brand_guidelines_template_generator.py`

```python
#!/usr/bin/env python3
"""
Sistema de generaci√≥n autom√°tica de brand guidelines y templates
- Generaci√≥n de brand guidelines completos
- Templates pre-configurados por tipo de contenido
- Validaci√≥n autom√°tica de compliance
- Generaci√≥n de documentaci√≥n de marca
- Exportaci√≥n a m√∫ltiples formatos
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class BrandGuideline:
    """Gu√≠a de marca"""
    guideline_id: str
    brand_name: str
    colors: Dict
    typography: Dict
    logo_usage: Dict
    spacing_rules: Dict
    tone_of_voice: Dict

@dataclass
class Template:
    """Template de contenido"""
    template_id: str
    name: str
    template_type: str
    structure: Dict
    brand_compliance: bool

class BrandGuidelinesTemplateGenerator:
    """Generador de brand guidelines y templates"""
    
    def __init__(self):
        self.guidelines = {}
        self.templates = {}
    
    def create_brand_guidelines(self, brand_name: str, brand_data: Dict) -> BrandGuideline:
        """Crea brand guidelines completo"""
        
        guideline = BrandGuideline(
            guideline_id=f"guideline_{datetime.now().timestamp()}",
            brand_name=brand_name,
            colors=self._extract_colors(brand_data),
            typography=self._extract_typography(brand_data),
            logo_usage=self._extract_logo_rules(brand_data),
            spacing_rules=self._extract_spacing_rules(brand_data),
            tone_of_voice=self._extract_tone_of_voice(brand_data)
        )
        
        self.guidelines[guideline.guideline_id] = guideline
        
        return guideline
    
    def _extract_colors(self, brand_data: Dict) -> Dict:
        """Extrae reglas de color"""
        
        return {
            'primary': brand_data.get('primary_color', '#3498DB'),
            'secondary': brand_data.get('secondary_color', '#2C3E50'),
            'accent': brand_data.get('accent_color', '#E74C3C'),
            'background': brand_data.get('background_color', '#FFFFFF'),
            'text': brand_data.get('text_color', '#333333'),
            'rules': {
                'min_contrast_ratio': 4.5,  # WCAG AA
                'allowed_combinations': [
                    ['primary', 'background'],
                    ['secondary', 'background'],
                    ['text', 'background']
                ]
            }
        }
    
    def _extract_typography(self, brand_data: Dict) -> Dict:
        """Extrae reglas de tipograf√≠a"""
        
        return {
            'primary_font': brand_data.get('primary_font', 'Arial'),
            'secondary_font': brand_data.get('secondary_font', 'Georgia'),
            'sizes': {
                'h1': brand_data.get('h1_size', '48px'),
                'h2': brand_data.get('h2_size', '36px'),
                'h3': brand_data.get('h3_size', '24px'),
                'body': brand_data.get('body_size', '16px'),
                'small': brand_data.get('small_size', '14px')
            },
            'weights': {
                'normal': 400,
                'bold': 700
            },
            'line_height': brand_data.get('line_height', 1.5)
        }
    
    def _extract_logo_rules(self, brand_data: Dict) -> Dict:
        """Extrae reglas de uso de logo"""
        
        return {
            'placement': ['top_left', 'top_right', 'bottom_left'],
            'min_size': brand_data.get('logo_min_size', '80px'),
            'clear_space': brand_data.get('logo_clear_space', '20px'),
            'variants': ['full_color', 'monochrome', 'white'],
            'restrictions': ['no_rotation', 'no_distortion', 'maintain_aspect_ratio']
        }
    
    def _extract_spacing_rules(self, brand_data: Dict) -> Dict:
        """Extrae reglas de espaciado"""
        
        return {
            'unit': 'px',
            'scale': [4, 8, 16, 24, 32, 48, 64],
            'padding': {
                'small': '8px',
                'medium': '16px',
                'large': '24px'
            },
            'margins': {
                'small': '8px',
                'medium': '16px',
                'large': '24px'
            }
        }
    
    def _extract_tone_of_voice(self, brand_data: Dict) -> Dict:
        """Extrae tono de voz"""
        
        return {
            'personality': brand_data.get('personality', ['professional', 'friendly']),
            'avoid_words': brand_data.get('avoid_words', ['jargon', 'slang']),
            'preferred_words': brand_data.get('preferred_words', ['claro', 'directo']),
            'voice_examples': brand_data.get('voice_examples', [])
        }
    
    def generate_template(self, template_type: str, guideline_id: str) -> Template:
        """Genera template basado en brand guidelines"""
        
        if guideline_id not in self.guidelines:
            return None
        
        guideline = self.guidelines[guideline_id]
        
        template_structures = {
            'carousel_standard': {
                'slides_count': 5,
                'structure': {
                    'slide_1': {'role': 'hook', 'has_headline': True, 'has_image': True},
                    'slide_2': {'role': 'problem', 'has_headline': True, 'has_body': True},
                    'slide_3': {'role': 'solution', 'has_headline': True, 'has_body': True},
                    'slide_4': {'role': 'proof', 'has_headline': True, 'has_image': True},
                    'slide_5': {'role': 'cta', 'has_headline': True, 'has_cta': True}
                }
            },
            'carousel_testimonial': {
                'slides_count': 4,
                'structure': {
                    'slide_1': {'role': 'hook', 'has_headline': True},
                    'slide_2': {'role': 'testimonial', 'has_quote': True, 'has_author': True},
                    'slide_3': {'role': 'benefits', 'has_list': True},
                    'slide_4': {'role': 'cta', 'has_headline': True, 'has_cta': True}
                }
            },
            'carousel_educational': {
                'slides_count': 6,
                'structure': {
                    'slide_1': {'role': 'title', 'has_headline': True},
                    'slide_2': {'role': 'content', 'has_headline': True, 'has_body': True},
                    'slide_3': {'role': 'content', 'has_headline': True, 'has_body': True},
                    'slide_4': {'role': 'content', 'has_headline': True, 'has_body': True},
                    'slide_5': {'role': 'summary', 'has_list': True},
                    'slide_6': {'role': 'cta', 'has_headline': True, 'has_cta': True}
                }
            }
        }
        
        structure = template_structures.get(template_type, template_structures['carousel_standard'])
        
        template = Template(
            template_id=f"template_{template_type}_{datetime.now().timestamp()}",
            name=f"{template_type.replace('_', ' ').title()} Template",
            template_type=template_type,
            structure=structure,
            brand_compliance=True
        )
        
        # Aplicar brand guidelines al template
        template = self._apply_brand_to_template(template, guideline)
        
        self.templates[template.template_id] = template
        
        return template
    
    def _apply_brand_to_template(self, template: Template, guideline: BrandGuideline) -> Template:
        """Aplica brand guidelines a template"""
        
        # En producci√≥n: aplicar colores, tipograf√≠a, espaciado al template
        # Por ahora: marcar como compliant
        
        return template
    
    def validate_compliance(self, carousel_data: Dict, guideline_id: str) -> Dict:
        """Valida compliance con brand guidelines"""
        
        if guideline_id not in self.guidelines:
            return {'status': 'error', 'message': 'Guideline not found'}
        
        guideline = self.guidelines[guideline_id]
        issues = []
        score = 100.0
        
        # Validar colores
        colors_used = carousel_data.get('colors', [])
        allowed_colors = [
            guideline.colors['primary'],
            guideline.colors['secondary'],
            guideline.colors['accent']
        ]
        
        for color in colors_used:
            if color not in allowed_colors:
                issues.append(f"Color {color} no est√° en brand guidelines")
                score -= 10
        
        # Validar tipograf√≠a
        font_used = carousel_data.get('font_family', '')
        if font_used and font_used not in [guideline.typography['primary_font'], guideline.typography['secondary_font']]:
            issues.append(f"Fuente {font_used} no est√° en brand guidelines")
            score -= 15
        
        # Validar logo
        logo_placement = carousel_data.get('logo_placement', '')
        if logo_placement and logo_placement not in guideline.logo_usage['placement']:
            issues.append(f"Logo placement {logo_placement} no permitido")
            score -= 10
        
        # Validar espaciado
        spacing_used = carousel_data.get('spacing', {})
        spacing_scale = guideline.spacing_rules['scale']
        # Simplificado: verificar si espaciados est√°n en escala
        for spacing_value in spacing_used.values():
            if isinstance(spacing_value, (int, float)):
                if spacing_value not in spacing_scale:
                    issues.append(f"Espaciado {spacing_value}px no est√° en escala de marca")
                    score -= 5
        
        compliance_level = 'high' if score >= 90 else 'medium' if score >= 70 else 'low'
        
        return {
            'status': 'success',
            'compliance_score': max(0.0, score),
            'compliance_level': compliance_level,
            'issues': issues,
            'issues_count': len(issues)
        }
    
    def export_guidelines(self, guideline_id: str, format: str) -> Dict:
        """Exporta brand guidelines a formato"""
        
        if guideline_id not in self.guidelines:
            return {'status': 'error', 'message': 'Guideline not found'}
        
        guideline = self.guidelines[guideline_id]
        
        formats = {
            'json': self._export_guidelines_json,
            'pdf': self._export_guidelines_pdf,
            'html': self._export_guidelines_html
        }
        
        exporter = formats.get(format.lower())
        if not exporter:
            return {'status': 'error', 'message': 'Format not supported'}
        
        return exporter(guideline)
    
    def _export_guidelines_json(self, guideline: BrandGuideline) -> Dict:
        """Exporta guidelines a JSON"""
        
        return {
            'status': 'success',
            'format': 'json',
            'content': json.dumps({
                'brand_name': guideline.brand_name,
                'colors': guideline.colors,
                'typography': guideline.typography,
                'logo_usage': guideline.logo_usage,
                'spacing_rules': guideline.spacing_rules,
                'tone_of_voice': guideline.tone_of_voice
            }, indent=2)
        }
    
    def _export_guidelines_pdf(self, guideline: BrandGuideline) -> Dict:
        """Exporta guidelines a PDF"""
        
        # En producci√≥n: usar reportlab o weasyprint
        return {
            'status': 'success',
            'format': 'pdf',
            'file_url': f"https://cdn.example.com/guidelines/{guideline.guideline_id}.pdf"
        }
    
    def _export_guidelines_html(self, guideline: BrandGuideline) -> Dict:
        """Exporta guidelines a HTML"""
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head><title>Brand Guidelines - {guideline.brand_name}</title></head>
        <body>
        <h1>Brand Guidelines: {guideline.brand_name}</h1>
        <h2>Colors</h2>
        <ul>
        """
        
        for color_name, color_value in guideline.colors.items():
            if isinstance(color_value, str) and color_value.startswith('#'):
                html += f"<li>{color_name}: <span style='color: {color_value}'>{color_value}</span></li>"
        
        html += """
        </ul>
        <h2>Typography</h2>
        <p>Primary Font: {}</p>
        <p>Secondary Font: {}</p>
        </body>
        </html>
        """.format(guideline.typography['primary_font'], guideline.typography['secondary_font'])
        
        return {
            'status': 'success',
            'format': 'html',
            'content': html
        }

if __name__ == '__main__':
    generator = BrandGuidelinesTemplateGenerator()
    
    # Crear brand guidelines
    brand_data = {
        'primary_color': '#3498DB',
        'secondary_color': '#2C3E50',
        'primary_font': 'Arial',
        'logo_min_size': '80px'
    }
    
    guideline = generator.create_brand_guidelines('Blatam', brand_data)
    
    print(f"Brand guidelines creado: {guideline.brand_name}")
    print(f"  ID: {guideline.guideline_id}")
    
    # Validar compliance
    carousel_data = {
        'colors': ['#3498DB', '#2C3E50'],
        'font_family': 'Arial',
        'logo_placement': 'top_left',
        'spacing': {'padding': 16, 'margin': 8}
    }
    
    compliance = generator.validate_compliance(carousel_data, guideline.guideline_id)
    print(f"\nCompliance Score: {compliance['compliance_score']:.1f}/100")
    print(f"  Level: {compliance['compliance_level']}")
    print(f"  Issues: {compliance['issues_count']}")
```

---

## üìä Sistema de An√°lisis de Sentimiento y Engagement en Tiempo Real

### Script de An√°lisis de Sentimiento Real-time

**Python**: `scripts/realtime_sentiment_engagement_analysis.py`

```python
#!/usr/bin/env python3
"""
Sistema de an√°lisis de sentimiento y engagement en tiempo real
- An√°lisis de sentimiento de comentarios y menciones
- Tracking de engagement en tiempo real
- Detecci√≥n de tendencias de sentimiento
- Alertas de sentimiento negativo
- An√°lisis de influencers y advocates
"""
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class Sentiment(Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    MIXED = "mixed"

@dataclass
class EngagementEvent:
    """Evento de engagement"""
    event_id: str
    carousel_id: str
    platform: str
    event_type: str  # like, comment, share, save
    sentiment: Optional[Sentiment]
    user_id: str
    timestamp: datetime

@dataclass
class SentimentAnalysis:
    """An√°lisis de sentimiento"""
    carousel_id: str
    period: Dict
    positive_count: int
    negative_count: int
    neutral_count: int
    overall_sentiment: Sentiment
    sentiment_score: float  # -1 to 1

class RealtimeSentimentEngagementAnalysis:
    """Sistema de an√°lisis de sentimiento en tiempo real"""
    
    def __init__(self):
        self.engagement_events = []
        self.sentiment_cache = {}
        self.negative_alert_threshold = 0.3  # 30% negativo
    
    def analyze_comment_sentiment(self, comment_text: str) -> Dict:
        """Analiza sentimiento de comentario"""
        
        # En producci√≥n: usar NLP (VADER, TextBlob, GPT-4)
        # Por ahora: an√°lisis simplificado por keywords
        
        positive_words = ['excelente', 'genial', 'me encanta', 'perfecto', 'recomiendo', 'gracias']
        negative_words = ['malo', 'horrible', 'no funciona', 'estafa', 'p√©simo', 'decepcionado']
        
        comment_lower = comment_text.lower()
        
        positive_count = sum(1 for word in positive_words if word in comment_lower)
        negative_count = sum(1 for word in negative_words if word in comment_lower)
        
        if positive_count > negative_count:
            sentiment = Sentiment.POSITIVE
            score = 0.5 + (positive_count * 0.1)
        elif negative_count > positive_count:
            sentiment = Sentiment.NEGATIVE
            score = -0.5 - (negative_count * 0.1)
        else:
            sentiment = Sentiment.NEUTRAL
            score = 0.0
        
        return {
            'sentiment': sentiment.value,
            'score': max(-1.0, min(1.0, score)),
            'confidence': 0.7,  # En producci√≥n: calcular confianza real
            'positive_signals': positive_count,
            'negative_signals': negative_count
        }
    
    def track_engagement_event(self, carousel_id: str, platform: str,
                              event_type: str, user_id: str,
                              comment_text: Optional[str] = None) -> EngagementEvent:
        """Trackea evento de engagement"""
        
        sentiment = None
        if comment_text:
            sentiment_analysis = self.analyze_comment_sentiment(comment_text)
            sentiment = Sentiment(sentiment_analysis['sentiment'])
        
        event = EngagementEvent(
            event_id=f"event_{datetime.now().timestamp()}",
            carousel_id=carousel_id,
            platform=platform,
            event_type=event_type,
            sentiment=sentiment,
            user_id=user_id,
            timestamp=datetime.now()
        )
        
        self.engagement_events.append(event)
        
        return event
    
    def analyze_carousel_sentiment(self, carousel_id: str,
                                  period_days: int = 7) -> SentimentAnalysis:
        """Analiza sentimiento de carrusel"""
        
        cutoff_date = datetime.now() - timedelta(days=period_days)
        
        recent_events = [
            e for e in self.engagement_events
            if e.carousel_id == carousel_id and e.timestamp >= cutoff_date and e.sentiment
        ]
        
        if not recent_events:
            return SentimentAnalysis(
                carousel_id=carousel_id,
                period={'start': cutoff_date.isoformat(), 'end': datetime.now().isoformat()},
                positive_count=0,
                negative_count=0,
                neutral_count=0,
                overall_sentiment=Sentiment.NEUTRAL,
                sentiment_score=0.0
            )
        
        positive_count = len([e for e in recent_events if e.sentiment == Sentiment.POSITIVE])
        negative_count = len([e for e in recent_events if e.sentiment == Sentiment.NEGATIVE])
        neutral_count = len([e for e in recent_events if e.sentiment == Sentiment.NEUTRAL])
        
        total = len(recent_events)
        
        # Calcular score general
        sentiment_score = ((positive_count - negative_count) / total) if total > 0 else 0.0
        
        # Determinar sentimiento general
        if sentiment_score > 0.3:
            overall = Sentiment.POSITIVE
        elif sentiment_score < -0.3:
            overall = Sentiment.NEGATIVE
        else:
            overall = Sentiment.NEUTRAL
        
        analysis = SentimentAnalysis(
            carousel_id=carousel_id,
            period={'start': cutoff_date.isoformat(), 'end': datetime.now().isoformat()},
            positive_count=positive_count,
            negative_count=negative_count,
            neutral_count=neutral_count,
            overall_sentiment=overall,
            sentiment_score=sentiment_score
        )
        
        self.sentiment_cache[carousel_id] = analysis
        
        return analysis
    
    def detect_negative_sentiment_alert(self, carousel_id: str) -> Optional[Dict]:
        """Detecta alerta de sentimiento negativo"""
        
        analysis = self.analyze_carousel_sentiment(carousel_id)
        
        total = analysis.positive_count + analysis.negative_count + analysis.neutral_count
        
        if total == 0:
            return None
        
        negative_ratio = analysis.negative_count / total
        
        if negative_ratio >= self.negative_alert_threshold:
            return {
                'carousel_id': carousel_id,
                'alert_type': 'negative_sentiment',
                'severity': 'high' if negative_ratio > 0.5 else 'medium',
                'negative_ratio': negative_ratio,
                'negative_count': analysis.negative_count,
                'total_comments': total,
                'message': f"Sentimiento negativo alto: {negative_ratio:.1%} de comentarios",
                'recommended_action': 'review_and_respond_immediately'
            }
        
        return None
    
    def analyze_engagement_trends(self, carousel_id: str,
                                 period_days: int = 7) -> Dict:
        """Analiza tendencias de engagement"""
        
        cutoff_date = datetime.now() - timedelta(days=period_days)
        
        recent_events = [
            e for e in self.engagement_events
            if e.carousel_id == carousel_id and e.timestamp >= cutoff_date
        ]
        
        # Agrupar por d√≠a
        daily_engagement = {}
        for event in recent_events:
            date_key = event.timestamp.date().isoformat()
            if date_key not in daily_engagement:
                daily_engagement[date_key] = {
                    'likes': 0,
                    'comments': 0,
                    'shares': 0,
                    'saves': 0
                }
            
            daily_engagement[date_key][event.event_type + 's'] += 1
        
        # Calcular tendencia
        engagement_values = [sum(v.values()) for v in daily_engagement.values()]
        trend = self._calculate_trend(engagement_values)
        
        return {
            'carousel_id': carousel_id,
            'period_days': period_days,
            'daily_breakdown': daily_engagement,
            'total_engagement': sum(engagement_values),
            'average_daily': sum(engagement_values) / len(daily_engagement) if daily_engagement else 0,
            'trend': 'rising' if trend > 0.1 else 'declining' if trend < -0.1 else 'stable',
            'trend_percentage': trend * 100
        }
    
    def _calculate_trend(self, values: List[float]) -> float:
        """Calcula tendencia"""
        
        if len(values) < 2:
            return 0.0
        
        growth_rates = []
        for i in range(1, len(values)):
            if values[i-1] > 0:
                growth = (values[i] - values[i-1]) / values[i-1]
                growth_rates.append(growth)
        
        if growth_rates:
            return sum(growth_rates) / len(growth_rates)
        
        return 0.0
    
    def identify_influencers(self, carousel_id: str, min_engagement: int = 10) -> List[Dict]:
        """Identifica influencers y advocates"""
        
        events = [e for e in self.engagement_events if e.carousel_id == carousel_id]
        
        # Agrupar por usuario
        user_engagement = {}
        for event in events:
            if event.user_id not in user_engagement:
                user_engagement[event.user_id] = {
                    'events_count': 0,
                    'positive_comments': 0,
                    'shares': 0
                }
            
            user_engagement[event.user_id]['events_count'] += 1
            
            if event.sentiment == Sentiment.POSITIVE:
                user_engagement[event.user_id]['positive_comments'] += 1
            
            if event.event_type == 'share':
                user_engagement[event.user_id]['shares'] += 1
        
        # Filtrar influencers
        influencers = []
        for user_id, engagement in user_engagement.items():
            if engagement['events_count'] >= min_engagement:
                influencers.append({
                    'user_id': user_id,
                    'total_engagement': engagement['events_count'],
                    'positive_comments': engagement['positive_comments'],
                    'shares': engagement['shares'],
                    'influence_score': engagement['events_count'] + (engagement['shares'] * 2)
                })
        
        # Ordenar por influence score
        influencers.sort(key=lambda x: x['influence_score'], reverse=True)
        
        return influencers

if __name__ == '__main__':
    analyzer = RealtimeSentimentEngagementAnalysis()
    
    # Analizar comentario
    sentiment = analyzer.analyze_comment_sentiment('Este curso es excelente, lo recomiendo totalmente!')
    print(f"Sentimiento: {sentiment['sentiment']}, Score: {sentiment['score']:.2f}")
    
    # Trackear eventos
    analyzer.track_engagement_event('curso_ia_1', 'instagram', 'like', 'user123')
    analyzer.track_engagement_event('curso_ia_1', 'instagram', 'comment', 'user456',
                                   comment_text='Me encanta, muy √∫til!')
    
    # An√°lisis de sentimiento
    analysis = analyzer.analyze_carousel_sentiment('curso_ia_1')
    print(f"\nAn√°lisis de sentimiento:")
    print(f"  Positivo: {analysis.positive_count}")
    print(f"  Negativo: {analysis.negative_count}")
    print(f"  Score general: {analysis.sentiment_score:.2f}")
```

---

**Versi√≥n**: 11.5 Master Ultra Pro + Performance & Governance  
**Fecha**: 2025-11  
**Nuevas secciones agregadas**:
- Scripts de an√°lisis de performance (`analyze_carousel_performance.py`)
- Validaci√≥n automatizada pre-publicaci√≥n (`validate_carousel_pre_launch.py`)
- Templates React/HTML para landing pages
- Gu√≠as de animaci√≥n SVG (CSS + SMIL)
- Dashboard avanzado de m√©tricas (SQL + Data Studio)
- Testing estad√≠stico A/B con significancia
- Estrategia multi-canal automatizada
- Integraci√≥n con `analyze_assets.sh` (an√°lisis completo de assets)
- Dashboard de cobertura de assets (matriz Producto √ó Formato √ó Variante)
- Workflow integrado Makefile (an√°lisis ‚Üí validaci√≥n ‚Üí export ‚Üí QA)
- Checklist QA completo (assets + validaci√≥n + tracking)
- CI/CD con GitHub Actions (pipeline automatizado de deploy)
- Auto-refresh de carruseles (renovaci√≥n autom√°tica basada en performance)
- Integraci√≥n Figma API (sincronizaci√≥n autom√°tica Figma ‚Üí SVG)
- Optimizaci√≥n SEO avanzada (Open Graph, Twitter Cards, Schema.org)
- Gesti√≥n de versiones (versionado sem√°ntico + changelog autom√°tico)
- Testing automatizado de landing pages (Selenium, Lighthouse, E2E)
- Optimizaci√≥n CRO avanzada (heatmaps, scroll depth, funnel analysis)
- Personalizaci√≥n din√°mica (segmentaci√≥n autom√°tica, A/B inteligente)
- Machine Learning para optimizaci√≥n (predicci√≥n de variantes, optimizaci√≥n continua)
- Analytics multi-fuente (GA4 + Meta + HubSpot aggregation)
- **Batch processing masivo** (procesamiento paralelo de m√∫ltiples carruseles)
- **Monitor en tiempo real** (tracking continuo, auto-pausar bajo performance)
- **Compliance automatizado** (GDPR/CCPA, disclaimers, permisos)
- **Generaci√≥n con IA** (GPT-4 para copy, DALL-E para visuales)
- **Auto-schedule multi-plataforma** (Buffer, Hootsuite, Meta simult√°neo)
- **An√°lisis predictivo avanzado** (forecasting, optimizaci√≥n de presupuesto)
- **üîç Lighthouse CI con Performance Budgets** (validaci√≥n autom√°tica de Core Web Vitals, bloqueo de PRs)
- **üõ°Ô∏è Gobernanza UTM en CI** (validador + autocorrecci√≥n + reportes de cumplimiento)
- **üé∞ Multi-Armed Bandit** (distribuci√≥n din√°mica de presupuesto con Thompson Sampling)
- **‚ôø Testing Automatizado de Accesibilidad WCAG** (validaci√≥n WCAG 2.1 AA, contraste, alt text, navegaci√≥n teclado)
- **üí¨ An√°lisis de Sentimiento y Automatizaci√≥n de Respuestas** (GPT-4 para an√°lisis, respuestas inteligentes, integraci√≥n CRM)
- **üíæ Sistema de Backup y Versionado de Assets** (backups autom√°ticos, versionado sem√°ntico, recuperaci√≥n)
- **üñºÔ∏è Optimizaci√≥n de Im√°genes con IA** (compresi√≥n inteligente, WebP/AVIF, detecci√≥n de tipo)
- **üì¢ Sistema de Notificaciones Avanzado** (Slack, Discord, Telegram, Email, SMS multi-canal)
- **üîç An√°lisis de Competidores Automatizado** (monitoreo, an√°lisis de copy/hashtags, recomendaciones)
- **üè∑Ô∏è Optimizaci√≥n de Hashtags con IA** (sugerencias GPT-4, balance volumen/engagement, A/B testing)
- **üìà An√°lisis de Tendencias en Tiempo Real** (detecci√≥n de cambios, predicciones, anomal√≠as, confianza)
- **üìä Generaci√≥n Autom√°tica de Reportes Ejecutivos** (dashboard con GPT-4, PDF/HTML, insights autom√°ticos)
- **üö® Sistema de Alertas Predictivas** (predicci√≥n de problemas, escalamiento inteligente, recomendaciones)
- **üìÖ Sistema de Calendarizaci√≥n Inteligente** (optimizaci√≥n de timing, mejores d√≠as/horas, calendarizaci√≥n autom√°tica)
- **üî• An√°lisis de Contenido Viral y Replicabilidad** (scoring viral, identificaci√≥n de patrones, recomendaciones)
- **ü§ñ Sistema de Aprendizaje Continuo y Auto-Mejora** (aprendizaje de patrones, auto-generaci√≥n de variantes, optimizaci√≥n iterativa)
- **üí∞ An√°lisis de ROI Avanzado y Atribuci√≥n Multi-Touch** (first/last/linear/time-decay/position-based, LTV, CAC)
- **üê¶ Integraci√≥n Avanzada con Twitter/X y TikTok** (adaptaci√≥n autom√°tica, publicaci√≥n simult√°nea, tracking unificado)
- **üë• Sistema de Colaboraci√≥n en Equipo** (workflow por roles, revisi√≥n y aprobaci√≥n, comentarios, versionado)
- **üéØ An√°lisis de Audiencia Avanzado con ML** (segmentaci√≥n K-Means, predicci√≥n de comportamiento, buyer personas)
- **üß™ Sistema de Testing de Creatividades Pre-Publicaci√≥n** (validaci√≥n visual/copy/CTA, predicci√≥n de performance, benchmarks)
- **üë§ Sistema de Gesti√≥n de UGC** (recopilaci√≥n autom√°tica, moderaci√≥n con IA, solicitud de permisos, conversi√≥n a carruseles)
- **üéÆ Sistema de Gamificaci√≥n para Engagement** (puntos, badges, leaderboards, desaf√≠os, recompensas)
- **üé® Integraci√≥n con Canva API** (sincronizaci√≥n de templates, generaci√≥n autom√°tica, exportaci√≥n optimizada)
- **ü§ñ Sistema de Recomendaciones Personalizadas con ML** (TF-IDF, cosine similarity, cold start, preferencias)
- **üõ°Ô∏è Sistema de Gesti√≥n de Crisis y Reputaci√≥n** (detecci√≥n temprana, escalamiento, respuestas, tracking)
- **üìä Sistema de A/B Testing Avanzado con An√°lisis Estad√≠stico** (power analysis, chi-square, sequential testing, segment analysis)
- **üìß Integraci√≥n Avanzada con Email Marketing** (segmentaci√≥n comportamental, nurturing sequences, trigger campaigns, ROI tracking)
- **ü§ù Sistema de Gesti√≥n de Influencers y Affiliates** (onboarding, tracking, comisiones, payout automation)
- **üìà Dashboard de Performance en Tiempo Real** (m√©tricas live, alertas autom√°ticas, tendencias, exportaci√≥n)
- **üí∞ Sistema de Optimizaci√≥n Autom√°tica de Budget con ML** (optimizaci√≥n multi-objetivo, predicci√≥n de performance, reasignaci√≥n din√°mica, SLSQP)
- **üìä Sistema de An√°lisis de Cohortes** (retenci√≥n por per√≠odos, LTV, comparaci√≥n entre cohortes, revenue por per√≠odo)
- **üåç Sistema de Localizaci√≥n Multiling√ºe** (traducci√≥n autom√°tica, adaptaci√≥n cultural, gesti√≥n por locale, testing por mercado)
- **üìÖ Sistema de Predicci√≥n de Demanda Estacional** (detecci√≥n de patrones, forecasting, alertas de picos, tendencias)
- **üîå Integraci√≥n Avanzada con Herramientas de BI** (Tableau, Power BI, Looker, exportaci√≥n autom√°tica, LookML generation)
- **üö® Sistema de Detecci√≥n de Anomal√≠as** (z-score, outliers, an√°lisis de causas, alertas autom√°ticas)
- **‚ö° Sistema de Auto-Scaling de Campa√±as** (escalamiento autom√°tico, reducci√≥n/aumento de budget, guardrails, performance scoring)
- **üéØ Sistema de Gesti√≥n de Contenido por Funnel Stage** (TOFU/MOFU/BOFU, personalizaci√≥n por etapa, recomendaciones)
- **üìã Integraci√≥n con Herramientas de Gesti√≥n de Proyectos** (Asana, Jira, Monday.com, creaci√≥n autom√°tica de tareas, sincronizaci√≥n)
- **üí¨ Sistema de An√°lisis de Sentimiento Avanzado** (detecci√≥n de emociones, alertas autom√°ticas, tendencias, keywords extraction)
- **üéØ Sistema de Optimizaci√≥n de Bidding Autom√°tico** (ajuste din√°mico CPC/CPM/CPA, maximizaci√≥n ROI, guardrails)
- **üß™ Sistema de Testing Multivariado Avanzado** (MVT, an√°lisis factorial, optimizaci√≥n de combinaciones, ANOVA)
- **üé® Sistema de Personalizaci√≥n Contextual Avanzada** (temporal, ubicaci√≥n, dispositivo, clima, comportamiento)
- **üí≥ Integraci√≥n con Sistemas de Pago** (Stripe, PayPal, tracking de revenue, webhooks, attribution)
- **‚öñÔ∏è Sistema de Gesti√≥n de Permisos y Derechos** (permisos de contenido, verificaci√≥n pre-publicaci√≥n, expiraci√≥n, tracking de uso)
- **üîç Sistema de An√°lisis de Competidores en Tiempo Real** (monitoreo, detecci√≥n de campa√±as, an√°lisis de hashtags, comparaci√≥n de engagement)
- **üìâ Sistema de Predicci√≥n de Churn** (probabilidad de abandono, segmentaci√≥n de riesgo, recomendaciones de retenci√≥n)
- **üé™ Sistema de Gesti√≥n de Eventos y Webhooks** (recepci√≥n, routing, retry logic, verificaci√≥n de firma, audit trail)
- **üöÄ Sistema de Optimizaci√≥n de CDN y Delivery** (distribuci√≥n autom√°tica, invalidaci√≥n de cache, optimizaci√≥n de im√°genes, m√©tricas)
- **üìä Sistema de Generaci√≥n Autom√°tica de Reportes con Visualizaciones** (HTML interactivo, Chart.js, dashboards, resumen ejecutivo)
- **üé® Sistema de Optimizaci√≥n de Creatividades con IA** (an√°lisis visual/copy, recomendaciones, predicci√≥n de CTR, variantes)
- **üìÖ Sistema de Gesti√≥n de Calendario Editorial Avanzado** (planificaci√≥n autom√°tica, timing optimizado, detecci√≥n de gaps, conflictos)
- **üìà Sistema de An√°lisis de ROI por Canal y Segmento** (ROI/ROAS por canal, segmento, CAC, LTV, recomendaciones)
- **‚öôÔ∏è Sistema de Automatizaci√≥n de Workflows y Triggers** (orquestaci√≥n, triggers por evento/tiempo/condici√≥n, ejecuci√≥n secuencial, retry logic)
- **üîó Sistema de Integraci√≥n Multi-Plataforma Avanzado** (sincronizaci√≥n bidireccional, adaptaci√≥n por plataforma, gesti√≥n de credenciales)
- **üéØ Sistema de Optimizaci√≥n de Landing Pages con A/B Testing** (variantes m√∫ltiples, an√°lisis estad√≠stico, significancia, recomendaciones)
- **üîê Sistema de Gesti√≥n de Seguridad y Compliance Avanzado** (auditor√≠a, GDPR/CCPA, detecci√≥n de amenazas, eliminaci√≥n de datos)
- **üìù Sistema de An√°lisis de Contenido con NLP Avanzado** (sentimiento, emociones, keywords, entidades, legibilidad, insights autom√°ticos)
- **üîÆ Sistema de Predicci√≥n de Tendencias de Contenido** (an√°lisis hist√≥rico, forecasting, temas trending, timing √≥ptimo)
- **‚ö° Sistema de Optimizaci√≥n de Performance y Carga** (tiempo de carga, optimizaci√≥n de im√°genes, compresi√≥n, CDN, caching)
- **üí¨ Sistema de Gesti√≥n de Feedback y Mejora Continua** (recolecci√≥n estructurada, an√°lisis de patrones, acciones de mejora, roadmap)
- **üé¨ Sistema de Conversi√≥n de Carruseles a Video** (generaci√≥n desde slides, transiciones, timing optimizado, m√∫ltiples formatos)
- **üé® Sistema de Animaci√≥n y Motion Graphics Autom√°tico** (animaciones desde assets, transiciones, easing, CSS/After Effects)
- **ü§ñ Sistema de Generaci√≥n Autom√°tica de Contenido con IA** (headlines GPT, variaciones, optimizaci√≥n, personalizaci√≥n)
- **üìä Sistema de An√°lisis Predictivo de Performance** (predicci√≥n CTR/engagement/conversiones, forecasting, recomendaciones ML)
- **üìê Sistema de Gesti√≥n de Templates y Brand Guidelines** (validaci√≥n autom√°tica, enforcement, templates reutilizables, versionado)
- **üîÑ Sistema de Sincronizaci√≥n Multi-Canal en Tiempo Real** (sync bidireccional, adaptaci√≥n por canal, resoluci√≥n de conflictos, estado unificado)
- **üß© Sistema de Componentes Reutilizables y Design System** (biblioteca de componentes, composici√≥n, versionado, reportes de uso)
- **üì± Sistema de Adaptaci√≥n Autom√°tica a M√≥vil** (responsive autom√°tico, testing multi-dispositivo, touch targets, score mobile)
- **‚ôø Sistema de Validaci√≥n Avanzada de Contraste y Accesibilidad Visual** (validaci√≥n WCAG 2.1 AA/AAA, sugerencias autom√°ticas, reportes)
- **ü§ñ Sistema de Generaci√≥n Autom√°tica de Alt Text con IA** (alt text con GPT, optimizaci√≥n SEO/accesibilidad, evaluaci√≥n de calidad)
- **‚å®Ô∏è Sistema de Testing de Navegaci√≥n por Teclado** (validaci√≥n de teclado, trampas de foco, orden l√≥gico, atajos)
- **üìä Sistema de Reportes Ejecutivos de Accesibilidad** (reportes consolidados, m√©tricas clave, tendencias, exportaci√≥n HTML)
- **üîç Sistema de Gesti√≥n Avanzada de Metadatos y SEO** (generaci√≥n autom√°tica, Open Graph, Twitter Cards, Schema.org, scoring SEO)
- **üéØ Sistema de Generaci√≥n Autom√°tica de Variantes A/B** (variantes inteligentes, predicci√≥n de performance, planes de testing)
- **üìä Sistema de Monitoreo de Performance y Alertas Inteligentes** (monitoreo tiempo real, alertas predictivas, detecci√≥n anomal√≠as, tendencias)
- **üìÖ Sistema de Calendarizaci√≥n Inteligente y Publicaci√≥n Autom√°tica** (optimizaci√≥n de timing, multi-plataforma, detecci√≥n conflictos, reportes)
- **üöÄ Sistema de Publicaci√≥n Multi-Plataforma Automatizada** (publicaci√≥n simult√°nea, adaptaci√≥n autom√°tica, manejo errores, tracking estado)
- **üìà Sistema de An√°lisis de Performance Comparativa Multi-Plataforma** (comparaci√≥n m√©tricas, identificaci√≥n best/worst, recomendaciones, reportes)
- **üé® Sistema de Gesti√≥n de Contenido Generado por Usuarios (UGC) y Testimonios** (colecci√≥n autom√°tica, moderaci√≥n IA, permisos, conversi√≥n a carruseles)
- **üîÑ Sistema de Automatizaci√≥n de Workflows y Triggers Complejos** (workflows eventos/tiempo/condiciones, dependencias, manejo errores, audit trail)
- **üîó Sistema de Integraci√≥n API Avanzada y Webhooks** (gesti√≥n integraciones, verificaci√≥n firmas, rate limiting, health monitoring)
- **üé≠ Sistema de Personalizaci√≥n Din√°mica Basada en Contexto Temporal** (personalizaci√≥n por hora/d√≠a/temporada, eventos, ubicaci√≥n, comportamiento)
- **üìä Sistema de Analytics Unificado Multi-Fuente** (agregaci√≥n GA4/Meta/CRM, normalizaci√≥n, m√©tricas derivadas, exportaci√≥n BI)
- **üîê Sistema de Seguridad Avanzada y Protecci√≥n de Datos** (encriptaci√≥n, gesti√≥n permisos, auditor√≠a, detecci√≥n amenazas, GDPR/CCPA)
- **üåê Sistema de Localizaci√≥n y Traducci√≥n Autom√°tica Multi-Idioma** (traducci√≥n IA, adaptaci√≥n cultural, testing por mercado, detecci√≥n idioma)
- **üéØ Sistema de Optimizaci√≥n Autom√°tica Basada en ML** (aprendizaje autom√°tico, auto-optimizaci√≥n, predicci√≥n variantes, feature importance)
- **üé® Sistema de Generaci√≥n Autom√°tica de Variantes Visuales con IA** (generaci√≥n DALL-E/Midjourney, an√°lisis estilo, optimizaci√≥n composici√≥n/colores, testing performance visual)
- **üì± Sistema de Adaptaci√≥n Autom√°tica Multi-Dispositivo** (detecci√≥n dispositivo, optimizaci√≥n pantalla, adaptaci√≥n tipograf√≠a/espaciados, optimizaci√≥n im√°genes, testing multi-dispositivo)
- **üîÑ Sistema de Sincronizaci√≥n y Versionado de Contenido** (versionado sem√°ntico, sincronizaci√≥n fuentes, resoluci√≥n conflictos, historial cambios, rollback)
- **üé¨ Sistema de Generaci√≥n Autom√°tica de Videos desde Carruseles** (conversi√≥n slides a video, transiciones, sincronizaci√≥n audio, optimizaci√≥n por plataforma, exportaci√≥n formatos)
- **üéµ Sistema de Generaci√≥n Autom√°tica de Audio y Voiceover** (text-to-speech, sincronizaci√≥n slides, efectos sonido, m√∫sica fondo, optimizaci√≥n formato)
- **üìä Sistema de Dashboard Interactivo en Tiempo Real** (visualizaci√≥n m√©tricas, gr√°ficos interactivos, filtros din√°micos, exportaci√≥n reportes PDF/Excel/PNG/HTML)
- **ü§ñ Sistema de Chatbot y Asistente Virtual para Gesti√≥n de Carruseles** (chatbot conversacional, generaci√≥n contenido por conversaci√≥n, an√°lisis performance lenguaje natural, recomendaciones interactivas)
- **üîç Sistema de B√∫squeda Inteligente y Recomendaciones de Contenido** (b√∫squeda sem√°ntica, recomendaciones ML, similitud visual, filtrado multi-criterio, historial b√∫squedas)
- **üéØ Sistema de Scoring y Ranking Autom√°tico de Carruseles** (scoring multi-dimensional, ranking autom√°tico, clasificaci√≥n categor√≠as, predicci√≥n potencial, recomendaciones optimizaci√≥n)
- **üé® Sistema de Generaci√≥n Autom√°tica de Design Systems y Componentes Reutilizables** (componentes SVG reutilizables, tokens dise√±o, biblioteca componentes, variantes autom√°ticas, exportaci√≥n formatos)
- **üì± Sistema de Testing Automatizado Multi-Plataforma y Multi-Dispositivo** (testing plataformas sociales, testing dispositivos/resoluciones, validaci√≥n performance, testing accesibilidad, screenshots/reportes)
- **üéØ Sistema de Segmentaci√≥n Avanzada y Personalizaci√≥n Din√°mica por Audiencia** (segmentaci√≥n multi-dimensional, personalizaci√≥n din√°mica por segmento, testing A/B por segmento, an√°lisis performance por audiencia, recomendaciones segmentaci√≥n)
- **üé® Sistema de Generaci√≥n Autom√°tica de Contenido Visual con IA** (generaci√≥n im√°genes DALL-E/Stable Diffusion, ilustraciones, gr√°ficos, optimizaci√≥n autom√°tica, variantes visuales, an√°lisis calidad)
- **üîÑ Sistema de Sincronizaci√≥n Bidireccional con Plataformas Externas** (sincronizaci√≥n CMS/DAM/Figma/Canva, detecci√≥n/resoluci√≥n conflictos, historial sincronizaciones, webhooks tiempo real, mapeo campos)
- **üìà Sistema de An√°lisis Predictivo Avanzado y Forecasting** (predicci√≥n CTR/engagement/conversiones, forecasting tr√°fico/revenue, detecci√≥n tendencias, an√°lisis estacionalidad, recomendaciones predicciones)
- **üéØ Sistema de Optimizaci√≥n Autom√°tica de Budget con IA** (optimizaci√≥n budget por carrusel, redistribuci√≥n autom√°tica, predicci√≥n ROI, optimizaci√≥n multi-objetivo, alertas budget)
- **üé≠ Sistema de Generaci√≥n Autom√°tica de Storyboards y Narrativas** (generaci√≥n narrativas coherentes, storyboards visuales, arcos narrativos, adaptaci√≥n por audiencia, exportaci√≥n formatos)
- **üé® Sistema de Generaci√≥n Autom√°tica de Brand Guidelines y Templates** (generaci√≥n brand guidelines, templates pre-configurados, validaci√≥n compliance, documentaci√≥n marca, exportaci√≥n formatos)
- **üìä Sistema de An√°lisis de Sentimiento y Engagement en Tiempo Real** (an√°lisis sentimiento comentarios, tracking engagement real-time, detecci√≥n tendencias, alertas negativo, an√°lisis influencers)

