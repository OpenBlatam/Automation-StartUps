# ğŸš€ Plataforma de AutomatizaciÃ³n Empresarial

> Plataforma modular y escalable para automatizaciÃ³n de procesos empresariales sobre Kubernetes, integrando data lake, workflows, RPA, MLOps, observabilidad y seguridad.

[![Terraform](https://img.shields.io/badge/terraform-1.6+-blue.svg)](https://terraform.io)
[![Kubernetes](https://img.shields.io/badge/kubernetes-latest-blue.svg)](https://kubernetes.io)
[![Helm](https://img.shields.io/badge/helm-3.13+-blue.svg)](https://helm.sh)

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#-descripciÃ³n-general)
- [Arquitectura](#-arquitectura)
- [Requisitos](#-requisitos)
- [Inicio RÃ¡pido](#-inicio-rÃ¡pido)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Despliegue](#-despliegue)
- [Componentes Principales](#-componentes-principales)
- [Plataformas de AutomatizaciÃ³n Empresarial](#-plataformas-de-automatizaciÃ³n-empresarial)
  - [Quick Start: Integrar en 15 Minutos](#quick-start-integrar-en-15-minutos)
  - [Decisiones ArquitectÃ³nicas Clave](#decisiones-arquitectÃ³nicas-clave)
  - [Seguridad en Integraciones](#seguridad-en-integraciones)
  - [Escalamiento y Performance](#escalamiento-y-performance)
  - [Testing de Integraciones](#testing-de-integraciones)
  - [Checklist de Go-Live](#checklist-de-go-live)
- [Casos de Uso](#-casos-de-uso)
- [OperaciÃ³n y Mantenimiento](#-operaciÃ³n-y-mantenimiento)
- [Seguridad](#-seguridad)
- [GuÃ­as de Onboarding](#-guÃ­as-de-onboarding)
- [Troubleshooting](#-troubleshooting)
- [MÃ©tricas y Monitoreo](#-mÃ©tricas-y-monitoreo)
- [Mejores PrÃ¡cticas](#-mejores-prÃ¡cticas)
- [Diagrama de Arquitectura Completo](#-diagrama-de-arquitectura-completo)
- [Checklist de Deployment](#-checklist-de-deployment)
- [FAQ](#-faq-preguntas-frecuentes)
- [Costos Estimados](#-costos-estimados)
- [Ejemplo de Flujo End-to-End Completo](#-ejemplo-de-flujo-end-to-end-completo)
- [Quick Links por Componente](#-quick-links-por-componente)
- [DocumentaciÃ³n Adicional](#-documentaciÃ³n-adicional)
- [Changelog](#-changelog)

## ğŸ¯ DescripciÃ³n General

Esta plataforma proporciona una soluciÃ³n completa para automatizar procesos de negocio, integrando:

### ğŸš€ Inicio RÃ¡pido (TL;DR)

**Para empezar en 5 minutos:**

```bash
# 1. Configurar cloud provider
cp platform.yaml.example platform.yaml
# Editar platform.yaml con tu configuraciÃ³n

# 2. Desplegar infraestructura
make tf-init TF_DIR=infra/terraform
make tf-apply TF_DIR=infra/terraform

# 3. Configurar Kubernetes
make k8s-namespaces
make k8s-ingress

# 4. Desplegar componentes base
make helmfile-apply

# 5. Acceder a dashboards
# Grafana: http://grafana.your-domain.com
# Kestra: http://kestra.your-domain.com
# Airflow: http://airflow.your-domain.com
```

**Componentes principales disponibles:**
- âœ… **Kestra**: Workflows declarativos (YAML) - `workflow/kestra/`
- âœ… **Flowable/Camunda**: BPMN para procesos de negocio - `workflow/`
- âœ… **Airflow**: Pipelines ETL enterprise-grade - `data/airflow/`
- âœ… **OpenRPA**: AutomatizaciÃ³n RPA open-source - `rpa/`
- âœ… **MLflow**: Tracking y serving de modelos ML - `ml/mlflow/`
- âœ… **Grafana/Prometheus**: Observabilidad completa - `observability/`

**Â¿Necesitas integrar plataformas comerciales?** Ver secciÃ³n [Plataformas de AutomatizaciÃ³n Empresarial](#-plataformas-de-automatizaciÃ³n-empresarial) para UiPath, ServiceNow y mÃ¡s.

### ğŸ’¡ Casos de Uso Principales

| Caso de Uso | Herramienta Recomendada | DocumentaciÃ³n |
|-------------|------------------------|---------------|
| **ETL de datos** | Airflow | `data/airflow/dags/INDEX_ETL_IMPROVED.md` |
| **Workflows simples** | Kestra | `workflow/kestra/flows/` |
| **Procesos BPMN formales** | Flowable/Camunda | `workflow/flowable/`, `workflow/camunda/` |
| **AutomatizaciÃ³n UI/Desktop** | OpenRPA | `rpa/OPENRPA.md` |
| **Machine Learning** | MLflow + KServe | `ml/mlflow/`, `ml/kubeflow/` |
| **Dashboards y KPIs** | Grafana + PostgreSQL | `docs/KPI_SYSTEM.md` |

### ğŸ—ºï¸ Rutas RÃ¡pidas por Rol

**ğŸ‘¨â€ğŸ’» Desarrollador:**
1. [Configurar ambiente local](#-inicio-rÃ¡pido) â†’ [Crear primer workflow](#-workflows-kestra) â†’ [Ejemplos de cÃ³digo](#ejemplos-de-integraciÃ³n-prÃ¡ctica)

**ğŸ”§ DevOps/Platform Engineer:**
1. [Desplegar infraestructura](#-despliegue) â†’ [Configurar observabilidad](#-mÃ©tricas-y-monitoreo) â†’ [Seguridad](#-seguridad)

**ğŸ“Š Data Engineer/Analyst:**
1. [ETL con Airflow](#airflow-automatizaciones-de-datos) â†’ [Sistema de KPIs](#-kpis-y-analytics) â†’ [Dashboards Grafana](#dashboard-de-kpis-en-tiempo-real-grafana)

**ğŸ¢ Arquitecto/Tomador de Decisiones:**
1. [ComparaciÃ³n de plataformas](#comparaciÃ³n-comerciales-vs-herramientas-integradas) â†’ [AnÃ¡lisis de ROI](#anÃ¡lisis-de-roi-uipath-vs-openrpa) â†’ [Decisiones arquitectÃ³nicas](#decisiones-arquitectÃ³nicas-clave)

**ğŸ”’ Security Engineer:**
1. [Seguridad de integraciones](#seguridad-en-integraciones) â†’ [Network Policies](#network-policies) â†’ [AuditorÃ­a](#4-auditorÃ­a-y-logging-de-seguridad)

### ğŸ“Š Mapa de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Plataforma de AutomatizaciÃ³n                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Workflows   â”‚  â”‚     RPA      â”‚  â”‚    MLOps     â”‚    â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚    â”‚
â”‚  â”‚ â€¢ Kestra     â”‚  â”‚ â€¢ OpenRPA    â”‚  â”‚ â€¢ MLflow     â”‚    â”‚
â”‚  â”‚ â€¢ Flowable   â”‚  â”‚ â€¢ UiPath*    â”‚  â”‚ â€¢ Kubeflow   â”‚    â”‚
â”‚  â”‚ â€¢ Camunda    â”‚  â”‚              â”‚  â”‚ â€¢ KServe     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     ETL      â”‚  â”‚ Observabilidadâ”‚  â”‚  IntegraciÃ³n â”‚    â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚    â”‚
â”‚  â”‚ â€¢ Airflow    â”‚  â”‚ â€¢ Prometheus â”‚  â”‚ â€¢ ServiceNow*â”‚    â”‚
â”‚  â”‚ â€¢ DAGs       â”‚  â”‚ â€¢ Grafana    â”‚  â”‚ â€¢ Kafka      â”‚    â”‚
â”‚  â”‚ â€¢ Plugins    â”‚  â”‚ â€¢ ELK Stack  â”‚  â”‚ â€¢ API Gatewayâ”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Infraestructura (Kubernetes)                â”‚  â”‚
â”‚  â”‚  EKS/AKS/OpenShift | Terraform | Helm | Kustomize    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* = IntegraciÃ³n opcional con plataformas comerciales
```

### ğŸ¯ CaracterÃ­sticas Destacadas

- âœ… **Multi-cloud**: AWS, Azure, OpenShift
- âœ… **Enterprise-ready**: Circuit breakers, retry logic, idempotencia
- âœ… **Observabilidad completa**: MÃ©tricas, logs, traces, dashboards
- âœ… **Seguridad**: RBAC, OPA, External Secrets, Network Policies
- âœ… **Escalable**: Auto-escalado horizontal, workers distribuidos
- âœ… **Open-source first**: Sin vendor lock-in
- âœ… **IntegraciÃ³n comercial**: Soporte para UiPath, ServiceNow (opcional)

Esta plataforma proporciona una soluciÃ³n completa para automatizar procesos de negocio, integrando:

- **Infraestructura**: Kubernetes (EKS/AKS/OpenShift) con gestiÃ³n multi-cloud
- **Almacenamiento**: Data Lake (S3/ADLS) + bases de datos relacionales/NoSQL
- **OrquestaciÃ³n**: Kestra, Flowable, Camunda para workflows y BPM
- **AutomatizaciÃ³n**: OpenRPA para tareas repetitivas
- **MLOps**: Kubeflow, MLflow, KServe para machine learning
- **IntegraciÃ³n**: API Gateway, Kafka para eventos en tiempo real
- **Observabilidad**: Prometheus, Grafana, ELK para monitoreo completo
- **KPIs y Analytics**: Dashboards automÃ¡ticos, reportes programados, alertas de KPIs crÃ­ticos, visualizaciÃ³n en tiempo real (ver `docs/KPI_SYSTEM.md`)
- **Seguridad**: RBAC, OPA Gatekeeper, External Secrets, Network Policies

## ğŸ—ï¸ Arquitectura

### Capas de la Plataforma

| Capa | Herramienta | FunciÃ³n | CaracterÃ­sticas Clave |
|------|------------|---------|----------------------|
| **Infraestructura** | Kubernetes (EKS/AKS/OpenShift) | Contenedores, orquestaciÃ³n, escalado | Despliegue hÃ­brido (nube + onâ€‘prem) y cumplimiento local |
| **Almacenamiento** | Data Lake + DB (S3/ADLS + SQL/NoSQL) | HistÃ³ricos, logs, mÃ©tricas | Gobierno de datos, metadatos, historizaciÃ³n |
| **OrquestaciÃ³n Global** | Kestra | Pipelines declarativos (YAML), triggers, UI | AdopciÃ³n por equipos mixtos (dev/ops/negocio) |
| **Procesos de Negocio (BPM)** | Flowable | BPMN para procesos formales | Automatizaciones gobernadas y auditables |
| **AutomatizaciÃ³n (RPA)** | OpenRPA | UI/desktop/API bots | Openâ€‘source, evita lockâ€‘in |
| **IA/ML/MLOps** | Kubeflow + MLflow + KServe | Entrenar/servir, tracking | EvoluciÃ³n hacia automatizaciÃ³n "autÃ³noma" |
| **IntegraciÃ³n / API / Eventos** | NGINX Ingress + Kafka | APIs, eventos, tiempo real | Escalabilidad y acoplamiento dÃ©bil |
| **Observabilidad** | Prometheus/Grafana + ELK + IAM | MÃ©tricas, logs, alertas, RBAC | OperaciÃ³n 24/7 y cumplimiento |

### Flujo End-to-End

1. **DefiniciÃ³n**: Usuarios definen procesos en Kestra (o programan triggers/eventos)
2. **BPM**: Kestra invoca rutas de negocio en Flowable (BPMN) cuando corresponde
3. **RPA**: Tareas sin API se ejecutan con bots OpenRPA coordinados por OpenFlow
4. **IA/ML**: Decisiones y predicciones via Kubeflow/MLflow/KServe
5. **EjecuciÃ³n**: Todo corre en Kubernetes, integrado por API y eventos (Kafka/Ingress)
6. **Observabilidad**: Monitoreo central (Prometheus/ELK) y gobierno (RBAC, OPA, auditorÃ­a)

## âœ… Requisitos

### Herramientas Locales

- **Terraform** >= 1.6
- **kubectl** y/o **oc** (OpenShift)
- **Helm** >= 3.13
- **Make** (para comandos simplificados)

### Accesos Necesarios

- Acceso a cloud provider (Azure/AWS/GCP)
- Identidades configuradas (IAM roles, service principals)
- Permisos para crear recursos de infraestructura

## ğŸš€ Inicio RÃ¡pido

### 1. ConfiguraciÃ³n Inicial

Edita `platform.yaml` para seleccionar el proveedor cloud y componentes:

```yaml
cloud:
  provider: aws  # opciones: aws | azure | openshift
  region: us-east-1

kubernetes:
  distribution: eks  # opciones: eks | aks | openshift
  clusterName: biz-automation-dev
```

### 2. Despliegue AWS (EKS + S3)

```bash
# Inicializar Terraform
make tf-init TF_DIR=infra/terraform

# Aplicar infraestructura
make tf-apply TF_DIR=infra/terraform

# Crear namespaces
make k8s-namespaces

# Configurar Ingress
make k8s-ingress

# Desplegar componentes de integraciÃ³n
make k8s-integration
```

### 3. Despliegue Azure (AKS + ADLS + ACR)

```bash
# Inicializar Terraform
make tf-init TF_DIR=infra/terraform/azure

# Aplicar infraestructura
make tf-apply TF_DIR=infra/terraform/azure

# Crear namespaces
make k8s-namespaces

# Configurar Ingress
make k8s-ingress

# Desplegar componentes de integraciÃ³n
make k8s-integration
```

### 4. Desplegar Componentes Adicionales

```bash
# Kafka y tÃ³picos
make k8s-kafka
make k8s-kafka-topics

# Instalar charts base (Airflow, Prometheus, Grafana, etc.)
make helmfile-apply
```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ platform.yaml                 # ConfiguraciÃ³n central de cloud y componentes
â”œâ”€â”€ Makefile                      # Comandos simplificados para despliegue
â”œâ”€â”€ helmfile.yaml                 # DefiniciÃ³n de releases Helm
â”‚
â”œâ”€â”€ infra/terraform/              # Infraestructura como CÃ³digo
â”‚   â”œâ”€â”€ main.tf                   # Terraform AWS (EKS + S3)
â”‚   â””â”€â”€ azure/                    # Terraform Azure (AKS + ADLS + ACR)
â”‚
â”œâ”€â”€ kubernetes/                   # Manifiestos Kubernetes
â”‚   â”œâ”€â”€ namespaces.yaml           # Namespaces por entorno
â”‚   â”œâ”€â”€ ingress/                  # ConfiguraciÃ³n de Ingress
â”‚   â”œâ”€â”€ integration/              # Componentes de integraciÃ³n
â”‚   â”œâ”€â”€ kafka/                    # Kafka (Strimzi) y tÃ³picos
â”‚   â””â”€â”€ overlays/                 # Kustomize overlays (dev/stg/prod)
â”‚
â”œâ”€â”€ data/                         # Pipelines y Datos
â”‚   â”œâ”€â”€ airflow/                  # DAGs de Airflow
â”‚   â”‚   â”œâ”€â”€ dags/                 # DAGs de ETL, KPIs, outreach, etc.
â”‚   â”‚   â””â”€â”€ plugins/              # Plugins personalizados
â”‚   â”œâ”€â”€ db/                       # Esquemas y scripts SQL
â”‚   â””â”€â”€ INTEGRATIONS.md           # GuÃ­a de integraciones de analÃ­tica
â”‚
â”œâ”€â”€ workflow/                     # Orquestadores de Procesos
â”‚   â”œâ”€â”€ kestra/                   # Kestra (pipelines YAML)
â”‚   â”‚   â””â”€â”€ flows/                # Flujos de ejemplo
â”‚   â”œâ”€â”€ flowable/                 # Flowable (BPMN)
â”‚   â””â”€â”€ camunda/                  # Camunda (alternativa)
â”‚
â”œâ”€â”€ ml/                           # MLOps
â”‚   â”œâ”€â”€ kubeflow/                 # Kubeflow pipelines
â”‚   â”œâ”€â”€ mlflow/                   # MLflow tracking y registry
â”‚   â””â”€â”€ kserve/                   # Model serving
â”‚
â”œâ”€â”€ observability/                # Monitoreo y Observabilidad
â”‚   â”œâ”€â”€ prometheus/               # Reglas de alerta
â”‚   â”œâ”€â”€ grafana/                  # Dashboards y datasources
â”‚   â”œâ”€â”€ elastic/                  # ELK stack
â”‚   â””â”€â”€ opencost/                 # AnÃ¡lisis de costes
â”‚
â”œâ”€â”€ security/                     # Seguridad y Cumplimiento
â”‚   â”œâ”€â”€ kubernetes/               # RBAC, LimitRanges, Quotas
â”‚   â”œâ”€â”€ policies/                 # OPA Gatekeeper policies
â”‚   â”œâ”€â”€ networkpolicies/          # Network Policies
â”‚   â”œâ”€â”€ secrets/                  # External Secrets Operator
â”‚   â””â”€â”€ cert-manager/             # GestiÃ³n de certificados
â”‚
â”œâ”€â”€ web/                          # Aplicaciones Web
â”‚   â”œâ”€â”€ kpis/                     # Interfaz TypeScript (Express)
â”‚   â””â”€â”€ kpis-next/                # Interfaz Next.js (React)
â”‚
â”œâ”€â”€ environments/                 # ConfiguraciÃ³n por entorno
â”‚   â”œâ”€â”€ dev.yaml
â”‚   â”œâ”€â”€ stg.yaml
â”‚   â””â”€â”€ prod.yaml
â”‚
â””â”€â”€ docs/                         # DocumentaciÃ³n Adicional
    â””â”€â”€ INDEX.md                  # Ãndice de documentaciÃ³n
```

## ğŸ”§ Despliegue

### Flujo de Despliegue (Alto Nivel)

1. **IaC**: Desplegar redes, cluster, storage, identidades con Terraform
2. **K8s Base**: Aplicar namespaces, ingress, secrets, policies
3. **Integraciones**: Desplegar Kafka, Airflow, Camunda/Kestra/Flowable
4. **Datos/ML**: Configurar data lake, MLflow, KServe, Databricks/Snowflake
5. **Observabilidad**: Activar Prometheus/Grafana, ELK, alertas
6. **Seguridad**: Aplicar polÃ­ticas de seguridad, RBAC, auditorÃ­a

### Despliegue por Entorno

#### Overlays (Kustomize)

```bash
# Desarrollo
kubectl apply -k kubernetes/overlays/dev

# Staging
kubectl apply -k kubernetes/overlays/stg

# ProducciÃ³n
kubectl apply -k kubernetes/overlays/prod
```

#### ValidaciÃ³n sin Aplicar Cambios

```bash
make kustomize-validate-dev
make kustomize-validate-stg
make kustomize-validate-prod
```

### Helmfile

Para instalar charts (Ingress, Airflow, Prometheus/Grafana, Strimzi, Camunda):

```bash
# Aplicar todos los releases
make helmfile-apply

# Ver diferencias
make helmfile-diff
```

## ğŸ§© Componentes Principales

### Airflow: Automatizaciones de Datos

DAGs incluidos en `data/airflow/dags/`:

- **`etl_example.py`**: Pipeline ETL enterprise-grade con:
  - Circuit breaker con auto-reset y tracking de fallos
  - DetecciÃ³n de anomalÃ­as de volumen (20 ejecuciones histÃ³ricas)
  - Paralelismo adaptativo optimizado
  - ValidaciÃ³n de checksum para cambios en datos
  - Idempotencia con TTL configurable
  - MÃ©tricas de throughput avanzadas (`rows_per_sec`, `ms_per_1k_rows`)
  - Dry run mode para testing
  - Dataset lineage completo
  - DQ checks expandidos (null_rate, min/max rows)
- **`employee_onboarding.py`**: AutomatizaciÃ³n de onboarding de empleados con:
  - âœ… ValidaciÃ³n robusta de datos (formato de emails, fechas, prevenciÃ³n de auto-asignaciÃ³n)
  - âœ… Idempotencia con TTL configurable por parÃ¡metro
  - âœ… Logging estructurado con correlaciÃ³n
  - âœ… IntegraciÃ³n opcional con HRIS para enriquecer datos
  - âœ… CreaciÃ³n de cuentas (IdP, email, workspace)
  - âœ… AsignaciÃ³n de tareas en tracker (Jira/Linear/Asana)
  - âœ… EnvÃ­o de email de bienvenida con documentaciÃ³n
  - âœ… MÃ©tricas de performance en Stats
  - âœ… Notificaciones Slack en Ã©xito/fallo
  - âœ… Persistencia de progreso en Airflow Variables
  - âœ… IntegraciÃ³n con Camunda BPMN para aprobaciones de manager
- **`kpi_reports_monthly.py`**: Reportes mensuales con idempotencia, detecciÃ³n de anomalÃ­as en KPIs y mÃ©tricas completas
- **`stripe_reconcile.py`**: ReconciliaciÃ³n de cargos Stripe vs tabla `payments`
- **`kpi_aggregate_daily.py`**: ConsolidaciÃ³n de mÃ©tricas diarias
- **`leads_sync_hubspot.py`**: SincronizaciÃ³n de contactos HubSpot
- **`outreach_multichannel.py`**: AutomatizaciÃ³n de outreach multi-canal
- **`payment_reminders.py`**: Recordatorios de pagos pendientes
- **`invoice_generate.py`**: GeneraciÃ³n automÃ¡tica de facturas

Ver `data/airflow/dags/INDEX_ETL_IMPROVED.md` para documentaciÃ³n completa y `data/airflow/README.md` para configuraciÃ³n.

### Workflows: Kestra

Pipelines declarativos en YAML. Ejemplos:

- **`employee_onboarding.yaml`**: Proceso completo automatizado de onboarding con 11 fases:
  - âœ… **Fase 1-2**: ValidaciÃ³n robusta, normalizaciÃ³n de datos, idempotencia, integraciÃ³n HRIS
  - âœ… **Fase 3**: Acciones en paralelo (crear cuentas IdP/Workspace, notificaciones TI, email bienvenida, tareas manager, calendario)
  - âœ… **Fase 4-5**: ConsolidaciÃ³n de resultados, tracking detallado, notificaciones Ã©xito/fallo
  - âœ… **Fase 6**: Persistencia completa en PostgreSQL (4 tablas: empleados, acciones, cuentas, seguimiento)
  - âœ… **Fase 7**: MÃ©tricas en tiempo real a Prometheus (tasa de Ã©xito, duraciÃ³n, cuentas creadas)
  - âœ… **Fase 8**: ConfirmaciÃ³n automÃ¡tica al HRIS con reporte completo
  - âœ… **Fase 9**: Reporte de auditorÃ­a con anÃ¡lisis de compliance y recomendaciones
  - âœ… **Fase 10**: Tareas de seguimiento post-onboarding (dÃ­a 1, 3, 7, 30)
  - âœ… **Fase 11**: Resumen final consolidado con prÃ³ximos pasos
  - Ver `workflow/kestra/flows/README_onboarding.md` para documentaciÃ³n completa
- **`leads_manychats_to_hubspot.yaml`**: ManyChat â†’ HubSpot + DB + scoring
- **`stripe_payments_to_sheets_db_ai.yaml`**: Stripe â†’ Sheets + DB + AI insights
- **`whatsapp_ticket_to_sheet_doc.yaml`**: WhatsApp â†’ OCR â†’ Sheets + Docs
- **`bpm_rpa_example.yaml`**: OrquestaciÃ³n BPM + RPA

### Aplicaciones Web

#### KPIs (TypeScript/Express)

```bash
cd web/kpis
npm install
KPIS_PG_HOST=localhost KPIS_PG_DB=analytics \
  KPIS_PG_USER=analytics KPIS_PG_PASSWORD=xxx npm run dev
```

#### KPIs (Next.js/React)

```bash
cd web/kpis-next
npm install
KPIS_PG_HOST=localhost KPIS_PG_DB=analytics \
  KPIS_PG_USER=analytics KPIS_PG_PASSWORD=xxx \
  NEXT_PUBLIC_BASE_URL=http://localhost:3000 npm run dev
```

### Casos de Uso Detallados de IntegraciÃ³n

#### Caso 1: Procesamiento AutomÃ¡tico de Facturas (UiPath + Kestra)

**Escenario**: Procesar 1000+ facturas PDF diarias, extraer datos estructurados, y cargar a ERP.

```yaml
# workflow/kestra/flows/uipath_invoice_processing.yaml
id: process_invoice_batch
namespace: finance
triggers:
  - id: s3_trigger
    type: io.kestra.plugin.aws.s3.Triggers.File
    bucket: invoices-bucket
    prefix: "incoming/"
    suffix: ".pdf"
tasks:
  - id: trigger_uipath_ocr
    type: io.kestra.plugin.http.HttpRequest
    uri: "https://{{ uipath_orchestrator }}/api/Jobs/Start"
    method: POST
    headers:
      Authorization: "Bearer {{ uipath_api_token }}"
    body:
      ReleaseKey: "invoice-processing-release"
      InputArguments: |
        {
          "pdfPath": "{{ trigger.uri }}",
          "outputFormat": "json"
        }
```

#### Caso 2: Aprobaciones ServiceNow + Camunda

```python
# workflow/camunda/worker/servicenow_approval.py
def create_snow_ticket(task: ExternalTask) -> TaskResult:
    servicenow = os.getenv("SERVICENOW_INSTANCE")
    response = requests.post(
        f"{servicenow}/api/now/table/sc_request",
        auth=(os.getenv("SNOW_USER"), os.getenv("SNOW_PASSWORD")),
        json={
            "short_description": f"Purchase: ${task.get_variable('amount')}",
            "category": "Procurement"
        }
    )
    return task.complete({
        "ticket_sys_id": response.json()["result"]["sys_id"]
    })
```

#### Caso 3: MigraciÃ³n Gradual UiPath â†’ OpenRPA

```yaml
# workflow/kestra/flows/hybrid_rpa_routing.yaml
id: hybrid_rpa_routing
tasks:
  - id: evaluate_complexity
    type: io.kestra.core.tasks.flows.Switch
    value: "{{ inputs.complexity_score }}"
    cases:
      - condition: "${value <= 3}"
        tasks:
          - execute_openrpa  # Gratis
      - condition: "${value > 3}"
        tasks:
          - execute_uipath  # Licenciado
```

### GuÃ­as Paso a Paso

#### Integrar UiPath con Kestra

1. **Configurar autenticaciÃ³n**:
```bash
curl -X POST "https://instance.orchestrator.uipath.com/api/account/authenticate" \
  -d '{"tenancyName": "default", "usernameOrEmailAddress": "user", "password": "pass"}'

kubectl create secret generic uipath-credentials \
  --from-literal=token='token' \
  --from-literal=orchestrator-url='https://instance.orchestrator.uipath.com'
```

2. **Crear workflow Kestra** (ver ejemplo Caso 1)

### Troubleshooting

**UiPath**: Jobs fallan
```bash
curl -H "Authorization: Bearer $TOKEN" \
  "https://instance.orchestrator.uipath.com/api/Robots"
```

**ServiceNow**: Tickets duplicados
```python
# Implementar idempotencia con business_key
def create_ticket_idempotent(business_key, ticket_data):
    existing = snow.get("sc_request", params={
        "sysparm_query": f"u_business_key={business_key}"
    })
    if existing.json()["result"]:
        return existing.json()["result"][0]
    return snow.create("sc_request", {**ticket_data, "u_business_key": business_key})
```

### MÃ©tricas y Monitoreo de Integraciones

#### MÃ©tricas Clave a Monitorear

| MÃ©trica | Plataforma | Threshold | AcciÃ³n |
|---------|-----------|-----------|--------|
| Tasa de Ã©xito de jobs | UiPath | < 95% | Alertar y revisar logs |
| Latencia promedio | UiPath API | > 5s | Investigar carga |
| Tiempo de respuesta | ServiceNow API | > 3s | Verificar instancia |
| Tickets duplicados | ServiceNow | > 1% | Revisar idempotencia |
| Tasa de error | Camunda workers | > 2% | Revisar cÃ³digo worker |
| Throughput jobs/hora | UiPath | < baseline | Escalar robots |

#### Dashboard Grafana para Integraciones

```json
{
  "dashboard": {
    "title": "Plataformas de AutomatizaciÃ³n - Integraciones",
    "panels": [
      {
        "title": "UiPath Jobs Success Rate",
        "targets": [{
          "expr": "rate(uipath_jobs_success_total[5m]) / rate(uipath_jobs_total[5m])"
        }]
      },
      {
        "title": "ServiceNow API Latency",
        "targets": [{
          "expr": "histogram_quantile(0.95, servicenow_api_duration_seconds_bucket)"
        }]
      },
      {
        "title": "Cost Savings (OpenRPA vs UiPath)",
        "targets": [{
          "expr": "sum(rpa_executions{bot_type='openrpa'}) * 150 - sum(rpa_executions{bot_type='uipath'}) * 150"
        }]
      }
    ]
  }
}
```

#### Alertas Prometheus

```yaml
# observability/prometheus/integration_alerts.yaml
groups:
  - name: integration_alerts
    rules:
      - alert: UiPathHighFailureRate
        expr: rate(uipath_jobs_failed_total[5m]) / rate(uipath_jobs_total[5m]) > 0.05
        for: 10m
        annotations:
          summary: "UiPath failure rate above 5%"
          
      - alert: ServiceNowSlowAPI
        expr: histogram_quantile(0.95, servicenow_api_duration_seconds_bucket) > 3
        for: 5m
        annotations:
          summary: "ServiceNow API latency above 3s"
          
      - alert: DuplicateTicketsDetected
        expr: rate(servicenow_tickets_duplicate_total[10m]) > 0.01
        for: 5m
        annotations:
          summary: "ServiceNow duplicate ticket rate above 1%"
```

### Diagramas de Flujo Detallados

#### Flujo Completo: Procesamiento de Facturas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Factura PDF    â”‚
â”‚  llega a S3     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (Trigger)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kestra Flow   â”‚
â”‚  - Valida PDF   â”‚
â”‚  - Prepara data â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (HTTP POST)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UiPath Bot      â”‚
â”‚ - OCR           â”‚
â”‚ - ExtracciÃ³n    â”‚
â”‚ - ValidaciÃ³n    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (Polling)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚
â”‚ - Guarda datos  â”‚
â”‚ - Actualiza BD  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (REST API)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ERP System    â”‚
â”‚ - Carga factura â”‚
â”‚ - Notifica      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Flujo: AprobaciÃ³n ServiceNow + Camunda

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Solicitud de   â”‚
â”‚  Compra ($50K)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Camunda Process â”‚
â”‚ (BPMN)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (External Task)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ServiceNow API  â”‚
â”‚ - Crea ticket   â”‚
â”‚ - Asigna grupo  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (Polling cada 10s)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Aprobador      â”‚
â”‚  revisa ticket  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
   SÃ        NO
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aprobadoâ”‚ â”‚Rechazadoâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Camunda recibeâ”‚
    â”‚  resultado    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚           â”‚
      â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Procesar â”‚ â”‚Notificar â”‚
â”‚ Compra   â”‚ â”‚Rechazo   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ComparaciÃ³n de Performance y Costos

#### AnÃ¡lisis de ROI: UiPath vs OpenRPA

| MÃ©trica | UiPath | OpenRPA | Diferencia |
|---------|--------|---------|------------|
| **Costo mensual** (10 bots) | $15,000 | $500 (infra) | **$14,500/mes** |
| **Time to market** | 2 semanas | 1 semana | +1 semana |
| **Tasa de Ã©xito** | 98% | 95% | -3% |
| **Soporte** | 24/7 | Comunidad | - |
| **ROI anual** | - | +$174,000 | **Ahorro** |

**CÃ¡lculo de ROI**:
```
Ahorro anual = ($15,000 - $500) Ã— 12 meses = $174,000
ROI = (Ahorro - Costo migraciÃ³n) / Costo migraciÃ³n
    = ($174,000 - $20,000) / $20,000 = 770%
```

#### Benchmark de Performance

| OperaciÃ³n | UiPath | ServiceNow | Camunda | OpenRPA |
|-----------|--------|------------|---------|---------|
| **Iniciar job/process** | 2-5s | 1-3s | <1s | <1s |
| **Ejecutar tarea simple** | 30-60s | 5-10s | 1-2s | 20-40s |
| **Procesar batch (100 items)** | 10-15 min | 5-8 min | 2-5 min | 8-12 min |
| **Throughput (items/hora)** | 400-600 | 750-1200 | 1200-3000 | 300-600 |

### Checklist de IntegraciÃ³n

#### Pre-integraciÃ³n

- [ ] Documentar casos de uso especÃ­ficos
- [ ] Evaluar costo-beneficio (ROI)
- [ ] Obtener aprobaciones de negocio
- [ ] Configurar cuentas de prueba
- [ ] Definir SLAs y mÃ©tricas objetivo
- [ ] Planificar migraciÃ³n gradual (si aplica)

#### Durante la IntegraciÃ³n

- [ ] Configurar autenticaciÃ³n/secretos
- [ ] Implementar idempotencia
- [ ] Configurar retry logic y timeouts
- [ ] Crear workflows/tasks de prueba
- [ ] Configurar monitoreo y alertas
- [ ] Documentar procesos y decisiones

#### Post-integraciÃ³n

- [ ] Verificar mÃ©tricas vs objetivos
- [ ] Revisar logs y errores
- [ ] Optimizar performance
- [ ] Entrenar equipo
- [ ] Documentar troubleshooting
- [ ] Planificar escalamiento

### Ejemplos de CÃ³digo Completos

#### Worker Camunda Completo para ServiceNow

```python
# workflow/camunda/worker/servicenow_complete.py
"""
Worker completo para integraciÃ³n ServiceNow + Camunda
Incluye: creaciÃ³n de tickets, polling de aprobaciÃ³n, manejo de errores
"""
import os
import time
import requests
from typing import Dict, Any
from camunda.external_task.external_task import ExternalTask, TaskResult
from camunda.external_task.external_task_worker import ExternalTaskWorker
from tenacity import retry, stop_after_attempt, wait_exponential

class ServiceNowClient:
    def __init__(self):
        self.instance = os.getenv("SERVICENOW_INSTANCE")
        self.auth = (os.getenv("SNOW_USER"), os.getenv("SNOW_PASSWORD"))
        self.timeout = 30
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    def create_ticket(self, ticket_data: Dict[str, Any]) -> Dict[str, Any]:
        """Crea ticket con retry automÃ¡tico"""
        response = requests.post(
            f"{self.instance}/api/now/table/sc_request",
            auth=self.auth,
            json=ticket_data,
            timeout=self.timeout
        )
        response.raise_for_status()
        return response.json()["result"]
    
    def get_ticket(self, sys_id: str) -> Dict[str, Any]:
        """Obtiene ticket por sys_id"""
        response = requests.get(
            f"{self.instance}/api/now/table/sc_request/{sys_id}",
            auth=self.auth,
            params={"sysparm_fields": "state,approval,work_notes,u_approval_status"},
            timeout=self.timeout
        )
        response.raise_for_status()
        return response.json()["result"]

def create_ticket_handler(task: ExternalTask) -> TaskResult:
    """Crea ticket en ServiceNow"""
    client = ServiceNowClient()
    
    amount = task.get_variable("amount", 0)
    priority = "2" if amount > 10000 else "3"
    
    ticket_data = {
        "short_description": f"Purchase approval: ${amount}",
        "description": task.get_variable("description", ""),
        "category": "Procurement",
        "priority": priority,
        "caller_id": task.get_variable("requester_email"),
        "u_amount": str(amount),
        "u_business_key": task.get_variable("business_key")
    }
    
    try:
        ticket = client.create_ticket(ticket_data)
        return task.complete({
            "ticket_sys_id": ticket["sys_id"],
            "ticket_number": ticket["number"],
            "ticket_url": f"{client.instance}/sc_request.do?sys_id={ticket['sys_id']}"
        })
    except Exception as e:
        return task.failure(
            error_message="Failed to create ServiceNow ticket",
            error_details=str(e),
            retries=task.get_retries() - 1,
            retry_timeout=300  # 5 minutos
        )

def check_approval_handler(task: ExternalTask) -> TaskResult:
    """Verifica estado de aprobaciÃ³n"""
    client = ServiceNowClient()
    ticket_sys_id = task.get_variable("ticket_sys_id")
    
    try:
        ticket = client.get_ticket(ticket_sys_id)
        state = ticket["state"]
        approval_status = ticket.get("u_approval_status", "").lower()
        
        if state == "4" and approval_status == "approved":
            return task.complete({
                "approved": True,
                "approval_date": ticket.get("sys_updated_on", "")
            })
        elif state == "5" or approval_status == "rejected":
            return task.complete({
                "approved": False,
                "rejection_reason": ticket.get("work_notes", "")
            })
        else:
            # AÃºn pendiente - BPMN error para reintentar
            return task.bpmn_error(
                error_code="APPROVAL_PENDING",
                error_message=f"Ticket still pending. State: {state}"
            )
    except Exception as e:
        return task.failure(
            error_message="Failed to check approval status",
            error_details=str(e)
        )

if __name__ == "__main__":
    worker = ExternalTaskWorker(
        worker_id="servicenow-worker",
        base_url="http://camunda:8080/engine-rest",
        max_tasks=10,
        lock_duration=60000  # 1 minuto
    )
    
    worker.subscribe("servicenow-create-ticket", create_ticket_handler)
    worker.subscribe("servicenow-check-approval", check_approval_handler)
    
    print("ServiceNow worker started...")
    worker.start()
```

### Mejores PrÃ¡cticas

1. **Idempotencia**: Siempre implementar checks antes de crear recursos externos
   - Usar `business_key` o identificadores Ãºnicos
   - Verificar existencia antes de crear
   
2. **Retry Logic**: Backoff exponencial para APIs externas
   - MÃ¡ximo 3-5 reintentos
   - Espera: 2s, 4s, 8s, 16s
   
3. **Timeouts**: Configurar apropiadamente
   - APIs sÃ­ncronas: 30-60s
   - Operaciones batch: 5-10 minutos
   
4. **Circuit Breakers**: Para APIs crÃ­ticas
   - Abrir despuÃ©s de 5 fallos consecutivos
   - Cerrar despuÃ©s de 60s de Ã©xito
   
5. **Secrets Management**: External Secrets Operator
   - Nunca hardcodear credenciales
   - RotaciÃ³n automÃ¡tica cuando sea posible
   
6. **Monitoreo y Alertas**: Prometheus/Grafana
   - MÃ©tricas de latencia, throughput, errores
   - Alertas proactivas antes de problemas

7. **Logging Estructurado**: Para debugging
   - Incluir correlation IDs
   - Log levels apropiados (DEBUG, INFO, WARN, ERROR)

8. **Testing**: Pruebas exhaustivas
   - Unit tests para workers
   - Integration tests con ambientes de prueba
   - Load tests para validar escalabilidad

### Quick Start: Integrar en 15 Minutos

#### OpciÃ³n 1: UiPath + Kestra (RPA BÃ¡sico)

```bash
# 1. Configurar credenciales UiPath
export UIPATH_ORCHESTRATOR="https://your-instance.orchestrator.uipath.com"
export UIPATH_TOKEN=$(curl -X POST "${UIPATH_ORCHESTRATOR}/api/account/authenticate" \
  -H "Content-Type: application/json" \
  -d '{"tenancyName":"default","usernameOrEmailAddress":"user","password":"pass"}' \
  | jq -r '.result')

# 2. Crear secret en Kubernetes
kubectl create secret generic uipath-credentials \
  --from-literal=orchestrator-url="${UIPATH_ORCHESTRATOR}" \
  --from-literal=token="${UIPATH_TOKEN}" \
  -n workflows

# 3. Desplegar workflow de ejemplo
kubectl apply -f workflow/kestra/flows/uipath_simple_example.yaml

# 4. Probar workflow
curl -X POST "http://kestra.example.com/api/v1/executions/trigger/uipath_simple_example" \
  -H "Content-Type: application/json" \
  -d '{"inputs":{"process_name":"hello_world"}}'
```

**Workflow mÃ­nimo** (`workflow/kestra/flows/uipath_simple_example.yaml`):

```yaml
id: uipath_simple_example
namespace: automation
inputs:
  - id: process_name
    type: STRING
    defaults: "hello_world"
tasks:
  - id: trigger_bot
    type: io.kestra.plugin.http.HttpRequest
    uri: "https://{{ secret('uipath-credentials', 'orchestrator-url') }}/api/Jobs/Start"
    method: POST
    headers:
      Authorization: "Bearer {{ secret('uipath-credentials', 'token') }}"
    body:
      ReleaseKey: "{{ vars[inputs.process_name ~ '_release_key'] }}"
```

#### OpciÃ³n 2: ServiceNow + Camunda (Aprobaciones)

```bash
# 1. Configurar ServiceNow
export SERVICENOW_INSTANCE="https://your-instance.service-now.com"
export SNOW_USER="api.user"
export SNOW_PASSWORD="api.password"

# 2. Crear secret
kubectl create secret generic servicenow-credentials \
  --from-literal=instance="${SERVICENOW_INSTANCE}" \
  --from-literal=username="${SNOW_USER}" \
  --from-literal=password="${SNOW_PASSWORD}" \
  -n workflows

# 3. Desplegar worker
kubectl apply -f workflow/camunda/worker/servicenow-worker-deployment.yaml

# 4. Iniciar proceso BPMN
curl -X POST "http://camunda.example.com/engine-rest/process-definition/key/purchase_approval/start" \
  -H "Content-Type: application/json" \
  -d '{
    "variables": {
      "amount": {"value": 5000, "type": "Double"},
      "description": {"value": "Laptop purchase", "type": "String"},
      "requester_email": {"value": "user@example.com", "type": "String"}
    }
  }'
```

### Configuraciones Completas de Ejemplo

#### ConfiguraciÃ³n Completa: UiPath Integration

```yaml
# kubernetes/integration/uipath-integration.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: uipath-config
  namespace: workflows
data:
  orchestrator-url: "https://your-instance.orchestrator.uipath.com"
  default-strategy: "ModernJobsCount"
  max-retries: "3"
  timeout-seconds: "300"
  polling-interval-seconds: "5"
---
apiVersion: v1
kind: Secret
metadata:
  name: uipath-credentials
  namespace: workflows
type: Opaque
stringData:
  token: "your-uipath-token"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: uipath-bridge
  namespace: workflows
spec:
  replicas: 2
  selector:
    matchLabels:
      app: uipath-bridge
  template:
    metadata:
      labels:
        app: uipath-bridge
    spec:
      containers:
      - name: bridge
        image: python:3.11-slim
        env:
          - name: UIPATH_ORCHESTRATOR_URL
            valueFrom:
              configMapKeyRef:
                name: uipath-config
                key: orchestrator-url
          - name: UIPATH_TOKEN
            valueFrom:
              secretKeyRef:
                name: uipath-credentials
                key: token
        command: ["python", "/app/bridge.py"]
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: uipath-bridge
  namespace: workflows
spec:
  selector:
    app: uipath-bridge
  ports:
    - port: 8080
      targetPort: 8080
```

#### ConfiguraciÃ³n Completa: ServiceNow Integration

```yaml
# kubernetes/integration/servicenow-integration.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: servicenow-config
  namespace: workflows
data:
  instance-url: "https://your-instance.service-now.com"
  api-version: "v1"
  default-table: "sc_request"
  polling-interval: "10"
  max-polling-attempts: "180"  # 30 minutos
---
apiVersion: v1
kind: Secret
metadata:
  name: servicenow-credentials
  namespace: workflows
type: Opaque
stringData:
  username: "api.user"
  password: "api.password"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: servicenow-worker
  namespace: workflows
spec:
  replicas: 3
  selector:
    matchLabels:
      app: servicenow-worker
  template:
    metadata:
      labels:
        app: servicenow-worker
    spec:
      containers:
      - name: worker
        image: camunda-worker-servicenow:latest
        env:
          - name: SERVICENOW_INSTANCE
            valueFrom:
              configMapKeyRef:
                name: servicenow-config
                key: instance-url
          - name: SNOW_USER
            valueFrom:
              secretKeyRef:
                name: servicenow-credentials
                key: username
          - name: SNOW_PASSWORD
            valueFrom:
              secretKeyRef:
                name: servicenow-credentials
                key: password
          - name: CAMUNDA_REST_URL
            value: "http://camunda:8080/engine-rest"
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
```

### Troubleshooting Avanzado

#### Problemas Comunes y Soluciones

**Problema 1: UiPath Jobs se quedan "Pending" indefinidamente**

```bash
# Diagnosticar
# 1. Verificar robots disponibles
curl -H "Authorization: Bearer $TOKEN" \
  "https://instance.orchestrator.uipath.com/api/Robots?$filter=State eq 'Available'"

# 2. Verificar queues
curl -H "Authorization: Bearer $TOKEN" \
  "https://instance.orchestrator.uipath.com/api/Queues"

# 3. Ver logs del job especÃ­fico
curl -H "Authorization: Bearer $TOKEN" \
  "https://instance.orchestrator.uipath.com/api/Jobs/{{job_id}}/OutputArguments"

# SoluciÃ³n: Asegurar robots disponibles y queues configuradas
```

**Problema 2: ServiceNow API rate limiting**

```python
# Implementar rate limiting client-side
from time import sleep
from functools import wraps

def rate_limit(max_per_minute=60):
    """Decorador para limitar llamadas API"""
    min_interval = 60.0 / max_per_minute
    last_called = [0.0]
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            left_to_wait = min_interval - elapsed
            if left_to_wait > 0:
                sleep(left_to_wait)
            ret = func(*args, **kwargs)
            last_called[0] = time.time()
            return ret
        return wrapper
    return decorator

# Uso
@rate_limit(max_per_minute=60)
def call_servicenow_api(endpoint, data):
    # Tu cÃ³digo aquÃ­
    pass
```

**Problema 3: Camunda workers no procesan tareas**

```bash
# Diagnosticar
# 1. Verificar workers conectados
curl "http://camunda:8080/engine-rest/external-task/count"

# 2. Ver tareas disponibles
curl "http://camunda:8080/engine-rest/external-task?topicName=servicenow-create-ticket&locked=false"

# 3. Ver logs del worker
kubectl logs -n workflows deployment/servicenow-worker -f

# SoluciÃ³n: Verificar conectividad, configuraciÃ³n de topic, y locks
```

**Problema 4: Tickets duplicados en ServiceNow**

```python
# Implementar lock distribuido
import redis
import hashlib
import json

redis_client = redis.Redis(host='redis', port=6379)

def create_ticket_with_lock(business_key, ticket_data, ttl=300):
    """Crea ticket con lock distribuido para evitar duplicados"""
    lock_key = f"servicenow:lock:{business_key}"
    ticket_key = f"servicenow:ticket:{business_key}"
    
    # Intentar adquirir lock
    if redis_client.set(lock_key, "1", nx=True, ex=ttl):
        try:
            # Verificar si ya existe
            existing = redis_client.get(ticket_key)
            if existing:
                return json.loads(existing)
            
            # Crear ticket
            ticket = snow_client.create("sc_request", {
                **ticket_data,
                "u_business_key": business_key
            })
            
            # Guardar en cache
            redis_client.set(
                ticket_key,
                json.dumps(ticket),
                ex=3600  # 1 hora
            )
            
            return ticket
        finally:
            # Liberar lock
            redis_client.delete(lock_key)
    else:
        # Lock adquirido por otro proceso, esperar y reintentar
        time.sleep(1)
        return create_ticket_with_lock(business_key, ticket_data, ttl)
```

### Scripts de Utilidad

#### Script: Monitorear Integraciones

```bash
#!/bin/bash
# scripts/monitor-integrations.sh

echo "=== Monitoring Integration Platforms ==="

# UiPath
echo "--- UiPath Status ---"
UIPATH_JOBS=$(curl -s -H "Authorization: Bearer ${UIPATH_TOKEN}" \
  "${UIPATH_ORCHESTRATOR}/api/Jobs?\$top=1&\$filter=State eq 'Running'" \
  | jq '.value | length')
echo "Running jobs: ${UIPATH_JOBS}"

UIPATH_ROBOTS=$(curl -s -H "Authorization: Bearer ${UIPATH_TOKEN}" \
  "${UIPATH_ORCHESTRATOR}/api/Robots?\$filter=State eq 'Available'" \
  | jq '.value | length')
echo "Available robots: ${UIPATH_ROBOTS}"

# ServiceNow
echo "--- ServiceNow Status ---"
SNOW_INCIDENTS=$(curl -s -u "${SNOW_USER}:${SNOW_PASSWORD}" \
  "${SERVICENOW_INSTANCE}/api/now/table/incident" \
  -G --data-urlencode "sysparm_query=state=1" \
  -G --data-urlencode "sysparm_fields=number" \
  | jq '.result | length')
echo "Open incidents: ${SNOW_INCIDENTS}"

# Camunda
echo "--- Camunda Status ---"
CAMUNDA_PROCESSES=$(curl -s "${CAMUNDA_URL}/engine-rest/process-instance/count" \
  | jq '.count')
echo "Active processes: ${CAMUNDA_PROCESSES}"

CAMUNDA_TASKS=$(curl -s "${CAMUNDA_URL}/engine-rest/external-task/count" \
  | jq '.count')
echo "Pending external tasks: ${CAMUNDA_TASKS}"
```

#### Script: Backup de ConfiguraciÃ³n de Integraciones

```bash
#!/bin/bash
# scripts/backup-integrations.sh

BACKUP_DIR="/backups/integrations/$(date +%Y%m%d)"
mkdir -p "${BACKUP_DIR}"

echo "Backing up integration configurations..."

# Backup secrets
kubectl get secrets -n workflows \
  -l app=uipath-bridge,app=servicenow-worker \
  -o yaml > "${BACKUP_DIR}/secrets.yaml"

# Backup configmaps
kubectl get configmaps -n workflows \
  uipath-config servicenow-config \
  -o yaml > "${BACKUP_DIR}/configmaps.yaml"

# Backup workflows Kestra
kubectl get flows -n automation -o yaml > "${BACKUP_DIR}/kestra-flows.yaml"

# Backup BPMN processes
kubectl exec -n workflows deployment/camunda -c camunda \
  -- find /camunda/webapps/camunda/WEB-INF/classes/bpmn \
  -name "*.bpmn" -exec tar czf "${BACKUP_DIR}/bpmn-processes.tar.gz" {} +

echo "Backup completed: ${BACKUP_DIR}"
```

### Roadmap de IntegraciÃ³n

#### Fase 1: POC (2-4 semanas)
- [ ] Configurar ambiente de prueba
- [ ] Implementar 1-2 casos de uso simples
- [ ] Validar integraciÃ³n bÃ¡sica
- [ ] Medir performance inicial

#### Fase 2: Piloto (1-2 meses)
- [ ] Expandir a 5-10 casos de uso
- [ ] Configurar monitoreo completo
- [ ] Implementar alertas
- [ ] Documentar procesos
- [ ] Entrenar equipo

#### Fase 3: ProducciÃ³n (3-6 meses)
- [ ] Migrar todos los casos de uso
- [ ] Optimizar performance
- [ ] Implementar auto-escalado
- [ ] Establecer SLAs
- [ ] Monitoreo avanzado

#### Fase 4: OptimizaciÃ³n (Ongoing)
- [ ] AnÃ¡lisis de costos y optimizaciÃ³n
- [ ] MigraciÃ³n gradual de comerciales a open-source
- [ ] Mejora continua basada en mÃ©tricas
- [ ] ExpansiÃ³n a nuevos casos de uso

### Recursos Adicionales

#### DocumentaciÃ³n Oficial
- **UiPath**: https://docs.uipath.com/
- **ServiceNow**: https://docs.servicenow.com/
- **Camunda**: https://docs.camunda.org/

#### Comunidades y Foros
- **UiPath Forum**: https://forum.uipath.com/
- **ServiceNow Community**: https://community.servicenow.com/
- **Camunda Forum**: https://forum.camunda.org/

#### Herramientas Ãštiles
- **UiPath API Explorer**: Swagger UI en `/swagger` de tu instancia
- **ServiceNow REST API Explorer**: `/api/now/doc`
- **Camunda Cockpit**: Dashboard web en `/camunda/app/cockpit`

### Decisiones ArquitectÃ³nicas Clave

#### Â¿CuÃ¡ndo usar cada plataforma?

**Use UiPath cuando:**
- Necesite automatizar interacciones complejas con UI legacy (Windows Forms, SAP GUI, Mainframes)
- Requiera componentes pre-construidos del marketplace
- Necesite soporte empresarial 24/7 para operaciones crÃ­ticas
- Tenga presupuesto para licencias y ROI positivo documentado

**Use ServiceNow cuando:**
- AutomatizaciÃ³n deba abarcar mÃºltiples departamentos (IT, HR, Finanzas)
- Requiera gobernanza centralizada y cumplimiento estricto
- Necesite integraciones pre-construidas con herramientas empresariales comunes
- Prefiera modelo SaaS sin gestiÃ³n de infraestructura

**Use Camunda cuando:**
- Procesos de negocio complejos requieran modelado formal (BPMN)
- Necesite alto control tÃ©cnico y personalizaciÃ³n
- Requiera anÃ¡lisis y optimizaciÃ³n de procesos
- Tenga equipos tÃ©cnicos capaces de mantener open-source

**Use herramientas integradas (Kestra/Flowable/OpenRPA) cuando:**
- Presupuesto limitado o preferencia por open-source
- Necesite control total sobre infraestructura
- Requiera integraciÃ³n nativa con Kubernetes/cloud
- Tenga capacidad tÃ©cnica interna para mantenimiento

### Seguridad en Integraciones

#### Mejores PrÃ¡cticas de Seguridad

**1. GestiÃ³n de Credenciales**

```yaml
# âœ… CORRECTO: Usar External Secrets Operator
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: uipath-credentials
  namespace: workflows
spec:
  secretStoreRef:
    name: aws-secrets-manager
    kind: SecretStore
  target:
    name: uipath-credentials
    creationPolicy: Owner
  data:
    - secretKey: token
      remoteRef:
        key: uipath/prod/token
    - secretKey: orchestrator-url
      remoteRef:
        key: uipath/prod/url

# âŒ INCORRECTO: Hardcodear en cÃ³digo
# token = "abc123..."  # NUNCA HACER ESTO
```

**2. Network Policies para Aislamiento**

```yaml
# security/networkpolicies/integration-isolation.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: integration-isolation
  namespace: workflows
spec:
  podSelector:
    matchLabels:
      app: uipath-bridge
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: kestra
      ports:
        - protocol: TCP
          port: 8080
  egress:
    - to:
        - namespaceSelector:
            matchLabels:
              name: external-services
      ports:
        - protocol: TCP
          port: 443
    - to:
        - podSelector:
            matchLabels:
              name: kube-dns
      ports:
        - protocol: UDP
          port: 53
```

**3. RotaciÃ³n de Tokens**

```python
# workflow/camunda/worker/token_rotation.py
import os
import requests
from datetime import datetime, timedelta
from functools import lru_cache

class TokenManager:
    def __init__(self):
        self.token_cache = {}
        self.token_ttl = timedelta(hours=1)
    
    @lru_cache(maxsize=1)
    def get_uipath_token(self, orchestrator_url, username, password):
        """Obtiene token UiPath con cache y rotaciÃ³n automÃ¡tica"""
        cache_key = f"{orchestrator_url}:{username}"
        
        if cache_key in self.token_cache:
            token_data = self.token_cache[cache_key]
            if datetime.now() < token_data['expires_at']:
                return token_data['token']
        
        # Renovar token
        response = requests.post(
            f"{orchestrator_url}/api/account/authenticate",
            json={
                "tenancyName": "default",
                "usernameOrEmailAddress": username,
                "password": password
            },
            timeout=10
        )
        response.raise_for_status()
        
        token = response.json()['result']
        expires_at = datetime.now() + self.token_ttl
        
        self.token_cache[cache_key] = {
            'token': token,
            'expires_at': expires_at
        }
        
        return token
```

**4. AuditorÃ­a y Logging de Seguridad**

```python
# security/audit/integration_audit.py
import logging
import json
from datetime import datetime

class SecurityAuditLogger:
    def __init__(self):
        self.logger = logging.getLogger('security_audit')
        handler = logging.FileHandler('/var/log/security-audit.log')
        handler.setFormatter(logging.Formatter(
            '%(asctime)s | %(levelname)s | %(message)s'
        ))
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)
    
    def log_api_call(self, platform, operation, user, success, details=None):
        """Log todas las llamadas API para auditorÃ­a"""
        event = {
            'timestamp': datetime.utcnow().isoformat(),
            'platform': platform,
            'operation': operation,
            'user': user,
            'success': success,
            'details': details or {}
        }
        self.logger.info(json.dumps(event))
    
    def log_token_usage(self, platform, user, token_type):
        """Log uso de tokens"""
        event = {
            'timestamp': datetime.utcnow().isoformat(),
            'event_type': 'token_usage',
            'platform': platform,
            'user': user,
            'token_type': token_type
        }
        self.logger.info(json.dumps(event))

# Uso
audit = SecurityAuditLogger()
audit.log_api_call(
    platform='uipath',
    operation='start_job',
    user='system@example.com',
    success=True,
    details={'job_id': '12345', 'process': 'invoice_processing'}
)
```

### Escalamiento y Performance

#### OptimizaciÃ³n de Throughput

**1. Pooling de Conexiones**

```python
# workflow/camunda/worker/connection_pool.py
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import requests

class PooledAPIClient:
    def __init__(self, base_url, max_connections=100):
        self.session = requests.Session()
        
        # Pool de conexiones
        adapter = HTTPAdapter(
            pool_connections=max_connections,
            pool_maxsize=max_connections,
            max_retries=Retry(
                total=3,
                backoff_factor=0.3,
                status_forcelist=[500, 502, 503, 504]
            )
        )
        
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
        self.base_url = base_url
    
    def post(self, endpoint, **kwargs):
        return self.session.post(f"{self.base_url}{endpoint}", **kwargs)
    
    def get(self, endpoint, **kwargs):
        return self.session.get(f"{self.base_url}{endpoint}", **kwargs)

# Uso compartido
servicenow_client = PooledAPIClient(
    base_url=os.getenv("SERVICENOW_INSTANCE"),
    max_connections=50
)
```

**2. Batch Processing**

```python
# workflow/camunda/worker/batch_processor.py
from typing import List, Dict
import asyncio

async def process_batch_async(items: List[Dict], batch_size: int = 10):
    """Procesa items en batches paralelos"""
    results = []
    
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        batch_results = await asyncio.gather(
            *[process_item_async(item) for item in batch],
            return_exceptions=True
        )
        results.extend(batch_results)
    
    return results

async def process_item_async(item: Dict):
    """Procesa un item individual"""
    # Tu lÃ³gica aquÃ­
    pass

# Uso
items = [{"id": i, "data": f"item_{i}"} for i in range(100)]
results = asyncio.run(process_batch_async(items, batch_size=10))
```

**3. Caching Inteligente**

```python
# workflow/camunda/worker/smart_cache.py
from functools import lru_cache
import redis
import hashlib
import json
from typing import Callable, Any

redis_client = redis.Redis(host='redis', port=6379, decode_responses=True)

def cached_api_call(cache_ttl: int = 300):
    """Decorador para cachear llamadas API"""
    def decorator(func: Callable) -> Callable:
        def wrapper(*args, **kwargs) -> Any:
            # Generar clave de cache
            cache_key = hashlib.md5(
                f"{func.__name__}:{str(args)}:{str(kwargs)}".encode()
            ).hexdigest()
            
            # Intentar obtener de cache
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # Ejecutar funciÃ³n
            result = func(*args, **kwargs)
            
            # Guardar en cache
            redis_client.setex(
                cache_key,
                cache_ttl,
                json.dumps(result)
            )
            
            return result
        return wrapper
    return decorator

# Uso
@cached_api_call(cache_ttl=600)
def get_servicenow_user(user_id: str) -> Dict:
    """Obtiene usuario de ServiceNow con cache de 10 minutos"""
    response = servicenow_client.get(f"/api/now/table/sys_user/{user_id}")
    return response.json()['result']
```

#### Auto-escalado de Workers

```yaml
# kubernetes/integration/servicenow-worker-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: servicenow-worker-hpa
  namespace: workflows
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: servicenow-worker
  minReplicas: 2
  maxReplicas: 20
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
    - type: Pods
      pods:
        metric:
          name: external_tasks_pending
        target:
          type: AverageValue
          averageValue: "10"  # Escalar si hay mÃ¡s de 10 tareas pendientes
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Pods
          value: 2
          periodSeconds: 60
        - type: Percent
          value: 100
          periodSeconds: 60
```

### Testing de Integraciones

#### Unit Tests

```python
# tests/integrations/test_servicenow_integration.py
import pytest
from unittest.mock import Mock, patch
from workflow.camunda.worker.servicenow_integration import create_snow_ticket

@pytest.fixture
def mock_task():
    task = Mock()
    task.get_variable.side_effect = lambda key, default=None: {
        'amount': 5000,
        'description': 'Test purchase',
        'requester_email': 'test@example.com',
        'business_key': 'test-key-123'
    }.get(key, default)
    return task

@patch('workflow.camunda.worker.servicenow_integration.requests')
def test_create_ticket_success(mock_requests, mock_task):
    """Test creaciÃ³n exitosa de ticket"""
    mock_response = Mock()
    mock_response.json.return_value = {
        'result': {
            'sys_id': 'abc123',
            'number': 'REQ001'
        }
    }
    mock_requests.post.return_value = mock_response
    
    result = create_snow_ticket(mock_task)
    
    assert result.is_success()
    assert result.variables['ticket_sys_id'] == 'abc123'
    mock_requests.post.assert_called_once()

@patch('workflow.camunda.worker.servicenow_integration.requests')
def test_create_ticket_failure(mock_requests, mock_task):
    """Test manejo de errores"""
    mock_requests.post.side_effect = Exception("API Error")
    
    result = create_snow_ticket(mock_task)
    
    assert result.is_failure()
    assert "API Error" in result.error_details
```

#### Integration Tests

```python
# tests/integrations/test_uipath_integration.py
import pytest
import requests
from workflow.kestra.flows.uipath_integration import trigger_uipath_bot

@pytest.mark.integration
@pytest.mark.skipif(
    not os.getenv("UIPATH_ORCHESTRATOR"),
    reason="UiPath orchestrator not configured"
)
def test_uipath_job_creation():
    """Test real de creaciÃ³n de job en UiPath"""
    result = trigger_uipath_bot(
        release_key="test-release-key",
        input_arguments={"test": "data"}
    )
    
    assert result['State'] == 'Pending' or result['State'] == 'Running'
    assert 'Id' in result
```

### Checklist de Go-Live

#### Pre-ProducciÃ³n

- [ ] Todas las integraciones probadas en staging
- [ ] Monitoreo y alertas configurados
- [ ] DocumentaciÃ³n completa actualizada
- [ ] Equipo entrenado en operaciÃ³n
- [ ] Plan de rollback documentado
- [ ] Backup de configuraciones realizado
- [ ] Secrets rotados y seguros
- [ ] Network policies aplicadas
- [ ] Resource limits configurados
- [ ] Health checks funcionando

#### Go-Live

- [ ] Desplegar a producciÃ³n durante ventana de mantenimiento
- [ ] Verificar health checks de todos los componentes
- [ ] Monitorear mÃ©tricas por 1 hora
- [ ] Ejecutar casos de uso de prueba
- [ ] Verificar logs sin errores crÃ­ticos
- [ ] Confirmar SLAs cumplidos

#### Post-Go-Live

- [ ] Revisar mÃ©tricas de las primeras 24 horas
- [ ] Optimizar basado en mÃ©tricas reales
- [ ] Documentar lecciones aprendidas
- [ ] Planificar prÃ³ximos pasos de optimizaciÃ³n

### ğŸ“š Recursos de Aprendizaje y Referencias

#### DocumentaciÃ³n por Plataforma

**Plataformas Open-Source Integradas:**
- **Kestra**: [DocumentaciÃ³n oficial](https://kestra.io/docs) | [Ejemplos](workflow/kestra/flows/)
- **Flowable**: [GuÃ­a BPMN](https://www.flowable.com/open-source/docs/bpmn/) | [Casos de uso](workflow/flowable/)
- **Camunda**: [DocumentaciÃ³n](https://docs.camunda.org/) | [BPMN Tutorial](https://camunda.com/bpmn/)
- **OpenRPA**: [DocumentaciÃ³n](rpa/OPENRPA.md) | [GuÃ­a de inicio](rpa/README.md)
- **Airflow**: [DocumentaciÃ³n](data/airflow/README.md) | [ETL avanzado](data/airflow/dags/INDEX_ETL_IMPROVED.md)
- **MLflow**: [Tracking ML](ml/mlflow/) | [Kubeflow](ml/kubeflow/README.md)

**Plataformas Comerciales (IntegraciÃ³n Opcional):**
- **UiPath**: [API Documentation](https://docs.uipath.com/orchestrator/reference) | [Forum](https://forum.uipath.com/)
- **ServiceNow**: [REST API](https://docs.servicenow.com/bundle/tokyo-application-development/page/integrate/inbound-rest/concept/c_RESTAPI.html) | [Community](https://community.servicenow.com/)

#### Cursos y Tutoriales Recomendados

**Para Desarrolladores:**
1. **Kubernetes Basics**: [Kubernetes.io Tutorials](https://kubernetes.io/docs/tutorials/)
2. **Airflow**: [Apache Airflow Documentation](https://airflow.apache.org/docs/)
3. **BPMN**: [BPMN 2.0 Specification](https://www.omg.org/spec/BPMN/2.0/)
4. **MLOps**: [MLflow Tutorials](https://mlflow.org/docs/latest/tutorials-and-examples/)

**Para Arquitectos:**
1. **Event-Driven Architecture**: Patrones con Kafka
2. **Microservices on Kubernetes**: Service mesh y patterns
3. **Observability**: MÃ©tricas, logs y traces

#### Comunidades y Soporte

- **GitHub Issues**: Reportar bugs o solicitar features
- **Slack/Discord**: Comunidad de la plataforma (si existe)
- **Stack Overflow**: Tag `[nombre-plataforma]` para preguntas tÃ©cnicas

### ğŸ“ GuÃ­as de Aprendizaje Progresivo

#### Nivel 1: Principiante (Primeras 2 semanas)

**Semana 1: Fundamentos**
- [ ] Configurar ambiente local
- [ ] Desplegar primer workflow en Kestra
- [ ] Crear DAG bÃ¡sico en Airflow
- [ ] Explorar dashboards (Grafana, Kestra UI)

**Semana 2: Integraciones BÃ¡sicas**
- [ ] Conectar workflow a base de datos PostgreSQL
- [ ] Crear webhook en Kestra
- [ ] Configurar alertas bÃ¡sicas en Prometheus
- [ ] Revisar logs en Grafana Loki

#### Nivel 2: Intermedio (Semanas 3-6)

**Semana 3-4: Workflows Avanzados**
- [ ] Crear proceso BPMN en Flowable/Camunda
- [ ] Implementar workers personalizados
- [ ] Configurar error handling y retry logic
- [ ] Optimizar performance de workflows

**Semana 5-6: Observabilidad y Seguridad**
- [ ] Configurar mÃ©tricas personalizadas
- [ ] Crear dashboards en Grafana
- [ ] Implementar Network Policies
- [ ] Configurar External Secrets Operator

#### Nivel 3: Avanzado (Mes 2+)

- [ ] DiseÃ±ar arquitectura de integraciones complejas
- [ ] Implementar auto-escalado avanzado
- [ ] Optimizar costos y performance
- [ ] Migrar de plataformas comerciales a open-source
- [ ] Contribuir a la documentaciÃ³n/proyecto

### ğŸ› ï¸ Plantillas y Configuraciones Listas para Usar

#### Plantilla: Workflow Kestra con Error Handling

```yaml
# workflow/kestra/flows/template_with_error_handling.yaml
id: template_with_error_handling
namespace: automation
description: Template con manejo robusto de errores
inputs:
  - id: input_data
    type: STRING
    required: true
tasks:
  - id: validate_input
    type: io.kestra.core.tasks.log.Log
    message: "Validating input: {{ inputs.input_data }}"
  
  - id: main_task
    type: io.kestra.plugin.http.HttpRequest
    uri: "https://api.example.com/process"
    method: POST
    body:
      data: "{{ inputs.input_data }}"
    retry:
      type: constant
      interval: PT5S
      maxAttempt: 3
    timeout: PT30S
  
  - id: handle_success
    type: io.kestra.core.tasks.log.Log
    message: "Task completed successfully"
    conditions:
      - type: execution.flow
        expression: "{{ outputs.main_task.status == 'SUCCESS' }}"
  
  - id: handle_failure
    type: io.kestra.plugin.notifications.slack.SlackExecution
    url: "{{ secret('slack-webhook-url') }}"
    message: "Task failed: {{ outputs.main_task.body }}"
    conditions:
      - type: execution.flow
        expression: "{{ outputs.main_task.status == 'FAILED' }}"
```

#### Plantilla: DAG Airflow con Circuit Breaker

```python
# data/airflow/dags/template_circuit_breaker.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
from data.airflow.plugins.etl_circuit_breaker import circuit_breaker

default_args = {
    'owner': 'platform-team',
    'depends_on_past': False,
    'start_date': days_ago(1),
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'template_circuit_breaker',
    default_args=default_args,
    description='Template con circuit breaker',
    schedule_interval='@daily',
    catchup=False,
    tags=['template', 'circuit-breaker']
)

@circuit_breaker(
    failure_threshold=5,
    reset_timeout=timedelta(minutes=10),
    dag_id='template_circuit_breaker'
)
def process_data(**context):
    """FunciÃ³n que usa circuit breaker automÃ¡tico"""
    # Tu lÃ³gica aquÃ­
    pass

task = PythonOperator(
    task_id='process_data',
    python_callable=process_data,
    dag=dag
)
```

#### Plantilla: Worker Camunda Completo

```python
# workflow/camunda/worker/template_worker.py
"""
Plantilla completa para worker de Camunda
Incluye: logging, error handling, mÃ©tricas, retry
"""
import logging
import time
from camunda.external_task.external_task import ExternalTask, TaskResult
from camunda.external_task.external_task_worker import ExternalTaskWorker
from prometheus_client import Counter, Histogram

# MÃ©tricas Prometheus
task_counter = Counter('camunda_worker_tasks_total', 'Total tasks processed', ['topic', 'status'])
task_duration = Histogram('camunda_worker_duration_seconds', 'Task duration', ['topic'])

logger = logging.getLogger(__name__)

def template_handler(task: ExternalTask) -> TaskResult:
    """Handler de tarea con mÃ©tricas y logging"""
    topic = task.get_topic_name()
    start_time = time.time()
    
    logger.info(f"Processing task {task.get_task_id()} for topic {topic}")
    
    try:
        # Obtener variables
        input_data = task.get_variable("input_data")
        business_key = task.get_variable("business_key")
        
        # Procesar
        result = process_business_logic(input_data, business_key)
        
        # Registrar mÃ©tricas de Ã©xito
        task_counter.labels(topic=topic, status='success').inc()
        task_duration.labels(topic=topic).observe(time.time() - start_time)
        
        logger.info(f"Task {task.get_task_id()} completed successfully")
        
        return task.complete({
            "output": result,
            "status": "success"
        })
        
    except Exception as e:
        # Registrar mÃ©tricas de error
        task_counter.labels(topic=topic, status='error').inc()
        task_duration.labels(topic=topic).observe(time.time() - start_time)
        
        logger.error(f"Task {task.get_task_id()} failed: {str(e)}", exc_info=True)
        
        return task.failure(
            error_message="Processing failed",
            error_details=str(e),
            retries=task.get_retries() - 1 if task.get_retries() > 0 else 0,
            retry_timeout=300
        )

def process_business_logic(input_data, business_key):
    """LÃ³gica de negocio - reemplazar con tu implementaciÃ³n"""
    # Tu cÃ³digo aquÃ­
    return {"processed": True, "key": business_key}

if __name__ == "__main__":
    worker = ExternalTaskWorker(
        worker_id="template-worker",
        base_url="http://camunda:8080/engine-rest",
        max_tasks=10
    )
    
    worker.subscribe("template-topic", template_handler)
    worker.start()
```

### ğŸ“‹ Checklist de MigraciÃ³n de Comercial a Open-Source

#### EvaluaciÃ³n Pre-MigraciÃ³n

**AnÃ¡lisis de Casos de Uso:**
- [ ] Inventario completo de procesos automatizados
- [ ] ClasificaciÃ³n por complejidad (simple/complejo/crÃ­tico)
- [ ] IdentificaciÃ³n de dependencias entre procesos
- [ ] DocumentaciÃ³n de requisitos de negocio

**AnÃ¡lisis TÃ©cnico:**
- [ ] Mapeo de funcionalidades usadas vs disponibles en open-source
- [ ] EvaluaciÃ³n de gaps tÃ©cnicos
- [ ] EstimaciÃ³n de esfuerzo de migraciÃ³n
- [ ] IdentificaciÃ³n de procesos no migrables (requieren comercial)

**AnÃ¡lisis de Costos:**
- [ ] Costo actual anual de plataforma comercial
- [ ] Costo estimado de infraestructura para open-source
- [ ] Costo de migraciÃ³n (tiempo + recursos)
- [ ] CÃ¡lculo de ROI y payback period

#### Plan de MigraciÃ³n

**Fase 1: POC (4-8 semanas)**
- [ ] Seleccionar 2-3 procesos simples para migrar
- [ ] Configurar ambiente de prueba
- [ ] Implementar procesos seleccionados
- [ ] Validar funcionalidad y performance
- [ ] Comparar resultados vs comercial
- [ ] Documentar lecciones aprendidas

**Fase 2: Piloto (3-6 meses)**
- [ ] Migrar 20-30% de procesos (no crÃ­ticos)
- [ ] Configurar monitoreo y alertas
- [ ] Entrenar equipo de operaciÃ³n
- [ ] Establecer SLAs y mÃ©tricas de Ã©xito
- [ ] Optimizar basado en feedback

**Fase 3: Escalamiento (6-12 meses)**
- [ ] Migrar procesos crÃ­ticos con supervisiÃ³n estrecha
- [ ] Implementar redundancia y alta disponibilidad
- [ ] Optimizar costos y performance
- [ ] Documentar mejores prÃ¡cticas

**Fase 4: ConsolidaciÃ³n (Ongoing)**
- [ ] Retirar plataforma comercial (si aplica)
- [ ] Continuar optimizaciÃ³n
- [ ] Expandir a nuevos casos de uso
- [ ] Contribuir a comunidades open-source

### ğŸ’° AnÃ¡lisis de Costos Detallado

#### ComparaciÃ³n Anual de Costos (100 usuarios, 1000 procesos/mes)

| Concepto | UiPath | ServiceNow | Open-Source Stack |
|----------|--------|------------|-------------------|
| **Licencias** | $180,000 | $120,000 | $0 |
| **Infraestructura Cloud** | $36,000 | $0 (SaaS) | $24,000 |
| **Soporte/Mantenimiento** | Incluido | Incluido | $12,000 (opcional) |
| **Costo de MigraciÃ³n** | $0 | $0 | $40,000 (one-time) |
| **TOTAL AÃ±o 1** | $216,000 | $120,000 | $76,000 |
| **TOTAL AÃ±o 2+** | $216,000 | $120,000 | $36,000 |

**Ahorro potencial:**
- AÃ±o 1: $44,000 - $140,000 (considerando migraciÃ³n)
- AÃ±o 2+: $84,000 - $180,000 anual
- ROI en 6-12 meses tÃ­picamente

#### Costos de Infraestructura Estimados

**Cluster Kubernetes (EKS/AKS):**
- 3 nodos m5.xlarge: $300/mes
- Data Lake (S3/ADLS): $200/mes (varÃ­a por uso)
- Bases de datos: $150/mes
- Load balancers: $50/mes
- **Total infraestructura base**: ~$700/mes

**Componentes de plataforma:**
- Airflow workers: $200/mes
- Kestra/Camunda: $100/mes
- Observabilidad stack: $150/mes
- **Total componentes**: ~$450/mes

**TOTAL**: ~$1,150/mes = ~$14,000/aÃ±o (puede escalar segÃºn uso)

### ğŸ”§ Comandos Ãštiles para OperaciÃ³n Diaria

#### Health Checks RÃ¡pidos

```bash
# Ver estado general del cluster
kubectl get pods -A | grep -E "(Running|Pending|Error|CrashLoop)"

# Verificar componentes principales
kubectl get pods -n data -l app=airflow
kubectl get pods -n workflows -l app=kestra
kubectl get pods -n workflows -l app=camunda

# Verificar recursos
kubectl top nodes
kubectl top pods -A --sort-by=memory

# Verificar servicios externos
kubectl get ingress -A
kubectl get services -A | grep LoadBalancer
```

#### Debugging de Workflows

```bash
# Kestra - Ver logs de ejecuciÃ³n
kubectl logs -n workflows deployment/kestra -f | grep "execution_id"

# Airflow - Ver logs de DAG
kubectl exec -n data deployment/airflow-webserver -- \
  airflow tasks logs <dag_id> <task_id> <execution_date>

# Camunda - Ver procesos activos
curl http://camunda.example.com/engine-rest/process-instance?active=true | jq

# Ver tareas pendientes en Camunda
curl http://camunda.example.com/engine-rest/external-task/count | jq
```

#### Monitoreo RÃ¡pido

```bash
# Ver mÃ©tricas de Prometheus
kubectl port-forward -n observability service/prometheus 9090:9090
# Acceder a: http://localhost:9090

# Ver dashboards de Grafana
kubectl port-forward -n observability service/grafana 3000:80
# Acceder a: http://localhost:3000

# Ver logs centralizados
kubectl logs -n observability deployment/loki -f
```

#### GestiÃ³n de Secretos

```bash
# Ver secrets sincronizados
kubectl get externalsecrets -A

# Forzar resincronizaciÃ³n
kubectl delete externalsecret <name> -n <namespace>

# Ver secretos (valores encriptados)
kubectl get secrets -n <namespace> -o yaml
```

### ğŸ“œ Scripts de AutomatizaciÃ³n

#### Script: Health Check Completo

```bash
#!/bin/bash
# scripts/health-check.sh

echo "=== Platform Health Check ==="
echo "Timestamp: $(date)"

# Verificar pods
echo -e "\n--- Pod Status ---"
kubectl get pods -A -o wide | grep -v Running | head -20

# Verificar servicios crÃ­ticos
echo -e "\n--- Critical Services ---"
services=("airflow-webserver" "kestra" "camunda" "prometheus" "grafana")
for service in "${services[@]}"; do
    status=$(kubectl get pods -A -l app="$service" -o jsonpath='{.items[0].status.phase}' 2>/dev/null)
    echo "$service: $status"
done

# Verificar recursos
echo -e "\n--- Resource Usage ---"
kubectl top nodes --no-headers | awk '{print $1": CPU="$2", Memory="$4}'

# Verificar errores recientes
echo -e "\n--- Recent Errors (last 100 lines) ---"
kubectl logs -n data deployment/airflow-scheduler --tail=100 | grep -i error | tail -5
kubectl logs -n workflows deployment/kestra --tail=100 | grep -i error | tail -5

# Verificar mÃ©tricas crÃ­ticas
echo -e "\n--- Critical Metrics ---"
kubectl exec -n observability deployment/prometheus -- \
  wget -qO- http://localhost:9090/api/v1/query?query=up | jq '.data.result[] | select(.value[1]=="0")'
```

#### Script: Backup AutomÃ¡tico

```bash
#!/bin/bash
# scripts/auto-backup.sh
# Ejecutar via Cron: 0 2 * * * /path/to/auto-backup.sh

BACKUP_ROOT="/backups/$(date +%Y%m%d)"
mkdir -p "$BACKUP_ROOT"

echo "Starting backup at $(date)"

# Backup de configuraciones Kubernetes
kubectl get all,configmap,secret -A -o yaml > "$BACKUP_ROOT/k8s-resources.yaml"

# Backup de variables Airflow
kubectl exec -n data deployment/airflow-webserver -- \
  airflow variables export - > "$BACKUP_ROOT/airflow-vars.json" 2>/dev/null

# Backup de conexiones Airflow
kubectl exec -n data deployment/airflow-webserver -- \
  airflow connections export - > "$BACKUP_ROOT/airflow-conns.json" 2>/dev/null

# Backup de base de datos (si estÃ¡ en PostgreSQL)
if kubectl get secret -n data postgres-credentials &>/dev/null; then
    PGPASSWORD=$(kubectl get secret -n data postgres-credentials -o jsonpath='{.data.password}' | base64 -d)
    kubectl exec -n data deployment/postgres -- \
      pg_dump -U postgres analytics > "$BACKUP_ROOT/database.sql"
fi

# Comprimir y limpiar backups antiguos (>30 dÃ­as)
tar czf "$BACKUP_ROOT.tar.gz" "$BACKUP_ROOT"
rm -rf "$BACKUP_ROOT"
find /backups -name "*.tar.gz" -mtime +30 -delete

echo "Backup completed at $(date)"
```

#### Script: Escalar Workers DinÃ¡micamente

```bash
#!/bin/bash
# scripts/scale-workers.sh

NAMESPACE="${1:-data}"
DEPLOYMENT="${2:-airflow-worker}"
TARGET_PODS="${3:-5}"

echo "Scaling $DEPLOYMENT in namespace $NAMESPACE to $TARGET_PODS replicas"

# Obtener pods actuales
CURRENT_PODS=$(kubectl get deployment -n "$NAMESPACE" "$DEPLOYMENT" -o jsonpath='{.spec.replicas}')

if [ "$CURRENT_PODS" != "$TARGET_PODS" ]; then
    kubectl scale deployment -n "$NAMESPACE" "$DEPLOYMENT" --replicas="$TARGET_PODS"
    
    # Esperar a que todos los pods estÃ©n listos
    kubectl wait --for=condition=ready pod \
      -l app="$DEPLOYMENT" -n "$NAMESPACE" \
      --timeout=300s
    
    echo "Scaled from $CURRENT_PODS to $TARGET_PODS pods"
else
    echo "Already at target: $TARGET_PODS pods"
fi
```

#### Script: Limpieza de Recursos

```bash
#!/bin/bash
# scripts/cleanup.sh

echo "Cleaning up old resources..."

# Limpiar pods completados
kubectl delete pods --all-namespaces --field-selector=status.phase=Succeeded

# Limpiar jobs completados (mÃ¡s de 1 dÃ­a)
kubectl delete jobs --all-namespaces --field-selector=status.successful=1

# Limpiar logs antiguos de Airflow (variables)
kubectl exec -n data deployment/airflow-webserver -- \
  airflow db clean --clean-before-timestamp "$(date -d '7 days ago' -u +%Y-%m-%dT%H:%M:%S)" \
  --tables log \
  --skip-archive \
  --yes

# Limpiar imÃ¡genes no usadas en nodes
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}' | \
  while read node; do
    kubectl debug node/"$node" -it --image=busybox -- \
      sh -c "crictl rmi --prune"
  done

echo "Cleanup completed"
```

### ğŸš¨ Troubleshooting por SÃ­ntoma

#### SÃ­ntoma: Workflows no se ejecutan

**Posibles causas y soluciones:**

1. **Scheduler no estÃ¡ corriendo**
```bash
kubectl get pods -n workflows -l app=kestra-scheduler
kubectl logs -n workflows deployment/kestra-scheduler
```

2. **Falta configuraciÃ³n de triggers**
```bash
# Verificar triggers configurados
kubectl exec -n workflows deployment/kestra -- \
  kestra triggers list
```

3. **Variables no configuradas**
```bash
# Verificar variables requeridas
kubectl exec -n workflows deployment/kestra -- \
  kestra variables list
```

#### SÃ­ntoma: DAGs de Airflow fallan constantemente

**DiagnÃ³stico:**

```bash
# Ver errores de importaciÃ³n
kubectl exec -n data deployment/airflow-webserver -- \
  airflow dags list-import-errors

# Ver logs de scheduler
kubectl logs -n data deployment/airflow-scheduler --tail=100

# Verificar conexiones de base de datos
kubectl exec -n data deployment/airflow-webserver -- \
  airflow connections list

# Verificar variables requeridas
kubectl exec -n data deployment/airflow-webserver -- \
  airflow variables list | grep -i required
```

#### SÃ­ntoma: Alto uso de CPU/Memoria

**DiagnÃ³stico y soluciÃ³n:**

```bash
# Identificar pods consumidores
kubectl top pods -A --sort-by=cpu | head -10
kubectl top pods -A --sort-by=memory | head -10

# Verificar HPA
kubectl get hpa -A

# Escalar manualmente si es necesario
kubectl scale deployment -n <namespace> <deployment> --replicas=<number>

# Verificar lÃ­mites de recursos
kubectl describe pod <pod-name> -n <namespace> | grep -A 5 "Limits"
```

### ğŸ“‹ Quick Reference Cards

#### Comandos Kubernetes Esenciales

```bash
# Namespaces
kubectl get namespaces
kubectl create namespace <name>
kubectl delete namespace <name>

# Pods
kubectl get pods -A
kubectl describe pod <pod-name> -n <namespace>
kubectl logs <pod-name> -n <namespace> -f
kubectl exec -it <pod-name> -n <namespace> -- /bin/sh

# Deployments
kubectl get deployments -A
kubectl scale deployment <name> -n <namespace> --replicas=<n>
kubectl rollout restart deployment <name> -n <namespace>

# Services
kubectl get services -A
kubectl get ingress -A

# ConfigMaps y Secrets
kubectl get configmaps -A
kubectl get secrets -A
kubectl edit configmap <name> -n <namespace>
```

#### Comandos Airflow

```bash
# Listar DAGs
kubectl exec -n data deployment/airflow-webserver -- airflow dags list

# Pausar/Despausar DAG
kubectl exec -n data deployment/airflow-webserver -- \
  airflow dags pause <dag_id>
kubectl exec -n data deployment/airflow-webserver -- \
  airflow dags unpause <dag_id>

# Trigger DAG manualmente
kubectl exec -n data deployment/airflow-webserver -- \
  airflow dags trigger <dag_id>

# Ver logs de tarea
kubectl exec -n data deployment/airflow-webserver -- \
  airflow tasks logs <dag_id> <task_id> <execution_date>

# Listar variables
kubectl exec -n data deployment/airflow-webserver -- \
  airflow variables list
```

#### Comandos Kestra

```bash
# Listar flows
curl http://kestra.example.com/api/v1/flows

# Ejecutar flow manualmente
curl -X POST http://kestra.example.com/api/v1/executions/trigger/<namespace>/<flow-id> \
  -H "Content-Type: application/json" \
  -d '{"inputs": {"key": "value"}}'

# Ver ejecuciones
curl http://kestra.example.com/api/v1/executions?namespace=<namespace>

# Ver logs de ejecuciÃ³n
curl http://kestra.example.com/api/v1/executions/<execution-id>/logs
```

#### Comandos Camunda

```bash
# Listar procesos
curl http://camunda.example.com/engine-rest/process-definition

# Iniciar proceso
curl -X POST http://camunda.example.com/engine-rest/process-definition/key/<process-key>/start \
  -H "Content-Type: application/json" \
  -d '{"variables": {"key": {"value": "value", "type": "String"}}}'

# Ver instancias activas
curl http://camunda.example.com/engine-rest/process-instance?active=true

# Ver tareas externas
curl http://camunda.example.com/engine-rest/external-task
```

### ğŸ”— Enlaces RÃ¡pidos de DocumentaciÃ³n

| Recurso | URL/Comando |
|---------|-------------|
| **Grafana** | `kubectl port-forward -n observability service/grafana 3000:80` |
| **Prometheus** | `kubectl port-forward -n observability service/prometheus 9090:9090` |
| **Kestra UI** | `kubectl port-forward -n workflows service/kestra 8080:8080` |
| **Airflow UI** | `kubectl port-forward -n data service/airflow-webserver 8080:8080` |
| **Camunda Cockpit** | `http://camunda.example.com/camunda/app/cockpit` |
| **DocumentaciÃ³n ETL** | `data/airflow/dags/INDEX_ETL_IMPROVED.md` |
| **Sistema de KPIs** | `docs/KPI_SYSTEM.md` |
| **GuÃ­a de Workflows** | `workflow/README.md` |

## ğŸ“– Casos de Uso

### Workflow: ManyChat â†’ HubSpot + DB + Scoring

**Archivo**: `workflow/kestra/flows/leads_manychats_to_hubspot.yaml`

**Pasos**:
1. Exponga Kestra por Ingress y obtenga URL base
2. Cargue el flow en Kestra y copie la URL del webhook generado
3. Configure el Webhook en ManyChat apuntando a esa URL
4. Defina variables: `hubspot_token`, `jdbc_url`, `jdbc_user`, `jdbc_password`
5. Ejecute `data/db/schema.sql` en su base de datos

**Flujo**: Recibe payload de ManyChat â†’ calcula score â†’ upsert a HubSpot â†’ upsert a BD â†’ actualiza lifecycle

### AutomatizaciÃ³n: HubSpot â†’ ManyChat (EnvÃ­o de Mensajes)

**Archivo**: `workflow/kestra/flows/hubspot_lead_to_manychat.yaml`

**Pasos**:
1. Configurar External Secrets para ManyChat API key:
   ```bash
   kubectl apply -f security/secrets/externalsecrets-manychat.yaml
   ```
2. Aplicar Ingress para Kestra webhooks (ver `kubernetes/ingress/kestra-ingress.yaml`)
3. Cargar flow en Kestra:
   ```bash
   # Desde UI de Kestra: Flows â†’ Create â†’ Paste contenido de hubspot_lead_to_manychat.yaml
   # O vÃ­a API
   curl -X POST http://kestra.example.com/api/v1/flows \
     -H "Content-Type: application/json" \
     -u admin:admin \
     -d @workflow/kestra/flows/hubspot_lead_to_manychat.yaml
   ```
4. Configurar variables en Kestra (o usar External Secrets):
   - `manychat_api_key`: Desde secret `manychat-api-key`
   - `hubspot_token`: Desde secret `hubspot-token` (ya configurado)
   - `hubspot_webhook_secret`: (Opcional) Para verificaciÃ³n de webhooks
5. Configurar webhook en HubSpot:
   - URL: `https://kestra.example.com/api/v1/executions/webhook/workflows/hubspot_lead_to_manychat/hubspot-lead`
   - Eventos: `contact.creation` y `contact.propertyChange` (filtrado por propiedad `interÃ©s_producto`)
6. Asegurar que los contactos tengan propiedades:
   - `interÃ©s_producto`: Valor del producto de interÃ©s
   - `manychat_user_id`: ID del usuario en ManyChat

**Flujo**: HubSpot crea/actualiza lead con `interÃ©s_producto` con valor â†’ Webhook dispara flow â†’ Valida datos â†’ EnvÃ­a mensaje a ManyChat: "Hola {nombre}, gracias por tu interÃ©s en {producto}. Â¿Te gustarÃ­a agendar una demo?" â†’ Retorna estado (sent/error/skipped)

**DocumentaciÃ³n completa**: Ver `workflow/kestra/flows/README.md`

### AutomatizaciÃ³n: Stripe â†’ Google Sheets + DB + AI

**Archivo**: `workflow/kestra/flows/stripe_payments_to_sheets_db_ai.yaml`

**Pasos**:
1. Cree la tabla `payments` ejecutando `data/db/payments.sql`
2. Importe el flow en Kestra y exponga el webhook `stripe_webhook`
3. Configure un endpoint de webhook en Stripe (evento: `payment_intent.succeeded`)
4. Provea variables: `jdbc_url`, `jdbc_user`, `jdbc_password`, `sheets_webhook_url`, `openai_api_key`

**Funcionalidad**:
- Registra el pago en la tabla `payments`
- EnvÃ­a datos a Google Sheets mediante webhook
- Llama a OpenAI para interpretaciÃ³n y pronÃ³stico usando Ãºltimos 30 dÃ­as

### AutomatizaciÃ³n: WhatsApp Ticket â†’ Sheets + Documento

**Archivo**: `workflow/kestra/flows/whatsapp_ticket_to_sheet_doc.yaml`

**Pasos**:
1. Exponga Kestra y configure el webhook `whatsapp_webhook` como endpoint
2. Provea inputs: `openai_api_key`, `sheets_webhook_url`, `docs_webhook_url`
3. EnvÃ­e una foto de un ticket al WhatsApp configurado

**Funcionalidad**: Extrae proveedor, fecha, total, moneda, items â†’ agrega a Google Sheets â†’ genera documento para contabilidad

### AutomatizaciÃ³n: ProgramaciÃ³n AutomÃ¡tica de Reuniones

**Archivo**: `workflow/kestra/flows/meeting_scheduler_automatic.yaml`

**Pasos**:
1. Exponga Kestra y configure el webhook `meeting_scheduler`
2. Configure inputs: `calendar_api_url`, `calendar_api_token`, `email_api_url`, `email_api_key`
3. Opcional: Configure `database_url`, `slack_webhook_url`, `webhook_secret`
4. EnvÃ­e solicitud de reuniÃ³n via POST al webhook

**Payload de ejemplo**:
```json
{
  "organizer_email": "juan@example.com",
  "attendees": ["maria@example.com", "pedro@example.com"],
  "subject": "ReuniÃ³n de seguimiento Q1",
  "duration_minutes": 30,
  "preferred_date": "2025-02-15",
  "preferred_times": ["14:00", "16:00"]
}
```

**Funcionalidad**:
- âœ… Recibe solicitud de reuniÃ³n â†’ valida datos â†’ verifica disponibilidad
- âœ… Selecciona mejor horario segÃºn preferencias â†’ crea evento en calendario
- âœ… Genera archivo iCal (.ics) â†’ envÃ­a invitaciones con adjunto
- âœ… Programa recordatorios automÃ¡ticos â†’ notifica en Slack (opcional)
- âœ… Persiste reuniÃ³n en base de datos para tracking

**CaracterÃ­sticas principales**:
- Elimina el "ping-pong" de correos para agendar citas
- Soporte multi-calendario (Google Calendar, Outlook, CalDAV)
- DetecciÃ³n automÃ¡tica de conflictos y duplicados
- Buffer time configurable entre reuniones
- Recordatorios automÃ¡ticos personalizables

Ver `workflow/kestra/flows/README_MEETING_SCHEDULER.md` para documentaciÃ³n detallada, ejemplos y troubleshooting.

### Dashboard de KPIs en Tiempo Real (Grafana)

**ConfiguraciÃ³n**:
- Datasource: `observability/grafana/datasources/postgres.yaml`
- Dashboard: `observability/grafana/dashboards/kpi.json`

**KPIs incluidos**:
- Ingresos (1h, 24h), ingresos por hora (24h), pagos/leads recientes
- Leads por prioridad (hoy), conversiÃ³n 7d (leadsâ†’pagos)
- Salud: tasa 5xx de Ingress y reinicios de pods

## ğŸ› ï¸ OperaciÃ³n y Mantenimiento

### Comandos Ãštiles

```bash
# Infraestructura
make tf-init TF_DIR=infra/terraform
make tf-plan TF_DIR=infra/terraform
make tf-apply TF_DIR=infra/terraform
make tf-fmt TF_DIR=infra/terraform
make tf-validate TF_DIR=infra/terraform

# Kubernetes
make k8s-namespaces
make k8s-ingress
make k8s-integration
make k8s-kafka
make k8s-kafka-topics
make k8s-connect

# Helmfile
make helmfile-apply
make helmfile-diff

# Kustomize
make kustomize-dev
make kustomize-stg
make kustomize-prod

# Desarrollo local (Airflow)
make airflow-up
make airflow-down
make airflow-init

# ValidaciÃ³n de cÃ³digo
make py-lint
make py-format
make js-lint
make js-format
make js-typecheck
make all-checks

# Tests
make py-test
make js-test
```

### GestiÃ³n de Recursos

- **LimitRanges y ResourceQuotas**: `security/kubernetes/limitranges-quotas.yaml`
- **Pod Disruption Budgets**: `kubernetes/integration/healthz-pdb.yaml`
- **Horizontal Pod Autoscaler**: `kubernetes/integration/healthz-hpa.yaml`

### Observabilidad

- **MÃ©tricas**: ServiceMonitors en `observability/servicemonitors/`
- **Alertas**: Reglas en `observability/prometheus/alertrules.yaml`
- **Costes**: OpenCost en `observability/opencost/values.yaml`

### Backups

- **Velero**: ConfiguraciÃ³n en `backup/velero/values.yaml`

### Lifecycle de Data Lake

- ConfiguraciÃ³n S3 lifecycle en Terraform (`infra/terraform/main.tf`)

## ğŸ” Seguridad

### External Secrets Operator

GestiÃ³n automÃ¡tica de secretos desde:

- **AWS**: `security/secrets/externalsecrets-aws.yaml` (requiere IRSA/role y ESO instalado)
- **Azure**: `security/secrets/externalsecrets-azure.yaml` (requiere Workload Identity/Key Vault y ESO)

### Certificados TLS

**cert-manager**:
1. Instalar con `helmfile apply`
2. Aplicar `security/cert-manager/clusterissuer.yaml`
3. En el Ingress, usar `cert-manager.io/cluster-issuer: letsencrypt-prod`

### AutenticaciÃ³n OIDC

**oauth2-proxy**:
1. Ajustar `security/oauth2-proxy/values.yaml` con su IdP
2. Desplegar el chart oauth2-proxy
3. Habilitar anotaciones `auth-url`/`auth-signin` en `api-gateway`

### Network Policies

PolÃ­ticas base en `security/networkpolicies/baseline.yaml` (deny-all ingress + DNS egress). AmplÃ­e segÃºn servicios necesarios.

### PolÃ­ticas OPA Gatekeeper

- **Requests/Limits obligatorios**: `security/policies/gatekeeper/limits.yaml`
- **Etiqueta `cost-center` obligatoria**: `security/policies/gatekeeper/cost-center.yaml`
- **Sin imÃ¡genes `latest`**: `security/policies/gatekeeper/no-latest.yaml`

### RBAC

ConfiguraciÃ³n base en `security/kubernetes/rbac-baseline.yaml`.

## ğŸ“š DocumentaciÃ³n Adicional

### DocumentaciÃ³n por Ãrea

- **Ãndice General**: `docs/INDEX.md`
- **Sistema de KPIs**: `docs/KPI_SYSTEM.md` (dashboards, reportes, alertas, mÃ©tricas en tiempo real)
- **Integraciones de AnalÃ­tica**: `data/INTEGRATIONS.md`
- **MLOps**: `ml/kubeflow/README.md`, `ml/training/README.md`
- **Workflows**: `workflow/kestra/`, `workflow/camunda/README_worker.md`
- **RPA**: `rpa/OPENRPA.md`
- **Airflow**: `data/airflow/README.md`, `data/airflow/dags/INDEX_ETL_IMPROVED.md`
- **Employee Onboarding**: `data/airflow/README_onboarding.md` (guÃ­a completa de configuraciÃ³n y uso)
- **Seguridad**: `security/README.md`
- **Grafana**: `observability/grafana/dashboards/README.md`

### Referencias RÃ¡pidas

| Componente | UbicaciÃ³n | DescripciÃ³n |
|------------|-----------|-------------|
| Employee Onboarding (Airflow) | `data/airflow/dags/employee_onboarding.py` | DAG de onboarding con validaciÃ³n robusta e integraciÃ³n HRIS |
| Employee Onboarding (Kestra) | `workflow/kestra/flows/employee_onboarding.yaml` | Flow completo con persistencia PostgreSQL |
| Employee Onboarding (Camunda) | `workflow/camunda/onboarding_employee.bpmn` | BPMN con aprobaciÃ³n de manager |
| Camunda Zeebe Worker | `workflow/camunda/worker/zeebe_worker.py` | Worker que conecta Camunda con Airflow |
| Kestra | `workflow/kestra/deployment.yaml` | OrquestaciÃ³n de workflows |
| Flowable | `workflow/flowable/deployment.yaml` | Motor BPM |
| OpenRPA | `rpa/OPENRPA.md` | AutomatizaciÃ³n RPA |
| Kubeflow | `ml/kubeflow/README.md` | ML pipelines |
| MLflow/KServe | `ml/` | Tracking y serving de modelos |

### CI/CD

- **Terraform PR checks**: `.github/workflows/infra.yaml` (fmt/validate/plan)
- **Deploy manual a K8s**: `.github/workflows/deploy.yaml` (requiere `KUBECONFIG_B64` en secrets)

## ğŸ‘¥ GuÃ­as de Onboarding

### Para Desarrolladores Nuevos

1. **Configurar ambiente local**:
```bash
# Clonar repositorio
git clone <repo-url>
cd IA

# Configurar variables de entorno
cp environments/dev.yaml.example environments/dev.yaml
# Editar con tus valores

# Inicializar Terraform
make tf-init TF_DIR=infra/terraform
```

2. **Ejecutar primeros workflows**:
```bash
# Probar DAG bÃ¡sico
airflow dags test etl_example

# Cargar workflow de Kestra
kubectl apply -f workflow/kestra/flows/leads_manychats_to_hubspot.yaml
```

3. **Leer documentaciÃ³n clave**:
- ETL: `data/airflow/dags/INDEX_ETL_IMPROVED.md`
- Workflows: `workflow/kestra/README.md`
- KPIs: `docs/KPI_SYSTEM.md`

### Para Operaciones

1. **Monitoreo bÃ¡sico**:
```bash
# Ver estado de componentes
kubectl get pods -A

# Ver logs de Airflow
kubectl logs -n airflow deployment/airflow-webserver -f

# Ver mÃ©tricas en Grafana
# Acceder a: http://grafana.your-domain.com
```

2. **Health checks**:
```bash
# Airflow
airflow tasks test etl_example health_check $(date +%Y-%m-%d)

# Kestra
curl http://kestra.your-domain.com/health
```

3. **GestiÃ³n de secretos**:
```bash
# Ver secrets sincronizados
kubectl get externalsecrets -A

# Forzar resincronizaciÃ³n
kubectl delete externalsecret <name> -n <namespace>
```

## ğŸ› Troubleshooting

### Problemas Comunes

#### 1. DAGs de Airflow no se ejecutan

```bash
# Verificar errores de importaciÃ³n
airflow dags list-import-errors

# Verificar variables y conexiones
airflow variables list
airflow connections list

# Verificar estado de scheduler
kubectl logs -n airflow deployment/airflow-scheduler
```

#### 2. Workflows de Kestra fallan

```bash
# Ver logs de ejecuciones
kubectl logs -n workflows deployment/kestra

# Verificar configuraciÃ³n
kubectl get configmap -n workflows

# Verificar webhooks
curl http://kestra.your-domain.com/webhook/<flow-key>
```

#### 2.1. Employee Onboarding falla

```bash
# Verificar logs del DAG de Airflow
kubectl logs -n airflow deployment/airflow-scheduler | grep employee_onboarding

# Verificar progreso guardado en Variables
airflow variables get onboarding_runs:<email>

# Verificar idempotency locks
airflow variables list | grep idemp:employee_onboarding

# Verificar configuraciÃ³n de integraciones
kubectl get configmap -n airflow | grep onboarding
kubectl get secrets -n airflow | grep onboarding

# Probar trigger manual
airflow dags trigger employee_onboarding \
  --conf '{"employee_email":"test@example.com","full_name":"Test User","start_date":"2025-01-01","manager_email":"manager@example.com"}'
```

#### 3. Problemas de conectividad

```bash
# Verificar network policies
kubectl get networkpolicies -A

# Verificar DNS
kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup <service>

# Verificar conectividad a bases de datos
kubectl run -it --rm debug --image=postgres:15 --restart=Never -- psql -h <host> -U <user> -d <db>
```

#### 4. MÃ©tricas no aparecen en Prometheus

```bash
# Verificar ServiceMonitors
kubectl get servicemonitor -A

# Verificar targets en Prometheus UI
# Navegar a: Status â†’ Targets

# Verificar que el servicio expone /metrics
curl http://airflow-scheduler.data.svc.cluster.local/metrics

# Ver logs del Prometheus operator
kubectl logs -n observability -l app.kubernetes.io/name=prometheus-operator
```

#### 5. Logs no aparecen en Kibana

```bash
# Verificar Fluent Bit
kubectl get pods -n observability -l app=fluent-bit
kubectl logs -n observability -l app=fluent-bit

# Verificar Ã­ndices en Elasticsearch
curl http://elasticsearch.observability.svc:9200/_cat/indices

# Verificar configuraciÃ³n de Fluent Bit
kubectl get configmap -n observability fluent-bit-config -o yaml
```

#### 6. Dashboard de Grafana vacÃ­o

```bash
# Verificar datasources
kubectl get configmap -n observability -l grafana_datasource

# Probar query en Prometheus directamente
# En Prometheus UI: probar la query que usa el dashboard

# Verificar que los dashboards estÃ¡n importados
# En Grafana UI: Configuration â†’ Dashboards
```

#### 7. Alertas no se disparan

```bash
# Verificar reglas de alerta
kubectl get prometheusrules -n observability

# Verificar que las mÃ©tricas existen
# En Prometheus UI: ejecutar la query de la alerta

# Verificar Alertmanager
kubectl get pods -n observability -l app=alertmanager
kubectl logs -n observability -l app=alertmanager

# Verificar configuraciÃ³n de notificaciones
kubectl get secret -n observability alertmanager-prometheus-kube-prometheus-alertmanager -o yaml
```

#### 8. Problemas de recursos

```bash
# Ver uso de recursos
kubectl top nodes
kubectl top pods -A

# Ver lÃ­mites y quotas
kubectl describe limitrange -n <namespace>
kubectl describe resourcequota -n <namespace>
```

#### 5. Problemas de secretos

```bash
# Verificar External Secrets
kubectl get externalsecrets -A
kubectl describe externalsecret <name> -n <namespace>

# Verificar sincronizaciÃ³n
kubectl get secrets -n <namespace>

# Forzar resincronizaciÃ³n
kubectl delete externalsecret <name> -n <namespace>
```

## ğŸ“Š MÃ©tricas y Monitoreo

### Stack de Observabilidad Completo

La plataforma incluye una pila completa de observabilidad para monitoreo proactivo y detecciÃ³n de problemas:

#### Prometheus - MÃ©tricas
- **ServiceMonitors configurados** para:
  - Airflow (scheduler y workers)
  - Kestra workflows
  - Camunda y Flowable procesos BPMN
  - APIs y servicios de integraciÃ³n
- **MÃ©tricas recolectadas**:
  - DAG runs (Ã©xitos, fallos, en ejecuciÃ³n)
  - Tareas por estado y duraciÃ³n (percentiles p50, p95, p99)
  - Throughput y latencia
  - Queue lengths y backlog
  - Health checks de componentes

#### Grafana - VisualizaciÃ³n
- **Dashboards principales**:
  - Monitoreo de Automatizaciones: Estado de DAGs, tasa de Ã©xito, duraciÃ³n de tareas
  - KPIs de Negocio: Ingresos, leads, conversiÃ³n
  - APIs HTTP: Requests, latencia, errores
  - ETL Mejorado: MÃ©tricas de pipeline, throughput, calidad de datos
- **Datasources**:
  - Prometheus (mÃ©tricas)
  - PostgreSQL (datos de negocio)
  - Elasticsearch (logs centralizados)
  - Loki (logs recientes)

#### ELK Stack - Logging
- **Elasticsearch**: Almacenamiento de logs con ILM (Index Lifecycle Management)
  - RetenciÃ³n: 30 dÃ­as en hot tier
  - BÃºsqueda rÃ¡pida y analÃ­tica avanzada
- **Kibana**: VisualizaciÃ³n y bÃºsqueda de logs
  - BÃºsqueda por namespace, componente, nivel de log
  - Visualizaciones personalizadas
- **Fluent Bit**: Recolector de logs (DaemonSet)
  - RecolecciÃ³n automÃ¡tica de todos los contenedores
  - Enriquecimiento con metadata de Kubernetes
  - EnvÃ­o a Elasticsearch
- **Logstash**: Procesamiento y transformaciÃ³n de logs (opcional)

#### Alertas Configuradas

Prometheus AlertManager estÃ¡ configurado con alertas crÃ­ticas y de advertencia:

**CrÃ­ticas**:
- `AirflowDagRunFailed`: DAG run fallÃ³
- `AirflowSchedulerLag`: Scheduler no saludable
- `HighErrorRate`: MÃ¡s del 5% de respuestas 5xx
- `PodCrashLooping`: Reinicios repetidos

**Advertencias**:
- `AirflowTaskFailed`: MÃºltiples tareas fallaron
- `HighTaskDuration`: P95 de duraciÃ³n > 30 minutos
- `AutomationQueueBacklog`: >50 DAG runs en cola
- `LowDailyLeads`: Leads diarios bajos
- `LowRevenueVsAvg7d`: Ingresos < 70% del promedio

### Acceso a Observabilidad

```bash
# Prometheus
kubectl port-forward -n observability svc/prometheus-operated 9090:9090
# http://localhost:9090

# Grafana
kubectl port-forward -n observability svc/prometheus-grafana 3000:80
# http://localhost:3000 (admin/admin por defecto)

# Kibana
kubectl port-forward -n observability svc/kibana-kibana 5601:5601
# http://localhost:5601
```

### BÃºsqueda de Logs

**En Kibana**:
```
# Logs de Airflow con errores
kubernetes.namespace_name:data AND automation_type:airflow AND level:ERROR

# Logs de workflows fallidos
automation_type:workflow AND (state:FAILED OR state:ERROR)

# Logs por componente
kubernetes.labels.app:airflow OR kubernetes.labels.app:kestra
```

**En Grafana (Loki)**:
```logql
# Logs estructurados de Airflow
{namespace="data", container="airflow-worker"} | json | status="failed"

# Errores recientes
{namespace="data"} |= "ERROR" | count_over_time(5m)
```

### MÃ©tricas Clave a Monitorear

**Airflow**:
- `airflow_dag_run_status{status="success"}` - DAGs exitosos
- `airflow_dag_run_status{status="failed"}` - DAGs fallidos
- `airflow_task_duration_seconds` - DuraciÃ³n de tareas (histograma)
- `airflow_dag_run_queue_length` - DAGs en cola
- `airflow_scheduler_heartbeat` - Salud del scheduler

**ETL EspecÃ­fico**:
- `etl_example_total_duration_ms` - DuraciÃ³n total del DAG
- `etl_example_throughput_rows_per_sec` - Throughput
- `etl_example_dq_null_rate_exceeded_total` - Fallos de calidad de datos

**Workflows**:
- `kestra_executions_total` - Total de ejecuciones
- `kestra_executions_failed_total` - Ejecuciones fallidas
- `camunda_process_instances_active` - Procesos activos

### Monitoreo Proactivo

1. **Configurar alertas crÃ­ticas**: Integrar con Slack/PagerDuty/Email
2. **Revisar dashboards diariamente**: Detectar tendencias y anomalÃ­as temprano
3. **AnÃ¡lisis de logs**: Buscar patrones de errores recurrentes
4. **OptimizaciÃ³n continua**: Ajustar thresholds y mÃ©tricas segÃºn necesidad

## ğŸ“Š MÃ©tricas y Monitoreo (Legacy)

### Dashboards Disponibles

#### Grafana

- **ETL Dashboard**: MÃ©tricas de pipelines ETL (duraciÃ³n, throughput, errores)
- **KPI Dashboard**: KPIs en tiempo real (revenue, leads, conversiÃ³n)
- **Infrastructure Dashboard**: Uso de recursos, salud de pods, network
- **Cost Dashboard**: AnÃ¡lisis de costes con OpenCost

#### Prometheus

- **MÃ©tricas de Airflow**: Exportadas automÃ¡ticamente
- **MÃ©tricas de Kestra**: Via ServiceMonitor
- **MÃ©tricas personalizadas**: VÃ­a Stats API de Airflow

### Alertas Configuradas

- **SLA Misses**: DAGs que exceden tiempo objetivo
- **Failures**: DAGs con tasa de fallo > 5%
- **Resource Exhaustion**: CPU/Memory > 80%
- **Circuit Breaker Open**: Servicios externos caÃ­dos
- **Rate Limit Hits**: APIs alcanzando lÃ­mites

### Comandos de Monitoreo

```bash
# Ver mÃ©tricas de Prometheus
curl http://prometheus.your-domain.com/api/v1/query?query=etl_dag_success_total

# Exportar mÃ©tricas de Airflow
airflow dags show etl_example | grep metrics

# Ver logs estructurados
kubectl logs -n airflow deployment/airflow-webserver | jq .
```

## ğŸ¯ Mejores PrÃ¡cticas

### Desarrollo

1. **Nunca commitee secretos**: Use External Secrets Operator
2. **Valide antes de aplicar**: 
   ```bash
   make tf-validate
   make kustomize-validate-dev
   ```
3. **Use overlays por entorno**: Separe configuraciones dev/stg/prod
4. **Testing local primero**: 
   ```bash
   make airflow-up  # Levantar Airflow local
   airflow dags test <dag_id>
   ```
5. **Documenta cambios**: Actualiza documentaciÃ³n con cada feature nueva

### Operaciones

1. **Monitoree costes**: Revise OpenCost regularmente
   ```bash
   # Acceder a OpenCost UI
   kubectl port-forward -n opencost service/opencost 9003:9003
   ```
2. **Aplique polÃ­ticas de seguridad**: Habilite Gatekeeper y Network Policies
3. **Backups regulares**: Configure Velero para backups automÃ¡ticos
4. **Mantenga logs estructurados**: Use logging estructurado en todos los componentes
5. **Revise mÃ©tricas semanalmente**: Identifique tendencias y optimizaciones

### Seguridad

1. **Principio de menor privilegio**: RBAC mÃ­nimo necesario
2. **RotaciÃ³n de secretos**: Automatizar rotaciÃ³n cada 90 dÃ­as
3. **Escaneo de imÃ¡genes**: Integrar en CI/CD pipeline
4. **Network Policies**: Aplicar deny-all por defecto
5. **AuditorÃ­a**: Habilitar auditorÃ­a de Kubernetes API

### Performance

1. **Chunking adaptativo**: Usar en pipelines ETL grandes
2. **Rate limiting**: Configurar segÃºn lÃ­mites de APIs externas
3. **Circuit breakers**: Para servicios externos crÃ­ticos
4. **Caching**: Cachear resultados de queries frecuentes
5. **Ãndices de BD**: Mantener Ã­ndices optimizados para queries frecuentes

## ğŸ’» Ejemplos PrÃ¡cticos con CÃ³digo

### Ejemplo 1: Crear un DAG de Airflow Simple

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

def hello_world():
    print("Hello from Airflow!")

with DAG(
    dag_id="mi_primer_dag",
    start_date=datetime(2025, 1, 1),
    schedule="@daily",
    catchup=False,
) as dag:
    task = PythonOperator(
        task_id="hello",
        python_callable=hello_world,
    )
```

**Guardar en**: `data/airflow/dags/mi_primer_dag.py`

### Ejemplo 2: Crear un Workflow de Kestra

```yaml
id: mi_primer_workflow
namespace: workflows

description: Ejemplo bÃ¡sico de workflow

tasks:
  - id: hello
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - echo "Hello from Kestra!"

triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "0 9 * * *"  # Diario a las 9 AM
```

**Guardar en**: `workflow/kestra/flows/mi_primer_workflow.yaml`

### Ejemplo 3: Health Check Endpoint

```python
from flask import Flask, jsonify
import psycopg2
import os

app = Flask(__name__)

@app.route('/health')
def health():
    try:
        # Check DB connection
        conn = psycopg2.connect(
            host=os.getenv('DB_HOST'),
            database=os.getenv('DB_NAME'),
            user=os.getenv('DB_USER'),
            password=os.getenv('DB_PASSWORD'),
            connect_timeout=5
        )
        conn.close()
        return jsonify({"status": "healthy", "database": "connected"}), 200
    except Exception as e:
        return jsonify({"status": "unhealthy", "error": str(e)}), 503

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### Ejemplo 4: Script de Monitoreo Simple

```bash
#!/bin/bash
# monitoreo.sh - Health check bÃ¡sico

# Verificar pods
echo "=== Estado de Pods ==="
kubectl get pods -A | grep -E "(Error|CrashLoop|Pending)"

# Verificar recursos
echo "=== Uso de Recursos ==="
kubectl top nodes

# Verificar servicios
echo "=== Servicios ==="
kubectl get svc -A | grep -E "(Error|Pending)"

# Verificar logs recientes con errores
echo "=== Errores Recientes ==="
kubectl logs -n airflow deployment/airflow-webserver --tail=100 | grep -i error
```

## ğŸ“ˆ Escalabilidad y OptimizaciÃ³n

### CuÃ¡ndo Escalar

| MÃ©trica | Umbral | AcciÃ³n |
|---------|--------|--------|
| CPU promedio > 70% | 5 minutos | Aumentar replicas o recursos |
| Memoria > 80% | 5 minutos | Aumentar lÃ­mites de memoria |
| Latencia p95 > SLA | 10 minutos | Investigar cuello de botella |
| Rate limit hits > 10/hora | Inmediato | Aumentar rate limits o instancias |
| Queue depth > 100 | 15 minutos | Aumentar workers |

### Configurar Auto-Scaling

#### Horizontal Pod Autoscaler (HPA)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: airflow-worker
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: airflow-worker
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### OptimizaciÃ³n de Base de Datos

```sql
-- Ãndices estratÃ©gicos para queries frecuentes
CREATE INDEX CONCURRENTLY idx_events_created_at 
ON etl_improved_events(created_at DESC);

CREATE INDEX CONCURRENTLY idx_events_status_created
ON etl_improved_events(status, created_at DESC)
WHERE status IN ('pending', 'processing');

-- Particionamiento por fecha (para grandes volÃºmenes)
CREATE TABLE etl_events_2025_01 PARTITION OF etl_improved_events
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

-- Vacuum automÃ¡tico (PostgreSQL)
ALTER TABLE etl_improved_events SET (
  autovacuum_vacuum_scale_factor = 0.05,
  autovacuum_analyze_scale_factor = 0.02
);
```

### OptimizaciÃ³n de Chunking ETL

```python
# Calcular chunk size Ã³ptimo basado en memoria disponible
import os

def calculate_optimal_chunk_size(available_memory_mb: int, row_size_kb: float = 1.0) -> int:
    """
    Calcula chunk size Ã³ptimo considerando:
    - Memoria disponible
    - TamaÃ±o promedio de fila
    - Overhead de procesamiento (2x)
    """
    # Dejar 20% de memoria libre
    usable_memory_mb = available_memory_mb * 0.8
    
    # Convertir a KB
    usable_memory_kb = usable_memory_mb * 1024
    
    # Calcular rows posibles (con overhead 2x)
    max_rows = int((usable_memory_kb / row_size_kb) / 2)
    
    # Limitar entre 100 y 10000
    return max(100, min(10000, max_rows))

# Uso
chunk_size = calculate_optimal_chunk_size(
    available_memory_mb=int(os.getenv('MEMORY_LIMIT_MB', '4096'))
)
```

## ğŸ­ Casos de Uso por Industria

### Fintech / Finanzas

**Use Cases**:
- ReconciliaciÃ³n automÃ¡tica de pagos
- DetecciÃ³n de fraude en tiempo real
- Reportes regulatorios automatizados
- Onboarding de clientes KYC/AML

**Componentes Clave**:
- `stripe_reconcile.py`, `bank_reconcile.py`
- `financial_reports.py`
- Circuit breakers para APIs de pagos
- Audit logs completos

### E-commerce / Retail

**Use Cases**:
- SincronizaciÃ³n de inventario
- Procesamiento de Ã³rdenes
- AnÃ¡lisis de comportamiento de clientes
- OptimizaciÃ³n de pricing dinÃ¡mico

**Componentes Clave**:
- ETL pipelines para datos de ventas
- Integraciones con sistemas de inventario
- AnÃ¡lisis con MLflow
- Dashboards de KPIs

### SaaS / B2B

**Use Cases**:
- Onboarding automatizado de clientes
- NutriciÃ³n de leads
- ReconciliaciÃ³n de suscripciones
- Reportes de uso y billing

**Componentes Clave**:
- `outreach_multichannel.py`
- `employee_onboarding.py`
- `invoice_generate.py`
- Workflows de Kestra para integraciones

### Healthcare / Salud

**Use Cases**:
- Procesamiento de claims
- IntegraciÃ³n con sistemas EHR
- Cumplimiento HIPAA
- AnÃ¡lisis de resultados clÃ­nicos

**Componentes Clave**:
- EncriptaciÃ³n end-to-end
- Audit trails completos
- Redundancia y backups
- Network policies estrictas

### Manufacturing / ProducciÃ³n

**Use Cases**:
- Monitoreo de IoT devices
- Mantenimiento predictivo
- OptimizaciÃ³n de supply chain
- Control de calidad automatizado

**Componentes Clave**:
- Kafka para streams de IoT
- ML para predicciÃ³n de fallos
- RPA para procesos repetitivos
- IntegraciÃ³n con sistemas MES/ERP

## ğŸ¥ Health Checks Avanzados

### Health Check Completo de Plataforma

```bash
#!/bin/bash
# platform-health-check.sh

echo "=== Platform Health Check ==="
echo "Fecha: $(date)"
echo ""

# 1. Kubernetes Cluster
echo "1. Kubernetes Cluster"
kubectl cluster-info --request-timeout=5s
if [ $? -eq 0 ]; then
    echo "âœ… Cluster accesible"
else
    echo "âŒ Cluster inaccesible"
    exit 1
fi

# 2. Componentes Principales
echo ""
echo "2. Componentes Principales"
components=("airflow-webserver" "kestra" "prometheus" "grafana")
for comp in "${components[@]}"; do
    if kubectl get deployment -n $(kubectl get namespaces -o name | grep -E "(airflow|workflows|observability)" | cut -d/ -f2) $comp &>/dev/null; then
        replicas=$(kubectl get deployment -n $(kubectl get namespaces -o name | grep -E "(airflow|workflows|observability)" | cut -d/ -f2) $comp -o jsonpath='{.status.readyReplicas}/{.spec.replicas}')
        echo "  âœ… $comp: $replicas replicas listas"
    else
        echo "  âš ï¸  $comp: No encontrado"
    fi
done

# 3. Recursos del Sistema
echo ""
echo "3. Recursos del Sistema"
echo "  CPU:"
kubectl top nodes --no-headers | awk '{print "    " $1 ": " $2 "% CPU, " $4 "% Memory"}'

# 4. Pods con Problemas
echo ""
echo "4. Pods con Problemas"
kubectl get pods -A --field-selector=status.phase!=Running,status.phase!=Succeeded --no-headers | head -5

# 5. Services
echo ""
echo "5. Servicios CrÃ­ticos"
services=("airflow-webserver" "kestra" "prometheus")
for svc in "${services[@]}"; do
    if kubectl get svc -A | grep -q $svc; then
        echo "  âœ… $svc: Disponible"
    else
        echo "  âŒ $svc: No encontrado"
    fi
done

# 6. Base de Datos
echo ""
echo "6. Conectividad de Base de Datos"
if kubectl run -it --rm db-check --image=postgres:15 --restart=Never -- psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "SELECT 1" &>/dev/null; then
    echo "  âœ… Base de datos accesible"
else
    echo "  âŒ Base de datos inaccesible"
fi

echo ""
echo "=== Health Check Completado ==="
```

### Health Check de Airflow

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
import requests
import psycopg2
import os

def check_airflow_api():
    """Verifica que Airflow API responda"""
    try:
        resp = requests.get('http://airflow-webserver:8080/health', timeout=5)
        assert resp.status_code == 200
        print("âœ… Airflow API OK")
    except Exception as e:
        raise Exception(f"âŒ Airflow API error: {e}")

def check_database():
    """Verifica conectividad a base de datos"""
    try:
        conn = psycopg2.connect(
            host=os.getenv('AIRFLOW__DATABASE__SQL_ALCHEMY_CONN').split('@')[1].split('/')[0],
            database=os.getenv('AIRFLOW__DATABASE__SQL_ALCHEMY_CONN').split('/')[-1],
            connect_timeout=5
        )
        conn.close()
        print("âœ… Database OK")
    except Exception as e:
        raise Exception(f"âŒ Database error: {e}")

with DAG(
    'health_check',
    schedule_interval='*/5 * * * *',  # Cada 5 minutos
    start_date=days_ago(1),
    catchup=False,
) as dag:
    check_api = PythonOperator(
        task_id='check_airflow_api',
        python_callable=check_airflow_api,
    )
    
    check_db = PythonOperator(
        task_id='check_database',
        python_callable=check_database,
    )
    
    check_api >> check_db
```

## ğŸ’¾ Backup y Disaster Recovery

### Estrategia de Backup

#### 1. Backups de Base de Datos

```bash
#!/bin/bash
# backup-database.sh

# Backup PostgreSQL
pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME \
    -F c -f /backups/db_$(date +%Y%m%d_%H%M%S).dump

# Backup a S3
aws s3 cp /backups/db_*.dump s3://backup-bucket/database/ --storage-class STANDARD_IA

# RetenciÃ³n: mantener Ãºltimos 30 dÃ­as
find /backups -name "db_*.dump" -mtime +30 -delete
```

#### 2. Backups de Kubernetes con Velero

```bash
# Instalar Velero
velero install \
    --provider aws \
    --bucket velero-backups \
    --secret-file ./credentials-velero

# Backup completo del namespace
velero backup create airflow-backup \
    --include-namespaces airflow \
    --ttl 720h

# Restore
velero restore create --from-backup airflow-backup
```

#### 3. Backup de Configuraciones

```bash
#!/bin/bash
# backup-configs.sh

# Exportar Variables de Airflow
airflow variables export /backups/airflow_vars_$(date +%Y%m%d).json

# Exportar Connections
airflow connections export /backups/airflow_conns_$(date +%Y%m%d).json

# Backup de secrets
kubectl get secrets -A -o yaml > /backups/k8s_secrets_$(date +%Y%m%d).yaml

# Backup a repositorio Git
git add /backups/*
git commit -m "Backup config $(date +%Y%m%d)"
git push
```

### Disaster Recovery Plan

#### RTO/RPO por Componente

| Componente | RTO (Recovery Time Objective) | RPO (Recovery Point Objective) |
|------------|-------------------------------|-------------------------------|
| Airflow DAGs | 1 hora | 24 horas |
| Base de Datos | 30 minutos | 1 hora |
| Configuraciones | 15 minutos | 6 horas |
| Logs y MÃ©tricas | 4 horas | 7 dÃ­as |
| Data Lake | 2 horas | 1 dÃ­a |

#### Procedimiento de RecuperaciÃ³n

```bash
# 1. Evaluar daÃ±o
./platform-health-check.sh > damage-assessment.txt

# 2. Restaurar infraestructura (si necesario)
make tf-apply TF_DIR=infra/terraform

# 3. Restaurar base de datos
pg_restore -h $DB_HOST -U $DB_USER -d $DB_NAME \
    -c /backups/db_latest.dump

# 4. Restaurar configuraciones
airflow variables import /backups/airflow_vars_latest.json
airflow connections import /backups/airflow_conns_latest.json

# 5. Verificar recuperaciÃ³n
./platform-health-check.sh
```

## ğŸš€ Quick Wins (Para Empezar RÃ¡pido)

### En 15 Minutos: Primer Workflow

```bash
# 1. Levantar Kestra local
kubectl apply -f workflow/kestra/deployment.yaml
kubectl port-forward -n workflows service/kestra 8080:8080

# 2. Crear workflow simple (ver Ejemplos PrÃ¡cticos)

# 3. Ejecutar y ver resultados
# Acceder a http://localhost:8080
```

### En 30 Minutos: Primer DAG de Airflow

```bash
# 1. Usar Airflow local
make airflow-up

# 2. Crear DAG (ver Ejemplos PrÃ¡cticos)

# 3. Verificar en UI
# Acceder a http://localhost:8080/admin
```

### En 1 Hora: Pipeline ETL Completo

1. **Configurar base de datos**: Ejecutar `data/db/schema.sql`
2. **Crear DAG**: Copiar `etl_example.py` y adaptar
3. **Configurar variables**: En Airflow UI
4. **Ejecutar**: `airflow dags trigger etl_example`
5. **Ver mÃ©tricas**: En Grafana dashboard

### Primer Mes: Automatizaciones Clave

- âœ… **Semana 1**: Setup bÃ¡sico y primer workflow
- âœ… **Semana 2**: Integrar fuente de datos principal
- âœ… **Semana 3**: Agregar notificaciones y alertas
- âœ… **Semana 4**: Optimizar y documentar

## ğŸ¤ ContribuciÃ³n

### Proceso de ContribuciÃ³n

1. **Fork el repositorio** y clona tu fork
2. **Crea una rama** para tu feature/fix: `git checkout -b feature/mi-feature`
3. **Desarrolla y prueba** tus cambios
4. **Actualiza documentaciÃ³n** si es necesario
5. **Commitea** con mensajes descriptivos
6. **Push y crea Pull Request**

### EstÃ¡ndares de CÃ³digo

- **Python**: Seguir PEP 8, usar type hints
- **TypeScript**: Seguir ESLint config, usar strict mode
- **Terraform**: Ejecutar `terraform fmt` antes de commit
- **Kubernetes**: Validar YAML con `kubectl apply --dry-run`

### Testing

```bash
# Tests de Python
pytest data/airflow/tests/

# Tests de TypeScript
cd web/kpis && npm test
cd web/kpis-next && npm test

# ValidaciÃ³n de Terraform
make tf-validate

# ValidaciÃ³n de Kubernetes
make kustomize-validate-dev
```

### DocumentaciÃ³n

- MantÃ©n READMEs actualizados
- Agrega ejemplos de uso
- Documenta breaking changes
- Actualiza `docs/INDEX.md` si agregas nueva documentaciÃ³n

## ğŸ“š GuÃ­as de Referencia RÃ¡pida

### Comandos Comunes

```bash
# Infraestructura
make tf-init TF_DIR=infra/terraform
make tf-apply TF_DIR=infra/terraform

# Kubernetes
make k8s-namespaces
make k8s-ingress
make k8s-integration

# Airflow
airflow dags list
airflow dags trigger <dag_id>
airflow tasks test <dag_id> <task_id> <execution_date>

# Desarrollo local
make airflow-up  # Levantar Airflow con docker-compose
make airflow-down # Detener
```

### Enlaces Ãštiles

- **DocumentaciÃ³n completa**: `docs/INDEX.md`
- **ETL Mejorado**: `data/airflow/dags/INDEX_ETL_IMPROVED.md`
- **KPIs**: `docs/KPI_SYSTEM.md`
- **Escalabilidad**: `docs/ESCALABILIDAD.md`
- **Integraciones**: `data/INTEGRATIONS.md`

## ğŸ“ Notas Importantes

> âš ï¸ **Importante**: Las plantillas provistas son ejemplos; adapte valores a su organizaciÃ³n y requisitos especÃ­ficos.

### Soporte

- **DocumentaciÃ³n completa**: Ver `docs/INDEX.md` para Ã­ndice general
- **ETL Mejorado**: `data/airflow/dags/INDEX_ETL_IMPROVED.md` (v2.4)
  - âœ… Seguridad avanzada (validaciÃ³n, whitelists, SQL injection prevention)
  - âœ… Escalabilidad detallada (HPA, auto-scaling, optimizaciÃ³n DB)
  - âœ… OptimizaciÃ³n de costos (ROI, tuning, materialized views)
  - âœ… Ejemplos prÃ¡cticos completos
- **Financiero**: `data/airflow/dags/INDEX_FINANCIAL.md`
- **KPIs**: `docs/KPI_SYSTEM.md`
- **Integraciones**: `data/INTEGRATIONS.md`
- **Issues**: Crear issue en el repositorio con label apropiado

### Roadmap

- âœ… Infraestructura multi-cloud (AWS/Azure)
- âœ… OrquestaciÃ³n con Kestra, Flowable, Camunda
- âœ… MLOps completo (MLflow, KServe, Kubeflow)
- âœ… Observabilidad completa (Prometheus, Grafana, ELK Stack, ServiceMonitors)
- âœ… Sistema de KPIs automatizado
- ğŸ”„ Integraciones adicionales (Salesforce, Zendesk)
- ğŸ”„ Dashboard de costos mejorado
- ğŸ”„ Multi-tenancy avanzado

---

**VersiÃ³n**: 0.3.0  
**Ãšltima actualizaciÃ³n**: 2025-01  
**Mantenido por**: platform-team  
**Licencia**: Ver LICENSE file (si aplica)

### Changelog v0.3.0

- âœ… **Observabilidad mejorada**: 
  - ServiceMonitors para todos los componentes (Airflow, Kestra, Camunda, Flowable)
  - Dashboards de Grafana para monitoreo de automatizaciones
  - Alertas avanzadas de Prometheus para detecciÃ³n proactiva de fallos
  - RecolecciÃ³n centralizada de logs con Fluent Bit y ELK Stack
- âœ… **DocumentaciÃ³n mejorada**: 
  - SecciÃ³n completa de observabilidad en README principal
  - GuÃ­as de troubleshooting para mÃ©tricas y logs
  - Ejemplos de bÃºsqueda de logs en Kibana y Grafana
